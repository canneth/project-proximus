
.vsteensy/build/firmware.elf:     file format elf32-littlearm

SYMBOL TABLE:
60000000 l    d  .text.progmem	00000000 .text.progmem
00000000 l    d  .text.itcm	00000000 .text.itcm
00007b10 l    d  .fini	00000000 .fini
00007b14 l    d  .text.itcm.padding	00000000 .text.itcm.padding
20000000 l    d  .data	00000000 .data
20000940 l    d  .bss	00000000 .bss
20200000 l    d  .bss.dma	00000000 .bss.dma
00000000 l    d  .ARM.attributes	00000000 .ARM.attributes
00000000 l    d  .comment	00000000 .comment
00000000 l    d  .debug_info	00000000 .debug_info
00000000 l    d  .debug_abbrev	00000000 .debug_abbrev
00000000 l    d  .debug_line	00000000 .debug_line
00000000 l    d  .debug_frame	00000000 .debug_frame
00000000 l    d  .debug_str	00000000 .debug_str
00000000 l    d  .debug_loc	00000000 .debug_loc
00000000 l    d  .debug_aranges	00000000 .debug_aranges
00000000 l    d  .debug_ranges	00000000 .debug_ranges
00000000 l    df *ABS*	00000000 bootdata.c
00000000 l    df *ABS*	00000000 startup.c
00006db0 l       .text.itcm	00000000 _MSP
00000000 l    df *ABS*	00000000 usb.c
00005b8c l     F .text.itcm	0000005c schedule_transfer
00005be8 l     F .text.itcm	00000036 run_callbacks
00005c20 l     F .text.itcm	000000a4 endpoint0_transmit.constprop.1
00005cc4 l     F .text.itcm	00000698 isr
20000b44 l     O .bss	00000004 endpointN_notify_mask
20000b48 l     O .bss	00000001 sof_usage
20000b54 l     O .bss	00000004 endpoint0_notify_mask
20000b58 l     O .bss	00000001 usb_reboot_timer
20000b60 l     O .bss	00000008 endpoint0_setupdata
20000b68 l     O .bss	00000008 reply_buffer
20000b70 l     O .bss	00000008 endpoint0_buffer
00000000 l    df *ABS*	00000000 analog.c
20000ba8 l     O .bss	00000001 calibrating
00000000 l    df *ABS*	00000000 tempmon.c
20000bac l     O .bss	00000004 s_hotTemp
20000bb0 l     O .bss	00000004 s_hot_ROOM
20000bb4 l     O .bss	00000004 s_roomC_hotC
20000bb8 l     O .bss	00000004 s_hotCount
00000000 l    df *ABS*	00000000 usb_desc.c
600016dc l     O .text.progmem	0000000a qualifier_descriptor
200000b8 l     O .data	00000012 device_descriptor
00000000 l    df *ABS*	00000000 c:/progra~2/arduino/hardware/tools/arm/bin/../lib/gcc/arm-none-eabi/5.4.1/armv7e-m/fpu/fpv5-d16/crti.o
00000000 l    df *ABS*	00000000 c:/progra~2/arduino/hardware/tools/arm/bin/../lib/gcc/arm-none-eabi/5.4.1/armv7e-m/fpu/fpv5-d16/crtn.o
00000000 l    df *ABS*	00000000 crtstuff.c
00000020 l     F .text.itcm	00000000 __do_global_dtors_aux
20000940 l       .bss	00000000 completed.8605
00000044 l     F .text.itcm	00000000 frame_dummy
20000944 l       .bss	00000000 object.8610
60001740 l     O .text.progmem	00000000 __frame_dummy_init_array_entry
00000000 l    df *ABS*	00000000 main.cpp
00002e1c l     F .text.itcm	000006d0 Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]
00000000 l    df *ABS*	00000000 memcpy-armv7m.o
00000000 l    df *ABS*	00000000 usb_serial.c
0000544c l     F .text.itcm	0000006c rx_queue_transfer
000054b8 l     F .text.itcm	000000b4 rx_event
0000556c l     F .text.itcm	00000098 usb_serial_flush_callback
00005604 l     F .text.itcm	0000017c usb_serial_write.part.1
2000096c l     O .bss	00000010 rx_index
2000097c l     O .bss	00000002 tx_packet_size
2000097e l     O .bss	00000001 tx_noautoflush
2000097f l     O .bss	00000001 tx_head
20000980 l     O .bss	00000100 rx_transfer
20000a80 l     O .bss	00000001 rx_tail
20000a84 l     O .bss	00000009 rx_list
20000a8e l     O .bss	00000002 rx_packet_size
20200000 l     O .bss.dma	00001000 rx_buffer
20201000 l     O .bss.dma	00002000 txbuffer
20000a90 l     O .bss	00000010 rx_count
20000aa0 l     O .bss	00000004 rx_available
20000aa4 l     O .bss	00000001 rx_head
20000aa5 l     O .bss	00000001 transmit_previous_timeout
20000aa6 l     O .bss	00000002 tx_available
20000ac0 l     O .bss	00000080 tx_transfer
00000000 l    df *ABS*	00000000 delay.c
00000000 l    df *ABS*	00000000 pwm.c
00000000 l    df *ABS*	00000000 main.cpp
00000000 l    df *ABS*	00000000 yield.cpp
20000b88 l     O .bss	00000001 yield::running
00000000 l    df *ABS*	00000000 EventResponder.cpp
00000000 l    df *ABS*	00000000 usb_inst.cpp
00000000 l    df *ABS*	00000000 Print.cpp
00000000 l    df *ABS*	00000000 new.cpp
00000000 l    df *ABS*	00000000 clockspeed.c
00000000 l    df *ABS*	00000000 nonstd.c
00000000 l    df *ABS*	00000000 HardwareSerial.cpp
00000000 l    df *ABS*	00000000 errno.c
00000000 l    df *ABS*	00000000 init.c
00000000 l    df *ABS*	00000000 malloc.c
00000000 l    df *ABS*	00000000 mallocr.c
00000000 l    df *ABS*	00000000 memset.c
00000000 l    df *ABS*	00000000 mlock.c
00000000 l    df *ABS*	00000000 sbrkr.c
00000000 l    df *ABS*	00000000 mallocr.c
00000000 l    df *ABS*	00000000 impure.c
20000100 l     O .data	00000428 impure_data
00000000 l    df *ABS*	00000000 reent.c
00000000 l    df *ABS*	00000000 
00000000 l       *UND*	00000000 __fini_array_end
00000000 l       *UND*	00000000 __bss_start__
00000000 l       *UND*	00000000 __bss_end__
00000000 l       *UND*	00000000 software_init_hook
00000000 l       *UND*	00000000 __fini_array_start
00000000 l       *UND*	00000000 hardware_init_hook
00000000 l       *UND*	00000000 __libc_fini
00000000 l       *UND*	00000000 __stack
600016f8 l     F .text.progmem	00000008 __startup_early_hook_veneer
60001700 l     F .text.progmem	00000008 __usb_init_serialnumber_veneer
60001708 l     F .text.progmem	00000008 __main_veneer
60001710 l     F .text.progmem	00000008 ____libc_init_array_veneer
60001718 l     F .text.progmem	00000008 __memset_veneer
60001720 l     F .text.progmem	00000008 __set_arm_clock_veneer
60001728 l     F .text.progmem	00000008 __startup_late_hook_veneer
60001730 l     F .text.progmem	00000008 __pwm_init_veneer
60001738 l     F .text.progmem	00000008 __delay_veneer
00007b00 l     F .text.itcm	00000008 ___init_veneer
000059bc g     F .text.itcm	0000000c usb_serial_available
00006dbc g     F .text.itcm	00000002 startup_default_late_hook
00006894  w    F .text.itcm	000000a0 yield
20000b4c g     O .bss	00000004 usb_timer1_callback
60001638 g     O .text.progmem	00000018 usb_string_manufacturer_name_default
20000bbc g     O .bss	0000001c HardwareSerial::serial_event_handler_checks
00006b6c g     F .text.itcm	00000020 Print::println()
00007868 g     F .text.itcm	00000002 __malloc_unlock
600014ac g     F .text.progmem	00000058 analog_init
00002844  w    F .text.itcm	000005d8 Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)
200000fc g     O .data	00000004 F_CPU_ACTUAL
000071b4 g     F .text.itcm	00000028 HardwareSerial::processSerialEvents()
00006a80 g     F .text.itcm	00000098 MillisTimer::runFromTimer()
20000ba0 g     O .bss	00000001 EventResponder::runningFromYield
000071dc g     F .text.itcm	0000000c __errno
60001000 g     O .text.progmem	00000020 ImageVectorTable
20000b8c g     O .bss	00000004 EventResponder::firstInterrupt
000064a4 g     F .text.itcm	00000004 usb_transfer_status
200000e2 g     O .data	00000001 usb_enable_serial_event_processing
00006b50  w    F .text.itcm	00000008 usb_serial_class::write(unsigned char const*, unsigned int)
200026c0 g     O .bss	00000004 errno
00007b10 g       .text.itcm	00000000 _etext
20000940 g       .bss	00000000 _sbss
60001750 g       *ABS*	00000000 _stextload
000034ec g     F .text.itcm	00001e2c loop
0000635c g     F .text.itcm	00000064 usb_config_rx
00006a18 g     F .text.itcm	00000068 MillisTimer::addToActiveList()
20000b90 g     O .bss	00000004 EventResponder::lastInterrupt
00005318 g     F .text.itcm	00000134 memcpy
0000146c  w    F .text.itcm	0000031e Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)
20000b84 g     O .bss	00000004 systick_millis_count
20000b78 g     O .bss	00000001 usb_configuration
60000000 g     O .text.progmem	00000200 FlexSPI_NOR_Config
60001638  w    O .text.progmem	00000018 usb_string_manufacturer_name
00007238 g     F .text.itcm	00000010 malloc
000069b4  w    F .text.itcm	0000001c EventResponder::triggerEvent(int, void*)
6000129c g     F .text.progmem	000000ec usb_init
20000be4 g     O .bss	00000004 __malloc_top_pad
20002280 g     O .bss	00000004 systick_safe_read
aaaaaaab g       *ABS*	00000000 _flexram_bank_config
20000000 g       .data	00000000 _sdata
60001698 g     O .text.progmem	00000043 usb_config_descriptor_480
0000786c g     F .text.itcm	00000024 _sbrk_r
00006db8 g     F .text.itcm	00000002 startup_default_early_hook
60001034 g     F .text.progmem	00000268 ResetHandler
00005a3c g     F .text.itcm	00000020 usb_serial_getchar
20000960  w    O .bss	0000000c Eigen::internal::manage_caching_sizes(Eigen::Action, int*, int*, int*)::m_cacheSizes
20000c10 g     O .bss	00000008 usb_cdc_line_coding
20000b98 g     O .bss	00000004 EventResponder::lastYield
0000201c  w    F .text.itcm	00000310 void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)
20000be0 g     O .bss	00000004 __malloc_max_sbrked_mem
00006c28 g     F .text.itcm	00000174 Print::printFloat(double, unsigned char)
20280000 g       .bss.dma	00000000 _heap_end
20000b9c g     O .bss	00000004 EventResponder::firstYield
000071e8 g     F .text.itcm	00000050 __libc_init_array
00006dc0  w    F .text.itcm	0000008c HardFault_HandlerC
00006b38  w    F .text.itcm	00000004 usb_serial_class::clear()
00006e4c g     F .text.itcm	00000030 _sbrk
60009264 g       *ABS*	00000000 _sdataload
20000ba4 g     O .bss	00000004 MillisTimer::listWaiting
200000f4 g     O .data	00000004 __brkval
20000aa8 g     O .bss	00000001 usb_cdc_line_rtsdtr
600016e8 g     F .text.progmem	00000000 _init
00005780 g     F .text.itcm	00000002 usb_serial_reset
00000550  w    F .text.itcm	000000a6 Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)
60001654 g     O .text.progmem	00000043 usb_config_descriptor_12
20002700 g       .bss	00000000 _ebss
00002674  w    F .text.itcm	000001d0 Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()
20203050 g       .bss.dma	00000000 _heap_start
00000001 g       *ABS*	00000000 _itcm_block_count
20001000 g     O .bss	00000020 endpoint0_transfer_data
00006574 g     F .text.itcm	000002b8 pwm_init
60001448 g     F .text.progmem	00000064 usb_pll_start
6000102c g     O .text.progmem	00000008 vector_table
00000000  w      *UND*	00000000 __deregister_frame_info
20001020 g     O .bss	00000020 endpoint0_transfer_ack
20000c18 g     O .bss	00000004 usb_cdc_line_rtsdtr_millis
00006458 g     F .text.itcm	00000028 usb_transmit
00006b18 g     F .text.itcm	00000020 systick_isr
200000e4 g     O .data	00000010 Serial
20000bd8 g     O .bss	00000001 HardwareSerial::serial_event_handlers_active
00006b58  w    F .text.itcm	00000006 usb_serial_class::write(unsigned char)
00006db8  w    F .text.itcm	00000002 startup_early_hook
00005978 g     F .text.itcm	00000044 usb_serial_peekchar
00006e7c g     F .text.itcm	000002c4 set_arm_clock
20000b7c g     O .bss	00000004 systick_cycle_count
200000cc g     O .data	00000016 usb_string_serial_number_default
0000792c g     F .text.itcm	000001d0 _free_r
00006b48  w    F .text.itcm	00000004 usb_serial_class::flush()
20000938 g     O .data	00000004 __malloc_sbrk_base
00006b40  w    F .text.itcm	00000004 usb_serial_class::read()
000006e4  w    F .text.itcm	000009cc Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)
00006428 g     F .text.itcm	0000002e usb_prepare_transfer
00006da0 g     F .text.itcm	00000018 unused_interrupt_vector
60001504 g     F .text.progmem	0000011c tempmon_init
20000b40 g     O .bss	00000004 usb_timer0_callback
00006b60  w    F .text.itcm	0000000c serialEvent()
000059c8 g     F .text.itcm	00000074 usb_serial_flush_input
00005a5c g     F .text.itcm	0000002c usb_serial_putchar
00000024 g       *ABS*	00000000 _teensy_model_identifier
20000be8 g     O .bss	00000028 __malloc_current_mallinfo
20000080  w    O .data	00000028 vtable for usb_serial_class
20000b80 g     O .bss	00000004 scale_cpu_cycles_to_microseconds
20000b94 g     O .bss	00000004 MillisTimer::listActive
2000052c g     O .data	00000408 __malloc_av_
00005aec g     F .text.itcm	000000a0 usb_serial_flush_output
00007864 g     F .text.itcm	00000002 __malloc_lock
20002400 g     O .bss	000002c0 _VectorsRam
0000178c  w    F .text.itcm	000001e6 Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)
20000b50 g     O .bss	00000001 usb_high_speed
000077c8 g     F .text.itcm	0000009a memset
00006884 g     F .text.itcm	00000010 main
20000bdc g     O .bss	00000004 __malloc_max_total_mem
20203000 g     O .bss.dma	00000043 usb_descriptor_buffer
0000682c g     F .text.itcm	00000058 usb_init_serialnumber
60001744 g       .text.progmem	00000000 __init_array_end
00007258 g     F .text.itcm	00000570 _malloc_r
00006934 g     F .text.itcm	00000080 EventResponder::triggerEventNotImmediate()
00000031 g       *ABS*	00000000 __rtc_localtime
00007890 g     F .text.itcm	0000009c _malloc_trim_r
60001650 g     O .text.progmem	00000004 string0
00005a88 g     F .text.itcm	00000018 usb_serial_write
00006dbc  w    F .text.itcm	00000002 startup_late_hook
000005f8  w    F .text.itcm	000000ec Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)
00006b44  w    F .text.itcm	00000004 usb_serial_class::available()
000001b0  w    F .text.itcm	00000310 void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)
0000232c  w    F .text.itcm	00000346 Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)
20002000 g     O .bss	00000280 endpoint_queue_head
60001620  w    O .text.progmem	00000016 usb_string_product_name
000064a8 g     F .text.itcm	000000cc delay
00007b10 g     F .fini	00000000 _fini
60001020 g     O .text.progmem	0000000c BootData
00006c0c g     F .text.itcm	00000016 Print::print(long)
00007190 g     F .text.itcm	00000024 Panic_Temp_isr
20000528 g     O .data	00000004 _impure_ptr
60001740 g       .text.progmem	00000000 __preinit_array_end
00000080 g     F .text.itcm	000000a0 print_mtxf(Eigen::Matrix<float, -1, -1, 0, -1, -1> const&)
0000007c g     F .text.itcm	00000002 setup
20000014 g     O .data	0000006c usb_descriptor_list
20078000 g       .bss.dma	00000000 _estack
00005aa0 g     F .text.itcm	0000004c usb_serial_write_buffer_free
00005784 g     F .text.itcm	00000108 usb_serial_configure
20000940 g       .data	00000000 _edata
00001a8c  w    F .text.itcm	00000590 Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)
00000120  w    F .text.itcm	00000090 Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)
00006b4c  w    F .text.itcm	00000004 usb_serial_class::availableForWrite()
00007140 g     F .text.itcm	0000004e ultoa
00006d9c g     F .text.itcm	00000004 operator new(unsigned int)
000069d0 g     F .text.itcm	00000044 EventResponder::runFromInterrupt()
20000934 g     O .data	00000004 __malloc_trim_threshold
00006b3c  w    F .text.itcm	00000004 usb_serial_class::peek()
00001974  w    F .text.itcm	00000118 Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)
000004c0  w    F .text.itcm	00000090 Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)
000013b4  w    F .text.itcm	000000b6 Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)
60001740 g       .text.progmem	00000000 __init_array_start
200000f8 g     O .data	00000004 F_BUS_ACTUAL
000010b0  w    F .text.itcm	00000304 Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)
00000000 g       .text.itcm	00000000 _stext
60001620 g     O .text.progmem	00000016 usb_string_product_name_default
60001388 g     F .text.progmem	000000c0 configure_cache
00000000  w      *UND*	00000000 _Jv_RegisterClasses
60001740 g       .text.progmem	00000000 __preinit_array_start
00006480 g     F .text.itcm	00000024 usb_receive
00009ba0 g       *ABS*	00000000 _flashimagelen
00000000  w      *UND*	00000000 __register_frame_info
00006a14 g     F .text.itcm	00000004 pendablesrvreq_isr
2000095c  w    O .bss	00000004 guard variable for Eigen::internal::manage_caching_sizes(Eigen::Action, int*, int*, int*)::m_cacheSizes
0000588c g     F .text.itcm	000000ec usb_serial_read
00006b8c g     F .text.itcm	0000007e Print::printNumber(unsigned long, unsigned char, unsigned char)
000063c0 g     F .text.itcm	00000068 usb_config_tx
00007248 g     F .text.itcm	00000010 free
200000cc  w    O .data	00000016 usb_string_serial_number



Disassembly of section .text.progmem:

60000000 <FlexSPI_NOR_Config>:
60000000:	FCFB...V........
	...
60000044:	.............. .
	...
60000080:	.....2.&........
60000090:	...$............
	...
600000b0:	................
	...
600000d0:	 ...............
	...
60000100:	................
60000110:	..... ..........
	...
60000130:	`...............
	...
600001c0:	................
600001d0:	................
	...
60000200:	................
60000210:	................
60000220:	................
60000230:	................
60000240:	................
60000250:	................
60000260:	................
60000270:	................
60000280:	................
60000290:	................
600002a0:	................
600002b0:	................
600002c0:	................
600002d0:	................
600002e0:	................
600002f0:	................
60000300:	................
60000310:	................
60000320:	................
60000330:	................
60000340:	................
60000350:	................
60000360:	................
60000370:	................
60000380:	................
60000390:	................
600003a0:	................
600003b0:	................
600003c0:	................
600003d0:	................
600003e0:	................
600003f0:	................
60000400:	................
60000410:	................
60000420:	................
60000430:	................
60000440:	................
60000450:	................
60000460:	................
60000470:	................
60000480:	................
60000490:	................
600004a0:	................
600004b0:	................
600004c0:	................
600004d0:	................
600004e0:	................
600004f0:	................
60000500:	................
60000510:	................
60000520:	................
60000530:	................
60000540:	................
60000550:	................
60000560:	................
60000570:	................
60000580:	................
60000590:	................
600005a0:	................
600005b0:	................
600005c0:	................
600005d0:	................
600005e0:	................
600005f0:	................
60000600:	................
60000610:	................
60000620:	................
60000630:	................
60000640:	................
60000650:	................
60000660:	................
60000670:	................
60000680:	................
60000690:	................
600006a0:	................
600006b0:	................
600006c0:	................
600006d0:	................
600006e0:	................
600006f0:	................
60000700:	................
60000710:	................
60000720:	................
60000730:	................
60000740:	................
60000750:	................
60000760:	................
60000770:	................
60000780:	................
60000790:	................
600007a0:	................
600007b0:	................
600007c0:	................
600007d0:	................
600007e0:	................
600007f0:	................
60000800:	................
60000810:	................
60000820:	................
60000830:	................
60000840:	................
60000850:	................
60000860:	................
60000870:	................
60000880:	................
60000890:	................
600008a0:	................
600008b0:	................
600008c0:	................
600008d0:	................
600008e0:	................
600008f0:	................
60000900:	................
60000910:	................
60000920:	................
60000930:	................
60000940:	................
60000950:	................
60000960:	................
60000970:	................
60000980:	................
60000990:	................
600009a0:	................
600009b0:	................
600009c0:	................
600009d0:	................
600009e0:	................
600009f0:	................
60000a00:	................
60000a10:	................
60000a20:	................
60000a30:	................
60000a40:	................
60000a50:	................
60000a60:	................
60000a70:	................
60000a80:	................
60000a90:	................
60000aa0:	................
60000ab0:	................
60000ac0:	................
60000ad0:	................
60000ae0:	................
60000af0:	................
60000b00:	................
60000b10:	................
60000b20:	................
60000b30:	................
60000b40:	................
60000b50:	................
60000b60:	................
60000b70:	................
60000b80:	................
60000b90:	................
60000ba0:	................
60000bb0:	................
60000bc0:	................
60000bd0:	................
60000be0:	................
60000bf0:	................
60000c00:	................
60000c10:	................
60000c20:	................
60000c30:	................
60000c40:	................
60000c50:	................
60000c60:	................
60000c70:	................
60000c80:	................
60000c90:	................
60000ca0:	................
60000cb0:	................
60000cc0:	................
60000cd0:	................
60000ce0:	................
60000cf0:	................
60000d00:	................
60000d10:	................
60000d20:	................
60000d30:	................
60000d40:	................
60000d50:	................
60000d60:	................
60000d70:	................
60000d80:	................
60000d90:	................
60000da0:	................
60000db0:	................
60000dc0:	................
60000dd0:	................
60000de0:	................
60000df0:	................
60000e00:	................
60000e10:	................
60000e20:	................
60000e30:	................
60000e40:	................
60000e50:	................
60000e60:	................
60000e70:	................
60000e80:	................
60000e90:	................
60000ea0:	................
60000eb0:	................
60000ec0:	................
60000ed0:	................
60000ee0:	................
60000ef0:	................
60000f00:	................
60000f10:	................
60000f20:	................
60000f30:	................
60000f40:	................
60000f50:	................
60000f60:	................
60000f70:	................
60000f80:	................
60000f90:	................
60000fa0:	................
60000fb0:	................
60000fc0:	................
60000fd0:	................
60000fe0:	................
60000ff0:	................

60001000 <ImageVectorTable>:
60001000:	.. @,..`........
60001010:	 ..`...`........

60001020 <BootData>:
60001020:	...`........

6000102c <vector_table>:
6000102c:	... 5..`

60001034 <ResetHandler>:
void ResetHandler(void)
{
	unsigned int i;

#if defined(__IMXRT1062__)
	IOMUXC_GPR_GPR17 = (uint32_t)&_flexram_bank_config;
60001034:	ldr	r3, [pc, #464]	; (60001208 <ResetHandler+0x1d4>)
	IOMUXC_GPR_GPR16 = 0x00200007;
	IOMUXC_GPR_GPR14 = 0x00AA0000;
60001036:	mov.w	r1, #11141120	; 0xaa0000
void ResetHandler(void)
{
	unsigned int i;

#if defined(__IMXRT1062__)
	IOMUXC_GPR_GPR17 = (uint32_t)&_flexram_bank_config;
6000103a:	ldr	r2, [pc, #464]	; (6000120c <ResetHandler+0x1d8>)
	IOMUXC_GPR_GPR16 = 0x00200007;
6000103c:	ldr	r0, [pc, #464]	; (60001210 <ResetHandler+0x1dc>)
void ResetHandler(void)
{
	unsigned int i;

#if defined(__IMXRT1062__)
	IOMUXC_GPR_GPR17 = (uint32_t)&_flexram_bank_config;
6000103e:	str	r2, [r3, #68]	; 0x44
	IOMUXC_GPR_GPR16 = 0x00200007;
60001040:	str	r0, [r3, #64]	; 0x40
	IOMUXC_GPR_GPR14 = 0x00AA0000;
	__asm__ volatile("mov sp, %0" : : "r" ((uint32_t)&_estack) : );
60001042:	ldr	r2, [pc, #464]	; (60001214 <ResetHandler+0x1e0>)
	unsigned int i;

#if defined(__IMXRT1062__)
	IOMUXC_GPR_GPR17 = (uint32_t)&_flexram_bank_config;
	IOMUXC_GPR_GPR16 = 0x00200007;
	IOMUXC_GPR_GPR14 = 0x00AA0000;
60001044:	str	r1, [r3, #56]	; 0x38
	__asm__ volatile("mov sp, %0" : : "r" ((uint32_t)&_estack) : );
60001046:	mov	sp, r2
}

__attribute__((section(".startup"), optimize("no-tree-loop-distribute-patterns")))
static void memory_copy(uint32_t *dest, const uint32_t *src, uint32_t *dest_end)
{
	if (dest == src) return;
60001048:	ldr	r2, [pc, #460]	; (60001218 <ResetHandler+0x1e4>)
6000104a:	ldr	r1, [pc, #464]	; (6000121c <ResetHandler+0x1e8>)
6000104c:	cmp	r2, r1
6000104e:	beq.n	60001070 <ResetHandler+0x3c>
	while (dest < dest_end) {
60001050:	ldr	r3, [pc, #460]	; (60001220 <ResetHandler+0x1ec>)
60001052:	cmp	r2, r3
60001054:	bcs.n	60001070 <ResetHandler+0x3c>
60001056:	mvns	r4, r2
60001058:	mov	r0, r1
6000105a:	add	r3, r4
6000105c:	bic.w	r3, r3, #3
60001060:	adds	r3, #4
60001062:	add	r3, r1
		*dest++ = *src++;
60001064:	ldr.w	r1, [r0], #4

__attribute__((section(".startup"), optimize("no-tree-loop-distribute-patterns")))
static void memory_copy(uint32_t *dest, const uint32_t *src, uint32_t *dest_end)
{
	if (dest == src) return;
	while (dest < dest_end) {
60001068:	cmp	r0, r3
		*dest++ = *src++;
6000106a:	str.w	r1, [r2], #4

__attribute__((section(".startup"), optimize("no-tree-loop-distribute-patterns")))
static void memory_copy(uint32_t *dest, const uint32_t *src, uint32_t *dest_end)
{
	if (dest == src) return;
	while (dest < dest_end) {
6000106e:	bne.n	60001064 <ResetHandler+0x30>
}

__attribute__((section(".startup"), optimize("no-tree-loop-distribute-patterns")))
static void memory_copy(uint32_t *dest, const uint32_t *src, uint32_t *dest_end)
{
	if (dest == src) return;
60001070:	ldr	r2, [pc, #432]	; (60001224 <ResetHandler+0x1f0>)
60001072:	ldr	r1, [pc, #436]	; (60001228 <ResetHandler+0x1f4>)
60001074:	cmp	r2, r1
60001076:	beq.n	60001098 <ResetHandler+0x64>
	while (dest < dest_end) {
60001078:	ldr	r3, [pc, #432]	; (6000122c <ResetHandler+0x1f8>)
6000107a:	cmp	r2, r3
6000107c:	bcs.n	60001098 <ResetHandler+0x64>
6000107e:	mvns	r4, r2
60001080:	mov	r0, r1
60001082:	add	r3, r4
60001084:	bic.w	r3, r3, #3
60001088:	adds	r3, #4
6000108a:	add	r3, r1
		*dest++ = *src++;
6000108c:	ldr.w	r1, [r0], #4

__attribute__((section(".startup"), optimize("no-tree-loop-distribute-patterns")))
static void memory_copy(uint32_t *dest, const uint32_t *src, uint32_t *dest_end)
{
	if (dest == src) return;
	while (dest < dest_end) {
60001090:	cmp	r0, r3
		*dest++ = *src++;
60001092:	str.w	r1, [r2], #4

__attribute__((section(".startup"), optimize("no-tree-loop-distribute-patterns")))
static void memory_copy(uint32_t *dest, const uint32_t *src, uint32_t *dest_end)
{
	if (dest == src) return;
	while (dest < dest_end) {
60001096:	bne.n	6000108c <ResetHandler+0x58>
}

__attribute__((section(".startup"), optimize("no-tree-loop-distribute-patterns")))
static void memory_clear(uint32_t *dest, uint32_t *dest_end)
{
	while (dest < dest_end) {
60001098:	ldr	r2, [pc, #404]	; (60001230 <ResetHandler+0x1fc>)
6000109a:	ldr	r3, [pc, #408]	; (60001234 <ResetHandler+0x200>)
6000109c:	cmp	r2, r3
6000109e:	bcs.n	600010b8 <ResetHandler+0x84>
600010a0:	mvns	r0, r2
600010a2:	mov	r1, r2
		*dest++ = 0;
600010a4:	movs	r4, #0
600010a6:	add	r3, r0
600010a8:	bic.w	r3, r3, #3
600010ac:	adds	r3, #4
600010ae:	add	r3, r2
600010b0:	str.w	r4, [r1], #4
}

__attribute__((section(".startup"), optimize("no-tree-loop-distribute-patterns")))
static void memory_clear(uint32_t *dest, uint32_t *dest_end)
{
	while (dest < dest_end) {
600010b4:	cmp	r3, r1
600010b6:	bne.n	600010b0 <ResetHandler+0x7c>
	memory_copy(&_stext, &_stextload, &_etext);
	memory_copy(&_sdata, &_sdataload, &_edata);
	memory_clear(&_sbss, &_ebss);

	// enable FPU
	SCB_CPACR = 0x00F00000;
600010b8:	ldr	r2, [pc, #380]	; (60001238 <ResetHandler+0x204>)
600010ba:	mov.w	r1, #15728640	; 0xf00000
600010be:	ldr	r3, [pc, #380]	; (6000123c <ResetHandler+0x208>)
600010c0:	str	r1, [r2, #0]
600010c2:	add.w	r1, r3, #704	; 0x2c0
600010c6:	ldr	r2, [pc, #376]	; (60001240 <ResetHandler+0x20c>)

	// set up blank interrupt & exception vector table
	for (i=0; i < NVIC_NUM_INTERRUPTS + 16; i++) _VectorsRam[i] = &unused_interrupt_vector;
600010c8:	str.w	r2, [r3, #4]!
600010cc:	cmp	r1, r3
600010ce:	bne.n	600010c8 <ResetHandler+0x94>
600010d0:	ldr	r3, [pc, #368]	; (60001244 <ResetHandler+0x210>)
	for (i=0; i < NVIC_NUM_INTERRUPTS; i++) NVIC_SET_PRIORITY(i, 128);
600010d2:	movs	r1, #128	; 0x80
600010d4:	ldr	r2, [pc, #368]	; (60001248 <ResetHandler+0x214>)
600010d6:	strb.w	r1, [r3], #1
600010da:	cmp	r3, r2
600010dc:	bne.n	600010d6 <ResetHandler+0xa2>
}

FLASHMEM void reset_PFD()
{	
	//Reset PLL2 PFDs, set default frequencies:
	CCM_ANALOG_PFD_528_SET = (1 << 31) | (1 << 23) | (1 << 15) | (1 << 7);
600010de:	ldr	r4, [pc, #364]	; (6000124c <ResetHandler+0x218>)
600010e0:	mov.w	r7, #2155905152	; 0x80808080
	reset_PFD();
	
	// Configure clocks
	// TODO: make sure all affected peripherals are turned off!
	// PIT & GPT timers to run from 24 MHz clock (independent of CPU speed)
	CCM_CSCMR1 = (CCM_CSCMR1 & ~CCM_CSCMR1_PERCLK_PODF(0x3F)) | CCM_CSCMR1_PERCLK_CLK_SEL;
600010e4:	ldr	r6, [pc, #360]	; (60001250 <ResetHandler+0x21c>)
	// UARTs run from 24 MHz clock (works if PLL3 off or bypassed)
	CCM_CSCDR1 = (CCM_CSCDR1 & ~CCM_CSCDR1_UART_CLK_PODF(0x3F)) | CCM_CSCDR1_UART_CLK_SEL;

#if defined(__IMXRT1062__)
	// Use fast GPIO6, GPIO7, GPIO8, GPIO9
	IOMUXC_GPR_GPR26 = 0xFFFFFFFF;
600010e6:	mov.w	r2, #4294967295
	SCB_CPACR = 0x00F00000;

	// set up blank interrupt & exception vector table
	for (i=0; i < NVIC_NUM_INTERRUPTS + 16; i++) _VectorsRam[i] = &unused_interrupt_vector;
	for (i=0; i < NVIC_NUM_INTERRUPTS; i++) NVIC_SET_PRIORITY(i, 128);
	SCB_VTOR = (uint32_t)_VectorsRam;
600010ea:	ldr.w	sl, [pc, #420]	; 60001290 <ResetHandler+0x25c>
static void configure_systick(void)
{
	_VectorsRam[14] = pendablesrvreq_isr;
	_VectorsRam[15] = systick_isr;
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
	SYST_CVR = 0;
600010ee:	movs	r5, #0

FLASHMEM void reset_PFD()
{	
	//Reset PLL2 PFDs, set default frequencies:
	CCM_ANALOG_PFD_528_SET = (1 << 31) | (1 << 23) | (1 << 15) | (1 << 7);
	CCM_ANALOG_PFD_528 = 0x2018101B; // PFD0:352, PFD1:594, PFD2:396, PFD3:297 MHz 	
600010f0:	ldr.w	r9, [pc, #416]	; 60001294 <ResetHandler+0x260>
	//PLL3:
	CCM_ANALOG_PFD_480_SET = (1 << 31) | (1 << 23) | (1 << 15) | (1 << 7);	
	CCM_ANALOG_PFD_480 = 0x13110D0C; // PFD0:720, PFD1:664, PFD2:508, PFD3:454 MHz
600010f4:	ldr.w	r8, [pc, #416]	; 60001298 <ResetHandler+0x264>
	SCB_CPACR = 0x00F00000;

	// set up blank interrupt & exception vector table
	for (i=0; i < NVIC_NUM_INTERRUPTS + 16; i++) _VectorsRam[i] = &unused_interrupt_vector;
	for (i=0; i < NVIC_NUM_INTERRUPTS; i++) NVIC_SET_PRIORITY(i, 128);
	SCB_VTOR = (uint32_t)_VectorsRam;
600010f8:	ldr	r3, [pc, #344]	; (60001254 <ResetHandler+0x220>)
	// UARTs run from 24 MHz clock (works if PLL3 off or bypassed)
	CCM_CSCDR1 = (CCM_CSCDR1 & ~CCM_CSCDR1_UART_CLK_PODF(0x3F)) | CCM_CSCDR1_UART_CLK_SEL;

#if defined(__IMXRT1062__)
	// Use fast GPIO6, GPIO7, GPIO8, GPIO9
	IOMUXC_GPR_GPR26 = 0xFFFFFFFF;
600010fa:	ldr	r1, [pc, #268]	; (60001208 <ResetHandler+0x1d4>)
	SCB_CPACR = 0x00F00000;

	// set up blank interrupt & exception vector table
	for (i=0; i < NVIC_NUM_INTERRUPTS + 16; i++) _VectorsRam[i] = &unused_interrupt_vector;
	for (i=0; i < NVIC_NUM_INTERRUPTS; i++) NVIC_SET_PRIORITY(i, 128);
	SCB_VTOR = (uint32_t)_VectorsRam;
600010fc:	str.w	sl, [r3]
}

FLASHMEM void reset_PFD()
{	
	//Reset PLL2 PFDs, set default frequencies:
	CCM_ANALOG_PFD_528_SET = (1 << 31) | (1 << 23) | (1 << 15) | (1 << 7);
60001100:	str.w	r7, [r4, #260]	; 0x104
	CCM_ANALOG_PFD_528 = 0x2018101B; // PFD0:352, PFD1:594, PFD2:396, PFD3:297 MHz 	
60001104:	str.w	r9, [r4, #256]	; 0x100
	//PLL3:
	CCM_ANALOG_PFD_480_SET = (1 << 31) | (1 << 23) | (1 << 15) | (1 << 7);	
60001108:	str.w	r7, [r4, #244]	; 0xf4
	CCM_ANALOG_PFD_480 = 0x13110D0C; // PFD0:720, PFD1:664, PFD2:508, PFD3:454 MHz
6000110c:	str.w	r8, [r4, #240]	; 0xf0
	reset_PFD();
	
	// Configure clocks
	// TODO: make sure all affected peripherals are turned off!
	// PIT & GPT timers to run from 24 MHz clock (independent of CPU speed)
	CCM_CSCMR1 = (CCM_CSCMR1 & ~CCM_CSCMR1_PERCLK_PODF(0x3F)) | CCM_CSCMR1_PERCLK_CLK_SEL;
60001110:	ldr	r3, [r6, #28]
60001112:	bic.w	r3, r3, #127	; 0x7f
60001116:	orr.w	r3, r3, #64	; 0x40
6000111a:	str	r3, [r6, #28]
	// UARTs run from 24 MHz clock (works if PLL3 off or bypassed)
	CCM_CSCDR1 = (CCM_CSCDR1 & ~CCM_CSCDR1_UART_CLK_PODF(0x3F)) | CCM_CSCDR1_UART_CLK_SEL;
6000111c:	ldr	r3, [r6, #36]	; 0x24
6000111e:	bic.w	r3, r3, #127	; 0x7f
60001122:	orr.w	r3, r3, #64	; 0x40
60001126:	str	r3, [r6, #36]	; 0x24

#if defined(__IMXRT1062__)
	// Use fast GPIO6, GPIO7, GPIO8, GPIO9
	IOMUXC_GPR_GPR26 = 0xFFFFFFFF;
60001128:	str	r2, [r1, #104]	; 0x68
	IOMUXC_GPR_GPR27 = 0xFFFFFFFF;
6000112a:	str	r2, [r1, #108]	; 0x6c
	IOMUXC_GPR_GPR28 = 0xFFFFFFFF;
6000112c:	str	r2, [r1, #112]	; 0x70
	IOMUXC_GPR_GPR29 = 0xFFFFFFFF;
6000112e:	str	r2, [r1, #116]	; 0x74
	// must enable PRINT_DEBUG_STUFF in debug/print.h
	printf_debug_init();
	printf("\n***********IMXRT Startup**********\n");
	printf("test %d %d %d\n", 1, -1234567, 3);

	configure_cache();
60001130:	bl	60001388 <configure_cache>
extern volatile uint32_t systick_cycle_count;
static void configure_systick(void)
{
	_VectorsRam[14] = pendablesrvreq_isr;
	_VectorsRam[15] = systick_isr;
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
60001134:	ldr	r2, [pc, #288]	; (60001258 <ResetHandler+0x224>)
60001136:	movs	r0, #99	; 0x63
	SYST_CVR = 0;
60001138:	ldr	r3, [pc, #288]	; (6000125c <ResetHandler+0x228>)
#define SYSTICK_EXT_FREQ 100000

extern volatile uint32_t systick_cycle_count;
static void configure_systick(void)
{
	_VectorsRam[14] = pendablesrvreq_isr;
6000113a:	ldr	r1, [pc, #292]	; (60001260 <ResetHandler+0x22c>)
	_VectorsRam[15] = systick_isr;
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
6000113c:	str	r0, [r2, #0]
	SYST_CVR = 0;
	SYST_CSR = SYST_CSR_TICKINT | SYST_CSR_ENABLE;
6000113e:	movs	r2, #3
static void configure_systick(void)
{
	_VectorsRam[14] = pendablesrvreq_isr;
	_VectorsRam[15] = systick_isr;
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
	SYST_CVR = 0;
60001140:	str	r5, [r3, #0]
#define SYSTICK_EXT_FREQ 100000

extern volatile uint32_t systick_cycle_count;
static void configure_systick(void)
{
	_VectorsRam[14] = pendablesrvreq_isr;
60001142:	str.w	r1, [sl, #56]	; 0x38
	_VectorsRam[15] = systick_isr;
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
	SYST_CVR = 0;
	SYST_CSR = SYST_CSR_TICKINT | SYST_CSR_ENABLE;
60001146:	str.w	r2, [r3, #-8]
	SCB_SHPR3 = 0x20200000;  // Systick, pendablesrvreq_isr = priority 32;
	ARM_DEMCR |= ARM_DEMCR_TRCENA;
6000114a:	ldr	r1, [pc, #280]	; (60001264 <ResetHandler+0x230>)
	_VectorsRam[14] = pendablesrvreq_isr;
	_VectorsRam[15] = systick_isr;
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
	SYST_CVR = 0;
	SYST_CSR = SYST_CSR_TICKINT | SYST_CSR_ENABLE;
	SCB_SHPR3 = 0x20200000;  // Systick, pendablesrvreq_isr = priority 32;
6000114c:	ldr	r2, [pc, #280]	; (60001268 <ResetHandler+0x234>)

extern volatile uint32_t systick_cycle_count;
static void configure_systick(void)
{
	_VectorsRam[14] = pendablesrvreq_isr;
	_VectorsRam[15] = systick_isr;
6000114e:	ldr	r0, [pc, #284]	; (6000126c <ResetHandler+0x238>)
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
	SYST_CVR = 0;
	SYST_CSR = SYST_CSR_TICKINT | SYST_CSR_ENABLE;
	SCB_SHPR3 = 0x20200000;  // Systick, pendablesrvreq_isr = priority 32;
60001150:	str.w	r2, [r3, #3336]	; 0xd08
	ARM_DEMCR |= ARM_DEMCR_TRCENA;
60001154:	ldr	r3, [r1, #0]
	ARM_DWT_CTRL |= ARM_DWT_CTRL_CYCCNTENA; // turn on cycle counter
60001156:	ldr	r2, [pc, #280]	; (60001270 <ResetHandler+0x23c>)
	_VectorsRam[15] = systick_isr;
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
	SYST_CVR = 0;
	SYST_CSR = SYST_CSR_TICKINT | SYST_CSR_ENABLE;
	SCB_SHPR3 = 0x20200000;  // Systick, pendablesrvreq_isr = priority 32;
	ARM_DEMCR |= ARM_DEMCR_TRCENA;
60001158:	orr.w	r3, r3, #16777216	; 0x1000000

extern volatile uint32_t systick_cycle_count;
static void configure_systick(void)
{
	_VectorsRam[14] = pendablesrvreq_isr;
	_VectorsRam[15] = systick_isr;
6000115c:	str.w	r0, [sl, #60]	; 0x3c
	SYST_CVR = 0;
	SYST_CSR = SYST_CSR_TICKINT | SYST_CSR_ENABLE;
	SCB_SHPR3 = 0x20200000;  // Systick, pendablesrvreq_isr = priority 32;
	ARM_DEMCR |= ARM_DEMCR_TRCENA;
	ARM_DWT_CTRL |= ARM_DWT_CTRL_CYCCNTENA; // turn on cycle counter
	systick_cycle_count = ARM_DWT_CYCCNT; // compiled 0, corrected w/1st systick
60001160:	ldr	r0, [pc, #272]	; (60001274 <ResetHandler+0x240>)
	_VectorsRam[15] = systick_isr;
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
	SYST_CVR = 0;
	SYST_CSR = SYST_CSR_TICKINT | SYST_CSR_ENABLE;
	SCB_SHPR3 = 0x20200000;  // Systick, pendablesrvreq_isr = priority 32;
	ARM_DEMCR |= ARM_DEMCR_TRCENA;
60001162:	str	r3, [r1, #0]
	ARM_DWT_CTRL |= ARM_DWT_CTRL_CYCCNTENA; // turn on cycle counter
60001164:	ldr	r3, [r2, #0]
	systick_cycle_count = ARM_DWT_CYCCNT; // compiled 0, corrected w/1st systick
60001166:	ldr	r1, [pc, #272]	; (60001278 <ResetHandler+0x244>)
	SYST_RVR = (SYSTICK_EXT_FREQ / 1000) - 1;
	SYST_CVR = 0;
	SYST_CSR = SYST_CSR_TICKINT | SYST_CSR_ENABLE;
	SCB_SHPR3 = 0x20200000;  // Systick, pendablesrvreq_isr = priority 32;
	ARM_DEMCR |= ARM_DEMCR_TRCENA;
	ARM_DWT_CTRL |= ARM_DWT_CTRL_CYCCNTENA; // turn on cycle counter
60001168:	orr.w	r3, r3, #1
6000116c:	str	r3, [r2, #0]
	systick_cycle_count = ARM_DWT_CYCCNT; // compiled 0, corrected w/1st systick
6000116e:	ldr	r3, [r0, #0]
60001170:	str	r3, [r1, #0]
	printf("\n***********IMXRT Startup**********\n");
	printf("test %d %d %d\n", 1, -1234567, 3);

	configure_cache();
	configure_systick();
	usb_pll_start();	
60001172:	bl	60001448 <usb_pll_start>
}

FLASHMEM void reset_PFD()
{	
	//Reset PLL2 PFDs, set default frequencies:
	CCM_ANALOG_PFD_528_SET = (1 << 31) | (1 << 23) | (1 << 15) | (1 << 7);
60001176:	str.w	r7, [r4, #260]	; 0x104
	configure_cache();
	configure_systick();
	usb_pll_start();	
	reset_PFD(); //TODO: is this really needed?
#ifdef F_CPU
	set_arm_clock(F_CPU);
6000117a:	ldr	r0, [pc, #256]	; (6000127c <ResetHandler+0x248>)

FLASHMEM void reset_PFD()
{	
	//Reset PLL2 PFDs, set default frequencies:
	CCM_ANALOG_PFD_528_SET = (1 << 31) | (1 << 23) | (1 << 15) | (1 << 7);
	CCM_ANALOG_PFD_528 = 0x2018101B; // PFD0:352, PFD1:594, PFD2:396, PFD3:297 MHz 	
6000117c:	str.w	r9, [r4, #256]	; 0x100
	//PLL3:
	CCM_ANALOG_PFD_480_SET = (1 << 31) | (1 << 23) | (1 << 15) | (1 << 7);	
60001180:	str.w	r7, [r4, #244]	; 0xf4
	CCM_ANALOG_PFD_480 = 0x13110D0C; // PFD0:720, PFD1:664, PFD2:508, PFD3:454 MHz
60001184:	str.w	r8, [r4, #240]	; 0xf0
	configure_cache();
	configure_systick();
	usb_pll_start();	
	reset_PFD(); //TODO: is this really needed?
#ifdef F_CPU
	set_arm_clock(F_CPU);
60001188:	bl	60001720 <__set_arm_clock_veneer>
#endif

	asm volatile("nop\n nop\n nop\n nop": : :"memory"); // why oh why?
6000118c:	nop
6000118e:	nop
60001190:	nop
60001192:	nop

	// Undo PIT timer usage by ROM startup
	CCM_CCGR1 |= CCM_CCGR1_PIT(CCM_CCGR_ON);
60001194:	ldr	r1, [r6, #108]	; 0x6c
	PIT_MCR = 0;
60001196:	ldr	r2, [pc, #232]	; (60001280 <ResetHandler+0x24c>)
#endif

	asm volatile("nop\n nop\n nop\n nop": : :"memory"); // why oh why?

	// Undo PIT timer usage by ROM startup
	CCM_CCGR1 |= CCM_CCGR1_PIT(CCM_CCGR_ON);
60001198:	orr.w	r1, r1, #12288	; 0x3000
	PIT_TCTRL1 = 0;
	PIT_TCTRL2 = 0;
	PIT_TCTRL3 = 0;

	// initialize RTC
	if (!(SNVS_LPCR & SNVS_LPCR_SRTC_ENV)) {
6000119c:	ldr	r3, [pc, #228]	; (60001284 <ResetHandler+0x250>)
#endif

	asm volatile("nop\n nop\n nop\n nop": : :"memory"); // why oh why?

	// Undo PIT timer usage by ROM startup
	CCM_CCGR1 |= CCM_CCGR1_PIT(CCM_CCGR_ON);
6000119e:	str	r1, [r6, #108]	; 0x6c
	PIT_MCR = 0;
600011a0:	str	r5, [r2, #0]
	PIT_TCTRL0 = 0;
600011a2:	str.w	r5, [r2, #264]	; 0x108
	PIT_TCTRL1 = 0;
600011a6:	str.w	r5, [r2, #280]	; 0x118
	PIT_TCTRL2 = 0;
600011aa:	str.w	r5, [r2, #296]	; 0x128
	PIT_TCTRL3 = 0;
600011ae:	str.w	r5, [r2, #312]	; 0x138

	// initialize RTC
	if (!(SNVS_LPCR & SNVS_LPCR_SRTC_ENV)) {
600011b2:	ldr	r2, [r3, #56]	; 0x38
600011b4:	lsls	r2, r2, #31
600011b6:	bmi.n	600011ca <ResetHandler+0x196>
		// if SRTC isn't running, start it with default Jan 1, 2019
		SNVS_LPSRTCLR = 1546300800u << 15;
		SNVS_LPSRTCMR = 1546300800u >> 17;
600011b8:	movw	r2, #11797	; 0x2e15
	PIT_TCTRL3 = 0;

	// initialize RTC
	if (!(SNVS_LPCR & SNVS_LPCR_SRTC_ENV)) {
		// if SRTC isn't running, start it with default Jan 1, 2019
		SNVS_LPSRTCLR = 1546300800u << 15;
600011bc:	ldr	r1, [pc, #200]	; (60001288 <ResetHandler+0x254>)
600011be:	str	r1, [r3, #84]	; 0x54
		SNVS_LPSRTCMR = 1546300800u >> 17;
600011c0:	str	r2, [r3, #80]	; 0x50
		SNVS_LPCR |= SNVS_LPCR_SRTC_ENV;
600011c2:	ldr	r2, [r3, #56]	; 0x38
600011c4:	orr.w	r2, r2, #1
600011c8:	str	r2, [r3, #56]	; 0x38
	}
	SNVS_HPCR |= SNVS_HPCR_RTC_EN | SNVS_HPCR_HP_TS;
600011ca:	ldr	r2, [pc, #184]	; (60001284 <ResetHandler+0x250>)
600011cc:	ldr	r4, [pc, #188]	; (6000128c <ResetHandler+0x258>)
600011ce:	ldr	r3, [r2, #8]
600011d0:	orr.w	r3, r3, #65537	; 0x10001
600011d4:	str	r3, [r2, #8]

	startup_early_hook();
600011d6:	bl	600016f8 <__startup_early_hook_veneer>
extern volatile uint32_t systick_millis_count;

static inline uint32_t millis(void) __attribute__((always_inline, unused));
static inline uint32_t millis(void)
{
	return systick_millis_count;
600011da:	ldr	r3, [r4, #0]
	while (millis() < 20) ; // wait at least 20ms before starting USB
600011dc:	cmp	r3, #19
600011de:	bls.n	600011da <ResetHandler+0x1a6>
	usb_init();
600011e0:	bl	6000129c <usb_init>
	analog_init();
600011e4:	bl	600014ac <analog_init>
	pwm_init();
600011e8:	bl	60001730 <__pwm_init_veneer>
	tempmon_init();
600011ec:	bl	60001504 <tempmon_init>

	startup_late_hook();
600011f0:	bl	60001728 <__startup_late_hook_veneer>
600011f4:	ldr	r3, [r4, #0]
	while (millis() < 300) ; // wait at least 300ms before calling user code
600011f6:	cmp.w	r3, #300	; 0x12c
600011fa:	bcc.n	600011f4 <ResetHandler+0x1c0>
	//printf("before C++ constructors\n");
	__libc_init_array();
600011fc:	bl	60001710 <____libc_init_array_veneer>
	//printf("after C++ constructors\n");
	//printf("before setup\n");
	main();
60001200:	bl	60001708 <__main_veneer>
60001204:	b.n	60001204 <ResetHandler+0x1d0>
60001206:	nop
60001208:	.word	0x400ac000
6000120c:	.word	0xaaaaaaab
60001210:	.word	0x00200007
60001214:	.word	0x20078000
60001218:	.word	0x00000000
6000121c:	.word	0x60001750
60001220:	.word	0x00007b10
60001224:	.word	0x20000000
60001228:	.word	0x60009264
6000122c:	.word	0x20000940
60001230:	.word	0x20000940
60001234:	.word	0x20002700
60001238:	.word	0xe000ed88
6000123c:	.word	0x200023fc
60001240:	.word	0x00006da1
60001244:	.word	0xe000e400
60001248:	.word	0xe000e4a0
6000124c:	.word	0x400d8000
60001250:	.word	0x400fc000
60001254:	.word	0xe000ed08
60001258:	.word	0xe000e014
6000125c:	.word	0xe000e018
60001260:	.word	0x00006a15
60001264:	.word	0xe000edfc
60001268:	.word	0x20200000
6000126c:	.word	0x00006b19
60001270:	.word	0xe0001000
60001274:	.word	0xe0001004
60001278:	.word	0x20000b7c
6000127c:	.word	0x23c34600
60001280:	.word	0x40084000
60001284:	.word	0x400d4000
60001288:	.word	0x56c00000
6000128c:	.word	0x20000b84
60001290:	.word	0x20002400
60001294:	.word	0x2018101b
60001298:	.word	0x13110d0c

6000129c <usb_init>:
FLASHMEM void usb_init(void)
{
	// TODO: only enable when VBUS detected
	// TODO: return to low power mode when VBUS removed
	// TODO: protect PMU access with MPU
	PMU_REG_3P0 = PMU_REG_3P0_OUTPUT_TRG(0x0F) | PMU_REG_3P0_BO_OFFSET(6)
6000129c:	ldr	r3, [pc, #192]	; (60001360 <usb_init+0xc4>)
6000129e:	movw	r2, #3937	; 0xf61

static void run_callbacks(endpoint_t *ep);


FLASHMEM void usb_init(void)
{
600012a2:	push	{r4, r5, r6, lr}
	// TODO: only enable when VBUS detected
	// TODO: return to low power mode when VBUS removed
	// TODO: protect PMU access with MPU
	PMU_REG_3P0 = PMU_REG_3P0_OUTPUT_TRG(0x0F) | PMU_REG_3P0_BO_OFFSET(6)
600012a4:	str.w	r2, [r3, #288]	; 0x120

	CCM_CCGR6 |= CCM_CCGR6_USBOH3(CCM_CCGR_ON); // turn on clocks to USB peripheral
	
	printf("BURSTSIZE=%08lX\n", USB1_BURSTSIZE);
	//USB1_BURSTSIZE = USB_BURSTSIZE_TXPBURST(4) | USB_BURSTSIZE_RXPBURST(4);
	USB1_BURSTSIZE = 0x0404;
600012a8:	movw	r5, #1028	; 0x404
	// TODO: return to low power mode when VBUS removed
	// TODO: protect PMU access with MPU
	PMU_REG_3P0 = PMU_REG_3P0_OUTPUT_TRG(0x0F) | PMU_REG_3P0_BO_OFFSET(6)
		| PMU_REG_3P0_ENABLE_LINREG;

	usb_init_serialnumber();
600012ac:	bl	60001700 <__usb_init_serialnumber_veneer>

	// assume PLL3 is already running - already done by usb_pll_start() in main.c

	CCM_CCGR6 |= CCM_CCGR6_USBOH3(CCM_CCGR_ON); // turn on clocks to USB peripheral
600012b0:	ldr	r1, [pc, #176]	; (60001364 <usb_init+0xc8>)
	
	printf("BURSTSIZE=%08lX\n", USB1_BURSTSIZE);
	//USB1_BURSTSIZE = USB_BURSTSIZE_TXPBURST(4) | USB_BURSTSIZE_RXPBURST(4);
	USB1_BURSTSIZE = 0x0404;
600012b2:	ldr	r0, [pc, #180]	; (60001368 <usb_init+0xcc>)

	usb_init_serialnumber();

	// assume PLL3 is already running - already done by usb_pll_start() in main.c

	CCM_CCGR6 |= CCM_CCGR6_USBOH3(CCM_CCGR_ON); // turn on clocks to USB peripheral
600012b4:	ldr.w	r2, [r1, #128]	; 0x80
	//printf("USB1_USBMODE=%08lX\n", USB1_USBMODE);

	// turn on PLL3, wait for 480 MHz lock?
	// turn on CCM clock gates?  CCGR6[CG0]
#if 1
	if ((USBPHY1_PWD & (USBPHY_PWD_RXPWDRX | USBPHY_PWD_RXPWDDIFF | USBPHY_PWD_RXPWD1PT1
600012b8:	ldr	r4, [pc, #176]	; (6000136c <usb_init+0xd0>)

	usb_init_serialnumber();

	// assume PLL3 is already running - already done by usb_pll_start() in main.c

	CCM_CCGR6 |= CCM_CCGR6_USBOH3(CCM_CCGR_ON); // turn on clocks to USB peripheral
600012ba:	orr.w	r2, r2, #3
	//printf("USB1_USBMODE=%08lX\n", USB1_USBMODE);

	// turn on PLL3, wait for 480 MHz lock?
	// turn on CCM clock gates?  CCGR6[CG0]
#if 1
	if ((USBPHY1_PWD & (USBPHY_PWD_RXPWDRX | USBPHY_PWD_RXPWDDIFF | USBPHY_PWD_RXPWD1PT1
600012be:	ldr	r3, [pc, #176]	; (60001370 <usb_init+0xd4>)

	usb_init_serialnumber();

	// assume PLL3 is already running - already done by usb_pll_start() in main.c

	CCM_CCGR6 |= CCM_CCGR6_USBOH3(CCM_CCGR_ON); // turn on clocks to USB peripheral
600012c0:	str.w	r2, [r1, #128]	; 0x80
	
	printf("BURSTSIZE=%08lX\n", USB1_BURSTSIZE);
	//USB1_BURSTSIZE = USB_BURSTSIZE_TXPBURST(4) | USB_BURSTSIZE_RXPBURST(4);
	USB1_BURSTSIZE = 0x0404;
600012c4:	str.w	r5, [r0, #352]	; 0x160
	//printf("USB1_USBMODE=%08lX\n", USB1_USBMODE);

	// turn on PLL3, wait for 480 MHz lock?
	// turn on CCM clock gates?  CCGR6[CG0]
#if 1
	if ((USBPHY1_PWD & (USBPHY_PWD_RXPWDRX | USBPHY_PWD_RXPWDDIFF | USBPHY_PWD_RXPWD1PT1
600012c8:	ldr	r2, [r4, #0]
600012ca:	ands	r3, r2
600012cc:	cbnz	r3, 600012d6 <usb_init+0x3a>
	  | USBPHY_PWD_RXPWDENV | USBPHY_PWD_TXPWDV2I | USBPHY_PWD_TXPWDIBIAS
	  | USBPHY_PWD_TXPWDFS)) || (USB1_USBMODE & USB_USBMODE_CM_MASK)) {
600012ce:	ldr.w	r3, [r0, #424]	; 0x1a8
600012d2:	lsls	r2, r3, #30
600012d4:	beq.n	6000130c <usb_init+0x70>
		// USB controller is turned on from previous use
		// reset needed to turn it off & start from clean slate
		USBPHY1_CTRL_SET = USBPHY_CTRL_SFTRST; // USBPHY1_CTRL page 3292
		USB1_USBCMD |= USB_USBCMD_RST; // reset controller
600012d6:	ldr	r3, [pc, #144]	; (60001368 <usb_init+0xcc>)
	if ((USBPHY1_PWD & (USBPHY_PWD_RXPWDRX | USBPHY_PWD_RXPWDDIFF | USBPHY_PWD_RXPWD1PT1
	  | USBPHY_PWD_RXPWDENV | USBPHY_PWD_TXPWDV2I | USBPHY_PWD_TXPWDIBIAS
	  | USBPHY_PWD_TXPWDFS)) || (USB1_USBMODE & USB_USBMODE_CM_MASK)) {
		// USB controller is turned on from previous use
		// reset needed to turn it off & start from clean slate
		USBPHY1_CTRL_SET = USBPHY_CTRL_SFTRST; // USBPHY1_CTRL page 3292
600012d8:	mov.w	r1, #2147483648	; 0x80000000
600012dc:	ldr	r2, [pc, #140]	; (6000136c <usb_init+0xd0>)
600012de:	str	r1, [r2, #52]	; 0x34
		USB1_USBCMD |= USB_USBCMD_RST; // reset controller
		int count=0;
		while (USB1_USBCMD & USB_USBCMD_RST) count++;
600012e0:	mov	r2, r3
	  | USBPHY_PWD_RXPWDENV | USBPHY_PWD_TXPWDV2I | USBPHY_PWD_TXPWDIBIAS
	  | USBPHY_PWD_TXPWDFS)) || (USB1_USBMODE & USB_USBMODE_CM_MASK)) {
		// USB controller is turned on from previous use
		// reset needed to turn it off & start from clean slate
		USBPHY1_CTRL_SET = USBPHY_CTRL_SFTRST; // USBPHY1_CTRL page 3292
		USB1_USBCMD |= USB_USBCMD_RST; // reset controller
600012e2:	ldr.w	r1, [r3, #320]	; 0x140
600012e6:	orr.w	r1, r1, #2
600012ea:	str.w	r1, [r3, #320]	; 0x140
		int count=0;
		while (USB1_USBCMD & USB_USBCMD_RST) count++;
600012ee:	ldr.w	r3, [r2, #320]	; 0x140
600012f2:	lsls	r3, r3, #30
600012f4:	bmi.n	600012ee <usb_init+0x52>
		NVIC_CLEAR_PENDING(IRQ_USB1);
600012f6:	mov.w	r0, #131072	; 0x20000
600012fa:	ldr	r1, [pc, #120]	; (60001374 <usb_init+0xd8>)
		USBPHY1_CTRL_CLR = USBPHY_CTRL_SFTRST; // reset PHY
600012fc:	ldr	r3, [pc, #108]	; (6000136c <usb_init+0xd0>)
600012fe:	mov.w	r2, #2147483648	; 0x80000000
		// reset needed to turn it off & start from clean slate
		USBPHY1_CTRL_SET = USBPHY_CTRL_SFTRST; // USBPHY1_CTRL page 3292
		USB1_USBCMD |= USB_USBCMD_RST; // reset controller
		int count=0;
		while (USB1_USBCMD & USB_USBCMD_RST) count++;
		NVIC_CLEAR_PENDING(IRQ_USB1);
60001302:	str	r0, [r1, #0]
		//printf("USBPHY1_PWD=%08lX\n", USBPHY1_PWD);
		//printf("USBPHY1_TX=%08lX\n", USBPHY1_TX);
		//printf("USBPHY1_RX=%08lX\n", USBPHY1_RX);
		//printf("USBPHY1_CTRL=%08lX\n", USBPHY1_CTRL);
		//printf("USB1_USBMODE=%08lX\n", USB1_USBMODE);
		delay(25);
60001304:	movs	r0, #25
		USBPHY1_CTRL_SET = USBPHY_CTRL_SFTRST; // USBPHY1_CTRL page 3292
		USB1_USBCMD |= USB_USBCMD_RST; // reset controller
		int count=0;
		while (USB1_USBCMD & USB_USBCMD_RST) count++;
		NVIC_CLEAR_PENDING(IRQ_USB1);
		USBPHY1_CTRL_CLR = USBPHY_CTRL_SFTRST; // reset PHY
60001306:	str	r2, [r3, #56]	; 0x38
		//printf("USBPHY1_PWD=%08lX\n", USBPHY1_PWD);
		//printf("USBPHY1_TX=%08lX\n", USBPHY1_TX);
		//printf("USBPHY1_RX=%08lX\n", USBPHY1_RX);
		//printf("USBPHY1_CTRL=%08lX\n", USBPHY1_CTRL);
		//printf("USB1_USBMODE=%08lX\n", USB1_USBMODE);
		delay(25);
60001308:	bl	60001738 <__delay_veneer>
	USBPHY1_PWD = 0;
	//printf("USBPHY1_PWD=%08lX\n", USBPHY1_PWD);
	//printf("USBPHY1_CTRL=%08lX\n", USBPHY1_CTRL);

	USB1_USBMODE = USB_USBMODE_CM(2) | USB_USBMODE_SLOM;
	memset(endpoint_queue_head, 0, sizeof(endpoint_queue_head));
6000130c:	ldr	r5, [pc, #104]	; (60001378 <usb_init+0xdc>)
	// ENDPTSTAT	pg 3247
	// ENDPTCOMPLETE   3248
	// ENDPTCTRL0	pg 3249

	USBPHY1_CTRL_CLR = USBPHY_CTRL_CLKGATE;
	USBPHY1_PWD = 0;
6000130e:	movs	r2, #0
	// ENDPTFLUSH	pg 3247
	// ENDPTSTAT	pg 3247
	// ENDPTCOMPLETE   3248
	// ENDPTCTRL0	pg 3249

	USBPHY1_CTRL_CLR = USBPHY_CTRL_CLKGATE;
60001310:	ldr	r3, [pc, #88]	; (6000136c <usb_init+0xd0>)
60001312:	mov.w	r1, #1073741824	; 0x40000000
	USBPHY1_PWD = 0;
	//printf("USBPHY1_PWD=%08lX\n", USBPHY1_PWD);
	//printf("USBPHY1_CTRL=%08lX\n", USBPHY1_CTRL);

	USB1_USBMODE = USB_USBMODE_CM(2) | USB_USBMODE_SLOM;
60001316:	ldr	r4, [pc, #80]	; (60001368 <usb_init+0xcc>)
60001318:	movs	r6, #10
	// ENDPTFLUSH	pg 3247
	// ENDPTSTAT	pg 3247
	// ENDPTCOMPLETE   3248
	// ENDPTCTRL0	pg 3249

	USBPHY1_CTRL_CLR = USBPHY_CTRL_CLKGATE;
6000131a:	str	r1, [r3, #56]	; 0x38
	USBPHY1_PWD = 0;
	//printf("USBPHY1_PWD=%08lX\n", USBPHY1_PWD);
	//printf("USBPHY1_CTRL=%08lX\n", USBPHY1_CTRL);

	USB1_USBMODE = USB_USBMODE_CM(2) | USB_USBMODE_SLOM;
	memset(endpoint_queue_head, 0, sizeof(endpoint_queue_head));
6000131c:	mov	r0, r5
	// ENDPTSTAT	pg 3247
	// ENDPTCOMPLETE   3248
	// ENDPTCTRL0	pg 3249

	USBPHY1_CTRL_CLR = USBPHY_CTRL_CLKGATE;
	USBPHY1_PWD = 0;
6000131e:	str	r2, [r3, #0]
	//printf("USBPHY1_PWD=%08lX\n", USBPHY1_PWD);
	//printf("USBPHY1_CTRL=%08lX\n", USBPHY1_CTRL);

	USB1_USBMODE = USB_USBMODE_CM(2) | USB_USBMODE_SLOM;
	memset(endpoint_queue_head, 0, sizeof(endpoint_queue_head));
60001320:	mov	r1, r2
	USBPHY1_CTRL_CLR = USBPHY_CTRL_CLKGATE;
	USBPHY1_PWD = 0;
	//printf("USBPHY1_PWD=%08lX\n", USBPHY1_PWD);
	//printf("USBPHY1_CTRL=%08lX\n", USBPHY1_CTRL);

	USB1_USBMODE = USB_USBMODE_CM(2) | USB_USBMODE_SLOM;
60001322:	str.w	r6, [r4, #424]	; 0x1a8
	memset(endpoint_queue_head, 0, sizeof(endpoint_queue_head));
60001326:	mov.w	r2, #640	; 0x280
6000132a:	bl	60001718 <__memset_veneer>
	endpoint_queue_head[0].config = (64 << 16) | (1 << 15);
6000132e:	mov.w	r6, #4227072	; 0x408000
	endpoint_queue_head[1].config = (64 << 16);
60001332:	mov.w	r0, #4194304	; 0x400000
	USB1_ENDPOINTLISTADDR = (uint32_t)&endpoint_queue_head;
	//  Recommended: enable all device interrupts including: USBINT, USBERRINT,
	// Port Change Detect, USB Reset Received, DCSuspend.
	USB1_USBINTR = USB_USBINTR_UE | USB_USBINTR_UEE | /* USB_USBINTR_PCE | */
60001336:	movw	r3, #323	; 0x143
static inline void attachInterruptVector(IRQ_NUMBER_t irq, void (*function)(void)) __attribute__((always_inline, unused));
static inline void attachInterruptVector(IRQ_NUMBER_t irq, void (*function)(void)) { _VectorsRam[irq + 16] = function; asm volatile("": : :"memory"); }
#else
extern void (* _VectorsRam[NVIC_NUM_INTERRUPTS+16])(void);
static inline void attachInterruptVector(enum IRQ_NUMBER_t irq, void (*function)(void)) __attribute__((always_inline, unused));
static inline void attachInterruptVector(enum IRQ_NUMBER_t irq, void (*function)(void)) { _VectorsRam[irq + 16] = function; asm volatile("": : :"memory"); }
6000133a:	ldr	r2, [pc, #64]	; (6000137c <usb_init+0xe0>)
6000133c:	ldr	r1, [pc, #64]	; (60001380 <usb_init+0xe4>)
	//printf("USBPHY1_PWD=%08lX\n", USBPHY1_PWD);
	//printf("USBPHY1_CTRL=%08lX\n", USBPHY1_CTRL);

	USB1_USBMODE = USB_USBMODE_CM(2) | USB_USBMODE_SLOM;
	memset(endpoint_queue_head, 0, sizeof(endpoint_queue_head));
	endpoint_queue_head[0].config = (64 << 16) | (1 << 15);
6000133e:	str	r6, [r5, #0]
	endpoint_queue_head[1].config = (64 << 16);
60001340:	str	r0, [r5, #64]	; 0x40
	USB1_ENDPOINTLISTADDR = (uint32_t)&endpoint_queue_head;
60001342:	str.w	r5, [r4, #344]	; 0x158
60001346:	str.w	r1, [r2, #516]	; 0x204
	//  Recommended: enable all device interrupts including: USBINT, USBERRINT,
	// Port Change Detect, USB Reset Received, DCSuspend.
	USB1_USBINTR = USB_USBINTR_UE | USB_USBINTR_UEE | /* USB_USBINTR_PCE | */
6000134a:	str.w	r3, [r4, #328]	; 0x148
		USB_USBINTR_URE | USB_USBINTR_SLE;
	//_VectorsRam[IRQ_USB1+16] = &isr;
	attachInterruptVector(IRQ_USB1, &isr);
	NVIC_ENABLE_IRQ(IRQ_USB1);
6000134e:	ldr	r2, [pc, #52]	; (60001384 <usb_init+0xe8>)
60001350:	mov.w	r1, #131072	; 0x20000
	//printf("USB1_ENDPTCTRL0=%08lX\n", USB1_ENDPTCTRL0);
	//printf("USB1_ENDPTCTRL1=%08lX\n", USB1_ENDPTCTRL1);
	//printf("USB1_ENDPTCTRL2=%08lX\n", USB1_ENDPTCTRL2);
	//printf("USB1_ENDPTCTRL3=%08lX\n", USB1_ENDPTCTRL3);
	USB1_USBCMD = USB_USBCMD_RS;
60001354:	movs	r3, #1
	// Port Change Detect, USB Reset Received, DCSuspend.
	USB1_USBINTR = USB_USBINTR_UE | USB_USBINTR_UEE | /* USB_USBINTR_PCE | */
		USB_USBINTR_URE | USB_USBINTR_SLE;
	//_VectorsRam[IRQ_USB1+16] = &isr;
	attachInterruptVector(IRQ_USB1, &isr);
	NVIC_ENABLE_IRQ(IRQ_USB1);
60001356:	str	r1, [r2, #0]
	//printf("USB1_ENDPTCTRL0=%08lX\n", USB1_ENDPTCTRL0);
	//printf("USB1_ENDPTCTRL1=%08lX\n", USB1_ENDPTCTRL1);
	//printf("USB1_ENDPTCTRL2=%08lX\n", USB1_ENDPTCTRL2);
	//printf("USB1_ENDPTCTRL3=%08lX\n", USB1_ENDPTCTRL3);
	USB1_USBCMD = USB_USBCMD_RS;
60001358:	str.w	r3, [r4, #320]	; 0x140
6000135c:	pop	{r4, r5, r6, pc}
6000135e:	nop
60001360:	.word	0x400d8000
60001364:	.word	0x400fc000
60001368:	.word	0x402e0000
6000136c:	.word	0x400d9000
60001370:	.word	0x001e1c00
60001374:	.word	0xe000e28c
60001378:	.word	0x20002000
6000137c:	.word	0x20002400
60001380:	.word	0x00005cc5
60001384:	.word	0xe000e10c

60001388 <configure_cache>:
#define SIZE_64M	(SCB_MPU_RASR_SIZE(25) | SCB_MPU_RASR_ENABLE)
#define SIZE_256M	(SCB_MPU_RASR_SIZE(26) | SCB_MPU_RASR_ENABLE)
#define REGION(n)	(SCB_MPU_RBAR_REGION(n) | SCB_MPU_RBAR_VALID)

FLASHMEM void configure_cache(void)
{
60001388:	push	{r4, r5, r6, r7, lr}

	// TODO: check if caches already active - skip?

	SCB_MPU_CTRL = 0; // turn off MPU

	SCB_MPU_RBAR = 0x00000000 | REGION(0); // ITCM
6000138a:	ldr	r2, [pc, #116]	; (60001400 <configure_cache+0x78>)
	//printf("MPU_TYPE = %08lX\n", SCB_MPU_TYPE);
	//printf("CCR = %08lX\n", SCB_CCR);

	// TODO: check if caches already active - skip?

	SCB_MPU_CTRL = 0; // turn off MPU
6000138c:	movs	r1, #0

	SCB_MPU_RBAR = 0x00000000 | REGION(0); // ITCM
	SCB_MPU_RASR = MEM_NOCACHE | READWRITE | SIZE_512K;
6000138e:	ldr	r3, [pc, #116]	; (60001404 <configure_cache+0x7c>)

	// TODO: check if caches already active - skip?

	SCB_MPU_CTRL = 0; // turn off MPU

	SCB_MPU_RBAR = 0x00000000 | REGION(0); // ITCM
60001390:	mov.w	lr, #16
	//printf("MPU_TYPE = %08lX\n", SCB_MPU_TYPE);
	//printf("CCR = %08lX\n", SCB_CCR);

	// TODO: check if caches already active - skip?

	SCB_MPU_CTRL = 0; // turn off MPU
60001394:	ldr	r0, [pc, #112]	; (60001408 <configure_cache+0x80>)

	// TODO: 32 byte sub-region at 0x00000000 with NOACCESS, to trap NULL pointer deref
	// TODO: protect access to power supply config
	// TODO: 32 byte sub-region at end of .bss section with NOACCESS, to trap stack overflow

	SCB_MPU_CTRL = SCB_MPU_CTRL_ENABLE;
60001396:	movs	r4, #1
	// TODO: check if caches already active - skip?

	SCB_MPU_CTRL = 0; // turn off MPU

	SCB_MPU_RBAR = 0x00000000 | REGION(0); // ITCM
	SCB_MPU_RASR = MEM_NOCACHE | READWRITE | SIZE_512K;
60001398:	ldr	r7, [pc, #112]	; (6000140c <configure_cache+0x84>)

	SCB_MPU_RBAR = 0x00200000 | REGION(1); // Boot ROM
6000139a:	ldr	r6, [pc, #116]	; (60001410 <configure_cache+0x88>)
	SCB_MPU_RASR = MEM_CACHE_WT | READONLY | SIZE_128K;
6000139c:	ldr	r5, [pc, #116]	; (60001414 <configure_cache+0x8c>)
	//printf("MPU_TYPE = %08lX\n", SCB_MPU_TYPE);
	//printf("CCR = %08lX\n", SCB_CCR);

	// TODO: check if caches already active - skip?

	SCB_MPU_CTRL = 0; // turn off MPU
6000139e:	str	r1, [r0, #0]

	SCB_MPU_RBAR = 0x00000000 | REGION(0); // ITCM
600013a0:	str.w	lr, [r2]
	SCB_MPU_RASR = MEM_NOCACHE | READWRITE | SIZE_512K;
600013a4:	str	r7, [r3, #0]

	SCB_MPU_RBAR = 0x00200000 | REGION(1); // Boot ROM
600013a6:	str	r6, [r2, #0]
	SCB_MPU_RASR = MEM_CACHE_WT | READONLY | SIZE_128K;

	SCB_MPU_RBAR = 0x20000000 | REGION(2); // DTCM
600013a8:	ldr	r7, [pc, #108]	; (60001418 <configure_cache+0x90>)

	SCB_MPU_RBAR = 0x00000000 | REGION(0); // ITCM
	SCB_MPU_RASR = MEM_NOCACHE | READWRITE | SIZE_512K;

	SCB_MPU_RBAR = 0x00200000 | REGION(1); // Boot ROM
	SCB_MPU_RASR = MEM_CACHE_WT | READONLY | SIZE_128K;
600013aa:	str	r5, [r3, #0]

	SCB_MPU_RBAR = 0x20000000 | REGION(2); // DTCM
	SCB_MPU_RASR = MEM_NOCACHE | READWRITE | NOEXEC | SIZE_512K;
600013ac:	ldr	r6, [pc, #108]	; (6000141c <configure_cache+0x94>)

	SCB_MPU_RBAR = 0x20200000 | REGION(3); // RAM (AXI bus)
600013ae:	ldr	r5, [pc, #112]	; (60001420 <configure_cache+0x98>)
	SCB_MPU_RASR = MEM_NOCACHE | READWRITE | SIZE_512K;

	SCB_MPU_RBAR = 0x00200000 | REGION(1); // Boot ROM
	SCB_MPU_RASR = MEM_CACHE_WT | READONLY | SIZE_128K;

	SCB_MPU_RBAR = 0x20000000 | REGION(2); // DTCM
600013b0:	str	r7, [r2, #0]
	SCB_MPU_RASR = MEM_NOCACHE | READWRITE | NOEXEC | SIZE_512K;
600013b2:	str	r6, [r3, #0]

	SCB_MPU_RBAR = 0x20200000 | REGION(3); // RAM (AXI bus)
	SCB_MPU_RASR = MEM_CACHE_WBWA | READWRITE | NOEXEC | SIZE_1M;
600013b4:	ldr	r7, [pc, #108]	; (60001424 <configure_cache+0x9c>)
	SCB_MPU_RASR = MEM_CACHE_WT | READONLY | SIZE_128K;

	SCB_MPU_RBAR = 0x20000000 | REGION(2); // DTCM
	SCB_MPU_RASR = MEM_NOCACHE | READWRITE | NOEXEC | SIZE_512K;

	SCB_MPU_RBAR = 0x20200000 | REGION(3); // RAM (AXI bus)
600013b6:	str	r5, [r2, #0]
	SCB_MPU_RASR = MEM_CACHE_WBWA | READWRITE | NOEXEC | SIZE_1M;

	SCB_MPU_RBAR = 0x40000000 | REGION(4); // Peripherals
600013b8:	ldr	r6, [pc, #108]	; (60001428 <configure_cache+0xa0>)
	SCB_MPU_RASR = DEV_NOCACHE | READWRITE | NOEXEC | SIZE_64M;
600013ba:	ldr	r5, [pc, #112]	; (6000142c <configure_cache+0xa4>)

	SCB_MPU_RBAR = 0x20000000 | REGION(2); // DTCM
	SCB_MPU_RASR = MEM_NOCACHE | READWRITE | NOEXEC | SIZE_512K;

	SCB_MPU_RBAR = 0x20200000 | REGION(3); // RAM (AXI bus)
	SCB_MPU_RASR = MEM_CACHE_WBWA | READWRITE | NOEXEC | SIZE_1M;
600013bc:	str	r7, [r3, #0]

	SCB_MPU_RBAR = 0x40000000 | REGION(4); // Peripherals
600013be:	str	r6, [r2, #0]
	SCB_MPU_RASR = DEV_NOCACHE | READWRITE | NOEXEC | SIZE_64M;

	SCB_MPU_RBAR = 0x60000000 | REGION(5); // QSPI Flash
600013c0:	ldr	r7, [pc, #108]	; (60001430 <configure_cache+0xa8>)

	SCB_MPU_RBAR = 0x20200000 | REGION(3); // RAM (AXI bus)
	SCB_MPU_RASR = MEM_CACHE_WBWA | READWRITE | NOEXEC | SIZE_1M;

	SCB_MPU_RBAR = 0x40000000 | REGION(4); // Peripherals
	SCB_MPU_RASR = DEV_NOCACHE | READWRITE | NOEXEC | SIZE_64M;
600013c2:	str	r5, [r3, #0]

	SCB_MPU_RBAR = 0x60000000 | REGION(5); // QSPI Flash
	SCB_MPU_RASR = MEM_CACHE_WBWA | READONLY | SIZE_16M;
600013c4:	ldr	r6, [pc, #108]	; (60001434 <configure_cache+0xac>)

	SCB_MPU_RBAR = 0x70000000 | REGION(6); // FlexSPI2
600013c6:	ldr	r5, [pc, #112]	; (60001438 <configure_cache+0xb0>)
	SCB_MPU_RASR = MEM_CACHE_WBWA | READWRITE | NOEXEC | SIZE_1M;

	SCB_MPU_RBAR = 0x40000000 | REGION(4); // Peripherals
	SCB_MPU_RASR = DEV_NOCACHE | READWRITE | NOEXEC | SIZE_64M;

	SCB_MPU_RBAR = 0x60000000 | REGION(5); // QSPI Flash
600013c8:	str	r7, [r2, #0]
	SCB_MPU_RASR = MEM_CACHE_WBWA | READONLY | SIZE_16M;
600013ca:	str	r6, [r3, #0]

	SCB_MPU_RBAR = 0x70000000 | REGION(6); // FlexSPI2
	SCB_MPU_RASR = MEM_CACHE_WBWA | READONLY | SIZE_256M;
600013cc:	ldr	r7, [pc, #108]	; (6000143c <configure_cache+0xb4>)
	SCB_MPU_RASR = DEV_NOCACHE | READWRITE | NOEXEC | SIZE_64M;

	SCB_MPU_RBAR = 0x60000000 | REGION(5); // QSPI Flash
	SCB_MPU_RASR = MEM_CACHE_WBWA | READONLY | SIZE_16M;

	SCB_MPU_RBAR = 0x70000000 | REGION(6); // FlexSPI2
600013ce:	str	r5, [r2, #0]
	SCB_MPU_RASR = MEM_CACHE_WBWA | READONLY | SIZE_256M;

	SCB_MPU_RBAR = 0x70000000 | REGION(7); // FlexSPI2
600013d0:	ldr	r6, [pc, #108]	; (60001440 <configure_cache+0xb8>)
	SCB_MPU_RASR = MEM_CACHE_WBWA | READWRITE | SIZE_16M;
600013d2:	ldr	r5, [pc, #112]	; (60001444 <configure_cache+0xbc>)

	SCB_MPU_RBAR = 0x60000000 | REGION(5); // QSPI Flash
	SCB_MPU_RASR = MEM_CACHE_WBWA | READONLY | SIZE_16M;

	SCB_MPU_RBAR = 0x70000000 | REGION(6); // FlexSPI2
	SCB_MPU_RASR = MEM_CACHE_WBWA | READONLY | SIZE_256M;
600013d4:	str	r7, [r3, #0]

	SCB_MPU_RBAR = 0x70000000 | REGION(7); // FlexSPI2
600013d6:	str	r6, [r2, #0]
	SCB_MPU_RASR = MEM_CACHE_WBWA | READWRITE | SIZE_16M;
600013d8:	str	r5, [r3, #0]

	// TODO: 32 byte sub-region at 0x00000000 with NOACCESS, to trap NULL pointer deref
	// TODO: protect access to power supply config
	// TODO: 32 byte sub-region at end of .bss section with NOACCESS, to trap stack overflow

	SCB_MPU_CTRL = SCB_MPU_CTRL_ENABLE;
600013da:	str	r4, [r0, #0]

	// cache enable, ARM DDI0403E, pg 628
	asm("dsb");
600013dc:	dsb	sy
	asm("isb");
600013e0:	isb	sy
	SCB_CACHE_ICIALLU = 0;
600013e4:	str.w	r1, [r3, #432]	; 0x1b0

	asm("dsb");
600013e8:	dsb	sy
	asm("isb");
600013ec:	isb	sy
	SCB_CCR |= (SCB_CCR_IC | SCB_CCR_DC);
600013f0:	ldr.w	r3, [r2, #-136]
600013f4:	orr.w	r3, r3, #196608	; 0x30000
600013f8:	str.w	r3, [r2, #-136]
600013fc:	pop	{r4, r5, r6, r7, pc}
600013fe:	nop
60001400:	.word	0xe000ed9c
60001404:	.word	0xe000eda0
60001408:	.word	0xe000ed94
6000140c:	.word	0x03080025
60001410:	.word	0x00200011
60001414:	.word	0x07020021
60001418:	.word	0x20000012
6000141c:	.word	0x13080025
60001420:	.word	0x20200013
60001424:	.word	0x130b0027
60001428:	.word	0x40000014
6000142c:	.word	0x13100033
60001430:	.word	0x60000015
60001434:	.word	0x070b002f
60001438:	.word	0x70000016
6000143c:	.word	0x070b0035
60001440:	.word	0x70000017
60001444:	.word	0x030b002f

60001448 <usb_pll_start>:
}


FLASHMEM void usb_pll_start()
{
60001448:	push	{r4, r5, r6, r7}
	while (1) {
		uint32_t n = CCM_ANALOG_PLL_USB1; // pg 759
6000144a:	ldr	r2, [pc, #92]	; (600014a8 <usb_pll_start+0x60>)
			CCM_ANALOG_PLL_USB1_CLR = CCM_ANALOG_PLL_USB1_BYPASS;
			continue;
		}
		if (!(n & CCM_ANALOG_PLL_USB1_EN_USB_CLKS)) {
			printf("  enable USB clocks\n");
			CCM_ANALOG_PLL_USB1_SET = CCM_ANALOG_PLL_USB1_EN_USB_CLKS;
6000144c:	movs	r7, #64	; 0x40
			printf("  wait for lock\n");
			continue;
		}
		if (n & CCM_ANALOG_PLL_USB1_BYPASS) {
			printf("  turn off bypass\n");
			CCM_ANALOG_PLL_USB1_CLR = CCM_ANALOG_PLL_USB1_BYPASS;
6000144e:	mov.w	r1, #65536	; 0x10000
			CCM_ANALOG_PLL_USB1_SET = CCM_ANALOG_PLL_USB1_ENABLE;
			continue;
		}
		if (!(n & CCM_ANALOG_PLL_USB1_POWER)) {
			printf("  power up PLL\n");
			CCM_ANALOG_PLL_USB1_SET = CCM_ANALOG_PLL_USB1_POWER;
60001452:	mov.w	r6, #4096	; 0x1000
			continue;
		}
		if (!(n & CCM_ANALOG_PLL_USB1_ENABLE)) {
			printf("  enable PLL\n");
			// TODO: should this be done so early, or later??
			CCM_ANALOG_PLL_USB1_SET = CCM_ANALOG_PLL_USB1_ENABLE;
60001456:	mov.w	r5, #8192	; 0x2000
	while (1) {
		uint32_t n = CCM_ANALOG_PLL_USB1; // pg 759
		printf("CCM_ANALOG_PLL_USB1=%08lX\n", n);
		if (n & CCM_ANALOG_PLL_USB1_DIV_SELECT) {
			printf("  ERROR, 528 MHz mode!\n"); // never supposed to use this mode!
			CCM_ANALOG_PLL_USB1_CLR = 0xC000;			// bypass 24 MHz
6000145a:	mov.w	r4, #49152	; 0xc000
			CCM_ANALOG_PLL_USB1_SET = CCM_ANALOG_PLL_USB1_BYPASS;	// bypass
			CCM_ANALOG_PLL_USB1_CLR = CCM_ANALOG_PLL_USB1_POWER |	// power down
6000145e:	movw	r0, #12354	; 0x3042


FLASHMEM void usb_pll_start()
{
	while (1) {
		uint32_t n = CCM_ANALOG_PLL_USB1; // pg 759
60001462:	ldr	r3, [r2, #16]
		printf("CCM_ANALOG_PLL_USB1=%08lX\n", n);
		if (n & CCM_ANALOG_PLL_USB1_DIV_SELECT) {
60001464:	tst.w	r3, #2
60001468:	beq.n	60001478 <usb_pll_start+0x30>
			printf("  ERROR, 528 MHz mode!\n"); // never supposed to use this mode!
			CCM_ANALOG_PLL_USB1_CLR = 0xC000;			// bypass 24 MHz
6000146a:	str	r4, [r2, #24]
			CCM_ANALOG_PLL_USB1_SET = CCM_ANALOG_PLL_USB1_BYPASS;	// bypass
6000146c:	str	r1, [r2, #20]
			CCM_ANALOG_PLL_USB1_CLR = CCM_ANALOG_PLL_USB1_POWER |	// power down
6000146e:	str	r0, [r2, #24]


FLASHMEM void usb_pll_start()
{
	while (1) {
		uint32_t n = CCM_ANALOG_PLL_USB1; // pg 759
60001470:	ldr	r3, [r2, #16]
		printf("CCM_ANALOG_PLL_USB1=%08lX\n", n);
		if (n & CCM_ANALOG_PLL_USB1_DIV_SELECT) {
60001472:	tst.w	r3, #2
60001476:	bne.n	6000146a <usb_pll_start+0x22>
				CCM_ANALOG_PLL_USB1_DIV_SELECT |		// use 480 MHz
				CCM_ANALOG_PLL_USB1_ENABLE |			// disable
				CCM_ANALOG_PLL_USB1_EN_USB_CLKS;		// disable usb
			continue;
		}
		if (!(n & CCM_ANALOG_PLL_USB1_ENABLE)) {
60001478:	tst.w	r3, #8192	; 0x2000
6000147c:	bne.n	60001482 <usb_pll_start+0x3a>
			printf("  enable PLL\n");
			// TODO: should this be done so early, or later??
			CCM_ANALOG_PLL_USB1_SET = CCM_ANALOG_PLL_USB1_ENABLE;
6000147e:	str	r5, [r2, #20]
			continue;
60001480:	b.n	60001462 <usb_pll_start+0x1a>
		}
		if (!(n & CCM_ANALOG_PLL_USB1_POWER)) {
60001482:	tst.w	r3, #4096	; 0x1000
60001486:	bne.n	6000148c <usb_pll_start+0x44>
			printf("  power up PLL\n");
			CCM_ANALOG_PLL_USB1_SET = CCM_ANALOG_PLL_USB1_POWER;
60001488:	str	r6, [r2, #20]
			continue;
6000148a:	b.n	60001462 <usb_pll_start+0x1a>
		}
		if (!(n & CCM_ANALOG_PLL_USB1_LOCK)) {
6000148c:	cmp	r3, #0
6000148e:	bge.n	60001462 <usb_pll_start+0x1a>
			printf("  wait for lock\n");
			continue;
		}
		if (n & CCM_ANALOG_PLL_USB1_BYPASS) {
60001490:	tst.w	r3, #65536	; 0x10000
60001494:	beq.n	6000149a <usb_pll_start+0x52>
			printf("  turn off bypass\n");
			CCM_ANALOG_PLL_USB1_CLR = CCM_ANALOG_PLL_USB1_BYPASS;
60001496:	str	r1, [r2, #24]
			continue;
60001498:	b.n	60001462 <usb_pll_start+0x1a>
		}
		if (!(n & CCM_ANALOG_PLL_USB1_EN_USB_CLKS)) {
6000149a:	lsls	r3, r3, #25
6000149c:	bmi.n	600014a2 <usb_pll_start+0x5a>
			printf("  enable USB clocks\n");
			CCM_ANALOG_PLL_USB1_SET = CCM_ANALOG_PLL_USB1_EN_USB_CLKS;
6000149e:	str	r7, [r2, #20]
			continue;
600014a0:	b.n	60001462 <usb_pll_start+0x1a>
		}
		return; // everything is as it should be  :-)
	}
}
600014a2:	pop	{r4, r5, r6, r7}
600014a4:	bx	lr
600014a6:	nop
600014a8:	.word	0x400d8000

600014ac <analog_init>:
{
	uint32_t mode, avg=0;

	printf("analogInit\n");

	CCM_CCGR1 |= CCM_CCGR1_ADC1(CCM_CCGR_ON);
600014ac:	ldr	r3, [pc, #68]	; (600014f4 <analog_init+0x48>)
	} else {
		mode |= ADC_CFG_ADIV(0) | ADC_CFG_ADICLK(0); // use IPG
	}
#endif
	//ADC1
	ADC1_CFG = mode | ADC_HC_AIEN | ADC_CFG_ADHSC;
600014ae:	ldr	r1, [pc, #72]	; (600014f8 <analog_init+0x4c>)
{
	uint32_t mode, avg=0;

	printf("analogInit\n");

	CCM_CCGR1 |= CCM_CCGR1_ADC1(CCM_CCGR_ON);
600014b0:	ldr	r0, [r3, #108]	; 0x6c
#endif
	//ADC1
	ADC1_CFG = mode | ADC_HC_AIEN | ADC_CFG_ADHSC;
	ADC1_GC = avg | ADC_GC_CAL;		// begin cal
	calibrating = 1;
	while (ADC1_GC & ADC_GC_CAL) ;
600014b2:	mov	r2, r1
{
	uint32_t mode, avg=0;

	printf("analogInit\n");

	CCM_CCGR1 |= CCM_CCGR1_ADC1(CCM_CCGR_ON);
600014b4:	orr.w	r0, r0, #196608	; 0x30000
}

#define MAX_ADC_CLOCK 20000000

FLASHMEM void analog_init(void)
{
600014b8:	push	{r4, r5}
	uint32_t mode, avg=0;

	printf("analogInit\n");

	CCM_CCGR1 |= CCM_CCGR1_ADC1(CCM_CCGR_ON);
600014ba:	str	r0, [r3, #108]	; 0x6c
	} else {
		mode |= ADC_CFG_ADIV(0) | ADC_CFG_ADICLK(0); // use IPG
	}
#endif
	//ADC1
	ADC1_CFG = mode | ADC_HC_AIEN | ADC_CFG_ADHSC;
600014bc:	movw	r5, #1719	; 0x6b7
	uint32_t mode, avg=0;

	printf("analogInit\n");

	CCM_CCGR1 |= CCM_CCGR1_ADC1(CCM_CCGR_ON);
	CCM_CCGR1 |= CCM_CCGR1_ADC2(CCM_CCGR_ON);
600014c0:	ldr	r0, [r3, #108]	; 0x6c
		mode |= ADC_CFG_ADIV(0) | ADC_CFG_ADICLK(0); // use IPG
	}
#endif
	//ADC1
	ADC1_CFG = mode | ADC_HC_AIEN | ADC_CFG_ADHSC;
	ADC1_GC = avg | ADC_GC_CAL;		// begin cal
600014c2:	movs	r4, #160	; 0xa0
	uint32_t mode, avg=0;

	printf("analogInit\n");

	CCM_CCGR1 |= CCM_CCGR1_ADC1(CCM_CCGR_ON);
	CCM_CCGR1 |= CCM_CCGR1_ADC2(CCM_CCGR_ON);
600014c4:	orr.w	r0, r0, #768	; 0x300
600014c8:	str	r0, [r3, #108]	; 0x6c
	} else {
		mode |= ADC_CFG_ADIV(0) | ADC_CFG_ADICLK(0); // use IPG
	}
#endif
	//ADC1
	ADC1_CFG = mode | ADC_HC_AIEN | ADC_CFG_ADHSC;
600014ca:	str	r5, [r1, #68]	; 0x44
	ADC1_GC = avg | ADC_GC_CAL;		// begin cal
600014cc:	str	r4, [r1, #72]	; 0x48
	calibrating = 1;
	while (ADC1_GC & ADC_GC_CAL) ;
600014ce:	ldr	r3, [r2, #72]	; 0x48
600014d0:	lsls	r3, r3, #24
600014d2:	bmi.n	600014ce <analog_init+0x22>
	calibrating = 0;
	//ADC2
	ADC2_CFG = mode | ADC_HC_AIEN | ADC_CFG_ADHSC;
600014d4:	ldr	r3, [pc, #36]	; (600014fc <analog_init+0x50>)
600014d6:	movw	r0, #1719	; 0x6b7
	ADC2_GC = avg | ADC_GC_CAL;		// begin cal
600014da:	movs	r1, #160	; 0xa0
	calibrating = 1;
	while (ADC2_GC & ADC_GC_CAL) ;
600014dc:	mov	r2, r3
	ADC1_GC = avg | ADC_GC_CAL;		// begin cal
	calibrating = 1;
	while (ADC1_GC & ADC_GC_CAL) ;
	calibrating = 0;
	//ADC2
	ADC2_CFG = mode | ADC_HC_AIEN | ADC_CFG_ADHSC;
600014de:	str	r0, [r3, #68]	; 0x44
	ADC2_GC = avg | ADC_GC_CAL;		// begin cal
600014e0:	str	r1, [r3, #72]	; 0x48
	calibrating = 1;
	while (ADC2_GC & ADC_GC_CAL) ;
600014e2:	ldr	r3, [r2, #72]	; 0x48
600014e4:	ands.w	r3, r3, #128	; 0x80
600014e8:	bne.n	600014e2 <analog_init+0x36>
	calibrating = 0;
600014ea:	ldr	r2, [pc, #20]	; (60001500 <analog_init+0x54>)
600014ec:	strb	r3, [r2, #0]
}
600014ee:	pop	{r4, r5}
600014f0:	bx	lr
600014f2:	nop
600014f4:	.word	0x400fc000
600014f8:	.word	0x400c4000
600014fc:	.word	0x400c8000
60001500:	.word	0x20000ba8

60001504 <tempmon_init>:
  uint32_t calibrationData;
  uint32_t roomCount;
  uint32_t tempCodeVal;
      
  //first power on the temperature sensor - no register change
  TEMPMON_TEMPSENSE0 &= ~0x1U;
60001504:	ldr	r2, [pc, #236]	; (600015f4 <tempmon_init+0xf0>)
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
    roomCount = (uint32_t)(calibrationData & 0xFFF00000U) >> 0x14U;
    s_hot_ROOM = s_hotTemp - 25.0f;
60001506:	vmov.f32	s13, #57	; 0x41c80000  25.0

  //set monitoring frequency - no register change
  TEMPMON_TEMPSENSE1 = (((uint32_t)(((uint32_t)(frequency)) << 0U)) & 0xFFFFU);
  
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
6000150a:	ldr	r1, [pc, #236]	; (600015f8 <tempmon_init+0xf4>)
  
  //Start temp monitoring
  TEMPMON_TEMPSENSE0 |= 0x2U;   //starts temp monitoring

  //PANIC shutdown:
  NVIC_SET_PRIORITY(IRQ_TEMPERATURE_PANIC, 0);
6000150c:	movs	r0, #0
  uint32_t calibrationData;
  uint32_t roomCount;
  uint32_t tempCodeVal;
      
  //first power on the temperature sensor - no register change
  TEMPMON_TEMPSENSE0 &= ~0x1U;
6000150e:	ldr	r3, [r2, #0]
  asm volatile ("dsb":::"memory");
  while (1) asm ("wfi");
}

FLASHMEM void tempmon_init(void)
{
60001510:	push	{r4, r5, r6, r7, lr}
  uint32_t calibrationData;
  uint32_t roomCount;
  uint32_t tempCodeVal;
      
  //first power on the temperature sensor - no register change
  TEMPMON_TEMPSENSE0 &= ~0x1U;
60001512:	bic.w	r3, r3, #1

  //set monitoring frequency - no register change
  TEMPMON_TEMPSENSE1 = (((uint32_t)(((uint32_t)(frequency)) << 0U)) & 0xFFFFU);
60001516:	movs	r4, #3
  
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
60001518:	ldr.w	lr, [pc, #256]	; 6000161c <tempmon_init+0x118>
  uint32_t calibrationData;
  uint32_t roomCount;
  uint32_t tempCodeVal;
      
  //first power on the temperature sensor - no register change
  TEMPMON_TEMPSENSE0 &= ~0x1U;
6000151c:	str	r3, [r2, #0]

  //set monitoring frequency - no register change
  TEMPMON_TEMPSENSE1 = (((uint32_t)(((uint32_t)(frequency)) << 0U)) & 0xFFFFU);
6000151e:	str.w	r4, [r2, #144]	; 0x90
  
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
60001522:	ldr.w	r3, [r1, #224]	; 0xe0
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
    roomCount = (uint32_t)(calibrationData & 0xFFF00000U) >> 0x14U;
    s_hot_ROOM = s_hotTemp - 25.0f;
    s_roomC_hotC = roomCount - s_hotCount;
60001526:	ldr	r7, [pc, #212]	; (600015fc <tempmon_init+0xf8>)
  //set monitoring frequency - no register change
  TEMPMON_TEMPSENSE1 = (((uint32_t)(((uint32_t)(frequency)) << 0U)) & 0xFFFFU);
  
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
60001528:	uxtb	r5, r3
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
6000152a:	ubfx	r4, r3, #8, #12
6000152e:	ldr	r6, [pc, #208]	; (60001600 <tempmon_init+0xfc>)
    roomCount = (uint32_t)(calibrationData & 0xFFF00000U) >> 0x14U;
    s_hot_ROOM = s_hotTemp - 25.0f;
    s_roomC_hotC = roomCount - s_hotCount;
60001530:	rsb	r3, r4, r3, lsr #20
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
    roomCount = (uint32_t)(calibrationData & 0xFFF00000U) >> 0x14U;
    s_hot_ROOM = s_hotTemp - 25.0f;
60001534:	vmov	s15, r5
    s_roomC_hotC = roomCount - s_hotCount;

    //time to set alarm temperatures
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
60001538:	sub.w	r1, r5, #85	; 0x55
  //set monitoring frequency - no register change
  TEMPMON_TEMPSENSE1 = (((uint32_t)(((uint32_t)(frequency)) << 0U)) & 0xFFFFU);
  
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
6000153c:	str.w	r5, [lr]
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
    roomCount = (uint32_t)(calibrationData & 0xFFF00000U) >> 0x14U;
    s_hot_ROOM = s_hotTemp - 25.0f;
60001540:	vcvt.f32.s32	s14, s15
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
60001544:	add.w	r5, r3, r3, lsl #2
    s_hot_ROOM = s_hotTemp - 25.0f;
    s_roomC_hotC = roomCount - s_hotCount;

    //time to set alarm temperatures
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
60001548:	vmov	s15, r4
6000154c:	mul.w	r1, r3, r1
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
    roomCount = (uint32_t)(calibrationData & 0xFFF00000U) >> 0x14U;
    s_hot_ROOM = s_hotTemp - 25.0f;
    s_roomC_hotC = roomCount - s_hotCount;
60001550:	str	r3, [r7, #0]
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
  
  // Set Low Temp Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - lowAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 0U)) & 0xFFFU);
60001552:	add.w	r3, r3, r3, lsl #6
    s_hot_ROOM = s_hotTemp - 25.0f;
    s_roomC_hotC = roomCount - s_hotCount;

    //time to set alarm temperatures
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
60001556:	vcvt.f32.s32	s10, s15
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
6000155a:	vmov	s15, r1
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
6000155e:	subs	r1, r1, r5
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
    roomCount = (uint32_t)(calibrationData & 0xFFF00000U) >> 0x14U;
    s_hot_ROOM = s_hotTemp - 25.0f;
60001560:	vsub.f32	s13, s14, s13
    s_roomC_hotC = roomCount - s_hotCount;

    //time to set alarm temperatures
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
60001564:	vcvt.f32.u32	s14, s15
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
    roomCount = (uint32_t)(calibrationData & 0xFFF00000U) >> 0x14U;
    s_hot_ROOM = s_hotTemp - 25.0f;
60001568:	ldr	r5, [pc, #152]	; (60001604 <tempmon_init+0x100>)
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
6000156a:	vmov	s15, r1
  
  // Set Low Temp Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - lowAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 0U)) & 0xFFFU);
6000156e:	add	r3, r1
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
    roomCount = (uint32_t)(calibrationData & 0xFFF00000U) >> 0x14U;
    s_hot_ROOM = s_hotTemp - 25.0f;
60001570:	vstr	s13, [r5]
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
60001574:	vcvt.f32.u32	s15, s15
  TEMPMON_TEMPSENSE1 = (((uint32_t)(((uint32_t)(frequency)) << 0U)) & 0xFFFFU);
  
  //read calibration data - this works
  calibrationData = HW_OCOTP_ANA1;
    s_hotTemp = (uint32_t)(calibrationData & 0xFFU) >> 0x00U;
    s_hotCount = (uint32_t)(calibrationData & 0xFFF00U) >> 0X08U;
60001578:	str	r4, [r6, #0]
    s_roomC_hotC = roomCount - s_hotCount;

    //time to set alarm temperatures
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
6000157a:	vdiv.f32	s11, s14, s13
6000157e:	ldr	r6, [pc, #136]	; (60001608 <tempmon_init+0x104>)
60001580:	ldr	r5, [r2, #0]
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
60001582:	ldr	r1, [pc, #136]	; (6000160c <tempmon_init+0x108>)
  
  //Start temp monitoring
  TEMPMON_TEMPSENSE0 |= 0x2U;   //starts temp monitoring

  //PANIC shutdown:
  NVIC_SET_PRIORITY(IRQ_TEMPERATURE_PANIC, 0);
60001584:	ldr	r4, [pc, #136]	; (60001610 <tempmon_init+0x10c>)
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
60001586:	vdiv.f32	s12, s15, s13
  
  // Set Low Temp Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - lowAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 0U)) & 0xFFFU);
6000158a:	vmov	s15, r3
6000158e:	ldr	r3, [pc, #132]	; (60001614 <tempmon_init+0x110>)
60001590:	str.w	r3, [r6, #320]	; 0x140
60001594:	vcvt.f32.u32	s15, s15
60001598:	vdiv.f32	s14, s15, s13
    s_roomC_hotC = roomCount - s_hotCount;

    //time to set alarm temperatures
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
6000159c:	vadd.f32	s11, s11, s10
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
600015a0:	vadd.f32	s13, s12, s10
    s_roomC_hotC = roomCount - s_hotCount;

    //time to set alarm temperatures
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
600015a4:	vcvt.u32.f32	s11, s11
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
600015a8:	vcvt.u32.f32	s13, s13
    s_roomC_hotC = roomCount - s_hotCount;

    //time to set alarm temperatures
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
600015ac:	vmov	r3, s11
600015b0:	orr.w	r3, r5, r3, lsl #20
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
600015b4:	vmov	r5, s13
  
  // Set Low Temp Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - lowAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 0U)) & 0xFFFU);
600015b8:	vadd.f32	s15, s14, s10
    s_roomC_hotC = roomCount - s_hotCount;

    //time to set alarm temperatures
  //Set High Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
600015bc:	str	r3, [r2, #0]
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
600015be:	and.w	r1, r1, r5, lsl #16
600015c2:	ldr.w	r3, [r2, #272]	; 0x110
  
  // Set Low Temp Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - lowAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 0U)) & 0xFFFU);
600015c6:	vcvt.u32.f32	s15, s15
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - highAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE0 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 20U)) & 0xFFF00000U);
  
  //Set Panic Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - panicAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 16U)) & 0xFFF0000U);
600015ca:	orrs	r3, r1
600015cc:	str.w	r3, [r2, #272]	; 0x110
  
  // Set Low Temp Alarm Temp
  tempCodeVal = (uint32_t)(s_hotCount + (s_hotTemp - lowAlarmTemp) * s_roomC_hotC / s_hot_ROOM);
    TEMPMON_TEMPSENSE2 |= (((uint32_t)(((uint32_t)(tempCodeVal)) << 0U)) & 0xFFFU);
600015d0:	vmov	r3, s15
600015d4:	ldr.w	r1, [r2, #272]	; 0x110
600015d8:	ubfx	r3, r3, #0, #12
600015dc:	orrs	r3, r1
600015de:	str.w	r3, [r2, #272]	; 0x110
  
  //Start temp monitoring
  TEMPMON_TEMPSENSE0 |= 0x2U;   //starts temp monitoring
600015e2:	ldr	r3, [r2, #0]
600015e4:	orr.w	r3, r3, #2
600015e8:	str	r3, [r2, #0]

  //PANIC shutdown:
  NVIC_SET_PRIORITY(IRQ_TEMPERATURE_PANIC, 0);
600015ea:	strb	r0, [r4, #0]
  attachInterruptVector(IRQ_TEMPERATURE_PANIC, &Panic_Temp_isr);
  NVIC_ENABLE_IRQ(IRQ_TEMPERATURE_PANIC);
600015ec:	ldr	r3, [pc, #40]	; (60001618 <tempmon_init+0x114>)
600015ee:	movs	r2, #1
600015f0:	str	r2, [r3, #0]
600015f2:	pop	{r4, r5, r6, r7, pc}
600015f4:	.word	0x400d8180
600015f8:	.word	0x401f4400
600015fc:	.word	0x20000bb4
60001600:	.word	0x20000bb8
60001604:	.word	0x20000bb0
60001608:	.word	0x20002400
6000160c:	.word	0x0fff0000
60001610:	.word	0xe000e440
60001614:	.word	0x00007191
60001618:	.word	0xe000e108
6000161c:	.word	0x20000bac

60001620 <usb_string_product_name_default>:
60001620:	..U.S.B. .S.e.r.
60001630:	i.a.l...

60001638 <usb_string_manufacturer_name_default>:
60001638:	..T.e.e.n.s.y.d.
60001648:	u.i.n.o.

60001650 <string0>:
60001650:	....

60001654 <usb_config_descriptor_12>:
60001654:	..C.....2.......
60001664:	...$....$....$..
60001674:	.$..............
60001684:	.........@......
60001694:	@...

60001698 <usb_config_descriptor_480>:
60001698:	..C.....2.......
600016a8:	...$....$....$..
600016b8:	.$..............
600016c8:	................
600016d8:	....

600016dc <qualifier_descriptor>:
600016dc:	.......@....

600016e8 <_init>:
600016e8:	push	{r3, r4, r5, r6, r7, lr}
600016ea:	nop
600016ec:	pop	{r3, r4, r5, r6, r7}
600016ee:	pop	{r3}
600016f0:	mov	lr, r3
600016f2:	bx	lr
600016f4:			; <UNDEFINED> instruction: 0xffffffff

600016f8 <__startup_early_hook_veneer>:
600016f8:	ldr.w	pc, [pc]	; 600016fc <__startup_early_hook_veneer+0x4>
600016fc:	.word	0x00006db9

60001700 <__usb_init_serialnumber_veneer>:
60001700:	ldr.w	pc, [pc]	; 60001704 <__usb_init_serialnumber_veneer+0x4>
60001704:	.word	0x0000682d

60001708 <__main_veneer>:
60001708:	ldr.w	pc, [pc]	; 6000170c <__main_veneer+0x4>
6000170c:	.word	0x00006885

60001710 <____libc_init_array_veneer>:
60001710:	ldr.w	pc, [pc]	; 60001714 <____libc_init_array_veneer+0x4>
60001714:	.word	0x000071e9

60001718 <__memset_veneer>:
60001718:	ldr.w	pc, [pc]	; 6000171c <__memset_veneer+0x4>
6000171c:	.word	0x000077c9

60001720 <__set_arm_clock_veneer>:
60001720:	ldr.w	pc, [pc]	; 60001724 <__set_arm_clock_veneer+0x4>
60001724:	.word	0x00006e7d

60001728 <__startup_late_hook_veneer>:
60001728:	ldr.w	pc, [pc]	; 6000172c <__startup_late_hook_veneer+0x4>
6000172c:	.word	0x00006dbd

60001730 <__pwm_init_veneer>:
60001730:	ldr.w	pc, [pc]	; 60001734 <__pwm_init_veneer+0x4>
60001734:	.word	0x00006575

60001738 <__delay_veneer>:
60001738:	ldr.w	pc, [pc]	; 6000173c <__delay_veneer+0x4>
6000173c:	.word	0x000064a9

60001740 <__init_array_start>:
60001740:	.word	0x00000045

60001744 <__init_array_end>:
60001744:	.word	0xffffffff
60001748:	.word	0xffffffff
6000174c:	.word	0xffffffff

Disassembly of section .text.itcm:

00000000 <_stext>:
	...

00000020 <__do_global_dtors_aux>:
{
	__disable_irq();
	sof_usage |= (1 << interface);
	uint32_t intr = USB1_USBINTR;
	if (!(intr & USB_USBINTR_SRE)) {
		USB1_USBSTS = USB_USBSTS_SRI; // clear prior SOF before SOF IRQ enable
      20:	.word	0x4c05b510
		USB1_USBINTR = intr | USB_USBINTR_SRE;
      24:	ldrb	r3, [r4, #0]
      26:	.short	0xb933
	}
	__enable_irq();
      28:	ldr	r3, [pc, #16]	; (3c <__rtc_localtime+0xb>)
      2a:	.short	0xb113
      2c:	ldr	r0, [pc, #16]	; (40 <__rtc_localtime+0xf>)
      2e:	.short	0xf3af
      30:	strh	r0, [r0, #0]
      32:	movs	r3, #1
    /* ready to read temperature code value */
    nmeas = (TEMPMON_TEMPSENSE0 & 0xFFF00U) >> 8U;
    /* Calculate temperature */
    tmeas = s_hotTemp - (float)((nmeas - s_hotCount) * s_hot_ROOM / s_roomC_hotC);

    return tmeas;
      34:	strb	r3, [r4, #0]
      36:	pop	{r4, pc}
      38:	.word	0x20000940
      3c:	movs	r0, r0
      3e:	.short	0x0000
}
      40:	ldrb	r4, [r2, #12]
	...

00000044 <frame_dummy>:
      44:	.word	0xb5104b08
      48:	cbz	r3, 52 <frame_dummy+0xe>
      4a:	.short	0x4908
      4c:	ldr	r0, [pc, #32]	; (70 <frame_dummy+0x2c>)
      4e:	.short	0xf3af
      50:	strh	r0, [r0, #0]
      52:	.short	0x4808
      54:	ldr	r3, [r0, #0]
      56:	.short	0xb903
      58:	pop	{r4, pc}
      5a:	.short	0x4b07
      mode |= 0;
      mode1 |= 0;
    }

  ADC1_CFG = mode;
  ADC2_CFG = mode1;
      5c:	cmp	r3, #0

    } else if (num >= 16) {
      mode |= ADC_CFG_AVGS(2);
      mode1 |= ADC_CFG_AVGS(2);

    } else if (num >= 8) {
      5e:	beq.n	58 <frame_dummy+0x14>
      60:	.word	0x4010e8bd
      mode |= ADC_CFG_AVGS(1);
      64:	bx	r3
      mode1 |= ADC_CFG_AVGS(1);
      66:	.short	0xbf00
      68:	movs	r0, r0
    } else {
      mode |= 0;
      mode1 |= 0;
    }

  ADC1_CFG = mode;
      6a:	.short	0x0000
  ADC2_CFG = mode1;
  
  if(num >= 4){
      6c:	lsrs	r4, r0, #5
      mode |= 0;
      mode1 |= 0;
    }

  ADC1_CFG = mode;
  ADC2_CFG = mode1;
      6e:	movs	r0, #0
    } else {
      mode |= 0;
      mode1 |= 0;
    }

  ADC1_CFG = mode;
      70:	ldrb	r4, [r2, #12]
  ADC2_CFG = mode1;
      72:	movs	r0, r0
  
  if(num >= 4){
      74:	lsrs	r0, r0, #5
      ADC1_GC |= ADC_GC_AVGE;// turns on averaging
      ADC2_GC |= ADC_GC_AVGE;// turns on averaging
  }
}
      76:	.short	0x2000
      78:	movs	r0, r0
	...

0000007c <setup>:

void print_mtxf(const Eigen::MatrixXf& K);

boolean ran = false;

void setup() {
      7c:	bx	lr
      7e:	nop

00000080 <print_mtxf(Eigen::Matrix<float, -1, -1, 0, -1, -1> const&)>:
      80:	.word	0x41f0e92d
	while (1) {
		volatile uint32_t n;
		GPIO2_DR_SET = (1<<3); //digitalWrite(13, HIGH);
		for (n=0; n < 2000000/6; n++) ;
		GPIO2_DR_CLEAR = (1<<3); //digitalWrite(13, LOW);
		for (n=0; n < 1500000/6; n++) ;
      84:	mov	r8, r0
      86:	.short	0x2106
        virtual int read() { return usb_serial_getchar(); }
        virtual int peek() { return usb_serial_peekchar(); }
        virtual void flush() { usb_serial_flush_output(); }  // TODO: actually wait for data to leave USB...
        virtual void clear(void) { usb_serial_flush_input(); }
        virtual size_t write(uint8_t c) { return usb_serial_putchar(c); }
        virtual size_t write(const uint8_t *buffer, size_t size) { return usb_serial_write(buffer, size); }
      88:	ldr	r0, [pc, #132]	; (110 <print_mtxf(Eigen::Matrix<float, -1, -1, 0, -1, -1> const&)+0x90>)
      8a:	ldr.w	r7, [r8, #4]
      8e:	ldr.w	r6, [r8, #8]
      92:	bl	5a88 <usb_serial_write>
	size_t print(char c)				{ return write((uint8_t)c); }
	size_t print(const char s[])			{ return write(s); }
	size_t print(const __FlashStringHelper *f)	{ return write((const char *)f); }

	size_t print(uint8_t b)				{ return printNumber(b, 10, 0); }
	size_t print(int n)				{ return print((long)n); }
      96:	mov	r1, r7
      98:	ldr	r0, [pc, #120]	; (114 <print_mtxf(Eigen::Matrix<float, -1, -1, 0, -1, -1> const&)+0x94>)
      9a:	bl	6c0c <Print::print(long)>
	size_t println(char c)				{ return print(c) + println(); }
	size_t println(const char s[])			{ return print(s) + println(); }
	size_t println(const __FlashStringHelper *f)	{ return print(f) + println(); }

	size_t println(uint8_t b)			{ return print(b) + println(); }
	size_t println(int n)				{ return print(n) + println(); }
      9e:	ldr	r0, [pc, #116]	; (114 <print_mtxf(Eigen::Matrix<float, -1, -1, 0, -1, -1> const&)+0x94>)
      a0:	bl	6b6c <Print::println()>
      a4:	.word	0x481c2106
      a8:	bl	5a88 <usb_serial_write>
	size_t print(char c)				{ return write((uint8_t)c); }
	size_t print(const char s[])			{ return write(s); }
	size_t print(const __FlashStringHelper *f)	{ return write((const char *)f); }

	size_t print(uint8_t b)				{ return printNumber(b, 10, 0); }
	size_t print(int n)				{ return print((long)n); }
      ac:	.word	0x48194631
      b0:	bl	6c0c <Print::print(long)>
	size_t println(char c)				{ return print(c) + println(); }
	size_t println(const char s[])			{ return print(s) + println(); }
	size_t println(const __FlashStringHelper *f)	{ return print(f) + println(); }

	size_t println(uint8_t b)			{ return print(b) + println(); }
	size_t println(int n)				{ return print(n) + println(); }
      b4:	.word	0xf0064817
      b8:	ldc2l	8, cr4, [r9, #-88]	; 0xffffffa8
    nrow = X.rows();
    ncol = X.cols();

    Serial.print("nrow: "); Serial.println(nrow);
    Serial.print("ncol: "); Serial.println(ncol);       
    Serial.println();
      bc:	bl	6b6c <Print::println()>
   
    for (i=0; i<nrow; i++)
      c0:	.word	0xdd202f00
      c4:	movs	r5, #0
    {
        for (j=0; j<ncol; j++)
      c6:	cmp	r6, #0
      c8:	.word	0x2400dd17
        {
            Serial.print(X(i,j), 6);   // print 6 decimal places
      cc:	ldr.w	r2, [r8, #4]
	size_t print(int n, int base)			{ return (base == 10) ? print(n) : printNumber(n, base, 0); }
	size_t print(unsigned int n, int base)		{ return printNumber(n, base, 0); }
	size_t print(long n, int base)			{ return (base == 10) ? print(n) : printNumber(n, base, 0); }
	size_t print(unsigned long n, int base)		{ return printNumber(n, base, 0); }

	size_t print(double n, int digits = 2)		{ return printFloat(n, digits); }
      d0:	.word	0xf8d82106
      d4:	adds	r0, #0
      d6:	mla	r2, r2, r4, r5
      da:	.short	0x480e
    Serial.print("ncol: "); Serial.println(ncol);       
    Serial.println();
   
    for (i=0; i<nrow; i++)
    {
        for (j=0; j<ncol; j++)
      dc:	adds	r4, #1
        {
            Serial.print(X(i,j), 6);   // print 6 decimal places
      de:	.short	0xeb03
      e0:	lsls	r2, r0, #14
      e2:	.short	0xed93
      e4:	lsrs	r0, r0, #8
      e6:	vcvt.f64.f32	d0, s0
      ea:	.short	0xf006
      ec:	ldc2	1, cr2, [sp, #8]
      f0:	.word	0xf005480a
      f4:	stc2l	2, cr4, [r9], {166}	; 0xa6
    Serial.print("ncol: "); Serial.println(ncol);       
    Serial.println();
   
    for (i=0; i<nrow; i++)
    {
        for (j=0; j<ncol; j++)
      f8:	bne.n	cc <print_mtxf(Eigen::Matrix<float, -1, -1, 0, -1, -1> const&)+0x4c>

    Serial.print("nrow: "); Serial.println(nrow);
    Serial.print("ncol: "); Serial.println(ncol);       
    Serial.println();
   
    for (i=0; i<nrow; i++)
      fa:	.short	0x3501
        for (j=0; j<ncol; j++)
        {
            Serial.print(X(i,j), 6);   // print 6 decimal places
            Serial.print(", ");
        }
        Serial.println();
      fc:	ldr	r0, [pc, #20]	; (114 <print_mtxf(Eigen::Matrix<float, -1, -1, 0, -1, -1> const&)+0x94>)
      fe:	.short	0xf006
     100:	ldc2	2, cr4, [r5, #-700]!	; 0xfffffd44

    Serial.print("nrow: "); Serial.println(nrow);
    Serial.print("ncol: "); Serial.println(ncol);       
    Serial.println();
   
    for (i=0; i<nrow; i++)
     104:	bne.n	c6 <print_mtxf(Eigen::Matrix<float, -1, -1, 0, -1, -1> const&)+0x46>
            Serial.print(X(i,j), 6);   // print 6 decimal places
            Serial.print(", ");
        }
        Serial.println();
    }
    Serial.println();
     106:	.short	0x4803
     108:	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
            Serial.print(X(i,j), 6);   // print 6 decimal places
            Serial.print(", ");
        }
        Serial.println();
    }
    Serial.println();
     10c:	.word	0xbd2ef006
     110:	movs	r0, r0
     112:	.short	0x2000
     114:	lsls	r4, r4, #3
     116:	movs	r0, #0
     118:	.word	0x20000008
     11c:	movs	r0, r2
     11e:	.short	0x2000

00000120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>:
      * Output: \verbinclude Matrix_resize_int_int.out
      *
      * \sa resize(Index) for vectors, resize(NoChange_t, Index), resize(Index, NoChange_t)
      */
    EIGEN_DEVICE_FUNC
    EIGEN_STRONG_INLINE void resize(Index rows, Index cols)
     120:	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
     124:	.word	0x46174604
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
     128:	mov	r6, r1
     12a:	.short	0xb131
     12c:	cbz	r2, 13a <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)+0x1a>
     12e:	.short	0xf06f
     130:	orrs	r0, r0
     132:	sdiv	r3, r3, r2
     136:	.short	0x4299
     138:	bgt.n	162 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)+0x42>
      m_rows = rows;
      m_cols = cols;
    }
    EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
    {
      if(size != m_rows*m_cols)
     13a:	.short	0x6862
        Index size = rows*cols;
        bool size_changed = size != this->size();
        m_storage.resize(size, rows, cols);
        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
      #else
        m_storage.resize(rows*cols, rows, cols);
     13c:	mul.w	r5, r7, r6
     140:	.word	0xfb0368a3
     144:	ssat	r2, #30, r2, lsl #18
     148:	.word	0x6823d007
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
     14c:	cbz	r3, 156 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)+0x36>
     14e:	.short	0xf853
     150:	lsrs	r4, r0, #16
     152:	bl	7248 <free>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
        if (size)
     156:	.short	0xb94d
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
     158:	str	r5, [r4, #0]
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
     15a:	.short	0x6066
      m_cols = cols;
     15c:	str	r7, [r4, #8]
      #endif
    }
     15e:	.short	0xe8bd
     160:	strh	r0, [r6, #14]
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
     162:	.short	0xf04f
     164:	adds	r0, #255	; 0xff
     166:	bl	6d9c <operator new(unsigned int)>
     16a:	.short	0xe7e6
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
     16c:	cmp.w	r5, #1073741824	; 0x40000000
     170:	.word	0x00add210
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
     174:	add.w	r0, r5, #16
     178:	.word	0xf85ef007
  if (original == 0) return 0;
     17c:	mov	r8, r0
     17e:	.short	0xb170
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
     180:	bic.w	r0, r0, #15
     184:	.word	0xf8403010
  *(reinterpret_cast<void**>(aligned) - 1) = original;
     188:	ldrh	r4, [r0, #32]
    {
      if(size != m_rows*m_cols)
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
        if (size)
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
     18a:	.short	0x6020
        else
          m_data = 0;
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
     18c:	str	r6, [r4, #4]
      m_cols = cols;
     18e:	str	r7, [r4, #8]
     190:	.word	0x81f0e8bd
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
     194:	mov.w	r0, #4294967295
     198:	.word	0xfe00f006
     19c:	b.n	172 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)+0x52>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
     19e:	.short	0xb12d
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
     1a0:	mov.w	r0, #4294967295
     1a4:	.word	0xfdfaf006
     1a8:	mov	r0, r8
     1aa:	b.n	18a <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)+0x6a>
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
     1ac:	.word	0xe7ec4628

000001b0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)>:
 * - the number of scalars that fit into a packet (when vectorization is enabled).
 *
 * \sa setCpuCacheSizes */

template<typename LhsScalar, typename RhsScalar, int KcFactor, typename Index>
void evaluateProductBlockingSizesHeuristic(Index& k, Index& m, Index& n, Index num_threads = 1)
     1b0:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
     1b4:	.word	0xb0834fbc
     1b8:	ldr	r4, [r7, #0]
     1ba:	.short	0x07e4
     1bc:	bpl.n	26c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0xbc>
     1be:	ldr	r5, [pc, #748]	; (4ac <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x2fc>)
  // per mr x kc horizontal small panels where mr is the blocking size along the m dimension
  // at the register level. This small horizontal panel has to stay within L1 cache.
  std::ptrdiff_t l1, l2, l3;
  manage_caching_sizes(GetAction, &l1, &l2, &l3);

  if (num_threads > 1) {
     1c0:	cmp	r3, #1
     1c2:	ldmia.w	r5, {r4, r6}
     1c6:	ldr	r5, [r5, #8]
     1c8:	ble.n	296 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0xe6>
     1ca:	.short	0xf1a4
     1cc:	lsrs	r0, r4, #24
     1ce:	.short	0x4fb8
    // Increasing k gives us more time to prefetch the content of the "C"
    // registers. However once the latency is hidden there is no point in
    // increasing the value of k, so we'll cap it at 320 (value determined
    // experimentally).
    const Index k_cache = (numext::mini<Index>)((l1-ksub)/kdiv, 320);
    if (k_cache < k) {
     1d0:	ldr.w	ip, [r0]
     1d4:	smull	r8, r7, r7, lr
     1d8:	mov.w	lr, lr, asr #31
     1dc:	rsb	r7, lr, r7, asr #2
     1e0:	.word	0x7fa0f5b7
     1e4:	it	ge
     1e6:	movge.w	r7, #320	; 0x140
     1ea:	cmp	ip, r7
     1ec:	ble.n	206 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x56>
      k = k_cache - (k_cache % kr);
     1ee:	ldr.w	ip, [pc, #716]	; 4bc <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x30c>
     1f2:	and.w	ip, r7, ip
     1f6:	cmp.w	ip, #0
     1fa:	blt.w	366 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1b6>
     1fe:	rsb	ip, ip, r7
     202:	str.w	ip, [r0]
     206:	ldr.w	lr, [r2]
      eigen_internal_assert(k > 0);
    }

    const Index n_cache = (l2-l1) / (nr * sizeof(RhsScalar) * k);
     20a:	subs	r4, r6, r4
     20c:	mov.w	ip, ip, lsl #4
// Integer division with rounding up.
// T is assumed to be an integer type with a>=0, and b>0
template<typename T>
T div_ceil(const T &a, const T &b)
{
  return (a+b-1) / b;
     210:	add.w	r7, r3, lr
     214:	subs	r7, #1
     216:	udiv	r4, r4, ip
     21a:	sdiv	r7, r7, r3
    const Index n_per_thread = numext::div_ceil(n, num_threads);
    if (n_cache <= n_per_thread) {
     21e:	cmp	r4, r7
     220:	ble.w	334 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x184>
      // Don't exceed the capacity of the l2 cache.
      eigen_internal_assert(n_cache >= static_cast<Index>(nr));
      n = n_cache - (n_cache % nr);
      eigen_internal_assert(n > 0);
    } else {
      n = (numext::mini<Index>)(n, (n_per_thread + nr - 1) - ((n_per_thread + nr - 1) % nr));
     224:	adds	r7, #3
     226:	ldr	r4, [pc, #652]	; (4b4 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x304>)
     228:	ands	r4, r7
     22a:	cmp	r4, #0
     22c:	blt.w	35c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1ac>
     230:	subs	r7, r7, r4
     232:	cmp	r7, lr
     234:	it	ge
     236:	movge	r7, lr
     238:	str	r7, [r2, #0]
    }

    if (l3 > l2) {
     23a:	cmp	r5, r6
     23c:	ble.w	356 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1a6>
     240:	ldr	r4, [r1, #0]
      // l3 is shared between all cores, so we'll give each thread its own chunk of l3.
      const Index m_cache = (l3-l2) / (sizeof(LhsScalar) * k * num_threads);
     242:	lsls	r7, r3, #2
     244:	ldr	r0, [r0, #0]
     246:	subs	r6, r5, r6
     248:	adds	r2, r3, r4
     24a:	mul.w	r5, r0, r7
     24e:	subs	r2, #1
     250:	udiv	r5, r6, r5
     254:	sdiv	r3, r2, r3
      const Index m_per_thread = numext::div_ceil(m, num_threads);
      if(m_cache < m_per_thread && m_cache >= static_cast<Index>(mr)) {
     258:	cmp	r5, r3
     25a:	bge.n	342 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x192>
     25c:	cmp	r5, #1
     25e:	ble.n	342 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x192>
        m = m_cache - (m_cache % mr);
     260:	bic.w	r5, r5, #1
     264:	str	r5, [r1, #0]
      else if (mc==0) return;
      m = (m%mc)==0 ? mc
                    : (mc - Traits::mr * ((mc/*-1*/-(m%mc))/(Traits::mr*(m/mc+1))));
    }
  }
}
     266:	add	sp, #12
     268:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
     26c:	mov.w	ip, #524288	; 0x80000
/** \internal */
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
     270:	ldr.w	lr, [pc, #568]	; 4ac <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x2fc>
     274:	mov.w	r8, #16384	; 0x4000
  // per mr x kc horizontal small panels where mr is the blocking size along the m dimension
  // at the register level. This small horizontal panel has to stay within L1 cache.
  std::ptrdiff_t l1, l2, l3;
  manage_caching_sizes(GetAction, &l1, &l2, &l3);

  if (num_threads > 1) {
     278:	cmp	r3, #1
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
     27a:	str.w	ip, [lr, #4]


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
     27e:	mov	r5, ip
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
    m_l3 = manage_caching_sizes_helper(l3CacheSize, defaultL3CacheSize);
     280:	str.w	ip, [lr, #8]


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
     284:	mov	r4, r8
/** \internal */
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
     286:	str.w	r8, [lr]


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
     28a:	mov.w	lr, #1
     28e:	mov	r6, ip
     290:	str.w	lr, [r7]
  // per mr x kc horizontal small panels where mr is the blocking size along the m dimension
  // at the register level. This small horizontal panel has to stay within L1 cache.
  std::ptrdiff_t l1, l2, l3;
  manage_caching_sizes(GetAction, &l1, &l2, &l3);

  if (num_threads > 1) {
     294:	bgt.n	1ca <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1a>
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
     296:	ldr	r7, [r1, #0]
     298:	ldr.w	ip, [r2]
     29c:	ldr.w	lr, [r0]

    // Early return for small problems because the computation below are time consuming for small problems.
    // Perhaps it would make more sense to consider k*n*m??
    // Note that for very tiny problem, this function should be bypassed anyway
    // because we use the coefficient-based implementation for them.
    if((numext::maxi)(k,(numext::maxi)(m,n))<48)
     2a0:	cmp	ip, r7
     2a2:	mov	r3, ip
     2a4:	it	lt
     2a6:	movlt	r3, r7
     2a8:	cmp	r3, lr
     2aa:	it	lt
     2ac:	movlt	r3, lr
     2ae:	cmp	r3, #47	; 0x2f
     2b0:	ble.n	356 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1a6>
    // Blocking on the third dimension (i.e., k) is chosen so that an horizontal panel
    // of size mr x kc of the lhs plus a vertical panel of kc x nr of the rhs both fits within L1 cache.
    // We also include a register-level block of the result (mx x nr).
    // (In an ideal world only the lhs panel would stay in L1)
    // Moreover, kc has to be a multiple of 8 to be compatible with loop peeling, leading to a maximum blocking size of:
    const Index max_kc = numext::maxi<Index>(((l1-k_sub)/k_div) & (~(k_peeling-1)),1);
     2b2:	sub.w	r8, r4, #32
     2b6:	ldr.w	fp, [pc, #504]	; 4b0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x300>
     2ba:	mov.w	r3, r8, asr #31
     2be:	smull	r9, fp, fp, r8
     2c2:	rsb	fp, r3, fp, asr #2
     2c6:	bic.w	fp, fp, #7
     2ca:	cmp.w	fp, #0
     2ce:	ble.w	438 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x288>
    const Index old_k = k;
    if(k>max_kc)
     2d2:	cmp	fp, lr
     2d4:	blt.n	388 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1d8>
     2d6:	mov.w	r3, lr, lsl #3
     2da:	mov.w	r9, #1572864	; 0x180000
     2de:	mov	r0, r7
     2e0:	str.w	fp, [sp]
     2e4:	mov.w	sl, lr, lsl #2
     2e8:	mov	r7, lr
     2ea:	mov.w	fp, lr, lsl #4
     2ee:	udiv	r9, r9, r3
    // to limit this growth: we bound nc to growth by a factor x1.5.
    // However, if the entire lhs block fit within L1, then we are not going to block on the rows at all,
    // and it becomes fruitful to keep the packed rhs blocks in L1 if there is enough remaining space.
    Index max_nc;
    const Index lhs_bytes = m * k * sizeof(LhsScalar);
    const Index remaining_l1 = l1- k_sub - lhs_bytes;
     2f2:	mul.w	r3, r7, r0
     2f6:	sub.w	r3, r8, r3, lsl #2
    if(remaining_l1 >= Index(Traits::nr*sizeof(RhsScalar))*k)
     2fa:	cmp	r3, fp
     2fc:	blt.w	428 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x278>
    {
      // L1 blocking
      max_nc = remaining_l1 / (k*sizeof(RhsScalar));
     300:	udiv	r3, r3, sl
    {
      // L2 blocking
      max_nc = (3*actual_l2)/(2*2*max_kc*sizeof(RhsScalar));
    }
    // WARNING Below, we assume that Traits::nr is a power of two.
    Index nc = numext::mini<Index>(actual_l2/(2*k*sizeof(RhsScalar)), max_nc) & (~(Traits::nr-1));
     304:	cmp	r9, r3
     306:	it	ge
     308:	movge	r9, r3
     30a:	bic.w	r9, r9, #3
    if(n>nc)
     30e:	cmp	r9, ip
     310:	bge.n	3cc <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x21c>
    {
      // We are really blocking over the columns:
      // -> reduce blocking size to make sure the last block is as large as possible
      //    while keeping the same number of sweeps over the packed lhs.
      //    Here we allow one more sweep if this gives us a perfect match, thus the commented "-1"
      n = (n%nc)==0 ? nc
     312:	sdiv	r1, ip, r9
     316:	mls	r3, r9, r1, ip
     31a:	cmp	r3, #0
     31c:	beq.w	460 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x2b0>
     320:	adds	r1, #1
     322:	rsb	ip, r3, r9
     326:	lsls	r3, r1, #2
     328:	sdiv	r3, ip, r3
     32c:	sub.w	r3, r9, r3, lsl #2
     330:	str	r3, [r2, #0]
     332:	b.n	356 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1a6>
    const Index n_cache = (l2-l1) / (nr * sizeof(RhsScalar) * k);
    const Index n_per_thread = numext::div_ceil(n, num_threads);
    if (n_cache <= n_per_thread) {
      // Don't exceed the capacity of the l2 cache.
      eigen_internal_assert(n_cache >= static_cast<Index>(nr));
      n = n_cache - (n_cache % nr);
     334:	ldr	r7, [pc, #380]	; (4b4 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x304>)
     336:	ands	r7, r4
     338:	cmp	r7, #0
     33a:	blt.n	374 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1c4>
     33c:	subs	r4, r4, r7
     33e:	str	r4, [r2, #0]
     340:	b.n	23a <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x8a>
      const Index m_per_thread = numext::div_ceil(m, num_threads);
      if(m_cache < m_per_thread && m_cache >= static_cast<Index>(mr)) {
        m = m_cache - (m_cache % mr);
        eigen_internal_assert(m > 0);
      } else {
        m = (numext::mini<Index>)(m, (m_per_thread + mr - 1) - ((m_per_thread + mr - 1) % mr));
     342:	adds	r3, #1
     344:	ldr	r2, [pc, #368]	; (4b8 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x308>)
     346:	ands	r2, r3
     348:	cmp	r2, #0
     34a:	blt.n	37e <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1ce>
     34c:	subs	r3, r3, r2
     34e:	cmp	r3, r4
     350:	it	ge
     352:	movge	r3, r4
     354:	str	r3, [r1, #0]
      else if (mc==0) return;
      m = (m%mc)==0 ? mc
                    : (mc - Traits::mr * ((mc/*-1*/-(m%mc))/(Traits::mr*(m/mc+1))));
    }
  }
}
     356:	add	sp, #12
     358:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
      // Don't exceed the capacity of the l2 cache.
      eigen_internal_assert(n_cache >= static_cast<Index>(nr));
      n = n_cache - (n_cache % nr);
      eigen_internal_assert(n > 0);
    } else {
      n = (numext::mini<Index>)(n, (n_per_thread + nr - 1) - ((n_per_thread + nr - 1) % nr));
     35c:	subs	r4, #1
     35e:	orn	r4, r4, #3
     362:	adds	r4, #1
     364:	b.n	230 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x80>
    // registers. However once the latency is hidden there is no point in
    // increasing the value of k, so we'll cap it at 320 (value determined
    // experimentally).
    const Index k_cache = (numext::mini<Index>)((l1-ksub)/kdiv, 320);
    if (k_cache < k) {
      k = k_cache - (k_cache % kr);
     366:	add.w	ip, ip, #4294967295
     36a:	orn	ip, ip, #7
     36e:	add.w	ip, ip, #1
     372:	b.n	1fe <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x4e>
    const Index n_cache = (l2-l1) / (nr * sizeof(RhsScalar) * k);
    const Index n_per_thread = numext::div_ceil(n, num_threads);
    if (n_cache <= n_per_thread) {
      // Don't exceed the capacity of the l2 cache.
      eigen_internal_assert(n_cache >= static_cast<Index>(nr));
      n = n_cache - (n_cache % nr);
     374:	subs	r7, #1
     376:	orn	r7, r7, #3
     37a:	adds	r7, #1
     37c:	b.n	33c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x18c>
      const Index m_per_thread = numext::div_ceil(m, num_threads);
      if(m_cache < m_per_thread && m_cache >= static_cast<Index>(mr)) {
        m = m_cache - (m_cache % mr);
        eigen_internal_assert(m > 0);
      } else {
        m = (numext::mini<Index>)(m, (m_per_thread + mr - 1) - ((m_per_thread + mr - 1) % mr));
     37e:	subs	r2, #1
     380:	orn	r2, r2, #1
     384:	adds	r2, #1
     386:	b.n	34c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x19c>
    if(k>max_kc)
    {
      // We are really blocking on the third dimension:
      // -> reduce blocking size to make sure the last block is as large as possible
      //    while keeping the same number of sweeps over the result.
      k = (k%max_kc)==0 ? max_kc
     388:	sdiv	r7, lr, fp
     38c:	mls	r9, fp, r7, lr
     390:	cmp.w	r9, #0
     394:	beq.n	478 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x2c8>
     396:	add.w	ip, fp, #4294967295
     39a:	adds	r7, #1
     39c:	mov.w	r3, #1572864	; 0x180000
     3a0:	str.w	fp, [sp]
     3a4:	rsb	ip, r9, ip
     3a8:	lsls	r7, r7, #3
     3aa:	sdiv	r7, ip, r7
     3ae:	sub.w	r7, fp, r7, lsl #3
     3b2:	mov.w	r9, r7, lsl #3
     3b6:	mov.w	sl, r7, lsl #2
     3ba:	mov.w	fp, r7, lsl #4
     3be:	udiv	r9, r3, r9
     3c2:	str	r7, [r0, #0]
     3c4:	ldr.w	ip, [r2]
     3c8:	ldr	r0, [r1, #0]
     3ca:	b.n	2f2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x142>
      //    while keeping the same number of sweeps over the packed lhs.
      //    Here we allow one more sweep if this gives us a perfect match, thus the commented "-1"
      n = (n%nc)==0 ? nc
                    : (nc - Traits::nr * ((nc/*-1*/-(n%nc))/(Traits::nr*(n/nc+1))));
    }
    else if(old_k==k)
     3cc:	cmp	lr, r7
     3ce:	bne.n	356 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1a6>
    {
      // So far, no blocking at all, i.e., kc==k, and nc==n.
      // In this case, let's perform a blocking over the rows such that the packed lhs data is kept in cache L1/L2
      // TODO: part of this blocking strategy is now implemented within the kernel itself, so the L1-based heuristic here should be obsolete.
      Index problem_size = k*n*sizeof(LhsScalar);
     3d0:	mul.w	lr, ip, lr
     3d4:	mov.w	lr, lr, lsl #2
      Index actual_lm = actual_l2;
      Index max_mc = m;
      if(problem_size<=1024)
     3d8:	cmp.w	lr, #1024	; 0x400
     3dc:	ble.n	49c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x2ec>
      {
        // problem is small enough to keep in L1
        // Let's choose m such that lhs's block fit in 1/3 of L1
        actual_lm = l1;
      }
      else if(l3!=0 && problem_size<=32768)
     3de:	cmp	r5, #0
     3e0:	beq.n	4a0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x2f0>
     3e2:	cmp.w	lr, #32768	; 0x8000
     3e6:	bgt.n	4a0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x2f0>
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
      return __a;
     3e8:	cmp.w	r0, #576	; 0x240
     3ec:	mov	r3, r0
     3ee:	mov	r4, r6
     3f0:	it	ge
     3f2:	movge.w	r3, #576	; 0x240
     3f6:	add.w	sl, sl, sl, lsl #1
     3fa:	udiv	r4, r4, sl
     3fe:	cmp	r4, r3
     400:	it	ge
     402:	movge	r4, r3
        // Let's choose m such that lhs's block fit in 1/3 of L2
        actual_lm = l2;
        max_mc = (numext::mini<Index>)(576,max_mc);
      }
      Index mc = (numext::mini<Index>)(actual_lm/(3*k*sizeof(LhsScalar)), max_mc);
      if (mc > Traits::mr) mc -= mc % Traits::mr;
     404:	cmp	r4, #2
     406:	ble.n	494 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x2e4>
     408:	bic.w	r4, r4, #1
      else if (mc==0) return;
      m = (m%mc)==0 ? mc
     40c:	sdiv	r3, r0, r4
     410:	mls	r0, r4, r3, r0
     414:	cbz	r0, 424 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x274>
     416:	adds	r3, #1
     418:	subs	r0, r4, r0
     41a:	lsls	r3, r3, #1
     41c:	sdiv	r3, r0, r3
     420:	sub.w	r4, r4, r3, lsl #1
     424:	str	r4, [r1, #0]
     426:	b.n	356 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1a6>
      max_nc = remaining_l1 / (k*sizeof(RhsScalar));
    }
    else
    {
      // L2 blocking
      max_nc = (3*actual_l2)/(2*2*max_kc*sizeof(RhsScalar));
     428:	ldr	r3, [sp, #0]
     42a:	mov.w	r8, r3, lsl #4
     42e:	mov.w	r3, #4718592	; 0x480000
     432:	udiv	r3, r3, r8
     436:	b.n	304 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x154>
    // We also include a register-level block of the result (mx x nr).
    // (In an ideal world only the lhs panel would stay in L1)
    // Moreover, kc has to be a multiple of 8 to be compatible with loop peeling, leading to a maximum blocking size of:
    const Index max_kc = numext::maxi<Index>(((l1-k_sub)/k_div) & (~(k_peeling-1)),1);
    const Index old_k = k;
    if(k>max_kc)
     438:	cmp.w	lr, #1
     43c:	bgt.n	464 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x2b4>
     43e:	mov.w	r3, lr, lsl #3
     442:	mov.w	r9, #1572864	; 0x180000
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
     446:	mov	r0, r7
     448:	mov.w	sl, lr, lsl #2
     44c:	str	r3, [sp, #4]
	return __b;
     44e:	movs	r3, #1
     450:	mov.w	fp, lr, lsl #4
     454:	mov	r7, lr
     456:	str	r3, [sp, #0]
     458:	ldr	r3, [sp, #4]
     45a:	udiv	r9, r9, r3
     45e:	b.n	2f2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x142>
     460:	mov	r3, r9
     462:	b.n	330 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x180>
     464:	movs	r3, #1
     466:	mov.w	r9, #196608	; 0x30000
     46a:	mov.w	fp, #16
     46e:	mov.w	sl, #4
     472:	str	r3, [sp, #0]
     474:	mov	r7, r3
     476:	b.n	3c2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x212>
     478:	mov.w	r3, fp, lsl #3
     47c:	mov.w	r9, #1572864	; 0x180000
    {
      // We are really blocking on the third dimension:
      // -> reduce blocking size to make sure the last block is as large as possible
      //    while keeping the same number of sweeps over the result.
      k = (k%max_kc)==0 ? max_kc
     480:	mov	r7, fp
     482:	str.w	fp, [sp]
     486:	mov.w	sl, fp, lsl #2
     48a:	mov.w	fp, fp, lsl #4
     48e:	udiv	r9, r9, r3
     492:	b.n	3c2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x212>
        actual_lm = l2;
        max_mc = (numext::mini<Index>)(576,max_mc);
      }
      Index mc = (numext::mini<Index>)(actual_lm/(3*k*sizeof(LhsScalar)), max_mc);
      if (mc > Traits::mr) mc -= mc % Traits::mr;
      else if (mc==0) return;
     494:	cmp	r4, #0
     496:	beq.w	356 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x1a6>
     49a:	b.n	40c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x25c>
      // In this case, let's perform a blocking over the rows such that the packed lhs data is kept in cache L1/L2
      // TODO: part of this blocking strategy is now implemented within the kernel itself, so the L1-based heuristic here should be obsolete.
      Index problem_size = k*n*sizeof(LhsScalar);
      Index actual_lm = actual_l2;
      Index max_mc = m;
      if(problem_size<=1024)
     49c:	mov	r3, r0
     49e:	b.n	3f6 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x246>
     4a0:	mov	r3, r0
     4a2:	mov.w	r4, #1572864	; 0x180000
     4a6:	b.n	3f6 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)+0x246>
     4a8:	.word	0x2000095c
     4ac:	.word	0x20000960
     4b0:	.word	0x2aaaaaab
     4b4:	.word	0x80000003
     4b8:	.word	0x80000001
     4bc:	.word	0x80000007

000004c0 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)>:
      * Output: \verbinclude Matrix_resize_int_int.out
      *
      * \sa resize(Index) for vectors, resize(NoChange_t, Index), resize(Index, NoChange_t)
      */
    EIGEN_DEVICE_FUNC
    EIGEN_STRONG_INLINE void resize(Index rows, Index cols)
     4c0:	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
     4c4:	mov	r4, r0
     4c6:	mov	r7, r2
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
     4c8:	mov	r6, r1
     4ca:	cbz	r1, 4da <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x1a>
     4cc:	cbz	r2, 4da <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x1a>
     4ce:	mvn.w	r3, #2147483648	; 0x80000000
     4d2:	sdiv	r3, r3, r2
     4d6:	cmp	r1, r3
     4d8:	bgt.n	502 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x42>
      m_rows = rows;
      m_cols = cols;
    }
    EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
    {
      if(size != m_rows*m_cols)
     4da:	ldr	r2, [r4, #4]
        Index size = rows*cols;
        bool size_changed = size != this->size();
        m_storage.resize(size, rows, cols);
        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
      #else
        m_storage.resize(rows*cols, rows, cols);
     4dc:	mul.w	r5, r7, r6
     4e0:	ldr	r3, [r4, #8]
     4e2:	mul.w	r3, r3, r2
     4e6:	cmp	r5, r3
     4e8:	beq.n	4fa <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x3a>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
     4ea:	ldr	r3, [r4, #0]
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
     4ec:	cbz	r3, 4f6 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x36>
     4ee:	ldr.w	r0, [r3, #-4]
     4f2:	bl	7248 <free>
        if (size)
     4f6:	cbnz	r5, 50c <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x4c>
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
     4f8:	str	r5, [r4, #0]
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
     4fa:	str	r6, [r4, #4]
      m_cols = cols;
     4fc:	str	r7, [r4, #8]
      #endif
    }
     4fe:	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
     502:	mov.w	r0, #4294967295
     506:	bl	6d9c <operator new(unsigned int)>
     50a:	b.n	4da <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x1a>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
     50c:	cmp.w	r5, #1073741824	; 0x40000000
     510:	bcs.n	534 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x74>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
     512:	lsls	r5, r5, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
     514:	add.w	r0, r5, #16
     518:	bl	7238 <malloc>
  if (original == 0) return 0;
     51c:	mov	r8, r0
     51e:	cbz	r0, 53e <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x7e>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
     520:	bic.w	r0, r0, #15
     524:	adds	r0, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
     526:	str.w	r8, [r0, #-4]
    {
      if(size != m_rows*m_cols)
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
        if (size)
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
     52a:	str	r0, [r4, #0]
        else
          m_data = 0;
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
     52c:	str	r6, [r4, #4]
      m_cols = cols;
     52e:	str	r7, [r4, #8]
     530:	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
     534:	mov.w	r0, #4294967295
     538:	bl	6d9c <operator new(unsigned int)>
     53c:	b.n	512 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x52>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
     53e:	cbz	r5, 54c <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x8c>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
     540:	mov.w	r0, #4294967295
     544:	bl	6d9c <operator new(unsigned int)>
     548:	mov	r0, r8
     54a:	b.n	52a <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x6a>
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
     54c:	mov	r0, r5
     54e:	b.n	52a <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)+0x6a>

00000550 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)>:
  typedef typename DataMapper::LinearMapper LinearMapper;
  EIGEN_DONT_INLINE void operator()(Scalar* blockA, const DataMapper& lhs, Index depth, Index rows, Index stride=0, Index offset=0);
};

template<typename Scalar, typename Index, typename DataMapper, int Pack1, int Pack2, bool Conjugate, bool PanelMode>
EIGEN_DONT_INLINE void gemm_pack_lhs<Scalar, Index, DataMapper, Pack1, Pack2, ColMajor, Conjugate, PanelMode>
     550:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
     554:	ldr	r6, [sp, #36]	; 0x24
  eigen_assert( ((Pack1%PacketSize)==0 && Pack1<=4*PacketSize) || (Pack1<=4) );
  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
  Index count = 0;

  const Index peeled_mc3 = Pack1>=3*PacketSize ? (rows/(3*PacketSize))*(3*PacketSize) : 0;
  const Index peeled_mc2 = Pack1>=2*PacketSize ? peeled_mc3+((rows-peeled_mc3)/(2*PacketSize))*(2*PacketSize) : 0;
     556:	cmp	r6, #0
     558:	ite	lt
     55a:	addlt	r7, r6, #1
     55c:	movge	r7, r6
     55e:	bic.w	r7, r7, #1
    }
  }
  // Pack 2 packets
  if(Pack1>=2*PacketSize)
  {
    for(; i<peeled_mc2; i+=2*PacketSize)
     562:	cmp	r7, #0
     564:	ble.n	5ea <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x9a>
     566:	mov.w	lr, #0
     56a:	mov.w	r8, r3, lsl #1
     56e:	mov	r0, lr
    {
      if(PanelMode) count += (2*PacketSize) * offset;

      for(Index k=0; k<depth; k++)
     570:	cmp	r3, #0
     572:	ble.n	5a4 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x54>
     574:	add.w	ip, r8, r0
     578:	ldr	r5, [r2, #4]
     57a:	ldr	r4, [r2, #0]
     57c:	add.w	r0, r1, r0, lsl #2
     580:	mov.w	sl, r5, lsl #2
     584:	add.w	r4, r4, lr, lsl #2
     588:	add.w	fp, r1, ip, lsl #2
     58c:	ldr.w	r9, [r4]
     590:	adds	r0, #8
     592:	ldr	r5, [r4, #4]
     594:	add	r4, sl
template<typename Packet> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet
plset(const typename unpacket_traits<Packet>::type& a) { return a; }

/** \internal copy the packet \a from to \a *to, \a to must be 16 bytes aligned */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }
     596:	str.w	r9, [r0, #-8]
     59a:	str.w	r5, [r0, #-4]
     59e:	cmp	r0, fp
     5a0:	bne.n	58c <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x3c>
     5a2:	mov	r0, ip
    }
  }
  // Pack 2 packets
  if(Pack1>=2*PacketSize)
  {
    for(; i<peeled_mc2; i+=2*PacketSize)
     5a4:	add.w	lr, lr, #2
     5a8:	cmp	r7, lr
     5aa:	bgt.n	570 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x20>
    }
  }
  // Pack 1 packets
  if(Pack1>=1*PacketSize)
  {
    for(; i<peeled_mc1; i+=1*PacketSize)
     5ac:	cmp	r6, r7
     5ae:	ble.n	5f2 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0xa2>
     5b0:	mov.w	ip, r7, lsl #2
    {
      if(PanelMode) count += (1*PacketSize) * offset;

      for(Index k=0; k<depth; k++)
     5b4:	cmp	r3, #0
     5b6:	ble.n	5dc <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x8c>
     5b8:	add.w	r8, r3, r0
     5bc:	ldr	r5, [r2, #4]
     5be:	ldr	r4, [r2, #0]
     5c0:	add.w	r0, r1, r0, lsl #2
     5c4:	mov.w	lr, r5, lsl #2
     5c8:	add	r4, ip
     5ca:	add.w	r9, r1, r8, lsl #2
     5ce:	ldr	r5, [r4, #0]
     5d0:	add	r4, lr
     5d2:	str.w	r5, [r0], #4
     5d6:	cmp	r0, r9
     5d8:	bne.n	5ce <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x7e>
     5da:	mov	r0, r8
    }
  }
  // Pack 1 packets
  if(Pack1>=1*PacketSize)
  {
    for(; i<peeled_mc1; i+=1*PacketSize)
     5dc:	adds	r7, #1
     5de:	add.w	ip, ip, #4
     5e2:	cmp	r6, r7
     5e4:	bne.n	5b4 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x64>
     5e6:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
  const Index peeled_mc2 = Pack1>=2*PacketSize ? peeled_mc3+((rows-peeled_mc3)/(2*PacketSize))*(2*PacketSize) : 0;
  const Index peeled_mc1 = Pack1>=1*PacketSize ? (rows/(1*PacketSize))*(1*PacketSize) : 0;
  const Index peeled_mc0 = Pack2>=1*PacketSize ? peeled_mc1
                         : Pack2>1             ? (rows/Pack2)*Pack2 : 0;

  Index i=0;
     5ea:	movs	r7, #0
    }
  }
  // Pack 1 packets
  if(Pack1>=1*PacketSize)
  {
    for(; i<peeled_mc1; i+=1*PacketSize)
     5ec:	cmp	r6, r7
  EIGEN_UNUSED_VARIABLE(stride);
  EIGEN_UNUSED_VARIABLE(offset);
  eigen_assert(((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride));
  eigen_assert( ((Pack1%PacketSize)==0 && Pack1<=4*PacketSize) || (Pack1<=4) );
  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
  Index count = 0;
     5ee:	mov	r0, r7
    }
  }
  // Pack 1 packets
  if(Pack1>=1*PacketSize)
  {
    for(; i<peeled_mc1; i+=1*PacketSize)
     5f0:	bgt.n	5b0 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x60>
     5f2:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
     5f6:	nop

000005f8 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)>:
  enum { PacketSize = packet_traits<Scalar>::size };
  EIGEN_DONT_INLINE void operator()(Scalar* blockB, const DataMapper& rhs, Index depth, Index cols, Index stride=0, Index offset=0);
};

template<typename Scalar, typename Index, typename DataMapper, int nr, bool Conjugate, bool PanelMode>
EIGEN_DONT_INLINE void gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>
     5f8:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
     5fc:	sub	sp, #20
     5fe:	str	r2, [sp, #12]
  EIGEN_UNUSED_VARIABLE(stride);
  EIGEN_UNUSED_VARIABLE(offset);
  eigen_assert(((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride));
  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
  Index packet_cols8 = nr>=8 ? (cols/8) * 8 : 0;
  Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
     600:	ldr.w	r8, [sp, #56]	; 0x38
     604:	mov	r2, r8
     606:	cmp	r2, #0
     608:	it	lt
     60a:	addlt.w	r8, r8, #3
     60e:	bic.w	r8, r8, #3
//     }
//   }

  if(nr>=4)
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
     612:	cmp.w	r8, #0
     616:	ble.n	6de <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0xe6>
     618:	ldr	r0, [sp, #12]
     61a:	mov.w	sl, #0
     61e:	str	r1, [sp, #0]
     620:	ldr	r2, [r0, #4]
     622:	mov	lr, sl
     624:	ldr.w	r9, [r0]
     628:	lsls	r0, r3, #2
     62a:	mov.w	fp, r2, lsl #4
     62e:	str	r0, [sp, #4]
     630:	add.w	ip, r9, r2, lsl #2
     634:	add.w	r0, r3, r2, lsl #1
     638:	lsls	r2, r2, #3
     63a:	lsls	r0, r0, #2
     63c:	mov	r7, r2
     63e:	str	r0, [sp, #8]
          pstoreu(blockB+count+2*PacketSize, cj.pconj(kernel.packet[2%PacketSize]));
          pstoreu(blockB+count+3*PacketSize, cj.pconj(kernel.packet[3%PacketSize]));
          count+=4*PacketSize;
        }
      }
      for(; k<depth; k++)
     640:	cmp	r3, #0
     642:	ble.n	686 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x8e>
     644:	ldr	r0, [sp, #8]
     646:	add.w	r5, r7, r9
     64a:	ldr	r2, [sp, #0]
     64c:	add.w	r1, ip, r7
     650:	add.w	r6, ip, r0
     654:	mov	r4, ip
     656:	add.w	r2, r2, lr, lsl #2
     65a:	mov	r0, r9
      {
        blockB[count+0] = cj(dm0(k));
     65c:	vldmia	r0!, {s15}
     660:	adds	r2, #16
     662:	vstr	s15, [r2, #-16]
        blockB[count+1] = cj(dm1(k));
     666:	vldmia	r4!, {s15}
     66a:	vstr	s15, [r2, #-12]
        blockB[count+2] = cj(dm2(k));
     66e:	vldmia	r5!, {s15}
     672:	vstr	s15, [r2, #-8]
        blockB[count+3] = cj(dm3(k));
     676:	vldmia	r1!, {s15}
          pstoreu(blockB+count+2*PacketSize, cj.pconj(kernel.packet[2%PacketSize]));
          pstoreu(blockB+count+3*PacketSize, cj.pconj(kernel.packet[3%PacketSize]));
          count+=4*PacketSize;
        }
      }
      for(; k<depth; k++)
     67a:	cmp	r6, r1
      {
        blockB[count+0] = cj(dm0(k));
        blockB[count+1] = cj(dm1(k));
        blockB[count+2] = cj(dm2(k));
        blockB[count+3] = cj(dm3(k));
     67c:	vstr	s15, [r2, #-4]
          pstoreu(blockB+count+2*PacketSize, cj.pconj(kernel.packet[2%PacketSize]));
          pstoreu(blockB+count+3*PacketSize, cj.pconj(kernel.packet[3%PacketSize]));
          count+=4*PacketSize;
        }
      }
      for(; k<depth; k++)
     680:	bne.n	65c <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x64>
     682:	ldr	r2, [sp, #4]
     684:	add	lr, r2
//     }
//   }

  if(nr>=4)
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
     686:	add.w	sl, sl, #4
     68a:	add	r9, fp
     68c:	add	ip, fp
     68e:	cmp	r8, sl
     690:	bgt.n	640 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x48>
     692:	ldr	r1, [sp, #0]
      if(PanelMode) count += 4 * (stride-offset-depth);
    }
  }

  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
     694:	ldr	r2, [sp, #56]	; 0x38
     696:	cmp	r2, r8
     698:	ble.n	6d8 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0xe0>
     69a:	ldr	r0, [sp, #12]
     69c:	mov.w	ip, r3, lsl #2
     6a0:	ldr.w	r9, [sp, #56]	; 0x38
     6a4:	ldr	r7, [r0, #4]
     6a6:	ldr	r2, [r0, #0]
     6a8:	mul.w	r6, r7, r8
     6ac:	lsls	r7, r7, #2
     6ae:	add.w	r6, r2, r6, lsl #2
  {
    if(PanelMode) count += offset;
    const LinearMapper dm0 = rhs.getLinearMapper(0, j2);
    for(Index k=0; k<depth; k++)
     6b2:	cmp	r3, #0
     6b4:	ble.n	6ce <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0xd6>
     6b6:	add.w	r0, r1, lr, lsl #2
     6ba:	add.w	r5, r6, ip
     6be:	mov	r2, r6
    {
      blockB[count] = cj(dm0(k));
     6c0:	ldr.w	r4, [r2], #4
  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
  {
    if(PanelMode) count += offset;
    const LinearMapper dm0 = rhs.getLinearMapper(0, j2);
    for(Index k=0; k<depth; k++)
     6c4:	cmp	r5, r2
    {
      blockB[count] = cj(dm0(k));
     6c6:	str.w	r4, [r0], #4
  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
  {
    if(PanelMode) count += offset;
    const LinearMapper dm0 = rhs.getLinearMapper(0, j2);
    for(Index k=0; k<depth; k++)
     6ca:	bne.n	6c0 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0xc8>
     6cc:	add	lr, r3
      if(PanelMode) count += 4 * (stride-offset-depth);
    }
  }

  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
     6ce:	add.w	r8, r8, #1
     6d2:	add	r6, r7
     6d4:	cmp	r9, r8
     6d6:	bne.n	6b2 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0xba>
      blockB[count] = cj(dm0(k));
      count += 1;
    }
    if(PanelMode) count += (stride-offset-depth);
  }
}
     6d8:	add	sp, #20
     6da:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
  EIGEN_UNUSED_VARIABLE(offset);
  eigen_assert(((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride));
  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
  Index packet_cols8 = nr>=8 ? (cols/8) * 8 : 0;
  Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
  Index count = 0;
     6de:	mov.w	lr, #0
     6e2:	b.n	694 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)+0x9c>

000006e4 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)>:
                  Index strideA=-1, Index strideB=-1, Index offsetA=0, Index offsetB=0);
};

template<typename LhsScalar, typename RhsScalar, typename Index, typename DataMapper, int mr, int nr, bool ConjugateLhs, bool ConjugateRhs>
EIGEN_DONT_INLINE
void gebp_kernel<LhsScalar,RhsScalar,Index,DataMapper,mr,nr,ConjugateLhs,ConjugateRhs>
     6e4:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
     6e8:	sub	sp, #84	; 0x54
     6ea:	ldr.w	sl, [sp, #124]	; 0x7c
     6ee:	str	r3, [sp, #36]	; 0x24
     6f0:	ldr	r3, [sp, #132]	; 0x84
    Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
    const Index peeled_mc3 = mr>=3*Traits::LhsProgress ? (rows/(3*LhsProgress))*(3*LhsProgress) : 0;
    const Index peeled_mc2 = mr>=2*Traits::LhsProgress ? peeled_mc3+((rows-peeled_mc3)/(2*LhsProgress))*(2*LhsProgress) : 0;
    const Index peeled_mc1 = mr>=1*Traits::LhsProgress ? (rows/(1*LhsProgress))*(1*LhsProgress) : 0;
    enum { pk = 8 }; // NOTE Such a large peeling factor is important for large matrices (~ +5% when >1000 on Haswell)
    const Index peeled_kc  = depth & ~(pk-1);
     6f2:	bic.w	fp, sl, #7
                  Index strideA=-1, Index strideB=-1, Index offsetA=0, Index offsetB=0);
};

template<typename LhsScalar, typename RhsScalar, typename Index, typename DataMapper, int mr, int nr, bool ConjugateLhs, bool ConjugateRhs>
EIGEN_DONT_INLINE
void gebp_kernel<LhsScalar,RhsScalar,Index,DataMapper,mr,nr,ConjugateLhs,ConjugateRhs>
     6f6:	str	r1, [sp, #32]
    {
      const Index l1 = defaultL1CacheSize; // in Bytes, TODO, l1 should be passed to this function.
      // The max(1, ...) here is needed because we may be using blocking params larger than what our known l1 cache size
      // suggests we should be using: either because our known l1 cache size is inaccurate (e.g. on Android, we can only guess),
      // or because we are testing specific blocking sizes.
      Index actual_panel_rows = (2*LhsProgress) * std::max<Index>(1,( (l1 - sizeof(ResScalar)*mr*nr - depth*nr*sizeof(RhsScalar)) / (depth * sizeof(LhsScalar) * 2*LhsProgress) ));
     6f8:	mov.w	r1, sl, lsl #2
     6fc:	cmp.w	r3, #4294967295
     700:	it	eq
     702:	moveq	r3, sl
                  Index strideA=-1, Index strideB=-1, Index offsetA=0, Index offsetB=0);
};

template<typename LhsScalar, typename RhsScalar, typename Index, typename DataMapper, int mr, int nr, bool ConjugateLhs, bool ConjugateRhs>
EIGEN_DONT_INLINE
void gebp_kernel<LhsScalar,RhsScalar,Index,DataMapper,mr,nr,ConjugateLhs,ConjugateRhs>
     704:	str	r2, [sp, #56]	; 0x38
    {
      const Index l1 = defaultL1CacheSize; // in Bytes, TODO, l1 should be passed to this function.
      // The max(1, ...) here is needed because we may be using blocking params larger than what our known l1 cache size
      // suggests we should be using: either because our known l1 cache size is inaccurate (e.g. on Android, we can only guess),
      // or because we are testing specific blocking sizes.
      Index actual_panel_rows = (2*LhsProgress) * std::max<Index>(1,( (l1 - sizeof(ResScalar)*mr*nr - depth*nr*sizeof(RhsScalar)) / (depth * sizeof(LhsScalar) * 2*LhsProgress) ));
     706:	mov.w	r2, sl, lsl #3
    if(strideA==-1) strideA = depth;
    if(strideB==-1) strideB = depth;
    conj_helper<LhsScalar,RhsScalar,ConjugateLhs,ConjugateRhs> cj;
    Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
    const Index peeled_mc3 = mr>=3*Traits::LhsProgress ? (rows/(3*LhsProgress))*(3*LhsProgress) : 0;
    const Index peeled_mc2 = mr>=2*Traits::LhsProgress ? peeled_mc3+((rows-peeled_mc3)/(2*LhsProgress))*(2*LhsProgress) : 0;
     70a:	ldr	r0, [sp, #120]	; 0x78
     70c:	str	r3, [sp, #132]	; 0x84
     70e:	ldr	r3, [sp, #136]	; 0x88
     710:	cmp.w	r3, #4294967295
     714:	it	eq
     716:	moveq	r3, sl
     718:	str	r3, [sp, #136]	; 0x88
    SwappedTraits straits;
    
    if(strideA==-1) strideA = depth;
    if(strideB==-1) strideB = depth;
    conj_helper<LhsScalar,RhsScalar,ConjugateLhs,ConjugateRhs> cj;
    Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
     71a:	ldr	r3, [sp, #128]	; 0x80
     71c:	cmp	r3, #0
     71e:	it	lt
     720:	addlt	r3, #3
    const Index peeled_mc3 = mr>=3*Traits::LhsProgress ? (rows/(3*LhsProgress))*(3*LhsProgress) : 0;
    const Index peeled_mc2 = mr>=2*Traits::LhsProgress ? peeled_mc3+((rows-peeled_mc3)/(2*LhsProgress))*(2*LhsProgress) : 0;
     722:	cmp	r0, #0
    SwappedTraits straits;
    
    if(strideA==-1) strideA = depth;
    if(strideB==-1) strideB = depth;
    conj_helper<LhsScalar,RhsScalar,ConjugateLhs,ConjugateRhs> cj;
    Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
     724:	bic.w	r3, r3, #3
    const Index peeled_mc3 = mr>=3*Traits::LhsProgress ? (rows/(3*LhsProgress))*(3*LhsProgress) : 0;
    const Index peeled_mc2 = mr>=2*Traits::LhsProgress ? peeled_mc3+((rows-peeled_mc3)/(2*LhsProgress))*(2*LhsProgress) : 0;
     728:	it	lt
     72a:	addlt	r0, #1
    SwappedTraits straits;
    
    if(strideA==-1) strideA = depth;
    if(strideB==-1) strideB = depth;
    conj_helper<LhsScalar,RhsScalar,ConjugateLhs,ConjugateRhs> cj;
    Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
     72c:	str	r3, [sp, #24]
    {
      const Index l1 = defaultL1CacheSize; // in Bytes, TODO, l1 should be passed to this function.
      // The max(1, ...) here is needed because we may be using blocking params larger than what our known l1 cache size
      // suggests we should be using: either because our known l1 cache size is inaccurate (e.g. on Android, we can only guess),
      // or because we are testing specific blocking sizes.
      Index actual_panel_rows = (2*LhsProgress) * std::max<Index>(1,( (l1 - sizeof(ResScalar)*mr*nr - depth*nr*sizeof(RhsScalar)) / (depth * sizeof(LhsScalar) * 2*LhsProgress) ));
     72e:	movw	r3, #4088	; 0xff8
    if(strideA==-1) strideA = depth;
    if(strideB==-1) strideB = depth;
    conj_helper<LhsScalar,RhsScalar,ConjugateLhs,ConjugateRhs> cj;
    Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
    const Index peeled_mc3 = mr>=3*Traits::LhsProgress ? (rows/(3*LhsProgress))*(3*LhsProgress) : 0;
    const Index peeled_mc2 = mr>=2*Traits::LhsProgress ? peeled_mc3+((rows-peeled_mc3)/(2*LhsProgress))*(2*LhsProgress) : 0;
     732:	bic.w	r0, r0, #1
    {
      const Index l1 = defaultL1CacheSize; // in Bytes, TODO, l1 should be passed to this function.
      // The max(1, ...) here is needed because we may be using blocking params larger than what our known l1 cache size
      // suggests we should be using: either because our known l1 cache size is inaccurate (e.g. on Android, we can only guess),
      // or because we are testing specific blocking sizes.
      Index actual_panel_rows = (2*LhsProgress) * std::max<Index>(1,( (l1 - sizeof(ResScalar)*mr*nr - depth*nr*sizeof(RhsScalar)) / (depth * sizeof(LhsScalar) * 2*LhsProgress) ));
     736:	subs	r3, r3, r1
    if(strideA==-1) strideA = depth;
    if(strideB==-1) strideB = depth;
    conj_helper<LhsScalar,RhsScalar,ConjugateLhs,ConjugateRhs> cj;
    Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
    const Index peeled_mc3 = mr>=3*Traits::LhsProgress ? (rows/(3*LhsProgress))*(3*LhsProgress) : 0;
    const Index peeled_mc2 = mr>=2*Traits::LhsProgress ? peeled_mc3+((rows-peeled_mc3)/(2*LhsProgress))*(2*LhsProgress) : 0;
     738:	str	r0, [sp, #40]	; 0x28
    {
      const Index l1 = defaultL1CacheSize; // in Bytes, TODO, l1 should be passed to this function.
      // The max(1, ...) here is needed because we may be using blocking params larger than what our known l1 cache size
      // suggests we should be using: either because our known l1 cache size is inaccurate (e.g. on Android, we can only guess),
      // or because we are testing specific blocking sizes.
      Index actual_panel_rows = (2*LhsProgress) * std::max<Index>(1,( (l1 - sizeof(ResScalar)*mr*nr - depth*nr*sizeof(RhsScalar)) / (depth * sizeof(LhsScalar) * 2*LhsProgress) ));
     73a:	lsls	r3, r3, #2
     73c:	udiv	r2, r3, r2
     740:	cmp	r2, #1
     742:	it	lt
     744:	movlt	r2, #1

      for(Index i1=peeled_mc3; i1<peeled_mc2; i1+=actual_panel_rows)
     746:	cmp	r0, #0
    {
      const Index l1 = defaultL1CacheSize; // in Bytes, TODO, l1 should be passed to this function.
      // The max(1, ...) here is needed because we may be using blocking params larger than what our known l1 cache size
      // suggests we should be using: either because our known l1 cache size is inaccurate (e.g. on Android, we can only guess),
      // or because we are testing specific blocking sizes.
      Index actual_panel_rows = (2*LhsProgress) * std::max<Index>(1,( (l1 - sizeof(ResScalar)*mr*nr - depth*nr*sizeof(RhsScalar)) / (depth * sizeof(LhsScalar) * 2*LhsProgress) ));
     748:	mov.w	r3, r2, lsl #1
     74c:	str	r3, [sp, #60]	; 0x3c

      for(Index i1=peeled_mc3; i1<peeled_mc2; i1+=actual_panel_rows)
     74e:	ble.w	cc0 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x5dc>
     752:	ldr	r1, [sp, #144]	; 0x90
     754:	lsls	r2, r2, #3
     756:	ldr	r0, [sp, #136]	; 0x88
     758:	add.w	r3, fp, #4294967295
     75c:	lsls	r1, r1, #2
     75e:	ldr	r4, [sp, #144]	; 0x90
     760:	lsrs	r3, r3, #3
     762:	str	r1, [sp, #76]	; 0x4c
     764:	ldr	r1, [sp, #24]
     766:	adds	r3, #1
     768:	mla	r1, r0, r1, r4
     76c:	str	r1, [sp, #72]	; 0x48
     76e:	ldr	r1, [sp, #132]	; 0x84
     770:	mul.w	r2, r1, r2
     774:	ldr	r1, [sp, #140]	; 0x8c
     776:	str	r2, [sp, #68]	; 0x44
     778:	ldr	r2, [sp, #56]	; 0x38
     77a:	add.w	r2, r2, r1, lsl #3
     77e:	str	r2, [sp, #28]
     780:	movs	r2, #0
     782:	str	r2, [sp, #12]
     784:	lsls	r2, r0, #2
     786:	str	r2, [sp, #48]	; 0x30
     788:	ldr	r2, [sp, #132]	; 0x84
     78a:	lsls	r2, r2, #3
     78c:	str	r2, [sp, #0]
     78e:	lsls	r2, r3, #7
     790:	str	r2, [sp, #44]	; 0x2c
     792:	lsls	r2, r3, #6
     794:	lsls	r3, r3, #5
     796:	str	r2, [sp, #8]
     798:	str	r3, [sp, #52]	; 0x34
      {
        Index actual_panel_end = (std::min)(i1+actual_panel_rows, peeled_mc2);
     79a:	ldr	r2, [sp, #12]
     79c:	ldr	r3, [sp, #60]	; 0x3c
     79e:	add	r3, r2
     7a0:	ldr	r2, [sp, #40]	; 0x28
     7a2:	cmp	r2, r3
     7a4:	str	r3, [sp, #64]	; 0x40
     7a6:	it	ge
     7a8:	movge	r2, r3
        for(Index j2=0; j2<packet_cols4; j2+=nr)
     7aa:	ldr	r3, [sp, #24]
     7ac:	cmp	r3, #0
     7ae:	mov	r9, r2
     7b0:	ble.w	b18 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x434>
     7b4:	ldr	r3, [sp, #76]	; 0x4c
     7b6:	str	r3, [sp, #20]
     7b8:	movs	r3, #0
     7ba:	str	r3, [sp, #16]
        {
          for(Index i=i1; i<actual_panel_end; i+=2*LhsProgress)
     7bc:	ldr	r3, [sp, #12]
     7be:	cmp	r9, r3
     7c0:	ble.w	b02 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x41e>
     7c4:	ldr	r5, [sp, #16]
     7c6:	ldr	r2, [sp, #32]
     7c8:	mov	r3, r5
     7ca:	ldr	r0, [sp, #36]	; 0x24
     7cc:	ldr	r1, [r2, #4]
     7ce:	adds	r4, r5, #2
     7d0:	ldr	r7, [sp, #20]
     7d2:	adds	r3, #3
     7d4:	mla	r6, r5, r1, r1
     7d8:	ldr	r2, [r2, #0]
     7da:	add.w	r8, r0, r7, lsl #2
     7de:	mov	r0, r5
     7e0:	ldr	r5, [sp, #12]
     7e2:	ldr.w	lr, [sp, #28]
     7e6:	mla	r7, r1, r0, r5
     7ea:	add	r6, r5
     7ec:	mla	r4, r1, r4, r5
     7f0:	mov	ip, r5
     7f2:	mla	r3, r1, r3, r5
     7f6:	ldr	r1, [sp, #44]	; 0x2c
     7f8:	add.w	r7, r2, r7, lsl #2
     7fc:	add	r1, r8
     7fe:	add.w	r6, r2, r6, lsl #2
     802:	add.w	r4, r2, r4, lsl #2
     806:	add.w	r5, r2, r3, lsl #2
     80a:	str	r1, [sp, #4]
          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB*nr];
          prefetch(&blB[0]);
          LhsPacket A0, A1;

          for(Index k=0; k<peeled_kc; k+=pk)
     80c:	cmp.w	fp, #0
#else
  // 32-bit pointer operand constraint for inlined asm
  asm(" prefetch.L1 [ %1 ];" : "=r"(addr) : "r"(addr));
#endif
#elif (!EIGEN_COMP_MSVC) && (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)
  __builtin_prefetch(addr);
     810:	pld	[lr]
          {
          
          // We selected a 2*Traits::LhsProgress x nr micro block of res which is entirely
          // stored into 2 x nr registers.
          
          const LhsScalar* blA = &blockA[i*strideA+offsetA*(2*Traits::LhsProgress)];
     814:	mov	r2, lr
     816:	pld	[r7, #32]
     81a:	pld	[r6, #32]
     81e:	pld	[r4, #32]
     822:	pld	[r5, #32]
     826:	pld	[r8]
          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB*nr];
          prefetch(&blB[0]);
          LhsPacket A0, A1;

          for(Index k=0; k<peeled_kc; k+=pk)
     82a:	ble.w	106c <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x988>
     82e:	vldr	s15, [pc, #864]	; b90 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x4ac>
     832:	add.w	r3, r8, #128	; 0x80
     836:	add.w	r2, lr, #64	; 0x40
     83a:	movs	r0, #0
     83c:	vmov.f32	s11, s15
     840:	vmov.f32	s13, s15
     844:	vmov.f32	s8, s15
     848:	vmov.f32	s9, s15
     84c:	vmov.f32	s12, s15
     850:	vmov.f32	s10, s15
     854:	vmov.f32	s14, s15
     858:	pld	[r3, #64]	; 0x40
              EIGEN_GEBP_2PX4_SPILLING_WORKAROUND                               \
              EIGEN_ASM_COMMENT("end step of gebp micro kernel 2pX4");          \
            } while(false)
            
            internal::prefetch(blB+(48+0));
            EIGEN_GEBGP_ONESTEP(0);
     85c:	vldr	s6, [r2, #-64]	; 0xffffffc0
     860:	mov	r1, r3
     862:	vldr	s7, [r2, #-60]	; 0xffffffc4
     866:	vldr	s5, [r3, #-128]	; 0xffffff80
     86a:	vldr	s3, [r3, #-124]	; 0xffffff84
     86e:	vldr	s4, [r3, #-120]	; 0xffffff88
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     872:	vfma.f32	s13, s5, s6
     876:	vfma.f32	s9, s5, s7
     87a:	vldr	s5, [r3, #-116]	; 0xffffff8c
     87e:	vfma.f32	s8, s6, s3
     882:	vfma.f32	s12, s7, s3
     886:	vfma.f32	s15, s6, s4
     88a:	vfma.f32	s10, s7, s4
     88e:	vfma.f32	s11, s6, s5
     892:	vfma.f32	s14, s7, s5
            EIGEN_GEBGP_ONESTEP(1);
     896:	vldr	s6, [r2, #-56]	; 0xffffffc8
     89a:	vldr	s7, [r2, #-52]	; 0xffffffcc
     89e:	vldr	s5, [r3, #-112]	; 0xffffff90
     8a2:	vldr	s3, [r3, #-108]	; 0xffffff94
     8a6:	vldr	s4, [r3, #-104]	; 0xffffff98
     8aa:	vfma.f32	s13, s5, s6
     8ae:	vfma.f32	s9, s5, s7
     8b2:	vldr	s5, [r3, #-100]	; 0xffffff9c
     8b6:	vfma.f32	s8, s6, s3
     8ba:	vfma.f32	s12, s7, s3
     8be:	vfma.f32	s15, s6, s4
     8c2:	vfma.f32	s10, s7, s4
     8c6:	vfma.f32	s11, s6, s5
     8ca:	vfma.f32	s14, s7, s5
            EIGEN_GEBGP_ONESTEP(2);
     8ce:	vldr	s6, [r2, #-48]	; 0xffffffd0
     8d2:	vldr	s7, [r2, #-44]	; 0xffffffd4
     8d6:	vldr	s5, [r3, #-96]	; 0xffffffa0
     8da:	vldr	s3, [r3, #-92]	; 0xffffffa4
     8de:	vldr	s4, [r3, #-88]	; 0xffffffa8
     8e2:	vfma.f32	s13, s5, s6
     8e6:	vfma.f32	s9, s5, s7
     8ea:	vldr	s5, [r3, #-84]	; 0xffffffac
     8ee:	vfma.f32	s8, s6, s3
     8f2:	vfma.f32	s12, s7, s3
     8f6:	vfma.f32	s15, s6, s4
     8fa:	vfma.f32	s10, s7, s4
     8fe:	vfma.f32	s11, s6, s5
     902:	vfma.f32	s14, s7, s5
            EIGEN_GEBGP_ONESTEP(3);
     906:	vldr	s6, [r2, #-40]	; 0xffffffd8
     90a:	vldr	s7, [r2, #-36]	; 0xffffffdc
     90e:	vldr	s5, [r3, #-80]	; 0xffffffb0
     912:	vldr	s3, [r3, #-76]	; 0xffffffb4
     916:	vldr	s4, [r3, #-72]	; 0xffffffb8
     91a:	vfma.f32	s13, s5, s6
     91e:	vfma.f32	s9, s5, s7
     922:	vldr	s5, [r3, #-68]	; 0xffffffbc
     926:	vfma.f32	s8, s6, s3
     92a:	vfma.f32	s12, s7, s3
     92e:	vfma.f32	s15, s6, s4
     932:	vfma.f32	s10, s7, s4
     936:	vfma.f32	s11, s6, s5
     93a:	vfma.f32	s14, s7, s5
     93e:	adds	r3, #128	; 0x80
#else
  // 32-bit pointer operand constraint for inlined asm
  asm(" prefetch.L1 [ %1 ];" : "=r"(addr) : "r"(addr));
#endif
#elif (!EIGEN_COMP_MSVC) && (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)
  __builtin_prefetch(addr);
     940:	pld	[r3]
            internal::prefetch(blB+(48+16));
            EIGEN_GEBGP_ONESTEP(4);
     944:	vldr	s6, [r2, #-32]	; 0xffffffe0
     948:	vldr	s7, [r2, #-28]	; 0xffffffe4
     94c:	vldr	s5, [r1, #-64]	; 0xffffffc0
     950:	vldr	s3, [r1, #-60]	; 0xffffffc4
     954:	vldr	s4, [r1, #-56]	; 0xffffffc8
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     958:	vfma.f32	s13, s5, s6
     95c:	vfma.f32	s9, s5, s7
     960:	vldr	s5, [r1, #-52]	; 0xffffffcc
     964:	vfma.f32	s8, s6, s3
     968:	vfma.f32	s12, s7, s3
     96c:	vfma.f32	s15, s6, s4
     970:	vfma.f32	s10, s7, s4
     974:	vfma.f32	s11, s6, s5
     978:	vfma.f32	s14, s7, s5
            EIGEN_GEBGP_ONESTEP(5);
     97c:	vldr	s6, [r2, #-24]	; 0xffffffe8
     980:	vldr	s7, [r2, #-20]	; 0xffffffec
     984:	vldr	s5, [r1, #-48]	; 0xffffffd0
     988:	vldr	s3, [r1, #-44]	; 0xffffffd4
     98c:	vldr	s4, [r1, #-40]	; 0xffffffd8
     990:	vfma.f32	s13, s5, s6
     994:	vfma.f32	s9, s5, s7
     998:	vldr	s5, [r1, #-36]	; 0xffffffdc
     99c:	vfma.f32	s8, s6, s3
     9a0:	vfma.f32	s12, s7, s3
     9a4:	vfma.f32	s15, s6, s4
     9a8:	vfma.f32	s10, s7, s4
     9ac:	vfma.f32	s11, s6, s5
     9b0:	vfma.f32	s14, s7, s5
            EIGEN_GEBGP_ONESTEP(6);
     9b4:	vldr	s6, [r2, #-16]
     9b8:	vldr	s7, [r2, #-12]
     9bc:	vldr	s5, [r1, #-32]	; 0xffffffe0
     9c0:	vldr	s3, [r1, #-28]	; 0xffffffe4
     9c4:	vldr	s4, [r1, #-24]	; 0xffffffe8
     9c8:	vfma.f32	s13, s5, s6
     9cc:	vfma.f32	s9, s5, s7
     9d0:	vldr	s5, [r1, #-20]	; 0xffffffec
     9d4:	vfma.f32	s8, s6, s3
     9d8:	vfma.f32	s12, s7, s3
     9dc:	vfma.f32	s15, s6, s4
     9e0:	vfma.f32	s10, s7, s4
     9e4:	vfma.f32	s11, s6, s5
     9e8:	vfma.f32	s14, s7, s5
            EIGEN_GEBGP_ONESTEP(7);
     9ec:	vldr	s6, [r2, #-8]
     9f0:	vldr	s7, [r2, #-4]
     9f4:	vldr	s5, [r1, #-16]
     9f8:	vldr	s3, [r1, #-12]
     9fc:	vldr	s4, [r1, #-8]
     a00:	vfma.f32	s13, s5, s6
     a04:	vfma.f32	s9, s5, s7
     a08:	vldr	s5, [r1, #-4]
     a0c:	vfma.f32	s8, s6, s3
     a10:	vfma.f32	s12, s7, s3
     a14:	vfma.f32	s15, s6, s4
     a18:	vfma.f32	s10, s7, s4
     a1c:	vfma.f32	s11, s6, s5
     a20:	vfma.f32	s14, s7, s5
          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB*nr];
          prefetch(&blB[0]);
          LhsPacket A0, A1;

          for(Index k=0; k<peeled_kc; k+=pk)
     a24:	adds	r0, #8
     a26:	adds	r2, #64	; 0x40
     a28:	cmp	fp, r0
     a2a:	bgt.w	858 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x174>
     a2e:	ldr	r3, [sp, #8]
     a30:	add.w	r2, lr, r3
            EIGEN_GEBGP_ONESTEP(4);
            EIGEN_GEBGP_ONESTEP(5);
            EIGEN_GEBGP_ONESTEP(6);
            EIGEN_GEBGP_ONESTEP(7);

            blB += pk*4*RhsProgress;
     a34:	ldr	r3, [sp, #4]
            blA += pk*(2*Traits::LhsProgress);

            EIGEN_ASM_COMMENT("end gebp micro kernel 2pX4");
          }
          // process remaining peeled loop
          for(Index k=peeled_kc; k<depth; k++)
     a36:	cmp	sl, fp
     a38:	ble.n	a82 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x39e>
     a3a:	adds	r3, #16
     a3c:	adds	r2, #8
     a3e:	mov	r1, fp
          {
            RhsPacket B_0, B1, B2, B3, T0;
            EIGEN_GEBGP_ONESTEP(0);
     a40:	vldr	s6, [r2, #-8]
     a44:	vldr	s7, [r2, #-4]
     a48:	vldr	s5, [r3, #-16]
     a4c:	vldr	s3, [r3, #-12]
     a50:	vldr	s4, [r3, #-8]
     a54:	vfma.f32	s13, s5, s6
     a58:	vfma.f32	s9, s5, s7
     a5c:	vldr	s5, [r3, #-4]
     a60:	vfma.f32	s8, s6, s3
     a64:	vfma.f32	s12, s7, s3
     a68:	vfma.f32	s15, s6, s4
     a6c:	vfma.f32	s10, s7, s4
     a70:	vfma.f32	s11, s6, s5
     a74:	vfma.f32	s14, s7, s5
            blA += pk*(2*Traits::LhsProgress);

            EIGEN_ASM_COMMENT("end gebp micro kernel 2pX4");
          }
          // process remaining peeled loop
          for(Index k=peeled_kc; k<depth; k++)
     a78:	adds	r1, #1
     a7a:	adds	r3, #16
     a7c:	adds	r2, #8
     a7e:	cmp	sl, r1
     a80:	bne.n	a40 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x35c>
     a82:	vldr	s4, [r7, #4]
     a86:	add.w	ip, ip, #2
     a8a:	vldr	s6, [r6]
     a8e:	adds	r7, #8
     a90:	vfma.f32	s4, s0, s9
     a94:	vldr	s7, [r6, #4]
     a98:	vmov.f32	s9, s6
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     a9c:	vldr	s5, [r7, #-8]
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     aa0:	vfma.f32	s7, s0, s12
     aa4:	ldr	r3, [sp, #0]
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     aa6:	vfma.f32	s5, s0, s13
      for(Index i1=peeled_mc3; i1<peeled_mc2; i1+=actual_panel_rows)
      {
        Index actual_panel_end = (std::min)(i1+actual_panel_rows, peeled_mc2);
        for(Index j2=0; j2<packet_cols4; j2+=nr)
        {
          for(Index i=i1; i<actual_panel_end; i+=2*LhsProgress)
     aaa:	cmp	r9, ip
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     aac:	vfma.f32	s9, s0, s8
     ab0:	add	lr, r3
     ab2:	add.w	r6, r6, #8
     ab6:	add.w	r4, r4, #8
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     aba:	vstr	s4, [r7, #-4]
     abe:	add.w	r5, r5, #8
     ac2:	vstr	s5, [r7, #-8]
     ac6:	vstr	s9, [r6, #-8]
     aca:	vstr	s7, [r6, #-4]
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     ace:	vldr	s9, [r4, #-4]
     ad2:	vldr	s12, [r5, #-8]
     ad6:	vldr	s13, [r5, #-4]
     ada:	vfma.f32	s9, s0, s10
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     ade:	vldr	s10, [r4, #-8]
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     ae2:	vfma.f32	s12, s0, s11
     ae6:	vfma.f32	s13, s0, s14
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     aea:	vfma.f32	s10, s0, s15
     aee:	vstr	s9, [r4, #-4]
     af2:	vstr	s10, [r4, #-8]
     af6:	vstr	s12, [r5, #-8]
     afa:	vstr	s13, [r5, #-4]
     afe:	bgt.w	80c <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x128>
     b02:	ldr	r2, [sp, #20]
     b04:	ldr	r1, [sp, #48]	; 0x30
      Index actual_panel_rows = (2*LhsProgress) * std::max<Index>(1,( (l1 - sizeof(ResScalar)*mr*nr - depth*nr*sizeof(RhsScalar)) / (depth * sizeof(LhsScalar) * 2*LhsProgress) ));

      for(Index i1=peeled_mc3; i1<peeled_mc2; i1+=actual_panel_rows)
      {
        Index actual_panel_end = (std::min)(i1+actual_panel_rows, peeled_mc2);
        for(Index j2=0; j2<packet_cols4; j2+=nr)
     b06:	ldr	r3, [sp, #16]
     b08:	add	r2, r1
     b0a:	adds	r3, #4
     b0c:	str	r2, [sp, #20]
     b0e:	ldr	r2, [sp, #24]
     b10:	str	r3, [sp, #16]
     b12:	cmp	r2, r3
     b14:	bgt.w	7bc <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0xd8>
          r3.storePacket(1 * Traits::ResPacketSize, R3);
          }
        }
      
        // Deal with remaining columns of the rhs
        for(Index j2=packet_cols4; j2<cols; j2++)
     b18:	ldr	r3, [sp, #128]	; 0x80
     b1a:	ldr	r2, [sp, #24]
     b1c:	mov	r1, r3
     b1e:	cmp	r1, r2
     b20:	ble.w	cac <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x5c8>
     b24:	ldr.w	r8, [sp, #72]	; 0x48
     b28:	ldr	r7, [sp, #0]
     b2a:	ldr.w	ip, [sp, #8]
     b2e:	str	r2, [sp, #4]
     b30:	str.w	r8, [sp, #16]
        {
          for(Index i=i1; i<actual_panel_end; i+=2*LhsProgress)
     b34:	ldr	r3, [sp, #12]
     b36:	cmp	r9, r3
     b38:	ble.w	c96 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x5b2>
     b3c:	ldr	r2, [sp, #32]
     b3e:	ldr	r1, [sp, #36]	; 0x24
     b40:	ldr	r0, [sp, #16]
     b42:	ldr	r3, [r2, #4]
     b44:	add.w	r6, r1, r0, lsl #2
     b48:	ldr	r0, [sp, #12]
     b4a:	ldr	r1, [sp, #4]
     b4c:	ldr	r2, [r2, #0]
     b4e:	mov	r5, r0
     b50:	mla	r3, r3, r1, r0
     b54:	ldr	r1, [sp, #52]	; 0x34
     b56:	add.w	r0, r3, #8
     b5a:	add.w	lr, r6, r1
     b5e:	add.w	r4, r2, r3, lsl #2
     b62:	ldr	r1, [sp, #28]
     b64:	add.w	r0, r2, r0, lsl #2

          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB];
          LhsPacket A0, A1;

          for(Index k=0; k<peeled_kc; k+=pk)
     b68:	cmp.w	fp, #0
#else
  // 32-bit pointer operand constraint for inlined asm
  asm(" prefetch.L1 [ %1 ];" : "=r"(addr) : "r"(addr));
#endif
#elif (!EIGEN_COMP_MSVC) && (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)
  __builtin_prefetch(addr);
     b6c:	pld	[r1]
        for(Index j2=packet_cols4; j2<cols; j2++)
        {
          for(Index i=i1; i<actual_panel_end; i+=2*LhsProgress)
          {
          // One column at a time
          const LhsScalar* blA = &blockA[i*strideA+offsetA*(2*Traits::LhsProgress)];
     b70:	mov	r3, r1
     b72:	pld	[r0]

  typedef ResPacket AccPacket;
  
  EIGEN_STRONG_INLINE void initAcc(AccPacket& p)
  {
    p = pset1<ResPacket>(ResScalar(0));
     b76:	vldr	s15, [pc, #24]	; b90 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x4ac>

          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB];
          LhsPacket A0, A1;

          for(Index k=0; k<peeled_kc; k+=pk)
     b7a:	ble.w	1064 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x980>
     b7e:	vmov.f32	s14, s15
     b82:	add.w	r2, r6, #32
     b86:	add.w	r3, r1, #64	; 0x40
     b8a:	mov.w	r8, #0
     b8e:	b.n	b94 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x4b0>
     b90:	.word	0x00000000
              traits.madd(A0, B_0, C0, B1);                                       \
              traits.madd(A1, B_0, C4, B_0);                                      \
              EIGEN_ASM_COMMENT("end step of gebp micro kernel 2pX1");            \
            } while(false)
        
            EIGEN_GEBGP_ONESTEP(0);
     b94:	vldr	s13, [r2, #-32]	; 0xffffffe0
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     b98:	vldr	s11, [r3, #-64]	; 0xffffffc0
     b9c:	vldr	s12, [r3, #-60]	; 0xffffffc4
     ba0:	vfma.f32	s14, s13, s11
     ba4:	vfma.f32	s15, s13, s12
            EIGEN_GEBGP_ONESTEP(1);
     ba8:	vldr	s13, [r2, #-28]	; 0xffffffe4
     bac:	vldr	s11, [r3, #-56]	; 0xffffffc8
     bb0:	vldr	s12, [r3, #-52]	; 0xffffffcc
     bb4:	vfma.f32	s14, s13, s11
     bb8:	vfma.f32	s15, s13, s12
            EIGEN_GEBGP_ONESTEP(2);
     bbc:	vldr	s13, [r2, #-24]	; 0xffffffe8
     bc0:	vldr	s11, [r3, #-48]	; 0xffffffd0
     bc4:	vldr	s12, [r3, #-44]	; 0xffffffd4
     bc8:	vfma.f32	s14, s13, s11
     bcc:	vfma.f32	s15, s13, s12
            EIGEN_GEBGP_ONESTEP(3);
     bd0:	vldr	s13, [r2, #-20]	; 0xffffffec
     bd4:	vldr	s11, [r3, #-40]	; 0xffffffd8
     bd8:	vldr	s12, [r3, #-36]	; 0xffffffdc
     bdc:	vfma.f32	s14, s13, s11
     be0:	vfma.f32	s15, s13, s12
            EIGEN_GEBGP_ONESTEP(4);
     be4:	vldr	s13, [r2, #-16]
     be8:	vldr	s11, [r3, #-32]	; 0xffffffe0
     bec:	vldr	s12, [r3, #-28]	; 0xffffffe4
     bf0:	vfma.f32	s14, s13, s11
     bf4:	vfma.f32	s15, s13, s12
            EIGEN_GEBGP_ONESTEP(5);
     bf8:	vldr	s13, [r2, #-12]
     bfc:	vldr	s11, [r3, #-24]	; 0xffffffe8
     c00:	vldr	s12, [r3, #-20]	; 0xffffffec
     c04:	vfma.f32	s14, s13, s11
     c08:	vfma.f32	s15, s13, s12
            EIGEN_GEBGP_ONESTEP(6);
     c0c:	vldr	s13, [r2, #-8]
     c10:	vldr	s11, [r3, #-16]
     c14:	vldr	s12, [r3, #-12]
     c18:	vfma.f32	s14, s13, s11
     c1c:	vfma.f32	s15, s13, s12
            EIGEN_GEBGP_ONESTEP(7);
     c20:	vldr	s13, [r2, #-4]
     c24:	vldr	s11, [r3, #-8]
     c28:	vldr	s12, [r3, #-4]
     c2c:	vfma.f32	s14, s13, s11
     c30:	vfma.f32	s15, s13, s12

          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB];
          LhsPacket A0, A1;

          for(Index k=0; k<peeled_kc; k+=pk)
     c34:	add.w	r8, r8, #8
     c38:	adds	r2, #32
     c3a:	adds	r3, #64	; 0x40
     c3c:	cmp	fp, r8
     c3e:	bgt.n	b94 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x4b0>
     c40:	add.w	r3, r1, ip
            EIGEN_GEBGP_ONESTEP(4);
            EIGEN_GEBGP_ONESTEP(5);
            EIGEN_GEBGP_ONESTEP(6);
            EIGEN_GEBGP_ONESTEP(7);

            blB += pk*RhsProgress;
     c44:	mov	r2, lr

            EIGEN_ASM_COMMENT("end gebp micro kernel 2pX1");
          }

          // process remaining peeled loop
          for(Index k=peeled_kc; k<depth; k++)
     c46:	cmp	sl, fp
     c48:	ble.n	c6c <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x588>
     c4a:	adds	r3, #8
     c4c:	mov	r8, fp
          {
            RhsPacket B_0, B1;
            EIGEN_GEBGP_ONESTEP(0);
     c4e:	vldmia	r2!, {s13}
     c52:	vldr	s11, [r3, #-8]
     c56:	vldr	s12, [r3, #-4]
     c5a:	vfma.f32	s14, s13, s11
     c5e:	vfma.f32	s15, s13, s12

            EIGEN_ASM_COMMENT("end gebp micro kernel 2pX1");
          }

          // process remaining peeled loop
          for(Index k=peeled_kc; k<depth; k++)
     c62:	add.w	r8, r8, #1
     c66:	adds	r3, #8
     c68:	cmp	sl, r8
     c6a:	bne.n	c4e <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x56a>
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     c6c:	vldr	s12, [r0, #-32]	; 0xffffffe0
     c70:	adds	r5, #2
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     c72:	vldr	s13, [r4, #4]
     c76:	add	r1, r7
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     c78:	vfma.f32	s12, s0, s14
        }
      
        // Deal with remaining columns of the rhs
        for(Index j2=packet_cols4; j2<cols; j2++)
        {
          for(Index i=i1; i<actual_panel_end; i+=2*LhsProgress)
     c7c:	cmp	r9, r5
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     c7e:	vfma.f32	s13, s0, s15
     c82:	add.w	r0, r0, #8
     c86:	add.w	r4, r4, #8
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     c8a:	vstr	s12, [r0, #-40]	; 0xffffffd8
     c8e:	vstr	s13, [r4, #-4]
     c92:	bgt.w	b68 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x484>
     c96:	ldr	r2, [sp, #16]
     c98:	ldr	r1, [sp, #136]	; 0x88
          r3.storePacket(1 * Traits::ResPacketSize, R3);
          }
        }
      
        // Deal with remaining columns of the rhs
        for(Index j2=packet_cols4; j2<cols; j2++)
     c9a:	ldr	r3, [sp, #4]
     c9c:	add	r2, r1
     c9e:	adds	r3, #1
     ca0:	str	r2, [sp, #16]
     ca2:	ldr	r2, [sp, #128]	; 0x80
     ca4:	str	r3, [sp, #4]
     ca6:	cmp	r2, r3
     ca8:	bne.w	b34 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x450>
     cac:	ldr	r2, [sp, #28]
     cae:	ldr	r1, [sp, #68]	; 0x44
     cb0:	ldr	r3, [sp, #64]	; 0x40
     cb2:	add	r2, r1
     cb4:	str	r3, [sp, #12]
     cb6:	str	r2, [sp, #28]
      // The max(1, ...) here is needed because we may be using blocking params larger than what our known l1 cache size
      // suggests we should be using: either because our known l1 cache size is inaccurate (e.g. on Android, we can only guess),
      // or because we are testing specific blocking sizes.
      Index actual_panel_rows = (2*LhsProgress) * std::max<Index>(1,( (l1 - sizeof(ResScalar)*mr*nr - depth*nr*sizeof(RhsScalar)) / (depth * sizeof(LhsScalar) * 2*LhsProgress) ));

      for(Index i1=peeled_mc3; i1<peeled_mc2; i1+=actual_panel_rows)
     cb8:	ldr	r2, [sp, #40]	; 0x28
     cba:	cmp	r2, r3
     cbc:	bgt.w	79a <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0xb6>
    }
    //---------- Process 1 * LhsProgress rows at once ----------
    if(mr>=1*Traits::LhsProgress)
    {
      // loops on each largest micro horizontal panel of lhs (1*LhsProgress x depth)
      for(Index i=peeled_mc2; i<peeled_mc1; i+=1*LhsProgress)
     cc0:	ldr	r3, [sp, #120]	; 0x78
     cc2:	ldr	r2, [sp, #40]	; 0x28
     cc4:	cmp	r3, r2
     cc6:	ble.w	105e <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x97a>
     cca:	ldr	r4, [sp, #136]	; 0x88
     ccc:	add.w	r1, fp, #4294967295
     cd0:	ldr	r5, [sp, #144]	; 0x90
     cd2:	ldr	r3, [sp, #24]
     cd4:	lsrs	r1, r1, #3
     cd6:	ldr	r0, [sp, #40]	; 0x28
     cd8:	mla	r3, r4, r3, r5
     cdc:	ldr	r5, [sp, #36]	; 0x24
     cde:	add.w	r2, r0, #8
     ce2:	ldr	r6, [sp, #144]	; 0x90
     ce4:	add.w	r3, r5, r3, lsl #2
     ce8:	lsls	r2, r2, #2
     cea:	str	r3, [sp, #36]	; 0x24
     cec:	add.w	r4, r5, r6, lsl #4
     cf0:	ldr	r3, [sp, #136]	; 0x88
     cf2:	str	r2, [sp, #16]
     cf4:	adds	r2, r1, #1
     cf6:	lsls	r3, r3, #4
     cf8:	str	r4, [sp, #28]
     cfa:	ldr	r6, [sp, #140]	; 0x8c
     cfc:	str	r3, [sp, #0]
     cfe:	lsls	r3, r2, #7
     d00:	ldr	r4, [sp, #132]	; 0x84
     d02:	str	r3, [sp, #8]
     d04:	lsls	r3, r2, #5
     d06:	mla	r0, r0, r4, r6
     d0a:	str	r3, [sp, #20]
     d0c:	ldr	r3, [sp, #136]	; 0x88
     d0e:	str	r0, [sp, #12]
     d10:	lsls	r3, r3, #2
     d12:	str	r3, [sp, #44]	; 0x2c
      {
        // loops on each largest micro vertical panel of rhs (depth * nr)
        for(Index j2=0; j2<packet_cols4; j2+=nr)
     d14:	ldr	r3, [sp, #24]
     d16:	cmp	r3, #0
     d18:	ble.w	f52 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x86e>
     d1c:	ldr	r2, [sp, #32]
     d1e:	mov.w	r8, #0
     d22:	ldr	r1, [sp, #56]	; 0x38
     d24:	ldr	r0, [sp, #12]
     d26:	ldr	r3, [r2, #4]
     d28:	add.w	r9, r1, r0, lsl #2
     d2c:	ldr	r1, [sp, #40]	; 0x28
     d2e:	ldr	r2, [r2, #0]
     d30:	mov.w	ip, r3, lsl #4
     d34:	adds	r7, r1, r3
     d36:	ldr	r1, [sp, #16]
     d38:	ldr	r4, [sp, #28]
     d3a:	adds	r6, r7, r3
     d3c:	add.w	lr, r2, r1
     d40:	adds	r7, #8
     d42:	ldr	r1, [sp, #20]
     d44:	add	r3, r6
     d46:	adds	r6, #8
     d48:	add	r1, r9
     d4a:	add.w	r7, r2, r7, lsl #2
     d4e:	adds	r3, #8
     d50:	add.w	r6, r2, r6, lsl #2
     d54:	str	r1, [sp, #4]
     d56:	add.w	r5, r2, r3, lsl #2
          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB*nr];
          prefetch(&blB[0]);
          LhsPacket A0;

          for(Index k=0; k<peeled_kc; k+=pk)
     d5a:	cmp.w	fp, #0
#else
  // 32-bit pointer operand constraint for inlined asm
  asm(" prefetch.L1 [ %1 ];" : "=r"(addr) : "r"(addr));
#endif
#elif (!EIGEN_COMP_MSVC) && (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)
  __builtin_prefetch(addr);
     d5e:	pld	[r9]
          r1.prefetch(prefetch_res_offset);
          r2.prefetch(prefetch_res_offset);
          r3.prefetch(prefetch_res_offset);

          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB*nr];
     d62:	mov	r3, r4
     d64:	pld	[lr]
     d68:	pld	[r7]
     d6c:	pld	[r6]
     d70:	pld	[r5]
     d74:	pld	[r4]
          prefetch(&blB[0]);
          LhsPacket A0;

          for(Index k=0; k<peeled_kc; k+=pk)
     d78:	ble.w	1098 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x9b4>
     d7c:	vldr	s15, [pc, #-496]	; b90 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x4ac>
     d80:	add.w	r3, r4, #128	; 0x80
     d84:	add.w	r1, r9, #32
     d88:	movs	r0, #0
     d8a:	vmov.f32	s12, s15
     d8e:	vmov.f32	s14, s15
     d92:	vmov.f32	s13, s15
     d96:	pld	[r3, #64]	; 0x40
              traits.madd(A0, B3,  C3, B3);                                     \
              EIGEN_ASM_COMMENT("end step of gebp micro kernel 1pX4");          \
            } while(false)
            
            internal::prefetch(blB+(48+0));
            EIGEN_GEBGP_ONESTEP(0);
     d9a:	vldr	s11, [r1, #-32]	; 0xffffffe0
     d9e:	mov	r2, r3
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     da0:	vldr	s10, [r3, #-128]	; 0xffffff80
     da4:	vldr	s8, [r3, #-124]	; 0xffffff84
     da8:	vldr	s9, [r3, #-120]	; 0xffffff88
     dac:	vfma.f32	s15, s10, s11
     db0:	vldr	s10, [r3, #-116]	; 0xffffff8c
     db4:	vfma.f32	s12, s11, s8
     db8:	vfma.f32	s13, s11, s9
     dbc:	vfma.f32	s14, s11, s10
            EIGEN_GEBGP_ONESTEP(1);
     dc0:	vldr	s11, [r1, #-28]	; 0xffffffe4
     dc4:	vldr	s10, [r3, #-112]	; 0xffffff90
     dc8:	vldr	s8, [r3, #-108]	; 0xffffff94
     dcc:	vldr	s9, [r3, #-104]	; 0xffffff98
     dd0:	vfma.f32	s15, s10, s11
     dd4:	vldr	s10, [r3, #-100]	; 0xffffff9c
     dd8:	vfma.f32	s12, s11, s8
     ddc:	vfma.f32	s13, s11, s9
     de0:	vfma.f32	s14, s11, s10
            EIGEN_GEBGP_ONESTEP(2);
     de4:	vldr	s11, [r1, #-24]	; 0xffffffe8
     de8:	vldr	s10, [r3, #-96]	; 0xffffffa0
     dec:	vldr	s8, [r3, #-92]	; 0xffffffa4
     df0:	vldr	s9, [r3, #-88]	; 0xffffffa8
     df4:	vfma.f32	s15, s10, s11
     df8:	vldr	s10, [r3, #-84]	; 0xffffffac
     dfc:	vfma.f32	s12, s11, s8
     e00:	vfma.f32	s13, s11, s9
     e04:	vfma.f32	s14, s11, s10
            EIGEN_GEBGP_ONESTEP(3);
     e08:	vldr	s11, [r1, #-20]	; 0xffffffec
     e0c:	vldr	s10, [r3, #-80]	; 0xffffffb0
     e10:	vldr	s8, [r3, #-76]	; 0xffffffb4
     e14:	vldr	s9, [r3, #-72]	; 0xffffffb8
     e18:	vfma.f32	s15, s10, s11
     e1c:	vldr	s10, [r3, #-68]	; 0xffffffbc
     e20:	vfma.f32	s12, s11, s8
     e24:	vfma.f32	s13, s11, s9
     e28:	vfma.f32	s14, s11, s10
     e2c:	adds	r3, #128	; 0x80
#else
  // 32-bit pointer operand constraint for inlined asm
  asm(" prefetch.L1 [ %1 ];" : "=r"(addr) : "r"(addr));
#endif
#elif (!EIGEN_COMP_MSVC) && (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)
  __builtin_prefetch(addr);
     e2e:	pld	[r3]
            internal::prefetch(blB+(48+16));
            EIGEN_GEBGP_ONESTEP(4);
     e32:	vldr	s11, [r1, #-16]
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     e36:	vldr	s10, [r2, #-64]	; 0xffffffc0
     e3a:	vldr	s8, [r2, #-60]	; 0xffffffc4
     e3e:	vldr	s9, [r2, #-56]	; 0xffffffc8
     e42:	vfma.f32	s15, s10, s11
     e46:	vldr	s10, [r2, #-52]	; 0xffffffcc
     e4a:	vfma.f32	s12, s11, s8
     e4e:	vfma.f32	s13, s11, s9
     e52:	vfma.f32	s14, s11, s10
            EIGEN_GEBGP_ONESTEP(5);
     e56:	vldr	s11, [r1, #-12]
     e5a:	vldr	s10, [r2, #-48]	; 0xffffffd0
     e5e:	vldr	s8, [r2, #-44]	; 0xffffffd4
     e62:	vldr	s9, [r2, #-40]	; 0xffffffd8
     e66:	vfma.f32	s15, s10, s11
     e6a:	vldr	s10, [r2, #-36]	; 0xffffffdc
     e6e:	vfma.f32	s12, s11, s8
     e72:	vfma.f32	s13, s11, s9
     e76:	vfma.f32	s14, s11, s10
            EIGEN_GEBGP_ONESTEP(6);
     e7a:	vldr	s11, [r1, #-8]
     e7e:	vldr	s10, [r2, #-32]	; 0xffffffe0
     e82:	vldr	s8, [r2, #-28]	; 0xffffffe4
     e86:	vldr	s9, [r2, #-24]	; 0xffffffe8
     e8a:	vfma.f32	s15, s10, s11
     e8e:	vldr	s10, [r2, #-20]	; 0xffffffec
     e92:	vfma.f32	s12, s11, s8
     e96:	vfma.f32	s13, s11, s9
     e9a:	vfma.f32	s14, s11, s10
            EIGEN_GEBGP_ONESTEP(7);
     e9e:	vldr	s11, [r1, #-4]
     ea2:	vldr	s10, [r2, #-16]
     ea6:	vldr	s8, [r2, #-12]
     eaa:	vldr	s9, [r2, #-8]
     eae:	vfma.f32	s15, s10, s11
     eb2:	vldr	s10, [r2, #-4]
     eb6:	vfma.f32	s12, s11, s8
     eba:	vfma.f32	s13, s11, s9
     ebe:	vfma.f32	s14, s11, s10
          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB*nr];
          prefetch(&blB[0]);
          LhsPacket A0;

          for(Index k=0; k<peeled_kc; k+=pk)
     ec2:	adds	r0, #8
     ec4:	adds	r1, #32
     ec6:	cmp	fp, r0
     ec8:	bgt.w	d96 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x6b2>
     ecc:	ldr	r3, [sp, #8]
            EIGEN_GEBGP_ONESTEP(5);
            EIGEN_GEBGP_ONESTEP(6);
            EIGEN_GEBGP_ONESTEP(7);

            blB += pk*4*RhsProgress;
            blA += pk*1*LhsProgress;
     ece:	ldr	r1, [sp, #4]
     ed0:	adds	r3, r4, r3

            EIGEN_ASM_COMMENT("end gebp micro kernel 1pX4");
          }
          // process remaining peeled loop
          for(Index k=peeled_kc; k<depth; k++)
     ed2:	cmp	sl, fp
     ed4:	ble.n	f06 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x822>
     ed6:	adds	r3, #16
     ed8:	mov	r2, fp
          {
            RhsPacket B_0, B1, B2, B3;
            EIGEN_GEBGP_ONESTEP(0);
     eda:	vldmia	r1!, {s11}
     ede:	vldr	s10, [r3, #-16]
     ee2:	vldr	s8, [r3, #-12]
     ee6:	vldr	s9, [r3, #-8]
     eea:	vfma.f32	s15, s10, s11
     eee:	vldr	s10, [r3, #-4]
     ef2:	vfma.f32	s12, s11, s8
     ef6:	vfma.f32	s13, s11, s9
     efa:	vfma.f32	s14, s11, s10
            blA += pk*1*LhsProgress;

            EIGEN_ASM_COMMENT("end gebp micro kernel 1pX4");
          }
          // process remaining peeled loop
          for(Index k=peeled_kc; k<depth; k++)
     efe:	adds	r2, #1
     f00:	adds	r3, #16
     f02:	cmp	sl, r2
     f04:	bne.n	eda <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x7f6>
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     f06:	vldr	s10, [lr, #-32]	; 0xffffffe0
    {
      // loops on each largest micro horizontal panel of lhs (1*LhsProgress x depth)
      for(Index i=peeled_mc2; i<peeled_mc1; i+=1*LhsProgress)
      {
        // loops on each largest micro vertical panel of rhs (depth * nr)
        for(Index j2=0; j2<packet_cols4; j2+=nr)
     f0a:	add.w	r8, r8, #4
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     f0e:	vldr	s11, [r7, #-32]	; 0xffffffe0
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     f12:	vfma.f32	s10, s0, s15
     f16:	ldr	r3, [sp, #0]
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     f18:	vmov.f32	s15, s11
     f1c:	add	r4, r3
     f1e:	ldr	r3, [sp, #24]
     f20:	vfma.f32	s15, s0, s12
     f24:	cmp	r3, r8
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     f26:	vstr	s10, [lr, #-32]	; 0xffffffe0
     f2a:	add	lr, ip
     f2c:	vstr	s15, [r7, #-32]	; 0xffffffe0
     f30:	add	r7, ip
     f32:	vldr	s12, [r6, #-32]	; 0xffffffe0
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     f36:	vldr	s15, [r5, #-32]	; 0xffffffe0
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     f3a:	vfma.f32	s12, s0, s13
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     f3e:	vfma.f32	s15, s0, s14
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
     f42:	vstr	s12, [r6, #-32]	; 0xffffffe0
     f46:	add	r6, ip
     f48:	vstr	s15, [r5, #-32]	; 0xffffffe0
     f4c:	add	r5, ip
     f4e:	bgt.w	d5a <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x676>
          r2.storePacket(0 * Traits::ResPacketSize, R0);
          r3.storePacket(0 * Traits::ResPacketSize, R1);
        }

        // Deal with remaining columns of the rhs
        for(Index j2=packet_cols4; j2<cols; j2++)
     f52:	ldr	r3, [sp, #128]	; 0x80
     f54:	ldr	r2, [sp, #24]
     f56:	cmp	r3, r2
     f58:	ble.n	1042 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x95e>
     f5a:	ldr	r2, [sp, #32]
     f5c:	ldr	r3, [sp, #56]	; 0x38
     f5e:	ldr	r5, [r2, #4]
     f60:	ldr	r1, [sp, #12]
     f62:	ldr	r6, [sp, #40]	; 0x28
     f64:	ldr	r0, [sp, #24]
     f66:	add.w	r4, r3, r1, lsl #2
     f6a:	ldr	r3, [r2, #0]
     f6c:	mla	r7, r5, r0, r6
     f70:	ldr	r2, [sp, #20]
     f72:	ldr	r1, [sp, #36]	; 0x24
     f74:	lsls	r5, r5, #2
     f76:	adds	r6, r4, r2
     f78:	add.w	r7, r3, r7, lsl #2
     f7c:	ldr.w	lr, [sp, #44]	; 0x2c
     f80:	mov	ip, r2
     f82:	ldr.w	r8, [sp, #128]	; 0x80

          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB];
          LhsPacket A0;

          for(Index k=0; k<peeled_kc; k+=pk)
     f86:	cmp.w	fp, #0
#else
  // 32-bit pointer operand constraint for inlined asm
  asm(" prefetch.L1 [ %1 ];" : "=r"(addr) : "r"(addr));
#endif
#elif (!EIGEN_COMP_MSVC) && (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)
  __builtin_prefetch(addr);
     f8a:	pld	[r4]
          traits.initAcc(C0);

          LinearMapper r0 = res.getLinearMapper(i, j2);

          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB];
     f8e:	mov	r9, r1
          LhsPacket A0;

          for(Index k=0; k<peeled_kc; k+=pk)
     f90:	ble.n	1090 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x9ac>
     f92:	add.w	r2, r1, #32
     f96:	add.w	r3, r4, #32
     f9a:	vldr	s15, [pc, #272]	; 10ac <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x9c8>
     f9e:	mov.w	r9, #0
}

/** \internal \returns a + b (coeff-wise) */
template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
padd(const Packet& a,
        const Packet& b) { return a+b; }
     fa2:	vldr	s13, [r2, #-32]	; 0xffffffe0
     fa6:	vldr	s14, [r3, #-32]	; 0xffffffe0
     faa:	vfma.f32	s15, s13, s14
     fae:	vldr	s13, [r2, #-28]	; 0xffffffe4
     fb2:	vldr	s14, [r3, #-28]	; 0xffffffe4
     fb6:	vfma.f32	s15, s13, s14
     fba:	vldr	s13, [r2, #-24]	; 0xffffffe8
     fbe:	vldr	s14, [r3, #-24]	; 0xffffffe8
     fc2:	vfma.f32	s15, s13, s14
     fc6:	vldr	s13, [r2, #-20]	; 0xffffffec
     fca:	vldr	s14, [r3, #-20]	; 0xffffffec
     fce:	vfma.f32	s15, s13, s14
     fd2:	vldr	s13, [r2, #-16]
     fd6:	vldr	s14, [r3, #-16]
     fda:	vfma.f32	s15, s13, s14
     fde:	vldr	s13, [r2, #-12]
     fe2:	vldr	s14, [r3, #-12]
     fe6:	vfma.f32	s15, s13, s14
     fea:	vldr	s13, [r2, #-8]
     fee:	vldr	s14, [r3, #-8]
     ff2:	vfma.f32	s15, s13, s14
     ff6:	vldr	s13, [r2, #-4]
     ffa:	vldr	s14, [r3, #-4]
     ffe:	vfma.f32	s15, s13, s14
    1002:	add.w	r9, r9, #8
    1006:	adds	r2, #32
    1008:	adds	r3, #32
    100a:	cmp	fp, r9
    100c:	bgt.n	fa2 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x8be>
    100e:	add.w	r9, r1, ip
            EIGEN_GEBGP_ONESTEP(5);
            EIGEN_GEBGP_ONESTEP(6);
            EIGEN_GEBGP_ONESTEP(7);

            blB += pk*RhsProgress;
            blA += pk*1*Traits::LhsProgress;
    1012:	mov	r2, r6

            EIGEN_ASM_COMMENT("end gebp micro kernel 1pX1");
          }

          // process remaining peeled loop
          for(Index k=peeled_kc; k<depth; k++)
    1014:	cmp	sl, fp
    1016:	ble.n	102c <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x948>
    1018:	mov	r3, fp
          {
            RhsPacket B_0;
            EIGEN_GEBGP_ONESTEP(0);
    101a:	vldmia	r2!, {s14}
    101e:	vldmia	r9!, {s13}
    1022:	vfma.f32	s15, s13, s14

            EIGEN_ASM_COMMENT("end gebp micro kernel 1pX1");
          }

          // process remaining peeled loop
          for(Index k=peeled_kc; k<depth; k++)
    1026:	adds	r3, #1
    1028:	cmp	sl, r3
    102a:	bne.n	101a <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x936>
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
{ (*to) = from; }

/** \internal copy the packet \a from to \a *to, (un-aligned store) */
template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
{  (*to) = from; }
    102c:	vldr	s14, [r7]
          r2.storePacket(0 * Traits::ResPacketSize, R0);
          r3.storePacket(0 * Traits::ResPacketSize, R1);
        }

        // Deal with remaining columns of the rhs
        for(Index j2=packet_cols4; j2<cols; j2++)
    1030:	adds	r0, #1
    1032:	add	r1, lr
    1034:	vfma.f32	s14, s0, s15
    1038:	cmp	r8, r0
    103a:	vstr	s14, [r7]
    103e:	add	r7, r5
    1040:	bne.n	f86 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x8a2>
    1042:	ldr	r2, [sp, #12]
    1044:	ldr	r1, [sp, #132]	; 0x84
    }
    //---------- Process 1 * LhsProgress rows at once ----------
    if(mr>=1*Traits::LhsProgress)
    {
      // loops on each largest micro horizontal panel of lhs (1*LhsProgress x depth)
      for(Index i=peeled_mc2; i<peeled_mc1; i+=1*LhsProgress)
    1046:	ldr	r3, [sp, #40]	; 0x28
    1048:	add	r2, r1
    104a:	adds	r3, #1
    104c:	str	r2, [sp, #12]
    104e:	ldr	r2, [sp, #16]
    1050:	str	r3, [sp, #40]	; 0x28
    1052:	adds	r2, #4
    1054:	str	r2, [sp, #16]
    1056:	ldr	r2, [sp, #120]	; 0x78
    1058:	cmp	r2, r3
    105a:	bne.w	d14 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x630>
          }
          res(i, j2) += alpha * C0;
        }
      }
    }
  }
    105e:	add	sp, #84	; 0x54
    1060:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}

          LinearMapper r0 = res.getLinearMapper(i, j2);
          r0.prefetch(prefetch_res_offset);

          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB];
    1064:	mov	r2, r6

  typedef ResPacket AccPacket;
  
  EIGEN_STRONG_INLINE void initAcc(AccPacket& p)
  {
    p = pset1<ResPacket>(ResScalar(0));
    1066:	vmov.f32	s14, s15
    106a:	b.n	c46 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x562>
    106c:	vldr	s14, [pc, #60]	; 10ac <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x9c8>
          r1.prefetch(prefetch_res_offset);
          r2.prefetch(prefetch_res_offset);
          r3.prefetch(prefetch_res_offset);

          // performs "inner" products
          const RhsScalar* blB = &blockB[j2*strideB+offsetB*nr];
    1070:	mov	r3, r8

  typedef ResPacket AccPacket;
  
  EIGEN_STRONG_INLINE void initAcc(AccPacket& p)
  {
    p = pset1<ResPacket>(ResScalar(0));
    1072:	vmov.f32	s10, s14
    1076:	vmov.f32	s12, s14
    107a:	vmov.f32	s9, s14
    107e:	vmov.f32	s11, s14
    1082:	vmov.f32	s15, s14
    1086:	vmov.f32	s8, s14
    108a:	vmov.f32	s13, s14
    108e:	b.n	a36 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x352>

        // Deal with remaining columns of the rhs
        for(Index j2=packet_cols4; j2<cols; j2++)
        {
          // One column at a time
          const LhsScalar* blA = &blockA[i*strideA+offsetA*(1*Traits::LhsProgress)];
    1090:	mov	r2, r4

  typedef ResPacket AccPacket;
  
  EIGEN_STRONG_INLINE void initAcc(AccPacket& p)
  {
    p = pset1<ResPacket>(ResScalar(0));
    1092:	vldr	s15, [pc, #24]	; 10ac <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x9c8>
    1096:	b.n	1014 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x930>
    1098:	vldr	s14, [pc, #16]	; 10ac <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x9c8>
        for(Index j2=0; j2<packet_cols4; j2+=nr)
        {
          // We select a 1*Traits::LhsProgress x nr micro block of res which is entirely
          // stored into 1 x nr registers.
          
          const LhsScalar* blA = &blockA[i*strideA+offsetA*(1*Traits::LhsProgress)];
    109c:	mov	r1, r9

  typedef ResPacket AccPacket;
  
  EIGEN_STRONG_INLINE void initAcc(AccPacket& p)
  {
    p = pset1<ResPacket>(ResScalar(0));
    109e:	vmov.f32	s13, s14
    10a2:	vmov.f32	s12, s14
    10a6:	vmov.f32	s15, s14
    10aa:	b.n	ed2 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)+0x7ee>
    10ac:	.word	0x00000000

000010b0 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)>:
{

typedef gebp_traits<LhsScalar,RhsScalar> Traits;

typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
static void run(Index rows, Index cols, Index depth,
    10b0:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    10b4:	vpush	{d8}
    10b8:	sub	sp, #164	; 0xa4
    10ba:	mov	r6, r3
    10bc:	mov	fp, r1
    10be:	vmov.f32	s16, s0
    10c2:	add	r7, sp, #32
    10c4:	ldr.w	r4, [r7, #196]	; 0xc4
    10c8:	str	r2, [r7, #52]	; 0x34
    10ca:	ldr	r2, [r4, #8]
    10cc:	ldr	r3, [r4, #16]
    10ce:	cmp	r2, r0
    10d0:	str	r0, [r7, #32]
    10d2:	mov	r1, r3
    10d4:	str	r3, [r7, #56]	; 0x38
    10d6:	mov	r3, r2
    10d8:	it	ge
    10da:	movge	r3, r0
    10dc:	mov	r2, r3
    10de:	str	r3, [r7, #24]
    10e0:	ldr	r3, [r4, #12]
#endif // EIGEN_HAS_OPENMP
  {
    EIGEN_UNUSED_VARIABLE(info);

    // this is the sequential version!
    std::size_t sizeA = kc*mc;
    10e2:	mul.w	r8, r2, r1
    10e6:	cmp	r3, fp
    10e8:	it	ge
    10ea:	movge	r3, fp
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    10ec:	cmp.w	r8, #1073741824	; 0x40000000
    10f0:	str	r3, [r7, #80]	; 0x50
    std::size_t sizeB = kc*nc;
    10f2:	mul.w	r5, r3, r1
    10f6:	bcc.n	1100 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x50>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    10f8:	mov.w	r0, #4294967295
    10fc:	bl	6d9c <operator new(unsigned int)>
    1100:	ldr	r3, [r4, #0]
    1102:	str	r3, [r7, #88]	; 0x58

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    1104:	cmp	r3, #0
    1106:	beq.w	1324 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x274>
    110a:	movs	r3, #0
    110c:	str	r3, [r7, #8]
    110e:	str	r3, [r7, #16]
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    1110:	cmp.w	r5, #1073741824	; 0x40000000
    1114:	bcc.n	111e <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x6e>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    1116:	mov.w	r0, #4294967295
    111a:	bl	6d9c <operator new(unsigned int)>
    111e:	ldr	r3, [r4, #4]
    1120:	str	r3, [r7, #96]	; 0x60
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());
    1122:	cmp	r3, #0
    1124:	beq.w	12fe <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x24e>
    1128:	movs	r3, #0
    112a:	str	r3, [r7, #4]
    112c:	str	r3, [r7, #12]

    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;
    112e:	ldr	r3, [r7, #32]
    1130:	ldr	r2, [r7, #24]
    1132:	cmp	r3, r2
    1134:	beq.w	12f8 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x248>
    1138:	ldr	r3, [r7, #52]	; 0x34
    113a:	ldr	r2, [r7, #56]	; 0x38
    113c:	ldr	r1, [r7, #80]	; 0x50
    113e:	cmp	r3, r2
    1140:	it	eq
    1142:	cmpeq	fp, r1
    1144:	ite	eq
    1146:	moveq	r3, #1
    1148:	movne	r3, #0
    114a:	str	r3, [r7, #76]	; 0x4c

    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    114c:	ldr	r3, [r7, #32]
    114e:	cmp	r3, #0
    1150:	ble.w	12d0 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x220>
    1154:	ldr	r3, [r7, #56]	; 0x38
    1156:	ldr	r1, [r7, #80]	; 0x50
    1158:	ldr.w	r2, [r7, #176]	; 0xb0
    115c:	ldr.w	r0, [r7, #192]	; 0xc0
    1160:	mul.w	r2, r3, r2
    1164:	mov	r3, r1
    1166:	str	r6, [r7, #36]	; 0x24
    1168:	mul.w	r3, r3, r0
    116c:	lsls	r2, r2, #2
    116e:	ldr	r0, [r7, #24]
    1170:	lsls	r3, r3, #2
    1172:	str	r2, [r7, #40]	; 0x28
    1174:	ldr.w	r2, [r7, #188]	; 0xbc
    1178:	lsls	r0, r0, #2
    117a:	str	r3, [r7, #68]	; 0x44
    117c:	mov	r3, r1
    117e:	str	r2, [r7, #48]	; 0x30
    1180:	ldr.w	r2, [r7, #184]	; 0xb8
    1184:	str	r0, [r7, #20]
    1186:	mul.w	r3, r3, r2
    118a:	str	r3, [r7, #72]	; 0x48
    118c:	movs	r3, #0
    118e:	str	r3, [r7, #44]	; 0x2c
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;
    1190:	ldr	r1, [r7, #24]

      for(Index k2=0; k2<depth; k2+=kc)
    1192:	mov.w	sl, #0
    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;

    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;
    1196:	ldr	r2, [r7, #44]	; 0x2c
    1198:	adds	r3, r1, r2
    119a:	ldr	r1, [r7, #36]	; 0x24
    119c:	str	r1, [r7, #64]	; 0x40
    119e:	ldr	r1, [r7, #32]
    11a0:	str	r3, [r7, #28]
    11a2:	cmp	r3, r1
    11a4:	ite	le
    11a6:	rsble	r2, r2, r3
    11aa:	rsbgt	r2, r2, r1

      for(Index k2=0; k2<depth; k2+=kc)
    11ae:	ldr	r1, [r7, #52]	; 0x34
    11b0:	cmp	sl, r1
    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;

    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;
    11b2:	str	r2, [r7, #92]	; 0x5c

      for(Index k2=0; k2<depth; k2+=kc)
    11b4:	bge.n	12b2 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x202>
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    11b6:	ldr	r3, [r7, #56]	; 0x38

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    11b8:	movs	r4, #0
  typedef typename packet_traits<Scalar>::half HalfPacket;

  typedef BlasLinearMapper<Scalar, Index, AlignmentType> LinearMapper;
  typedef BlasVectorMapper<Scalar, Index> VectorMapper;

  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE blas_data_mapper(Scalar* data, Index stride) : m_data(data), m_stride(stride) {}
    11ba:	ldr	r5, [r7, #64]	; 0x40
    11bc:	add.w	r2, r7, #120	; 0x78
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    11c0:	add	r3, sl

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    11c2:	str	r4, [sp, #8]
    11c4:	str	r5, [r7, #120]	; 0x78
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    11c6:	mov	r0, r3
    11c8:	str	r3, [r7, #60]	; 0x3c

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    11ca:	ldr	r3, [r7, #92]	; 0x5c
    11cc:	ldr.w	r5, [r7, #176]	; 0xb0
    11d0:	str	r3, [sp, #0]
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    11d2:	mov	r3, r1

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    11d4:	str	r4, [sp, #4]
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    11d6:	cmp	r3, r0
    11d8:	ite	le
    11da:	rsble	sl, sl, r3
    11de:	rsbgt	sl, sl, r0

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    11e2:	ldr	r1, [r7, #88]	; 0x58
    11e4:	add.w	r0, r7, #108	; 0x6c
    11e8:	str	r5, [r7, #124]	; 0x7c
    11ea:	mov	r3, sl
    11ec:	bl	550 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)>

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
    11f0:	cmp	fp, r4
    11f2:	ble.n	12a0 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x1f0>
    11f4:	ldr	r3, [r7, #44]	; 0x2c

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
            pack_rhs(blockB, rhs.getSubMapper(k2,j2), actual_kc, actual_nc);
    11f6:	mov	r8, r4
    11f8:	ldr	r2, [r7, #60]	; 0x3c
    11fa:	clz	r3, r3
    11fe:	ldr	r1, [r7, #56]	; 0x38
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
    1200:	ldr	r5, [r7, #48]	; 0x30
    1202:	lsrs	r3, r3, #5
    1204:	rsb	r9, r1, r2

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
            pack_rhs(blockB, rhs.getSubMapper(k2,j2), actual_kc, actual_nc);
    1208:	str	r5, [r7, #100]	; 0x64
    120a:	str	r3, [r7, #84]	; 0x54
    120c:	b.n	125a <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x1aa>

          // Everything is packed, we can now call the panel * block kernel:
          gebp(res.getSubMapper(i2, j2), blockA, blockB, actual_mc, actual_kc, actual_nc, alpha);
    120e:	str	r4, [sp, #8]
    1210:	mov.w	r2, #4294967295
    1214:	ldr	r4, [r7, #72]	; 0x48
    1216:	mov.w	r1, #4294967295
    121a:	ldr	r5, [r7, #100]	; 0x64
    121c:	vmov.f32	s0, s16
    1220:	add	r9, r4
    1222:	ldr	r4, [r7, #92]	; 0x5c
    1224:	str	r5, [r7, #120]	; 0x78
    1226:	add.w	r0, r7, #116	; 0x74
    122a:	str	r4, [sp, #0]
    122c:	ldr	r4, [r7, #68]	; 0x44
    122e:	str	r2, [sp, #16]
    1230:	add	r5, r4
    1232:	ldr.w	r4, [r7, #192]	; 0xc0
    1236:	str	r1, [sp, #12]
    1238:	add.w	r1, r7, #120	; 0x78
    123c:	str.w	r8, [sp, #24]
    1240:	str.w	r8, [sp, #20]
    1244:	ldr	r3, [r7, #96]	; 0x60
    1246:	ldr	r2, [r7, #88]	; 0x58
    1248:	str.w	sl, [sp, #4]
    124c:	str	r4, [r7, #124]	; 0x7c
    124e:	mov	r4, r6
    1250:	str	r5, [r7, #100]	; 0x64
    1252:	bl	6e4 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)>
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
    1256:	cmp	fp, r6
    1258:	ble.n	12a0 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x1f0>
        {
          const Index actual_nc = (std::min)(j2+nc,cols)-j2;
    125a:	ldr	r3, [r7, #80]	; 0x50

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
    125c:	ldr	r2, [r7, #84]	; 0x54
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
        {
          const Index actual_nc = (std::min)(j2+nc,cols)-j2;
    125e:	adds	r6, r3, r4

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
    1260:	ldr	r3, [r7, #76]	; 0x4c
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
        {
          const Index actual_nc = (std::min)(j2+nc,cols)-j2;
    1262:	cmp	fp, r6
    1264:	ite	le
    1266:	rsble	r4, r4, fp
    126a:	rsbgt	r4, r4, r6

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
    126e:	cmp	r3, r2
    1270:	bhi.n	120e <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x15e>
    1272:	ldr.w	r3, [r7, #180]	; 0xb4
            pack_rhs(blockB, rhs.getSubMapper(k2,j2), actual_kc, actual_nc);
    1276:	add.w	r2, r7, #120	; 0x78
    127a:	ldr.w	r5, [r7, #184]	; 0xb8
    127e:	add.w	r0, r7, #112	; 0x70
    1282:	add.w	lr, r3, r9, lsl #2
    1286:	str.w	r8, [sp, #8]
    128a:	str.w	r8, [sp, #4]
    128e:	mov	r3, sl
    1290:	str	r4, [sp, #0]
    1292:	ldr	r1, [r7, #96]	; 0x60
    1294:	str	r5, [r7, #124]	; 0x7c
    1296:	str.w	lr, [r7, #120]	; 0x78
    129a:	bl	5f8 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 4, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)>
    129e:	b.n	120e <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x15e>
    12a0:	ldr	r3, [r7, #64]	; 0x40
    12a2:	ldr	r2, [r7, #40]	; 0x28
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    12a4:	ldr.w	sl, [r7, #60]	; 0x3c
    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
    12a8:	ldr	r1, [r7, #52]	; 0x34
    12aa:	add	r3, r2
    12ac:	cmp	sl, r1
    12ae:	str	r3, [r7, #64]	; 0x40
    12b0:	blt.n	11b6 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x106>
    12b2:	ldr	r2, [r7, #36]	; 0x24
    12b4:	ldr	r1, [r7, #20]
    12b6:	mov	r0, r2
    12b8:	ldr	r2, [r7, #48]	; 0x30
    12ba:	ldr	r3, [r7, #28]
    12bc:	add	r0, r1
    12be:	str	r3, [r7, #44]	; 0x2c
    12c0:	str	r0, [r7, #36]	; 0x24
    12c2:	mov	r0, r2
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());

    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;

    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    12c4:	ldr	r2, [r7, #32]
    12c6:	add	r0, r1
    12c8:	cmp	r3, r2
    12ca:	str	r0, [r7, #48]	; 0x30
    12cc:	blt.w	1190 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0xe0>
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    12d0:	ldr	r3, [r7, #4]
    12d2:	cbz	r3, 12de <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x22e>
    12d4:	ldr	r3, [r7, #12]
    12d6:	ldr.w	r0, [r3, #-4]
    12da:	bl	7248 <free>
    12de:	ldr	r3, [r7, #8]
    12e0:	cbz	r3, 12ec <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x23c>
    12e2:	ldr	r3, [r7, #16]
    12e4:	ldr.w	r0, [r3, #-4]
    12e8:	bl	7248 <free>
          gebp(res.getSubMapper(i2, j2), blockA, blockB, actual_mc, actual_kc, actual_nc, alpha);
        }
      }
    }
  }
}
    12ec:	adds	r7, #132	; 0x84
    12ee:	mov	sp, r7
    12f0:	vpop	{d8}
    12f4:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    std::size_t sizeB = kc*nc;

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());

    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;
    12f8:	movs	r3, #0
    12fa:	str	r3, [r7, #76]	; 0x4c
    12fc:	b.n	114c <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x9c>
    // this is the sequential version!
    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*nc;

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());
    12fe:	lsls	r0, r5, #2
    1300:	cmp.w	r0, #131072	; 0x20000
    1304:	bhi.n	134c <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x29c>
    1306:	add.w	r3, r0, #29
    130a:	movs	r2, #0
    130c:	bic.w	r3, r3, #7
    1310:	str	r2, [r7, #4]
    1312:	sub.w	sp, sp, r3
    1316:	add.w	r3, sp, #47	; 0x2f
    131a:	bic.w	r3, r3, #15
    131e:	str	r3, [r7, #96]	; 0x60
    1320:	str	r3, [r7, #12]
    1322:	b.n	112e <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x7e>

    // this is the sequential version!
    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*nc;

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    1324:	mov.w	r0, r8, lsl #2
    1328:	cmp.w	r0, #131072	; 0x20000
    132c:	bhi.n	1376 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x2c6>
    132e:	add.w	r3, r0, #29
    1332:	movs	r2, #0
    1334:	bic.w	r3, r3, #7
    1338:	str	r2, [r7, #8]
    133a:	sub.w	sp, sp, r3
    133e:	add.w	r3, sp, #47	; 0x2f
    1342:	bic.w	r3, r3, #15
    1346:	str	r3, [r7, #88]	; 0x58
    1348:	str	r3, [r7, #16]
    134a:	b.n	1110 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x60>
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    134c:	adds	r0, #16
    134e:	bl	7238 <malloc>
  if (original == 0) return 0;
    1352:	cbz	r0, 13a0 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x2f0>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    1354:	bic.w	r3, r0, #15
    1358:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    135a:	str.w	r0, [r3, #-4]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    135e:	str	r3, [r7, #96]	; 0x60
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());
    1360:	ldr	r3, [r4, #4]
    1362:	cmp	r3, #0
    1364:	bne.w	1128 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x78>
    1368:	ldr	r2, [r7, #96]	; 0x60
    136a:	adds	r3, r2, #0
    136c:	str	r2, [r7, #12]
    136e:	it	ne
    1370:	movne	r3, #1
    1372:	str	r3, [r7, #4]
    1374:	b.n	112e <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x7e>
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    1376:	adds	r0, #16
    1378:	bl	7238 <malloc>
  if (original == 0) return 0;
    137c:	cbz	r0, 13aa <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x2fa>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    137e:	bic.w	r3, r0, #15
    1382:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    1384:	str.w	r0, [r3, #-4]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    1388:	str	r3, [r7, #88]	; 0x58

    // this is the sequential version!
    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*nc;

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    138a:	ldr	r3, [r4, #0]
    138c:	cmp	r3, #0
    138e:	bne.w	110a <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x5a>
    1392:	ldr	r2, [r7, #88]	; 0x58
    1394:	adds	r3, r2, #0
    1396:	str	r2, [r7, #16]
    1398:	it	ne
    139a:	movne	r3, #1
    139c:	str	r3, [r7, #8]
    139e:	b.n	1110 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x60>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    13a0:	mov.w	r0, #4294967295
    13a4:	bl	6d9c <operator new(unsigned int)>
    13a8:	b.n	1360 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x2b0>
    13aa:	mov.w	r0, #4294967295
    13ae:	bl	6d9c <operator new(unsigned int)>
    13b2:	b.n	138a <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x2da>

000013b4 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)>:
  enum { PacketSize = packet_traits<Scalar>::size };
  EIGEN_DONT_INLINE void operator()(Scalar* blockB, const DataMapper& rhs, Index depth, Index cols, Index stride=0, Index offset=0);
};

template<typename Scalar, typename Index, typename DataMapper, int nr, bool Conjugate, bool PanelMode>
EIGEN_DONT_INLINE void gemm_pack_rhs<Scalar, Index, DataMapper, nr, RowMajor, Conjugate, PanelMode>
    13b4:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
    13b8:	ldr	r7, [sp, #32]
  EIGEN_UNUSED_VARIABLE(stride);
  EIGEN_UNUSED_VARIABLE(offset);
  eigen_assert(((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride));
  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
  Index packet_cols8 = nr>=8 ? (cols/8) * 8 : 0;
  Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
    13ba:	cmp	r7, #0
    13bc:	ite	lt
    13be:	addlt	r6, r7, #3
    13c0:	movge	r6, r7
    13c2:	bic.w	r6, r6, #3
//       if(PanelMode) count += 8 * (stride-offset-depth);
//     }
//   }
  if(nr>=4)
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
    13c6:	cmp	r6, #0
    13c8:	ble.n	145e <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)+0xaa>
    13ca:	mov.w	ip, #0
    13ce:	mov.w	r9, r3, lsl #2
    13d2:	mov	r0, ip
    {
      // skip what we have before
      if(PanelMode) count += 4 * offset;
      for(Index k=0; k<depth; k++)
    13d4:	cmp	r3, #0
    13d6:	ble.n	1418 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)+0x64>
    13d8:	add.w	r8, r0, r9
    13dc:	ldr	r5, [r2, #4]
    13de:	ldr	r4, [r2, #0]
    13e0:	add.w	r0, r1, r0, lsl #2
    13e4:	lsls	r5, r5, #2
    13e6:	add.w	r4, r4, ip, lsl #2
    13ea:	add.w	sl, r1, r8, lsl #2
          Packet A = rhs.loadPacket(k, j2);
          pstoreu(blockB+count, cj.pconj(A));
          count += PacketSize;
        } else {
          const LinearMapper dm0 = rhs.getLinearMapper(k, j2);
          blockB[count+0] = cj(dm0(0));
    13ee:	ldr.w	lr, [r4]
    13f2:	adds	r0, #16
    13f4:	str.w	lr, [r0, #-16]
          blockB[count+1] = cj(dm0(1));
    13f8:	ldr.w	lr, [r4, #4]
    13fc:	str.w	lr, [r0, #-12]
          blockB[count+2] = cj(dm0(2));
    1400:	ldr.w	lr, [r4, #8]
    1404:	str.w	lr, [r0, #-8]
          blockB[count+3] = cj(dm0(3));
    1408:	ldr.w	lr, [r4, #12]
    140c:	add	r4, r5
    140e:	str.w	lr, [r0, #-4]
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
    {
      // skip what we have before
      if(PanelMode) count += 4 * offset;
      for(Index k=0; k<depth; k++)
    1412:	cmp	r0, sl
    1414:	bne.n	13ee <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)+0x3a>
    1416:	mov	r0, r8
//       if(PanelMode) count += 8 * (stride-offset-depth);
//     }
//   }
  if(nr>=4)
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
    1418:	add.w	ip, ip, #4
    141c:	cmp	r6, ip
    141e:	bgt.n	13d4 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)+0x20>
      // skip what we have after
      if(PanelMode) count += 4 * (stride-offset-depth);
    }
  }
  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
    1420:	cmp	r7, r6
    1422:	ble.n	1466 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)+0xb2>
    1424:	mov.w	ip, r6, lsl #2
  {
    if(PanelMode) count += offset;
    for(Index k=0; k<depth; k++)
    1428:	cmp	r3, #0
    142a:	ble.n	1450 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)+0x9c>
    142c:	add.w	r8, r3, r0
    1430:	ldr	r5, [r2, #4]
    1432:	ldr	r4, [r2, #0]
    1434:	add.w	r0, r1, r0, lsl #2
    1438:	lsls	r5, r5, #2
    143a:	add	r4, ip
    143c:	add.w	r9, r1, r8, lsl #2
    {
      blockB[count] = cj(rhs(k, j2));
    1440:	ldr.w	lr, [r4]
    1444:	add	r4, r5
    1446:	str.w	lr, [r0], #4
  }
  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
  {
    if(PanelMode) count += offset;
    for(Index k=0; k<depth; k++)
    144a:	cmp	r9, r0
    144c:	bne.n	1440 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)+0x8c>
    144e:	mov	r0, r8
      // skip what we have after
      if(PanelMode) count += 4 * (stride-offset-depth);
    }
  }
  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
    1450:	adds	r6, #1
    1452:	add.w	ip, ip, #4
    1456:	cmp	r7, r6
    1458:	bne.n	1428 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)+0x74>
    145a:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    145e:	cmp	r7, r6
  EIGEN_UNUSED_VARIABLE(offset);
  eigen_assert(((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride));
  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
  Index packet_cols8 = nr>=8 ? (cols/8) * 8 : 0;
  Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
  Index count = 0;
    1460:	mov.w	r0, #0
      // skip what we have after
      if(PanelMode) count += 4 * (stride-offset-depth);
    }
  }
  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
    1464:	bgt.n	1424 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)+0x70>
    1466:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    146a:	nop

0000146c <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)>:
{

typedef gebp_traits<LhsScalar,RhsScalar> Traits;

typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
static void run(Index rows, Index cols, Index depth,
    146c:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    1470:	vpush	{d8}
    1474:	sub	sp, #172	; 0xac
    1476:	mov	r6, r3
    1478:	mov	sl, r1
    147a:	vmov.f32	s16, s0
    147e:	add	r7, sp, #32
    1480:	ldr.w	r4, [r7, #204]	; 0xcc
    1484:	str	r2, [r7, #64]	; 0x40
    1486:	ldr	r2, [r4, #8]
    1488:	ldr	r3, [r4, #16]
    148a:	cmp	r2, r0
    148c:	str	r0, [r7, #36]	; 0x24
    148e:	mov	r1, r3
    1490:	str	r3, [r7, #52]	; 0x34
    1492:	mov	r3, r2
    1494:	it	ge
    1496:	movge	r3, r0
    1498:	mov	r2, r3
    149a:	str	r3, [r7, #28]
    149c:	ldr	r3, [r4, #12]
#endif // EIGEN_HAS_OPENMP
  {
    EIGEN_UNUSED_VARIABLE(info);

    // this is the sequential version!
    std::size_t sizeA = kc*mc;
    149e:	mul.w	r8, r2, r1
    14a2:	cmp	r3, sl
    14a4:	it	ge
    14a6:	movge	r3, sl
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    14a8:	cmp.w	r8, #1073741824	; 0x40000000
    14ac:	str	r3, [r7, #88]	; 0x58
    std::size_t sizeB = kc*nc;
    14ae:	mul.w	r5, r3, r1
    14b2:	bcc.n	14bc <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x50>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    14b4:	mov.w	r0, #4294967295
    14b8:	bl	6d9c <operator new(unsigned int)>
    14bc:	ldr	r3, [r4, #0]
    14be:	str	r3, [r7, #96]	; 0x60

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    14c0:	cmp	r3, #0
    14c2:	beq.w	16fa <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x28e>
    14c6:	movs	r3, #0
    14c8:	str	r3, [r7, #8]
    14ca:	str	r3, [r7, #16]
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    14cc:	cmp.w	r5, #1073741824	; 0x40000000
    14d0:	bcc.n	14da <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x6e>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    14d2:	mov.w	r0, #4294967295
    14d6:	bl	6d9c <operator new(unsigned int)>
    14da:	ldr	r3, [r4, #4]
    14dc:	str	r3, [r7, #104]	; 0x68
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());
    14de:	cmp	r3, #0
    14e0:	beq.w	16d4 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x268>
    14e4:	movs	r3, #0
    14e6:	str	r3, [r7, #4]
    14e8:	str	r3, [r7, #12]

    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;
    14ea:	ldr	r3, [r7, #36]	; 0x24
    14ec:	ldr	r2, [r7, #28]
    14ee:	cmp	r3, r2
    14f0:	beq.w	16ce <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x262>
    14f4:	ldr	r3, [r7, #64]	; 0x40
    14f6:	ldr	r2, [r7, #52]	; 0x34
    14f8:	ldr	r1, [r7, #88]	; 0x58
    14fa:	cmp	r3, r2
    14fc:	it	eq
    14fe:	cmpeq	sl, r1
    1500:	ite	eq
    1502:	moveq	r3, #1
    1504:	movne	r3, #0
    1506:	str	r3, [r7, #84]	; 0x54

    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    1508:	ldr	r3, [r7, #36]	; 0x24
    150a:	cmp	r3, #0
    150c:	ble.w	16a6 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x23a>
    1510:	ldr	r0, [r7, #88]	; 0x58
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
            pack_rhs(blockB, rhs.getSubMapper(k2,j2), actual_kc, actual_nc);

          // Everything is packed, we can now call the panel * block kernel:
          gebp(res.getSubMapper(i2, j2), blockA, blockB, actual_mc, actual_kc, actual_nc, alpha);
    1512:	mov.w	fp, #4294967295
    1516:	ldr	r1, [r7, #52]	; 0x34
    1518:	ldr.w	r4, [r7, #200]	; 0xc8
    151c:	mov	r3, r0
    151e:	ldr.w	r2, [r7, #184]	; 0xb8
    1522:	mul.w	r3, r3, r4
    1526:	ldr	r4, [r7, #28]
    1528:	mul.w	r2, r1, r2
    152c:	lsls	r3, r3, #2
    152e:	str	r6, [r7, #40]	; 0x28
    1530:	lsls	r2, r2, #2
    1532:	str	r3, [r7, #80]	; 0x50
    1534:	lsls	r4, r4, #2
    1536:	ldr.w	r3, [r7, #192]	; 0xc0
    153a:	str	r2, [r7, #48]	; 0x30
    153c:	ldr.w	r2, [r7, #196]	; 0xc4
    1540:	str	r4, [r7, #24]
    1542:	str	r2, [r7, #56]	; 0x38
    1544:	mov	r2, r3
    1546:	mov	r3, r1
    1548:	mul.w	r3, r2, r3
    154c:	str	r3, [r7, #44]	; 0x2c
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());

    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;

    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    154e:	movs	r3, #0
    1550:	str	r3, [r7, #60]	; 0x3c
    1552:	negs	r3, r0
    1554:	str	r3, [r7, #20]
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;
    1556:	ldr	r1, [r7, #28]

      for(Index k2=0; k2<depth; k2+=kc)
    1558:	mov.w	r9, #0
    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;

    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;
    155c:	ldr	r2, [r7, #60]	; 0x3c
    155e:	adds	r3, r1, r2
    1560:	ldr	r1, [r7, #20]
    1562:	str	r1, [r7, #76]	; 0x4c
    1564:	ldr	r1, [r7, #40]	; 0x28
    1566:	str	r3, [r7, #32]
    1568:	str	r1, [r7, #72]	; 0x48
    156a:	ldr	r1, [r7, #36]	; 0x24
    156c:	cmp	r3, r1
    156e:	ite	le
    1570:	rsble	r2, r2, r3
    1574:	rsbgt	r2, r2, r1

      for(Index k2=0; k2<depth; k2+=kc)
    1578:	ldr	r1, [r7, #64]	; 0x40
    157a:	cmp	r9, r1
    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;

    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;
    157c:	str	r2, [r7, #100]	; 0x64

      for(Index k2=0; k2<depth; k2+=kc)
    157e:	bge.w	1688 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x21c>
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    1582:	ldr	r3, [r7, #52]	; 0x34

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    1584:	movs	r4, #0
    1586:	ldr	r5, [r7, #72]	; 0x48
    1588:	add.w	r2, r7, #128	; 0x80
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    158c:	add	r3, r9

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    158e:	str	r4, [sp, #8]
    1590:	str.w	r5, [r7, #128]	; 0x80
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    1594:	mov	r0, r3
    1596:	str	r3, [r7, #68]	; 0x44

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    1598:	ldr	r3, [r7, #100]	; 0x64
    159a:	ldr.w	r5, [r7, #184]	; 0xb8
    159e:	str	r3, [sp, #0]
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    15a0:	mov	r3, r1

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    15a2:	str	r4, [sp, #4]
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    15a4:	cmp	r3, r0
    15a6:	ite	le
    15a8:	rsble	r9, r9, r3
    15ac:	rsbgt	r9, r9, r0

        // OK, here we have selected one horizontal panel of rhs and one vertical panel of lhs.
        // => Pack lhs's panel into a sequential chunk of memory (L2/L3 caching)
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);
    15b0:	ldr	r1, [r7, #96]	; 0x60
    15b2:	add.w	r0, r7, #116	; 0x74
    15b6:	str.w	r5, [r7, #132]	; 0x84
    15ba:	mov	r3, r9
    15bc:	bl	550 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)>

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
    15c0:	cmp	sl, r4
    15c2:	ble.n	166c <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x200>
    15c4:	ldr	r3, [r7, #60]	; 0x3c

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
            pack_rhs(blockB, rhs.getSubMapper(k2,j2), actual_kc, actual_nc);
    15c6:	mov	r8, r4
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
    15c8:	ldr	r6, [r7, #56]	; 0x38
    15ca:	clz	r3, r3

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
            pack_rhs(blockB, rhs.getSubMapper(k2,j2), actual_kc, actual_nc);
    15ce:	str	r6, [r7, #108]	; 0x6c
    15d0:	lsrs	r3, r3, #5
    15d2:	str	r3, [r7, #92]	; 0x5c
    15d4:	b.n	161e <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x1b2>

          // Everything is packed, we can now call the panel * block kernel:
          gebp(res.getSubMapper(i2, j2), blockA, blockB, actual_mc, actual_kc, actual_nc, alpha);
    15d6:	str	r4, [sp, #8]
    15d8:	vmov.f32	s0, s16
    15dc:	ldr	r4, [r7, #100]	; 0x64
    15de:	add.w	r1, r7, #128	; 0x80
    15e2:	ldr	r6, [r7, #108]	; 0x6c
    15e4:	add.w	r0, r7, #124	; 0x7c
    15e8:	str	r4, [sp, #0]
    15ea:	ldr	r4, [r7, #80]	; 0x50
    15ec:	str.w	r6, [r7, #128]	; 0x80
    15f0:	add	r6, r4
    15f2:	ldr.w	r4, [r7, #200]	; 0xc8
    15f6:	str.w	r8, [sp, #24]
    15fa:	str.w	r8, [sp, #20]
    15fe:	ldr	r3, [r7, #104]	; 0x68
    1600:	str.w	fp, [sp, #16]
    1604:	ldr	r2, [r7, #96]	; 0x60
    1606:	str.w	fp, [sp, #12]
    160a:	str.w	r9, [sp, #4]
    160e:	str.w	r4, [r7, #132]	; 0x84
    1612:	mov	r4, r5
    1614:	str	r6, [r7, #108]	; 0x6c
    1616:	bl	6e4 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)>
        // Note that this panel will be read as many times as the number of blocks in the rhs's
        // horizontal panel which is, in practice, a very low number.
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
    161a:	cmp	sl, r5
    161c:	ble.n	166c <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x200>
        {
          const Index actual_nc = (std::min)(j2+nc,cols)-j2;
    161e:	ldr	r3, [r7, #88]	; 0x58

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
    1620:	ldr	r2, [r7, #92]	; 0x5c
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
        {
          const Index actual_nc = (std::min)(j2+nc,cols)-j2;
    1622:	adds	r5, r3, r4

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
    1624:	ldr	r3, [r7, #84]	; 0x54
        pack_lhs(blockA, lhs.getSubMapper(i2,k2), actual_kc, actual_mc);

        // For each kc x nc block of the rhs's horizontal panel...
        for(Index j2=0; j2<cols; j2+=nc)
        {
          const Index actual_nc = (std::min)(j2+nc,cols)-j2;
    1626:	cmp	sl, r5
    1628:	ite	le
    162a:	rsble	r4, r4, sl
    162e:	rsbgt	r4, r4, r5

          // We pack the rhs's block into a sequential chunk of memory (L2 caching)
          // Note that this block will be read a very high number of times, which is equal to the number of
          // micro horizontal panel of the large rhs's panel (e.g., rows/12 times).
          if((!pack_rhs_once) || i2==0)
    1632:	cmp	r3, r2
    1634:	bhi.n	15d6 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x16a>
    1636:	ldr	r3, [r7, #76]	; 0x4c
            pack_rhs(blockB, rhs.getSubMapper(k2,j2), actual_kc, actual_nc);
    1638:	add.w	r0, r7, #120	; 0x78
    163c:	ldr.w	r2, [r7, #188]	; 0xbc
    1640:	add.w	lr, r5, r3
    1644:	ldr.w	r6, [r7, #192]	; 0xc0
    1648:	str.w	r8, [sp, #8]
    164c:	mov	r3, r9
    164e:	add.w	lr, r2, lr, lsl #2
    1652:	str.w	r8, [sp, #4]
    1656:	str	r4, [sp, #0]
    1658:	add.w	r2, r7, #128	; 0x80
    165c:	ldr	r1, [r7, #104]	; 0x68
    165e:	str.w	r6, [r7, #132]	; 0x84
    1662:	str.w	lr, [r7, #128]	; 0x80
    1666:	bl	13b4 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 1>, 4, 1, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 1> const&, int, int, int, int)>
    166a:	b.n	15d6 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x16a>
    166c:	ldr	r3, [r7, #72]	; 0x48
    166e:	ldr	r2, [r7, #48]	; 0x30
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
      {
        const Index actual_kc = (std::min)(k2+kc,depth)-k2;
    1670:	ldr.w	r9, [r7, #68]	; 0x44
    1674:	add	r3, r2
    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    {
      const Index actual_mc = (std::min)(i2+mc,rows)-i2;

      for(Index k2=0; k2<depth; k2+=kc)
    1676:	ldr	r1, [r7, #64]	; 0x40
    1678:	ldr	r2, [r7, #44]	; 0x2c
    167a:	str	r3, [r7, #72]	; 0x48
    167c:	cmp	r9, r1
    167e:	ldr	r3, [r7, #76]	; 0x4c
    1680:	add	r3, r2
    1682:	str	r3, [r7, #76]	; 0x4c
    1684:	blt.w	1582 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x116>
    1688:	ldr	r2, [r7, #40]	; 0x28
    168a:	ldr	r1, [r7, #24]
    168c:	mov	r0, r2
    168e:	ldr	r2, [r7, #56]	; 0x38
    1690:	ldr	r3, [r7, #32]
    1692:	add	r0, r1
    1694:	str	r3, [r7, #60]	; 0x3c
    1696:	str	r0, [r7, #40]	; 0x28
    1698:	mov	r0, r2
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());

    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;

    // For each horizontal panel of the rhs, and corresponding panel of the lhs...
    for(Index i2=0; i2<rows; i2+=mc)
    169a:	ldr	r2, [r7, #36]	; 0x24
    169c:	add	r0, r1
    169e:	cmp	r3, r2
    16a0:	str	r0, [r7, #56]	; 0x38
    16a2:	blt.w	1556 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0xea>
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    16a6:	ldr	r3, [r7, #4]
    16a8:	cbz	r3, 16b4 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x248>
    16aa:	ldr	r3, [r7, #12]
    16ac:	ldr.w	r0, [r3, #-4]
    16b0:	bl	7248 <free>
    16b4:	ldr	r3, [r7, #8]
    16b6:	cbz	r3, 16c2 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x256>
    16b8:	ldr	r3, [r7, #16]
    16ba:	ldr.w	r0, [r3, #-4]
    16be:	bl	7248 <free>
          gebp(res.getSubMapper(i2, j2), blockA, blockB, actual_mc, actual_kc, actual_nc, alpha);
        }
      }
    }
  }
}
    16c2:	adds	r7, #140	; 0x8c
    16c4:	mov	sp, r7
    16c6:	vpop	{d8}
    16ca:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    std::size_t sizeB = kc*nc;

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());

    const bool pack_rhs_once = mc!=rows && kc==depth && nc==cols;
    16ce:	movs	r3, #0
    16d0:	str	r3, [r7, #84]	; 0x54
    16d2:	b.n	1508 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x9c>
    // this is the sequential version!
    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*nc;

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());
    16d4:	lsls	r0, r5, #2
    16d6:	cmp.w	r0, #131072	; 0x20000
    16da:	bhi.n	1722 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x2b6>
    16dc:	add.w	r3, r0, #29
    16e0:	movs	r2, #0
    16e2:	bic.w	r3, r3, #7
    16e6:	str	r2, [r7, #4]
    16e8:	sub.w	sp, sp, r3
    16ec:	add.w	r3, sp, #47	; 0x2f
    16f0:	bic.w	r3, r3, #15
    16f4:	str	r3, [r7, #104]	; 0x68
    16f6:	str	r3, [r7, #12]
    16f8:	b.n	14ea <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x7e>

    // this is the sequential version!
    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*nc;

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    16fa:	mov.w	r0, r8, lsl #2
    16fe:	cmp.w	r0, #131072	; 0x20000
    1702:	bhi.n	174c <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x2e0>
    1704:	add.w	r3, r0, #29
    1708:	movs	r2, #0
    170a:	bic.w	r3, r3, #7
    170e:	str	r2, [r7, #8]
    1710:	sub.w	sp, sp, r3
    1714:	add.w	r3, sp, #47	; 0x2f
    1718:	bic.w	r3, r3, #15
    171c:	str	r3, [r7, #96]	; 0x60
    171e:	str	r3, [r7, #16]
    1720:	b.n	14cc <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x60>
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    1722:	adds	r0, #16
    1724:	bl	7238 <malloc>
  if (original == 0) return 0;
    1728:	cbz	r0, 1776 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x30a>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    172a:	bic.w	r3, r0, #15
    172e:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    1730:	str.w	r0, [r3, #-4]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    1734:	str	r3, [r7, #104]	; 0x68
    ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());
    1736:	ldr	r3, [r4, #4]
    1738:	cmp	r3, #0
    173a:	bne.w	14e4 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x78>
    173e:	ldr	r2, [r7, #104]	; 0x68
    1740:	adds	r3, r2, #0
    1742:	str	r2, [r7, #12]
    1744:	it	ne
    1746:	movne	r3, #1
    1748:	str	r3, [r7, #4]
    174a:	b.n	14ea <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x7e>
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    174c:	adds	r0, #16
    174e:	bl	7238 <malloc>
  if (original == 0) return 0;
    1752:	cbz	r0, 1780 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x314>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    1754:	bic.w	r3, r0, #15
    1758:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    175a:	str.w	r0, [r3, #-4]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    175e:	str	r3, [r7, #96]	; 0x60

    // this is the sequential version!
    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*nc;

    ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
    1760:	ldr	r3, [r4, #0]
    1762:	cmp	r3, #0
    1764:	bne.w	14c6 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x5a>
    1768:	ldr	r2, [r7, #96]	; 0x60
    176a:	adds	r3, r2, #0
    176c:	str	r2, [r7, #16]
    176e:	it	ne
    1770:	movne	r3, #1
    1772:	str	r3, [r7, #8]
    1774:	b.n	14cc <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x60>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    1776:	mov.w	r0, #4294967295
    177a:	bl	6d9c <operator new(unsigned int)>
    177e:	b.n	1736 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x2ca>
    1780:	mov.w	r0, #4294967295
    1784:	bl	6d9c <operator new(unsigned int)>
    1788:	b.n	1760 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)+0x2f4>
    178a:	nop

0000178c <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)>:
    * of columns of the matrix \a lu, and an integer \a nb_transpositions
    * which returns the actual number of transpositions.
    *
    * \returns The index of the first pivot which is exactly zero if any, or a negative number otherwise.
    */
  static Index unblocked_lu(MatrixType& lu, PivIndex* row_transpositions, PivIndex& nb_transpositions)
    178c:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
{
    T m_value;
    EIGEN_DEVICE_FUNC variable_if_dynamic() { eigen_assert(false); }
  public:
    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T value) : m_value(value) {}
    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T value() const { return m_value; }
    1790:	ldr	r3, [r0, #8]
    1792:	sub	sp, #36	; 0x24
    1794:	ldr	r4, [r0, #4]
    typedef scalar_score_coeff_op<Scalar> Scoring;
    typedef typename Scoring::result_type Score;
    const Index rows = lu.rows();
    const Index cols = lu.cols();
    const Index size = (std::min)(rows,cols);
    nb_transpositions = 0;
    1796:	movs	r7, #0
    * of columns of the matrix \a lu, and an integer \a nb_transpositions
    * which returns the actual number of transpositions.
    *
    * \returns The index of the first pivot which is exactly zero if any, or a negative number otherwise.
    */
  static Index unblocked_lu(MatrixType& lu, PivIndex* row_transpositions, PivIndex& nb_transpositions)
    1798:	str	r2, [sp, #28]
    179a:	cmp	r4, r3
    typedef scalar_score_coeff_op<Scalar> Scoring;
    typedef typename Scoring::result_type Score;
    const Index rows = lu.rows();
    const Index cols = lu.cols();
    const Index size = (std::min)(rows,cols);
    nb_transpositions = 0;
    179c:	str	r7, [r2, #0]
    179e:	mov	r2, r4
    17a0:	it	ge
    17a2:	movge	r2, r3
    Index first_zero_pivot = -1;
    for(Index k = 0; k < size; ++k)
    17a4:	cmp	r2, r7
    17a6:	str	r2, [sp, #8]
    17a8:	ble.w	1964 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x1d8>
    17ac:	add.w	fp, r3, #4294967295
    17b0:	ldr.w	sl, [r0]
    17b4:	mov.w	r3, #4294967295
    17b8:	subs	r2, r4, #1
    17ba:	mov.w	lr, r4, lsl #2
    17be:	str	r1, [sp, #4]
    17c0:	str	r3, [sp, #16]
    17c2:	mov	r3, sl
    17c4:	mov	r8, r2
    17c6:	mov	sl, fp
    17c8:	mov	fp, r3
    17ca:	str	r2, [sp, #12]
    EIGEN_DEVICE_FUNC
    inline BlockImpl_dense(XprType& xpr,
          Index startRow, Index startCol,
          Index blockRows, Index blockCols)
      : Base(xpr.data()+xpr.innerStride()*(XprTypeIsRowMajor?startCol:startRow) + xpr.outerStride()*(XprTypeIsRowMajor?startRow:startCol), blockRows, blockCols),
        m_xpr(xpr), m_startRow(startRow), m_startCol(startCol)
    17cc:	ldr	r2, [r0, #4]
{
  EIGEN_DEVICE_FUNC
  static inline void run(const Derived& mat, Visitor& visitor)
  {
    visitor.init(mat.coeff(0,0), 0, 0);
    for(Index i = 1; i < mat.rows(); ++i)
    17ce:	cmp	r4, #1
    17d0:	ldr	r3, [r0, #36]	; 0x24
    17d2:	sub.w	r1, r2, r4
    17d6:	mla	r1, r3, r7, r1
    17da:	add.w	r1, fp, r1, lsl #2
#endif

#ifndef __CORRECT_ISO_CPP_MATH_H_PROTO
  inline _GLIBCXX_CONSTEXPR float
  abs(float __x)
  { return __builtin_fabsf(__x); }
    17de:	vldr	s14, [r1]
    17e2:	vabs.f32	s14, s14
    17e6:	ble.n	18c4 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x138>
    17e8:	adds	r1, #4
    17ea:	movs	r3, #0
    17ec:	movs	r2, #1
    17ee:	vldmia	r1!, {s15}
    17f2:	vabs.f32	s15, s15
{
  typedef typename Derived::Scalar Scalar; 
  EIGEN_DEVICE_FUNC
  void operator() (const Scalar& value, Index i, Index j)
  {
    if(value > this->res)
    17f6:	vcmpe.f32	s15, s14
    17fa:	vmrs	APSR_nzcv, fpscr
    17fe:	ble.n	1806 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x7a>
    {
      this->res = value;
    1800:	vmov.f32	s14, s15
{
  typedef typename Derived::Scalar Scalar; 
  EIGEN_DEVICE_FUNC
  void operator() (const Scalar& value, Index i, Index j)
  {
    if(value > this->res)
    1804:	mov	r3, r2
{
  EIGEN_DEVICE_FUNC
  static inline void run(const Derived& mat, Visitor& visitor)
  {
    visitor.init(mat.coeff(0,0), 0, 0);
    for(Index i = 1; i < mat.rows(); ++i)
    1806:	adds	r2, #1
    1808:	cmp	r4, r2
    180a:	bne.n	17ee <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x62>
        = lu.col(k).tail(rows-k).unaryExpr(Scoring()).maxCoeff(&row_of_biggest_in_col);
      row_of_biggest_in_col += k;

      row_transpositions[k] = PivIndex(row_of_biggest_in_col);

      if(biggest_in_corner != Score(0))
    180c:	vcmp.f32	s14, #0.0
      Index rcols = cols-k-1;

      Index row_of_biggest_in_col;
      Score biggest_in_corner
        = lu.col(k).tail(rows-k).unaryExpr(Scoring()).maxCoeff(&row_of_biggest_in_col);
      row_of_biggest_in_col += k;
    1810:	add	r3, r7

      row_transpositions[k] = PivIndex(row_of_biggest_in_col);
    1812:	ldr	r2, [sp, #4]
    1814:	lsls	r1, r7, #2

      if(biggest_in_corner != Score(0))
    1816:	vmrs	APSR_nzcv, fpscr
      Index row_of_biggest_in_col;
      Score biggest_in_corner
        = lu.col(k).tail(rows-k).unaryExpr(Scoring()).maxCoeff(&row_of_biggest_in_col);
      row_of_biggest_in_col += k;

      row_transpositions[k] = PivIndex(row_of_biggest_in_col);
    181a:	str	r3, [r2, #0]

      if(biggest_in_corner != Score(0))
    181c:	beq.n	18d4 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x148>
      {
        if(k != row_of_biggest_in_col)
    181e:	cmp	r3, r7
    1820:	beq.n	185c <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0xd0>
    1822:	ldr.w	ip, [r0, #8]
                                || ((BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) && ( XprTypeIsRowMajor)) ? xpr.innerStride() : xpr.outerStride()),
             BlockRows==1 ? 1 : xpr.rows(),
             BlockCols==1 ? 1 : xpr.cols()),
        m_xpr(xpr),
        m_startRow( (BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) ? i : 0),
        m_startCol( (BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) ? i : 0)
    1826:	lsls	r3, r3, #2
    const internal::variable_if_dynamic<StorageIndex, ColsAtCompileTime> m_blockCols;
};

/** \internal Internal implementation of dense Blocks in the direct access case.*/
template<typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
class BlockImpl_dense<XprType,BlockRows,BlockCols, InnerPanel,true>
    1828:	ldr	r6, [r0, #36]	; 0x24
struct dense_assignment_loop<Kernel, LinearTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
  {
    const Index size = kernel.size();
    for(Index i = 0; i < size; ++i)
    182a:	cmp.w	ip, #0
    182e:	ble.n	1854 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0xc8>
    1830:	lsls	r6, r6, #2
    1832:	add	r3, fp
    1834:	add.w	r2, fp, r1
    1838:	movs	r5, #0
    183a:	adds	r5, #1
#endif
    {
      // concept requirements
      __glibcxx_function_requires(_SGIAssignableConcept<_Tp>)

      _Tp __tmp = _GLIBCXX_MOVE(__a);
    183c:	ldr.w	r9, [r2]
      __a = _GLIBCXX_MOVE(__b);
    1840:	vldr	s15, [r3]
    1844:	cmp	ip, r5
    1846:	vstr	s15, [r2]
    184a:	add	r2, r6
      __b = _GLIBCXX_MOVE(__tmp);
    184c:	str.w	r9, [r3]
    1850:	add	r3, r6
    1852:	bne.n	183a <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0xae>
        {
          lu.row(k).swap(lu.row(row_of_biggest_in_col));
          ++nb_transpositions;
    1854:	ldr	r2, [sp, #28]
    1856:	ldr	r3, [r2, #0]
    1858:	adds	r3, #1
    185a:	str	r3, [r2, #0]
                                || ((BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) && ( XprTypeIsRowMajor)) ? xpr.innerStride() : xpr.outerStride()),
             BlockRows==1 ? 1 : xpr.rows(),
             BlockCols==1 ? 1 : xpr.cols()),
        m_xpr(xpr),
        m_startRow( (BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) ? i : 0),
        m_startCol( (BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) ? i : 0)
    185c:	ldr	r3, [r0, #36]	; 0x24
    185e:	cmp.w	r8, #0
    1862:	ldr	r2, [r0, #4]
    1864:	sub.w	lr, lr, #4
    1868:	mul.w	r3, r3, r7
    186c:	rsb	r2, r8, r2
    1870:	add.w	r5, r3, r7
    1874:	mov.w	r3, r3, lsl #2
    1878:	add.w	r5, fp, r5, lsl #2
    187c:	add.w	r3, r3, r2, lsl #2
    1880:	vldr	s13, [r5]
    1884:	ble.n	189e <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x112>
    1886:	add.w	r5, fp, r3
    188a:	add	r3, lr
    188c:	add	r3, fp
  *
  */
template<typename DstScalar, typename SrcScalar=DstScalar> struct div_assign_op {

  EIGEN_EMPTY_STRUCT_CTOR(div_assign_op)
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(DstScalar& a, const SrcScalar& b) const { a /= b; }
    188e:	vldr	s14, [r5]
    1892:	vdiv.f32	s15, s14, s13
    1896:	vstmia	r5!, {s15}
    189a:	cmp	r5, r3
    189c:	bne.n	188e <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x102>
        // the pivot is exactly zero, we record the index of the first pivot which is exactly 0,
        // and continue the factorization such we still have A = PLU
        first_zero_pivot = k;
      }

      if(k<rows-1)
    189e:	ldr	r3, [sp, #12]
    18a0:	cmp	r3, r7
    18a2:	bgt.n	18e6 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x15a>
    18a4:	ldr	r3, [sp, #4]
    const Index rows = lu.rows();
    const Index cols = lu.cols();
    const Index size = (std::min)(rows,cols);
    nb_transpositions = 0;
    Index first_zero_pivot = -1;
    for(Index k = 0; k < size; ++k)
    18a6:	adds	r7, #1
    18a8:	subs	r4, #1
    18aa:	add.w	r8, r8, #4294967295
    18ae:	adds	r3, #4
    18b0:	add.w	sl, sl, #4294967295
    18b4:	str	r3, [sp, #4]
    18b6:	ldr	r3, [sp, #8]
    18b8:	cmp	r7, r3
    18ba:	bne.n	17cc <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x40>

      if(k<rows-1)
        lu.bottomRightCorner(rrows,rcols).noalias() -= lu.col(k).tail(rrows) * lu.row(k).tail(rcols);
    }
    return first_zero_pivot;
  }
    18bc:	ldr	r0, [sp, #16]
    18be:	add	sp, #36	; 0x24
    18c0:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
        = lu.col(k).tail(rows-k).unaryExpr(Scoring()).maxCoeff(&row_of_biggest_in_col);
      row_of_biggest_in_col += k;

      row_transpositions[k] = PivIndex(row_of_biggest_in_col);

      if(biggest_in_corner != Score(0))
    18c4:	vcmp.f32	s14, #0.0
      Index row_of_biggest_in_col;
      Score biggest_in_corner
        = lu.col(k).tail(rows-k).unaryExpr(Scoring()).maxCoeff(&row_of_biggest_in_col);
      row_of_biggest_in_col += k;

      row_transpositions[k] = PivIndex(row_of_biggest_in_col);
    18c8:	ldr	r3, [sp, #4]
    18ca:	lsls	r1, r7, #2
    18cc:	str	r7, [r3, #0]

      if(biggest_in_corner != Score(0))
    18ce:	vmrs	APSR_nzcv, fpscr
    18d2:	bne.n	185c <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0xd0>

        // FIXME shall we introduce a safe quotient expression in cas 1/lu.coeff(k,k)
        // overflow but not the actual quotient?
        lu.col(k).tail(rrows) /= lu.coeff(k,k);
      }
      else if(first_zero_pivot==-1)
    18d4:	ldr	r3, [sp, #16]
    18d6:	sub.w	lr, lr, #4
    18da:	adds	r3, #1
        // the pivot is exactly zero, we record the index of the first pivot which is exactly 0,
        // and continue the factorization such we still have A = PLU
        first_zero_pivot = k;
      }

      if(k<rows-1)
    18dc:	ldr	r3, [sp, #12]
    18de:	it	eq
    18e0:	streq	r7, [sp, #16]
    18e2:	cmp	r3, r7
    18e4:	ble.n	18a4 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x118>
      */
    EIGEN_DEVICE_FUNC
    inline BlockImpl_dense(XprType& xpr,
          Index startRow, Index startCol,
          Index blockRows, Index blockCols)
      : Base(xpr.data()+xpr.innerStride()*(XprTypeIsRowMajor?startCol:startRow) + xpr.outerStride()*(XprTypeIsRowMajor?startRow:startCol), blockRows, blockCols),
    18e6:	ldr	r3, [r0, #8]
  evaluator<Rhs> rhsEval(rhs);
  typename nested_eval<Lhs,Rhs::SizeAtCompileTime>::type actual_lhs(lhs);
  // FIXME if cols is large enough, then it might be useful to make sure that lhs is sequentially stored
  // FIXME not very good if rhs is real and lhs complex while alpha is real too
  const Index cols = dst.cols();
  for (Index j=0; j<cols; ++j)
    18e8:	cmp.w	sl, #0
    18ec:	ldr	r2, [r0, #36]	; 0x24
    18ee:	rsb	ip, sl, r3
    18f2:	ldr	r3, [r0, #4]
    18f4:	mul.w	ip, r2, ip
    18f8:	rsb	r9, r8, r3
    18fc:	add.w	r3, r9, ip
    1900:	mla	r9, r7, r2, r9
    1904:	add.w	r1, r1, ip, lsl #2
    1908:	mov.w	ip, r3, lsl #2
    190c:	mov.w	r3, r9, lsl #2
    1910:	ble.n	18a4 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x118>
    1912:	str	r7, [sp, #20]
    1914:	mov.w	r9, r2, lsl #2
    1918:	str	r4, [sp, #24]
    191a:	add.w	r5, fp, ip
    191e:	movs	r6, #0
    1920:	mov	r7, r3
    1922:	mov	r4, r1
    1924:	rsb	r3, ip, r5
    1928:	cmp.w	r8, #0
    192c:	add	r3, r4
    192e:	vldr	s13, [r3]
    1932:	ble.n	1956 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x1ca>
    1934:	vneg.f32	s13, s13
    1938:	add.w	r2, fp, r7
    193c:	add.w	r1, lr, r5
    1940:	mov	r3, r5
    1942:	vldmia	r2!, {s14}
  *
  */
template<typename DstScalar,typename SrcScalar> struct sub_assign_op {

  EIGEN_EMPTY_STRUCT_CTOR(sub_assign_op)
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(DstScalar& a, const SrcScalar& b) const { a -= b; }
    1946:	vldr	s15, [r3]
    194a:	vfma.f32	s15, s13, s14
    194e:	vstmia	r3!, {s15}
    1952:	cmp	r3, r1
    1954:	bne.n	1942 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x1b6>
    1956:	adds	r6, #1
    1958:	add	r5, r9
    195a:	cmp	sl, r6
    195c:	bne.n	1924 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x198>
    195e:	ldr	r7, [sp, #20]
    1960:	ldr	r4, [sp, #24]
    1962:	b.n	18a4 <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)+0x118>
    typedef typename Scoring::result_type Score;
    const Index rows = lu.rows();
    const Index cols = lu.cols();
    const Index size = (std::min)(rows,cols);
    nb_transpositions = 0;
    Index first_zero_pivot = -1;
    1964:	mov.w	r3, #4294967295
    1968:	str	r3, [sp, #16]

      if(k<rows-1)
        lu.bottomRightCorner(rrows,rcols).noalias() -= lu.col(k).tail(rrows) * lu.row(k).tail(rcols);
    }
    return first_zero_pivot;
  }
    196a:	ldr	r0, [sp, #16]
    196c:	add	sp, #36	; 0x24
    196e:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    1972:	nop

00001974 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)>:
  enum { PacketSize = packet_traits<Scalar>::size };
  EIGEN_DONT_INLINE void operator()(Scalar* blockB, const DataMapper& rhs, Index depth, Index cols, Index stride=0, Index offset=0);
};

template<typename Scalar, typename Index, typename DataMapper, int nr, bool Conjugate, bool PanelMode>
EIGEN_DONT_INLINE void gemm_pack_rhs<Scalar, Index, DataMapper, nr, ColMajor, Conjugate, PanelMode>
    1974:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    1978:	sub	sp, #28
    197a:	str	r1, [sp, #8]
    197c:	str	r2, [sp, #20]
  EIGEN_UNUSED_VARIABLE(stride);
  EIGEN_UNUSED_VARIABLE(offset);
  eigen_assert(((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride));
  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
  Index packet_cols8 = nr>=8 ? (cols/8) * 8 : 0;
  Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
    197e:	ldr.w	ip, [sp, #64]	; 0x40
    1982:	mov	r2, ip
    1984:	cmp	r2, #0
    1986:	it	lt
    1988:	addlt.w	ip, ip, #3
    198c:	bic.w	ip, ip, #3
//     }
//   }

  if(nr>=4)
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
    1990:	cmp.w	ip, #0
    1994:	ble.n	1a88 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)+0x114>
    1996:	ldr	r2, [sp, #68]	; 0x44
    1998:	mov.w	r9, #0
    199c:	ldr	r1, [sp, #72]	; 0x48
    199e:	mov	r7, r9
    19a0:	subs	r0, r2, r1
    19a2:	ldr	r1, [sp, #20]
    19a4:	ldr	r2, [r1, #4]
    19a6:	subs	r0, r0, r3
    19a8:	ldr.w	r8, [r1]
    19ac:	mov.w	fp, r2, lsl #4
    19b0:	add.w	r1, r3, r2, lsl #1
    19b4:	add.w	lr, r8, r2, lsl #2
    19b8:	mov.w	sl, r2, lsl #3
    19bc:	ldr	r2, [sp, #72]	; 0x48
    19be:	lsls	r0, r0, #2
    19c0:	lsls	r2, r2, #2
    19c2:	lsls	r1, r1, #2
    19c4:	str	r0, [sp, #4]
    19c6:	str	r2, [sp, #0]
    19c8:	lsls	r2, r3, #2
    19ca:	str	r1, [sp, #16]
    19cc:	str	r2, [sp, #12]
    {
      // skip what we have before
      if(PanelMode) count += 4 * offset;
    19ce:	ldr	r2, [sp, #0]
          pstoreu(blockB+count+2*PacketSize, cj.pconj(kernel.packet[2%PacketSize]));
          pstoreu(blockB+count+3*PacketSize, cj.pconj(kernel.packet[3%PacketSize]));
          count+=4*PacketSize;
        }
      }
      for(; k<depth; k++)
    19d0:	cmp	r3, #0
  if(nr>=4)
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
    {
      // skip what we have before
      if(PanelMode) count += 4 * offset;
    19d2:	add	r7, r2
          pstoreu(blockB+count+2*PacketSize, cj.pconj(kernel.packet[2%PacketSize]));
          pstoreu(blockB+count+3*PacketSize, cj.pconj(kernel.packet[3%PacketSize]));
          count+=4*PacketSize;
        }
      }
      for(; k<depth; k++)
    19d4:	ble.n	1a18 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)+0xa4>
    19d6:	ldr	r0, [sp, #16]
    19d8:	add.w	r5, sl, r8
    19dc:	ldr	r2, [sp, #8]
    19de:	add.w	r1, lr, sl
    19e2:	add.w	r6, lr, r0
    19e6:	mov	r4, lr
    19e8:	add.w	r2, r2, r7, lsl #2
    19ec:	mov	r0, r8
      {
        blockB[count+0] = cj(dm0(k));
    19ee:	vldmia	r0!, {s15}
    19f2:	adds	r2, #16
    19f4:	vstr	s15, [r2, #-16]
        blockB[count+1] = cj(dm1(k));
    19f8:	vldmia	r4!, {s15}
    19fc:	vstr	s15, [r2, #-12]
        blockB[count+2] = cj(dm2(k));
    1a00:	vldmia	r5!, {s15}
    1a04:	vstr	s15, [r2, #-8]
        blockB[count+3] = cj(dm3(k));
    1a08:	vldmia	r1!, {s15}
          pstoreu(blockB+count+2*PacketSize, cj.pconj(kernel.packet[2%PacketSize]));
          pstoreu(blockB+count+3*PacketSize, cj.pconj(kernel.packet[3%PacketSize]));
          count+=4*PacketSize;
        }
      }
      for(; k<depth; k++)
    1a0c:	cmp	r6, r1
      {
        blockB[count+0] = cj(dm0(k));
        blockB[count+1] = cj(dm1(k));
        blockB[count+2] = cj(dm2(k));
        blockB[count+3] = cj(dm3(k));
    1a0e:	vstr	s15, [r2, #-4]
          pstoreu(blockB+count+2*PacketSize, cj.pconj(kernel.packet[2%PacketSize]));
          pstoreu(blockB+count+3*PacketSize, cj.pconj(kernel.packet[3%PacketSize]));
          count+=4*PacketSize;
        }
      }
      for(; k<depth; k++)
    1a12:	bne.n	19ee <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)+0x7a>
    1a14:	ldr	r2, [sp, #12]
    1a16:	add	r7, r2
//     }
//   }

  if(nr>=4)
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
    1a18:	add.w	r9, r9, #4
        blockB[count+2] = cj(dm2(k));
        blockB[count+3] = cj(dm3(k));
        count += 4;
      }
      // skip what we have after
      if(PanelMode) count += 4 * (stride-offset-depth);
    1a1c:	ldr	r2, [sp, #4]
    1a1e:	add	r8, fp
    1a20:	add	lr, fp
//     }
//   }

  if(nr>=4)
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
    1a22:	cmp	ip, r9
        blockB[count+2] = cj(dm2(k));
        blockB[count+3] = cj(dm3(k));
        count += 4;
      }
      // skip what we have after
      if(PanelMode) count += 4 * (stride-offset-depth);
    1a24:	add	r7, r2
//     }
//   }

  if(nr>=4)
  {
    for(Index j2=packet_cols8; j2<packet_cols4; j2+=4)
    1a26:	bgt.n	19ce <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)+0x5a>
    1a28:	mov	r6, r7
      if(PanelMode) count += 4 * (stride-offset-depth);
    }
  }

  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
    1a2a:	ldr	r2, [sp, #64]	; 0x40
    1a2c:	cmp	r2, ip
    1a2e:	ble.n	1a82 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)+0x10e>
    1a30:	ldr	r1, [sp, #20]
    1a32:	mov.w	r8, r3, lsl #2
    1a36:	ldr	r4, [sp, #72]	; 0x48
    1a38:	ldr	r2, [r1, #4]
    1a3a:	ldr	r0, [sp, #68]	; 0x44
    1a3c:	mov	sl, r4
    1a3e:	ldr	r1, [r1, #0]
    1a40:	mul.w	r5, r2, ip
    1a44:	subs	r7, r0, r4
    1a46:	mov.w	lr, r2, lsl #2
    1a4a:	add.w	r5, r1, r5, lsl #2
    1a4e:	ldr.w	fp, [sp, #8]
    1a52:	subs	r7, r7, r3
    1a54:	ldr.w	r9, [sp, #64]	; 0x40
  {
    if(PanelMode) count += offset;
    const LinearMapper dm0 = rhs.getLinearMapper(0, j2);
    for(Index k=0; k<depth; k++)
    1a58:	cmp	r3, #0
  }

  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
  {
    if(PanelMode) count += offset;
    1a5a:	add	r6, sl
    const LinearMapper dm0 = rhs.getLinearMapper(0, j2);
    for(Index k=0; k<depth; k++)
    1a5c:	ble.n	1a76 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)+0x102>
    1a5e:	add.w	r1, fp, r6, lsl #2
    1a62:	add.w	r4, r5, r8
    1a66:	mov	r2, r5
    {
      blockB[count] = cj(dm0(k));
    1a68:	ldr.w	r0, [r2], #4
  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
  {
    if(PanelMode) count += offset;
    const LinearMapper dm0 = rhs.getLinearMapper(0, j2);
    for(Index k=0; k<depth; k++)
    1a6c:	cmp	r4, r2
    {
      blockB[count] = cj(dm0(k));
    1a6e:	str.w	r0, [r1], #4
  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
  {
    if(PanelMode) count += offset;
    const LinearMapper dm0 = rhs.getLinearMapper(0, j2);
    for(Index k=0; k<depth; k++)
    1a72:	bne.n	1a68 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)+0xf4>
    1a74:	add	r6, r3
      if(PanelMode) count += 4 * (stride-offset-depth);
    }
  }

  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
    1a76:	add.w	ip, ip, #1
    for(Index k=0; k<depth; k++)
    {
      blockB[count] = cj(dm0(k));
      count += 1;
    }
    if(PanelMode) count += (stride-offset-depth);
    1a7a:	add	r6, r7
    1a7c:	add	r5, lr
      if(PanelMode) count += 4 * (stride-offset-depth);
    }
  }

  // copy the remaining columns one at a time (nr==1)
  for(Index j2=packet_cols4; j2<cols; ++j2)
    1a7e:	cmp	r9, ip
    1a80:	bne.n	1a58 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)+0xe4>
      blockB[count] = cj(dm0(k));
      count += 1;
    }
    if(PanelMode) count += (stride-offset-depth);
  }
}
    1a82:	add	sp, #28
    1a84:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
  EIGEN_UNUSED_VARIABLE(offset);
  eigen_assert(((!PanelMode) && stride==0 && offset==0) || (PanelMode && stride>=depth && offset<=stride));
  conj_if<NumTraits<Scalar>::IsComplex && Conjugate> cj;
  Index packet_cols8 = nr>=8 ? (cols/8) * 8 : 0;
  Index packet_cols4 = nr>=4 ? (cols/4) * 4 : 0;
  Index count = 0;
    1a88:	movs	r6, #0
    1a8a:	b.n	1a2a <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)+0xb6>

00001a8c <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)>:
    const Scalar* _tri, Index triStride,
    Scalar* _other, Index otherStride,
    level3_blocking<Scalar,Scalar>& blocking);
};
template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
EIGEN_DONT_INLINE void triangular_solve_matrix<Scalar,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor>::run(
    1a8c:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    1a90:	sub	sp, #228	; 0xe4
    1a92:	mov	r9, r2
    1a94:	add	r7, sp, #32
    1a96:	ldr.w	r5, [r7, #240]	; 0xf0
    1a9a:	str	r0, [r7, #92]	; 0x5c
    1a9c:	ldr	r2, [r5, #8]
    1a9e:	str	r3, [r7, #56]	; 0x38
    1aa0:	cmp	r2, r0
    1aa2:	ldr	r3, [r5, #16]
    1aa4:	str.w	r1, [r7, #128]	; 0x80
    1aa8:	it	ge
    1aaa:	movge	r2, r0
    1aac:	str.w	r3, [r7, #132]	; 0x84

    Index kc = blocking.kc();                   // cache block size along the K direction
    Index mc = (std::min)(size,blocking.mc());  // cache block size along the M direction

    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*cols;
    1ab0:	mul.w	r4, r3, r1
    1ab4:	mov	r0, r2
    1ab6:	str	r2, [r7, #48]	; 0x30
    };

    Index kc = blocking.kc();                   // cache block size along the K direction
    Index mc = (std::min)(size,blocking.mc());  // cache block size along the M direction

    std::size_t sizeA = kc*mc;
    1ab8:	mul.w	r8, r0, r3
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    1abc:	cmp.w	r8, #1073741824	; 0x40000000
    1ac0:	bcc.n	1aca <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x3e>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    1ac2:	mov.w	r0, #4294967295
    1ac6:	bl	6d9c <operator new(unsigned int)>
    1aca:	ldr	r3, [r5, #0]
    1acc:	str.w	r3, [r7, #152]	; 0x98
    std::size_t sizeB = kc*cols;

    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
    1ad0:	cmp	r3, #0
    1ad2:	beq.w	1f2c <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4a0>
    1ad6:	movs	r3, #0
    1ad8:	str	r3, [r7, #100]	; 0x64
    1ada:	str	r3, [r7, #120]	; 0x78
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    1adc:	cmp.w	r4, #1073741824	; 0x40000000
    1ae0:	bcc.n	1aea <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x5e>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    1ae2:	mov.w	r0, #4294967295
    1ae6:	bl	6d9c <operator new(unsigned int)>
    1aea:	ldr	r3, [r5, #4]
    1aec:	str.w	r3, [r7, #144]	; 0x90
    ei_declare_aligned_stack_constructed_variable(Scalar, blockB, sizeB, blocking.blockB());
    1af0:	cmp	r3, #0
    1af2:	beq.w	1f04 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x478>
    1af6:	movs	r3, #0
    1af8:	str	r3, [r7, #104]	; 0x68
    1afa:	str	r3, [r7, #116]	; 0x74


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    1afc:	ldr	r0, [pc, #724]	; (1dd4 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x348>)
    1afe:	ldr	r3, [r0, #0]
    1b00:	lsls	r2, r3, #31
    1b02:	bpl.w	1eec <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x460>
    1b06:	ldr	r3, [pc, #720]	; (1dd8 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x34c>)
    1b08:	ldr	r3, [r3, #4]

    // the goal here is to subdivise the Rhs panels such that we keep some cache
    // coherence when accessing the rhs elements
    std::ptrdiff_t l1, l2, l3;
    manage_caching_sizes(GetAction, &l1, &l2, &l3);
    Index subcols = cols>0 ? l2/(4 * sizeof(Scalar) * std::max<Index>(otherStride,size)) : 0;
    1b0a:	ldr.w	r2, [r7, #128]	; 0x80
    1b0e:	cmp	r2, #0
    1b10:	ble.w	1ee4 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x458>
    subcols = std::max<Index>((subcols/Traits::nr)*Traits::nr, Traits::nr);
    1b14:	ldr.w	r2, [r7, #236]	; 0xec
    1b18:	ldr	r1, [r7, #92]	; 0x5c
    1b1a:	cmp	r2, r1
    1b1c:	it	lt
    1b1e:	movlt	r2, r1
    1b20:	lsls	r2, r2, #4
    1b22:	udiv	r3, r3, r2
    1b26:	cmp	r3, #0
    1b28:	it	lt
    1b2a:	addlt	r3, #3
    1b2c:	bic.w	r3, r3, #3
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
    1b30:	cmp	r3, #4
    1b32:	it	lt
    1b34:	movlt	r3, #4
    1b36:	str.w	r3, [r7, #140]	; 0x8c

    for(Index k2=IsLower ? 0 : size;
    1b3a:	ldr	r0, [r7, #92]	; 0x5c
    1b3c:	cmp	r0, #0
    1b3e:	ble.w	1fc6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x53a>
    1b42:	ldr.w	r2, [r7, #132]	; 0x84
    1b46:	ldr	r1, [r7, #56]	; 0x38
    1b48:	mov	r3, r2
    1b4a:	ldr.w	r6, [r7, #232]	; 0xe8
    1b4e:	mul.w	r3, r1, r3
    1b52:	mov	r4, r3
    1b54:	str	r3, [r7, #36]	; 0x24
    1b56:	mov	r3, r2
    1b58:	lsls	r2, r2, #2
    1b5a:	mov	r5, r2
    1b5c:	str	r2, [r7, #8]
    1b5e:	mov	r2, r1
    1b60:	lsls	r1, r1, #2
    1b62:	add	r4, r3
    1b64:	subs	r3, r0, r3
    1b66:	str	r1, [r7, #52]	; 0x34
    1b68:	movs	r1, #0
    1b6a:	str	r3, [r7, #124]	; 0x7c
    1b6c:	adds	r5, r6, r5
    1b6e:	str	r1, [r7, #96]	; 0x60
    1b70:	str	r1, [r7, #108]	; 0x6c
    1b72:	str	r1, [r7, #84]	; 0x54
    1b74:	ldr.w	r3, [r7, #236]	; 0xec
    1b78:	ldr.w	r1, [r7, #140]	; 0x8c
    1b7c:	str	r4, [r7, #12]
    1b7e:	mul.w	r3, r3, r1
    1b82:	ldr	r4, [r7, #52]	; 0x34
    1b84:	str	r5, [r7, #60]	; 0x3c
    1b86:	mov	r5, r9
    1b88:	str	r3, [r7, #24]
    1b8a:	mov	r3, r2
    1b8c:	adds	r4, #4
    1b8e:	adds	r3, #1
    1b90:	str	r4, [r7, #16]
    1b92:	str.w	r3, [r7, #156]	; 0x9c
    1b96:	ldr.w	r3, [r7, #236]	; 0xec
    1b9a:	mov.w	fp, r3, lsl #2
    1b9e:	ldr	r3, [r7, #48]	; 0x30
    1ba0:	mov	r6, fp
    1ba2:	lsls	r3, r3, #2
    1ba4:	str	r3, [r7, #20]
    1ba6:	ldr.w	r2, [r7, #132]	; 0x84
    1baa:	ldr	r1, [r7, #124]	; 0x7c
    1bac:	adds	r3, r1, r2
    1bae:	mov	r1, r3

      // The tricky part: compute R1 = A11^-1 B while updating B from R1
      // The idea is to split A11 into multiple small vertical panels.
      // Each panel can be split into a small triangular part T1k which is processed without optimization,
      // and the remaining small part T2k which is processed using gebp with appropriate block strides
      for(Index j2=0; j2<cols; j2+=subcols)
    1bb0:	ldr.w	r3, [r7, #128]	; 0x80
    1bb4:	cmp	r1, r2
    1bb6:	it	ge
    1bb8:	movge	r1, r2
    1bba:	cmp	r3, #0
    1bbc:	str.w	r1, [r7, #160]	; 0xa0
    1bc0:	ble.w	1e10 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x384>
    1bc4:	ldr.w	r2, [r7, #128]	; 0x80
    1bc8:	movs	r3, #0
    1bca:	ldr.w	r1, [r7, #140]	; 0x8c
    1bce:	mov	fp, r5
    1bd0:	str	r2, [r7, #88]	; 0x58
    1bd2:	ldr.w	r2, [r7, #160]	; 0xa0
    1bd6:	str	r3, [r7, #72]	; 0x48
    1bd8:	mul.w	r2, r2, r1
    1bdc:	str.w	r3, [r7, #148]	; 0x94
    1be0:	str	r2, [r7, #32]
    1be2:	str.w	r3, [r7, #164]	; 0xa4
    1be6:	ldr	r3, [r7, #88]	; 0x58
    1be8:	ldr.w	r2, [r7, #140]	; 0x8c
    1bec:	cmp	r3, r2
    1bee:	it	ge
    1bf0:	movge	r3, r2
    1bf2:	str	r3, [r7, #64]	; 0x40
      {
        Index actual_cols = (std::min)(cols-j2,subcols);
        // for each small vertical panels [T1k^T, T2k^T]^T of lhs
        for (Index k1=0; k1<actual_kc; k1+=SmallPanelWidth)
    1bf4:	ldr.w	r3, [r7, #160]	; 0xa0
    1bf8:	cmp	r3, #0
    1bfa:	ble.w	1ddc <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x350>
    1bfe:	ldr	r2, [r7, #84]	; 0x54
    1c00:	ldr.w	r1, [r7, #148]	; 0x94
    1c04:	ldr	r0, [r7, #72]	; 0x48
    1c06:	adds	r3, r1, r2
    1c08:	ldr.w	r1, [r7, #144]	; 0x90
    1c0c:	str	r2, [r7, #112]	; 0x70
    1c0e:	add.w	r1, r1, r0, lsl #2
    1c12:	adds	r3, #1
    1c14:	ldr.w	r2, [r7, #164]	; 0xa4
    1c18:	str	r1, [r7, #44]	; 0x2c
    1c1a:	str	r3, [r7, #4]
    1c1c:	movs	r3, #0
    1c1e:	ldr	r1, [r7, #96]	; 0x60
    1c20:	str.w	r3, [r7, #136]	; 0x88
    1c24:	adds	r1, #1
    1c26:	ldr	r3, [r7, #64]	; 0x40
    1c28:	str	r1, [r7, #80]	; 0x50
    1c2a:	adds	r5, r3, r2
    1c2c:	ldr	r1, [r7, #108]	; 0x6c
    1c2e:	str	r5, [r7, #40]	; 0x28
    1c30:	str	r1, [r7, #76]	; 0x4c
    1c32:	ldr.w	r2, [r7, #160]	; 0xa0
    1c36:	ldr.w	r1, [r7, #136]	; 0x88
    1c3a:	subs	r3, r2, r1
    1c3c:	cmp	r3, #4
    1c3e:	str	r3, [r7, #28]
    1c40:	it	ge
    1c42:	movge	r3, #4
        {
          Index actualPanelWidth = std::min<Index>(actual_kc-k1, SmallPanelWidth);
          // tr solve
          for (Index k=0; k<actualPanelWidth; ++k)
    1c44:	cmp	r3, #0
    1c46:	str	r3, [r7, #68]	; 0x44
    1c48:	ble.n	1cc4 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x238>
    1c4a:	add.w	ip, r3, #4294967295
    1c4e:	mov.w	lr, r3, lsl #2
    1c52:	ldr	r3, [r7, #4]
    1c54:	mov	r5, ip
    1c56:	ldr.w	r9, [r7, #80]	; 0x50
    1c5a:	mov	r2, r3
    1c5c:	ldr	r3, [r7, #40]	; 0x28
    1c5e:	add.w	sl, r2, r1
    1c62:	mov	ip, r3
            Index rs = actualPanelWidth - k - 1; // remaining size
            Index s  = TriStorageOrder==RowMajor ? (IsLower ? k2+k1 : i+1)
                                                 :  IsLower ? i+1 : i-rs;

            Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(tri(i,i));
            for (Index j=j2; j<j2+actual_cols; ++j)
    1c64:	ldr.w	r3, [r7, #164]	; 0xa4
    1c68:	sub.w	lr, lr, #4
    1c6c:	cmp	r3, ip
    1c6e:	bge.n	1cb0 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x224>
    1c70:	ldr.w	r3, [r7, #232]	; 0xe8
    1c74:	mov.w	r8, r9, lsl #2
    1c78:	ldr.w	r4, [r7, #164]	; 0xa4
    1c7c:	add.w	r0, r3, sl, lsl #2

                other(i,j) = (other(i,j) - b)*a;
              }
              else
              {
                Scalar b = (other(i,j) *= a);
    1c80:	vldr	s13, [r0, #-4]
                Scalar* r = &other(s,j);
                const Scalar* l = &tri(s,i);
                for (Index i3=0;i3<rs;++i3)
    1c84:	cbz	r5, 1ca8 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x21c>
    1c86:	vneg.f32	s13, s13
    1c8a:	add.w	r2, fp, r8
    1c8e:	add.w	r1, lr, r0
    1c92:	mov	r3, r0
                  r[i3] -= b * conj(l[i3]);
    1c94:	vldmia	r2!, {s14}
    1c98:	vldr	s15, [r3]
    1c9c:	vfma.f32	s15, s13, s14
    1ca0:	vstmia	r3!, {s15}
              else
              {
                Scalar b = (other(i,j) *= a);
                Scalar* r = &other(s,j);
                const Scalar* l = &tri(s,i);
                for (Index i3=0;i3<rs;++i3)
    1ca4:	cmp	r1, r3
    1ca6:	bne.n	1c94 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x208>
            Index rs = actualPanelWidth - k - 1; // remaining size
            Index s  = TriStorageOrder==RowMajor ? (IsLower ? k2+k1 : i+1)
                                                 :  IsLower ? i+1 : i-rs;

            Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(tri(i,i));
            for (Index j=j2; j<j2+actual_cols; ++j)
    1ca8:	adds	r4, #1
    1caa:	add	r0, r6
    1cac:	cmp	r4, ip
    1cae:	bne.n	1c80 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x1f4>
    1cb0:	ldr.w	r3, [r7, #156]	; 0x9c
    1cb4:	subs	r5, #1
    1cb6:	add.w	sl, sl, #1
    1cba:	add	r9, r3
        // for each small vertical panels [T1k^T, T2k^T]^T of lhs
        for (Index k1=0; k1<actual_kc; k1+=SmallPanelWidth)
        {
          Index actualPanelWidth = std::min<Index>(actual_kc-k1, SmallPanelWidth);
          // tr solve
          for (Index k=0; k<actualPanelWidth; ++k)
    1cbc:	adds	r3, r5, #1
    1cbe:	bne.n	1c64 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x1d8>
    1cc0:	str.w	ip, [r7, #40]	; 0x28
                  r[i3] -= b * conj(l[i3]);
              }
            }
          }

          Index lengthTarget = actual_kc-k1-actualPanelWidth;
    1cc4:	ldr	r1, [r7, #28]
    1cc6:	ldr	r0, [r7, #68]	; 0x44
    1cc8:	ldr.w	r3, [r7, #148]	; 0x94
    1ccc:	mov	r5, r1
    1cce:	ldr	r2, [r7, #112]	; 0x70
    1cd0:	rsb	r9, r0, r5
          Index startBlock   = IsLower ? k2+k1 : k2-k1-actualPanelWidth;
          Index blockBOffset = IsLower ? k1 : lengthTarget;

          // update the respective rows of B from other
          pack_rhs(blockB+actual_kc*j2, other.getSubMapper(startBlock,j2), actualPanelWidth, actual_cols, actual_kc, blockBOffset);
    1cd4:	mov	r5, r0
    1cd6:	adds	r4, r3, r2
    1cd8:	mov	r3, r0
    1cda:	ldr.w	r0, [r7, #232]	; 0xe8
    1cde:	ldr	r2, [r7, #64]	; 0x40
    1ce0:	add.w	lr, r0, r4, lsl #2
    1ce4:	add.w	r4, r7, #184	; 0xb8
    1ce8:	ldr.w	r0, [r7, #160]	; 0xa0
    1cec:	str	r2, [sp, #0]
    1cee:	mov	r2, r4
    1cf0:	add.w	r4, r7, #180	; 0xb4
    1cf4:	ldr.w	r1, [r7, #136]	; 0x88
    1cf8:	str	r0, [sp, #4]
    1cfa:	mov	r0, r4
    1cfc:	ldr.w	r4, [r7, #236]	; 0xec
    1d00:	str	r1, [sp, #8]
    1d02:	ldr	r1, [r7, #44]	; 0x2c
    1d04:	str.w	r4, [r7, #188]	; 0xbc
    1d08:	str.w	lr, [r7, #184]	; 0xb8
    1d0c:	bl	1974 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)>

          // GEBP
          if (lengthTarget>0)
    1d10:	cmp.w	r9, #0
    1d14:	ble.n	1da6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x31a>
          {
            Index startTarget  = IsLower ? k2+k1+actualPanelWidth : k2-actual_kc;
    1d16:	ldr	r2, [r7, #112]	; 0x70
    1d18:	mov	r4, r5

            pack_lhs(blockA, tri.getSubMapper(startTarget,startBlock), actualPanelWidth, lengthTarget);
    1d1a:	mov	r3, r5
    1d1c:	str	r5, [r7, #68]	; 0x44
          pack_rhs(blockB+actual_kc*j2, other.getSubMapper(startBlock,j2), actualPanelWidth, actual_cols, actual_kc, blockBOffset);

          // GEBP
          if (lengthTarget>0)
          {
            Index startTarget  = IsLower ? k2+k1+actualPanelWidth : k2-actual_kc;
    1d1e:	add	r4, r2

            pack_lhs(blockA, tri.getSubMapper(startTarget,startBlock), actualPanelWidth, lengthTarget);
    1d20:	add.w	r5, r7, #184	; 0xb8
    1d24:	ldr	r2, [r7, #76]	; 0x4c
    1d26:	mov.w	r8, #0
    1d2a:	ldr.w	sl, [r7, #152]	; 0x98
    1d2e:	add.w	lr, r2, r4
    1d32:	mov	r2, r5
    1d34:	add.w	r5, r7, #176	; 0xb0
    1d38:	mov	r1, sl
    1d3a:	add.w	lr, fp, lr, lsl #2
    1d3e:	str.w	r9, [sp]
    1d42:	mov	r0, r5
    1d44:	ldr	r5, [r7, #56]	; 0x38
    1d46:	str.w	r8, [sp, #8]
    1d4a:	str.w	r8, [sp, #4]
    1d4e:	str.w	r5, [r7, #188]	; 0xbc
    1d52:	str.w	lr, [r7, #184]	; 0xb8
    1d56:	bl	550 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)>
    1d5a:	ldr.w	r3, [r7, #148]	; 0x94

            gebp_kernel(other.getSubMapper(startTarget,j2), blockA, blockB+actual_kc*j2, lengthTarget, actualPanelWidth, actual_cols, Scalar(-1),
    1d5e:	vmov.f32	s0, #240	; 0xbf800000 -1.0
    1d62:	ldr.w	r5, [r7, #232]	; 0xe8
    1d66:	add	r4, r3
    1d68:	ldr.w	r1, [r7, #136]	; 0x88
    1d6c:	ldr.w	r0, [r7, #160]	; 0xa0
    1d70:	add.w	r4, r5, r4, lsl #2
    1d74:	ldr	r2, [r7, #64]	; 0x40
    1d76:	str	r1, [sp, #24]
    1d78:	ldr	r1, [r7, #68]	; 0x44
    1d7a:	str.w	r4, [r7, #184]	; 0xb8
    1d7e:	ldr.w	r4, [r7, #236]	; 0xec
    1d82:	str	r0, [sp, #16]
    1d84:	add.w	r0, r7, #172	; 0xac
    1d88:	str	r1, [sp, #12]
    1d8a:	str	r2, [sp, #8]
    1d8c:	mov	r2, sl
    1d8e:	str	r1, [sp, #4]
    1d90:	add.w	r1, r7, #184	; 0xb8
    1d94:	str.w	r8, [sp, #20]
    1d98:	ldr	r3, [r7, #44]	; 0x2c
    1d9a:	str.w	r9, [sp]
    1d9e:	str.w	r4, [r7, #188]	; 0xbc
    1da2:	bl	6e4 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)>
    1da6:	ldr	r2, [r7, #112]	; 0x70
    1da8:	ldr	r1, [r7, #52]	; 0x34
    1daa:	adds	r2, #4
      // and the remaining small part T2k which is processed using gebp with appropriate block strides
      for(Index j2=0; j2<cols; j2+=subcols)
      {
        Index actual_cols = (std::min)(cols-j2,subcols);
        // for each small vertical panels [T1k^T, T2k^T]^T of lhs
        for (Index k1=0; k1<actual_kc; k1+=SmallPanelWidth)
    1dac:	ldr.w	r3, [r7, #136]	; 0x88
    1db0:	str	r2, [r7, #112]	; 0x70
    1db2:	adds	r3, #4
    1db4:	ldr	r2, [r7, #76]	; 0x4c
    1db6:	str.w	r3, [r7, #136]	; 0x88
    1dba:	add	r2, r1
    1dbc:	ldr	r1, [r7, #16]
    1dbe:	str	r2, [r7, #76]	; 0x4c
    1dc0:	ldr	r2, [r7, #80]	; 0x50
    1dc2:	add	r2, r1
    1dc4:	str	r2, [r7, #80]	; 0x50
    1dc6:	ldr.w	r2, [r7, #160]	; 0xa0
    1dca:	cmp	r2, r3
    1dcc:	bgt.w	1c32 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x1a6>
    1dd0:	b.n	1ddc <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x350>
    1dd2:	nop
    1dd4:	.word	0x2000095c
    1dd8:	.word	0x20000960

      // The tricky part: compute R1 = A11^-1 B while updating B from R1
      // The idea is to split A11 into multiple small vertical panels.
      // Each panel can be split into a small triangular part T1k which is processed without optimization,
      // and the remaining small part T2k which is processed using gebp with appropriate block strides
      for(Index j2=0; j2<cols; j2+=subcols)
    1ddc:	ldr.w	r1, [r7, #140]	; 0x8c
    1de0:	ldr	r0, [r7, #88]	; 0x58
    1de2:	ldr.w	r3, [r7, #164]	; 0xa4
    1de6:	subs	r2, r0, r1
    1de8:	add	r3, r1
    1dea:	ldr	r1, [r7, #24]
    1dec:	str	r2, [r7, #88]	; 0x58
    1dee:	ldr.w	r2, [r7, #148]	; 0x94
    1df2:	str.w	r3, [r7, #164]	; 0xa4
    1df6:	add	r2, r1
    1df8:	ldr	r1, [r7, #32]
    1dfa:	str.w	r2, [r7, #148]	; 0x94
    1dfe:	ldr	r2, [r7, #72]	; 0x48
    1e00:	add	r2, r1
    1e02:	str	r2, [r7, #72]	; 0x48
    1e04:	ldr.w	r2, [r7, #128]	; 0x80
    1e08:	cmp	r2, r3
    1e0a:	bgt.w	1be6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x15a>
    1e0e:	mov	r5, fp
        }
      }
      
      // R2 -= A21 * B => GEPP
      {
        Index start = IsLower ? k2+kc : 0;
    1e10:	ldr	r3, [r7, #84]	; 0x54
    1e12:	ldr.w	r2, [r7, #132]	; 0x84
    1e16:	add	r3, r2
        Index end   = IsLower ? size : k2-kc;
        for(Index i2=start; i2<end; i2+=mc)
    1e18:	ldr	r2, [r7, #92]	; 0x5c
    1e1a:	cmp	r3, r2
        }
      }
      
      // R2 -= A21 * B => GEPP
      {
        Index start = IsLower ? k2+kc : 0;
    1e1c:	str	r3, [r7, #84]	; 0x54
        Index end   = IsLower ? size : k2-kc;
        for(Index i2=start; i2<end; i2+=mc)
    1e1e:	bge.w	1fc6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x53a>
    1e22:	ldr.w	r3, [r7, #132]	; 0x84
        {
          const Index actual_mc = (std::min)(mc,end-i2);
          if (actual_mc>0)
          {
            pack_lhs(blockA, tri.getSubMapper(i2, IsLower ? k2 : k2-kc), actual_kc, actual_mc);
    1e26:	mov.w	r8, #0
    1e2a:	ldr	r2, [r7, #96]	; 0x60
    1e2c:	mov	fp, r5
      
      // R2 -= A21 * B => GEPP
      {
        Index start = IsLower ? k2+kc : 0;
        Index end   = IsLower ? size : k2-kc;
        for(Index i2=start; i2<end; i2+=mc)
    1e2e:	ldr	r4, [r7, #124]	; 0x7c
        {
          const Index actual_mc = (std::min)(mc,end-i2);
          if (actual_mc>0)
          {
            pack_lhs(blockA, tri.getSubMapper(i2, IsLower ? k2 : k2-kc), actual_kc, actual_mc);
    1e30:	str.w	r6, [r7, #148]	; 0x94
    1e34:	add.w	sl, r3, r2
      
      // R2 -= A21 * B => GEPP
      {
        Index start = IsLower ? k2+kc : 0;
        Index end   = IsLower ? size : k2-kc;
        for(Index i2=start; i2<end; i2+=mc)
    1e38:	ldr.w	r9, [r7, #60]	; 0x3c
        {
          const Index actual_mc = (std::min)(mc,end-i2);
          if (actual_mc>0)
          {
            pack_lhs(blockA, tri.getSubMapper(i2, IsLower ? k2 : k2-kc), actual_kc, actual_mc);
    1e3c:	str.w	r4, [r7, #164]	; 0xa4
    1e40:	ldr	r6, [r7, #48]	; 0x30
    1e42:	b.n	1e68 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x3dc>
        Index start = IsLower ? k2+kc : 0;
        Index end   = IsLower ? size : k2-kc;
        for(Index i2=start; i2<end; i2+=mc)
        {
          const Index actual_mc = (std::min)(mc,end-i2);
          if (actual_mc>0)
    1e44:	cmp	r6, #0
    1e46:	bgt.w	2014 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x588>
    1e4a:	ldr.w	r3, [r7, #164]	; 0xa4
    1e4e:	add	sl, r6
      
      // R2 -= A21 * B => GEPP
      {
        Index start = IsLower ? k2+kc : 0;
        Index end   = IsLower ? size : k2-kc;
        for(Index i2=start; i2<end; i2+=mc)
    1e50:	ldr	r2, [r7, #92]	; 0x5c
    1e52:	subs	r3, r3, r6
    1e54:	str.w	r3, [r7, #164]	; 0xa4
    1e58:	ldr	r3, [r7, #20]
    1e5a:	add	r9, r3
    1e5c:	ldr	r3, [r7, #108]	; 0x6c
    1e5e:	rsb	r3, r3, sl
    1e62:	cmp	r3, r2
    1e64:	bge.w	1fea <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x55e>
    min(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
    1e68:	ldr.w	r5, [r7, #164]	; 0xa4
    1e6c:	cmp	r5, r6
    1e6e:	bge.n	1e44 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x3b8>
    1e70:	add.w	lr, fp, sl, lsl #2
    1e74:	ldr	r4, [r7, #56]	; 0x38
        {
          const Index actual_mc = (std::min)(mc,end-i2);
          if (actual_mc>0)
          {
            pack_lhs(blockA, tri.getSubMapper(i2, IsLower ? k2 : k2-kc), actual_kc, actual_mc);
    1e76:	ldr.w	r3, [r7, #160]	; 0xa0
    1e7a:	add.w	r2, r7, #184	; 0xb8
    1e7e:	ldr.w	r1, [r7, #152]	; 0x98
    1e82:	add.w	r0, r7, #176	; 0xb0
    1e86:	str.w	r8, [sp, #8]
    1e8a:	str.w	r8, [sp, #4]
    1e8e:	str	r5, [sp, #0]
    1e90:	str.w	r4, [r7, #188]	; 0xbc
    1e94:	str.w	lr, [r7, #184]	; 0xb8
    1e98:	bl	550 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)>

            gebp_kernel(other.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc, cols, Scalar(-1), -1, -1, 0, 0);
    1e9c:	mov.w	lr, #4294967295
    1ea0:	ldr.w	r3, [r7, #128]	; 0x80
    1ea4:	ldr.w	r1, [r7, #160]	; 0xa0
    1ea8:	vmov.f32	s0, #240	; 0xbf800000 -1.0
    1eac:	ldr.w	r4, [r7, #236]	; 0xec
    1eb0:	add.w	r0, r7, #172	; 0xac
    1eb4:	str	r3, [sp, #8]
    1eb6:	str	r1, [sp, #4]
    1eb8:	add.w	r1, r7, #184	; 0xb8
    1ebc:	str.w	r8, [sp, #24]
    1ec0:	str.w	r8, [sp, #20]
    1ec4:	ldr.w	r3, [r7, #144]	; 0x90
    1ec8:	ldr.w	r2, [r7, #152]	; 0x98
    1ecc:	str	r5, [sp, #0]
    1ece:	str.w	lr, [sp, #16]
    1ed2:	str.w	lr, [sp, #12]
    1ed6:	str.w	r9, [r7, #184]	; 0xb8
    1eda:	str.w	r4, [r7, #188]	; 0xbc
    1ede:	bl	6e4 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)>
    1ee2:	b.n	1e4a <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x3be>
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
	return __b;
    1ee4:	movs	r3, #4
    1ee6:	str.w	r3, [r7, #140]	; 0x8c
    1eea:	b.n	1b3a <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0xae>
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
    1eec:	mov.w	r1, #524288	; 0x80000
/** \internal */
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    1ef0:	ldr	r2, [pc, #292]	; (2018 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x58c>)
    1ef2:	mov.w	r5, #16384	; 0x4000


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    1ef6:	movs	r4, #1
    1ef8:	mov	r3, r1
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
    1efa:	str	r1, [r2, #4]
    m_l3 = manage_caching_sizes_helper(l3CacheSize, defaultL3CacheSize);
    1efc:	str	r1, [r2, #8]
/** \internal */
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    1efe:	str	r5, [r2, #0]


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    1f00:	str	r4, [r0, #0]
    1f02:	b.n	1b0a <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x7e>

    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*cols;

    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
    ei_declare_aligned_stack_constructed_variable(Scalar, blockB, sizeB, blocking.blockB());
    1f04:	lsls	r0, r4, #2
    1f06:	cmp.w	r0, #131072	; 0x20000
    1f0a:	bhi.n	1f56 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4ca>
    1f0c:	add.w	r3, r0, #29
    1f10:	movs	r2, #0
    1f12:	bic.w	r3, r3, #7
    1f16:	str	r2, [r7, #104]	; 0x68
    1f18:	sub.w	sp, sp, r3
    1f1c:	add.w	r3, sp, #47	; 0x2f
    1f20:	bic.w	r3, r3, #15
    1f24:	str.w	r3, [r7, #144]	; 0x90
    1f28:	str	r3, [r7, #116]	; 0x74
    1f2a:	b.n	1afc <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x70>
    Index mc = (std::min)(size,blocking.mc());  // cache block size along the M direction

    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*cols;

    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
    1f2c:	mov.w	r0, r8, lsl #2
    1f30:	cmp.w	r0, #131072	; 0x20000
    1f34:	bhi.n	1f84 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4f8>
    1f36:	add.w	r3, r0, #29
    1f3a:	movs	r2, #0
    1f3c:	bic.w	r3, r3, #7
    1f40:	str	r2, [r7, #100]	; 0x64
    1f42:	sub.w	sp, sp, r3
    1f46:	add.w	r3, sp, #47	; 0x2f
    1f4a:	bic.w	r3, r3, #15
    1f4e:	str.w	r3, [r7, #152]	; 0x98
    1f52:	str	r3, [r7, #120]	; 0x78
    1f54:	b.n	1adc <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x50>
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    1f56:	adds	r0, #16
    1f58:	bl	7238 <malloc>
  if (original == 0) return 0;
    1f5c:	cbz	r0, 1fb2 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x526>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    1f5e:	bic.w	r3, r0, #15
    1f62:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    1f64:	str.w	r0, [r3, #-4]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    1f68:	str.w	r3, [r7, #144]	; 0x90
    ei_declare_aligned_stack_constructed_variable(Scalar, blockB, sizeB, blocking.blockB());
    1f6c:	ldr	r3, [r5, #4]
    1f6e:	cmp	r3, #0
    1f70:	bne.w	1af6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x6a>
    1f74:	ldr.w	r2, [r7, #144]	; 0x90
    1f78:	adds	r3, r2, #0
    1f7a:	str	r2, [r7, #116]	; 0x74
    1f7c:	it	ne
    1f7e:	movne	r3, #1
    1f80:	str	r3, [r7, #104]	; 0x68
    1f82:	b.n	1afc <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x70>
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    1f84:	adds	r0, #16
    1f86:	bl	7238 <malloc>
  if (original == 0) return 0;
    1f8a:	cbz	r0, 1fbc <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x530>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    1f8c:	bic.w	r3, r0, #15
    1f90:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    1f92:	str.w	r0, [r3, #-4]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    1f96:	str.w	r3, [r7, #152]	; 0x98
    Index mc = (std::min)(size,blocking.mc());  // cache block size along the M direction

    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*cols;

    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
    1f9a:	ldr	r3, [r5, #0]
    1f9c:	cmp	r3, #0
    1f9e:	bne.w	1ad6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4a>
    1fa2:	ldr.w	r2, [r7, #152]	; 0x98
    1fa6:	adds	r3, r2, #0
    1fa8:	str	r2, [r7, #120]	; 0x78
    1faa:	it	ne
    1fac:	movne	r3, #1
    1fae:	str	r3, [r7, #100]	; 0x64
    1fb0:	b.n	1adc <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x50>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    1fb2:	mov.w	r0, #4294967295
    1fb6:	bl	6d9c <operator new(unsigned int)>
    1fba:	b.n	1f6c <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4e0>
    1fbc:	mov.w	r0, #4294967295
    1fc0:	bl	6d9c <operator new(unsigned int)>
    1fc4:	b.n	1f9a <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x50e>
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    1fc6:	ldr	r3, [r7, #104]	; 0x68
    1fc8:	cbz	r3, 1fd4 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x548>
    1fca:	ldr	r3, [r7, #116]	; 0x74
    1fcc:	ldr.w	r0, [r3, #-4]
    1fd0:	bl	7248 <free>
    1fd4:	ldr	r3, [r7, #100]	; 0x64
    1fd6:	cbz	r3, 1fe2 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x556>
    1fd8:	ldr	r3, [r7, #120]	; 0x78
    1fda:	ldr.w	r0, [r3, #-4]
    1fde:	bl	7248 <free>
            gebp_kernel(other.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc, cols, Scalar(-1), -1, -1, 0, 0);
          }
        }
      }
    }
  }
    1fe2:	adds	r7, #196	; 0xc4
    1fe4:	mov	sp, r7
    1fe6:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    1fea:	ldr	r3, [r7, #108]	; 0x6c
    1fec:	mov	r5, fp
    1fee:	ldr	r2, [r7, #36]	; 0x24
    1ff0:	ldr.w	r6, [r7, #148]	; 0x94
    1ff4:	add	r3, r2
    1ff6:	ldr.w	r2, [r7, #132]	; 0x84
    1ffa:	str	r3, [r7, #108]	; 0x6c
    1ffc:	ldr	r3, [r7, #124]	; 0x7c
    1ffe:	subs	r3, r3, r2
    2000:	ldr	r2, [r7, #12]
    2002:	str	r3, [r7, #124]	; 0x7c
    2004:	ldr	r3, [r7, #96]	; 0x60
    2006:	add	r3, r2
    2008:	ldr	r2, [r7, #8]
    200a:	str	r3, [r7, #96]	; 0x60
    200c:	ldr	r3, [r7, #60]	; 0x3c
    200e:	add	r3, r2
    2010:	str	r3, [r7, #60]	; 0x3c
    2012:	b.n	1ba6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x11a>
    2014:	mov	r5, r6
    2016:	b.n	1e70 <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x3e4>
    2018:	.word	0x20000960

0000201c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)>:
 * - the number of scalars that fit into a packet (when vectorization is enabled).
 *
 * \sa setCpuCacheSizes */

template<typename LhsScalar, typename RhsScalar, int KcFactor, typename Index>
void evaluateProductBlockingSizesHeuristic(Index& k, Index& m, Index& n, Index num_threads = 1)
    201c:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    2020:	ldr	r7, [pc, #752]	; (2314 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2f8>)
 * - the number of scalars that fit into a packet (when vectorization is enabled).
 *
 * \sa setCpuCacheSizes */

template<typename LhsScalar, typename RhsScalar, int KcFactor, typename Index>
void evaluateProductBlockingSizesHeuristic(Index& k, Index& m, Index& n, Index num_threads = 1)
    2022:	sub	sp, #12


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    2024:	ldr	r4, [r7, #0]
    2026:	lsls	r4, r4, #31
    2028:	bpl.n	20d8 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0xbc>
    202a:	ldr	r5, [pc, #748]	; (2318 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2fc>)
  // per mr x kc horizontal small panels where mr is the blocking size along the m dimension
  // at the register level. This small horizontal panel has to stay within L1 cache.
  std::ptrdiff_t l1, l2, l3;
  manage_caching_sizes(GetAction, &l1, &l2, &l3);

  if (num_threads > 1) {
    202c:	cmp	r3, #1
    202e:	ldmia.w	r5, {r4, r6}
    2032:	ldr	r5, [r5, #8]
    2034:	ble.n	2102 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0xe6>
    2036:	sub.w	lr, r4, #32
    203a:	ldr	r7, [pc, #736]	; (231c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x300>)
    // Increasing k gives us more time to prefetch the content of the "C"
    // registers. However once the latency is hidden there is no point in
    // increasing the value of k, so we'll cap it at 320 (value determined
    // experimentally).
    const Index k_cache = (numext::mini<Index>)((l1-ksub)/kdiv, 320);
    if (k_cache < k) {
    203c:	ldr.w	ip, [r0]
    2040:	smull	r8, r7, r7, lr
    2044:	mov.w	lr, lr, asr #31
    2048:	rsb	r7, lr, r7, asr #4
    204c:	cmp.w	r7, #320	; 0x140
    2050:	it	ge
    2052:	movge.w	r7, #320	; 0x140
    2056:	cmp	ip, r7
    2058:	ble.n	2072 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x56>
      k = k_cache - (k_cache % kr);
    205a:	ldr.w	ip, [pc, #716]	; 2328 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x30c>
    205e:	and.w	ip, r7, ip
    2062:	cmp.w	ip, #0
    2066:	blt.w	21d2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1b6>
    206a:	rsb	ip, ip, r7
    206e:	str.w	ip, [r0]
    2072:	ldr.w	lr, [r2]
      eigen_internal_assert(k > 0);
    }

    const Index n_cache = (l2-l1) / (nr * sizeof(RhsScalar) * k);
    2076:	subs	r4, r6, r4
    2078:	mov.w	ip, ip, lsl #4
    207c:	add.w	r7, r3, lr
    2080:	subs	r7, #1
    2082:	udiv	r4, r4, ip
    2086:	sdiv	r7, r7, r3
    const Index n_per_thread = numext::div_ceil(n, num_threads);
    if (n_cache <= n_per_thread) {
    208a:	cmp	r4, r7
    208c:	ble.w	21a0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x184>
      // Don't exceed the capacity of the l2 cache.
      eigen_internal_assert(n_cache >= static_cast<Index>(nr));
      n = n_cache - (n_cache % nr);
      eigen_internal_assert(n > 0);
    } else {
      n = (numext::mini<Index>)(n, (n_per_thread + nr - 1) - ((n_per_thread + nr - 1) % nr));
    2090:	adds	r7, #3
    2092:	ldr	r4, [pc, #652]	; (2320 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x304>)
    2094:	ands	r4, r7
    2096:	cmp	r4, #0
    2098:	blt.w	21c8 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1ac>
    209c:	subs	r7, r7, r4
    209e:	cmp	r7, lr
    20a0:	it	ge
    20a2:	movge	r7, lr
    20a4:	str	r7, [r2, #0]
    }

    if (l3 > l2) {
    20a6:	cmp	r5, r6
    20a8:	ble.w	21c2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1a6>
    20ac:	ldr	r4, [r1, #0]
      // l3 is shared between all cores, so we'll give each thread its own chunk of l3.
      const Index m_cache = (l3-l2) / (sizeof(LhsScalar) * k * num_threads);
    20ae:	lsls	r7, r3, #2
    20b0:	ldr	r0, [r0, #0]
    20b2:	subs	r6, r5, r6
    20b4:	adds	r2, r3, r4
    20b6:	mul.w	r5, r0, r7
    20ba:	subs	r2, #1
    20bc:	udiv	r5, r6, r5
    20c0:	sdiv	r3, r2, r3
      const Index m_per_thread = numext::div_ceil(m, num_threads);
      if(m_cache < m_per_thread && m_cache >= static_cast<Index>(mr)) {
    20c4:	cmp	r5, r3
    20c6:	bge.n	21ae <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x192>
    20c8:	cmp	r5, #1
    20ca:	ble.n	21ae <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x192>
        m = m_cache - (m_cache % mr);
    20cc:	bic.w	r5, r5, #1
    20d0:	str	r5, [r1, #0]
      else if (mc==0) return;
      m = (m%mc)==0 ? mc
                    : (mc - Traits::mr * ((mc/*-1*/-(m%mc))/(Traits::mr*(m/mc+1))));
    }
  }
}
    20d2:	add	sp, #12
    20d4:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
    20d8:	mov.w	ip, #524288	; 0x80000
/** \internal */
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    20dc:	ldr.w	lr, [pc, #568]	; 2318 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2fc>
    20e0:	mov.w	r8, #16384	; 0x4000
  // per mr x kc horizontal small panels where mr is the blocking size along the m dimension
  // at the register level. This small horizontal panel has to stay within L1 cache.
  std::ptrdiff_t l1, l2, l3;
  manage_caching_sizes(GetAction, &l1, &l2, &l3);

  if (num_threads > 1) {
    20e4:	cmp	r3, #1
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
    20e6:	str.w	ip, [lr, #4]


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    20ea:	mov	r5, ip
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
    m_l3 = manage_caching_sizes_helper(l3CacheSize, defaultL3CacheSize);
    20ec:	str.w	ip, [lr, #8]


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    20f0:	mov	r4, r8
/** \internal */
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    20f2:	str.w	r8, [lr]


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    20f6:	mov.w	lr, #1
    20fa:	mov	r6, ip
    20fc:	str.w	lr, [r7]
  // per mr x kc horizontal small panels where mr is the blocking size along the m dimension
  // at the register level. This small horizontal panel has to stay within L1 cache.
  std::ptrdiff_t l1, l2, l3;
  manage_caching_sizes(GetAction, &l1, &l2, &l3);

  if (num_threads > 1) {
    2100:	bgt.n	2036 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1a>
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
    2102:	ldr	r7, [r1, #0]
    2104:	ldr.w	ip, [r2]
    2108:	ldr.w	lr, [r0]

    // Early return for small problems because the computation below are time consuming for small problems.
    // Perhaps it would make more sense to consider k*n*m??
    // Note that for very tiny problem, this function should be bypassed anyway
    // because we use the coefficient-based implementation for them.
    if((numext::maxi)(k,(numext::maxi)(m,n))<48)
    210c:	cmp	ip, r7
    210e:	mov	r3, ip
    2110:	it	lt
    2112:	movlt	r3, r7
    2114:	cmp	r3, lr
    2116:	it	lt
    2118:	movlt	r3, lr
    211a:	cmp	r3, #47	; 0x2f
    211c:	ble.n	21c2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1a6>
    // Blocking on the third dimension (i.e., k) is chosen so that an horizontal panel
    // of size mr x kc of the lhs plus a vertical panel of kc x nr of the rhs both fits within L1 cache.
    // We also include a register-level block of the result (mx x nr).
    // (In an ideal world only the lhs panel would stay in L1)
    // Moreover, kc has to be a multiple of 8 to be compatible with loop peeling, leading to a maximum blocking size of:
    const Index max_kc = numext::maxi<Index>(((l1-k_sub)/k_div) & (~(k_peeling-1)),1);
    211e:	sub.w	r8, r4, #32
    2122:	ldr.w	fp, [pc, #504]	; 231c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x300>
    2126:	mov.w	r3, r8, asr #31
    212a:	smull	r9, fp, fp, r8
    212e:	rsb	fp, r3, fp, asr #4
    2132:	bic.w	fp, fp, #7
    2136:	cmp.w	fp, #0
    213a:	ble.w	22a4 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x288>
    const Index old_k = k;
    if(k>max_kc)
    213e:	cmp	fp, lr
    2140:	blt.n	21f4 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1d8>
    2142:	mov.w	r3, lr, lsl #3
    2146:	mov.w	r9, #1572864	; 0x180000
    214a:	mov	r0, r7
    214c:	str.w	fp, [sp]
    2150:	mov.w	sl, lr, lsl #2
    2154:	mov	r7, lr
    2156:	mov.w	fp, lr, lsl #4
    215a:	udiv	r9, r9, r3
    // to limit this growth: we bound nc to growth by a factor x1.5.
    // However, if the entire lhs block fit within L1, then we are not going to block on the rows at all,
    // and it becomes fruitful to keep the packed rhs blocks in L1 if there is enough remaining space.
    Index max_nc;
    const Index lhs_bytes = m * k * sizeof(LhsScalar);
    const Index remaining_l1 = l1- k_sub - lhs_bytes;
    215e:	mul.w	r3, r7, r0
    2162:	sub.w	r3, r8, r3, lsl #2
    if(remaining_l1 >= Index(Traits::nr*sizeof(RhsScalar))*k)
    2166:	cmp	r3, fp
    2168:	blt.w	2294 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x278>
    {
      // L1 blocking
      max_nc = remaining_l1 / (k*sizeof(RhsScalar));
    216c:	udiv	r3, r3, sl
    {
      // L2 blocking
      max_nc = (3*actual_l2)/(2*2*max_kc*sizeof(RhsScalar));
    }
    // WARNING Below, we assume that Traits::nr is a power of two.
    Index nc = numext::mini<Index>(actual_l2/(2*k*sizeof(RhsScalar)), max_nc) & (~(Traits::nr-1));
    2170:	cmp	r9, r3
    2172:	it	ge
    2174:	movge	r9, r3
    2176:	bic.w	r9, r9, #3
    if(n>nc)
    217a:	cmp	r9, ip
    217c:	bge.n	2238 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x21c>
    {
      // We are really blocking over the columns:
      // -> reduce blocking size to make sure the last block is as large as possible
      //    while keeping the same number of sweeps over the packed lhs.
      //    Here we allow one more sweep if this gives us a perfect match, thus the commented "-1"
      n = (n%nc)==0 ? nc
    217e:	sdiv	r1, ip, r9
    2182:	mls	r3, r9, r1, ip
    2186:	cmp	r3, #0
    2188:	beq.w	22cc <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2b0>
    218c:	adds	r1, #1
    218e:	rsb	ip, r3, r9
    2192:	lsls	r3, r1, #2
    2194:	sdiv	r3, ip, r3
    2198:	sub.w	r3, r9, r3, lsl #2
    219c:	str	r3, [r2, #0]
    219e:	b.n	21c2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1a6>
    const Index n_cache = (l2-l1) / (nr * sizeof(RhsScalar) * k);
    const Index n_per_thread = numext::div_ceil(n, num_threads);
    if (n_cache <= n_per_thread) {
      // Don't exceed the capacity of the l2 cache.
      eigen_internal_assert(n_cache >= static_cast<Index>(nr));
      n = n_cache - (n_cache % nr);
    21a0:	ldr	r7, [pc, #380]	; (2320 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x304>)
    21a2:	ands	r7, r4
    21a4:	cmp	r7, #0
    21a6:	blt.n	21e0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1c4>
    21a8:	subs	r4, r4, r7
    21aa:	str	r4, [r2, #0]
    21ac:	b.n	20a6 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x8a>
      const Index m_per_thread = numext::div_ceil(m, num_threads);
      if(m_cache < m_per_thread && m_cache >= static_cast<Index>(mr)) {
        m = m_cache - (m_cache % mr);
        eigen_internal_assert(m > 0);
      } else {
        m = (numext::mini<Index>)(m, (m_per_thread + mr - 1) - ((m_per_thread + mr - 1) % mr));
    21ae:	adds	r3, #1
    21b0:	ldr	r2, [pc, #368]	; (2324 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x308>)
    21b2:	ands	r2, r3
    21b4:	cmp	r2, #0
    21b6:	blt.n	21ea <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1ce>
    21b8:	subs	r3, r3, r2
    21ba:	cmp	r3, r4
    21bc:	it	ge
    21be:	movge	r3, r4
    21c0:	str	r3, [r1, #0]
      else if (mc==0) return;
      m = (m%mc)==0 ? mc
                    : (mc - Traits::mr * ((mc/*-1*/-(m%mc))/(Traits::mr*(m/mc+1))));
    }
  }
}
    21c2:	add	sp, #12
    21c4:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
      // Don't exceed the capacity of the l2 cache.
      eigen_internal_assert(n_cache >= static_cast<Index>(nr));
      n = n_cache - (n_cache % nr);
      eigen_internal_assert(n > 0);
    } else {
      n = (numext::mini<Index>)(n, (n_per_thread + nr - 1) - ((n_per_thread + nr - 1) % nr));
    21c8:	subs	r4, #1
    21ca:	orn	r4, r4, #3
    21ce:	adds	r4, #1
    21d0:	b.n	209c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x80>
    // registers. However once the latency is hidden there is no point in
    // increasing the value of k, so we'll cap it at 320 (value determined
    // experimentally).
    const Index k_cache = (numext::mini<Index>)((l1-ksub)/kdiv, 320);
    if (k_cache < k) {
      k = k_cache - (k_cache % kr);
    21d2:	add.w	ip, ip, #4294967295
    21d6:	orn	ip, ip, #7
    21da:	add.w	ip, ip, #1
    21de:	b.n	206a <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x4e>
    const Index n_cache = (l2-l1) / (nr * sizeof(RhsScalar) * k);
    const Index n_per_thread = numext::div_ceil(n, num_threads);
    if (n_cache <= n_per_thread) {
      // Don't exceed the capacity of the l2 cache.
      eigen_internal_assert(n_cache >= static_cast<Index>(nr));
      n = n_cache - (n_cache % nr);
    21e0:	subs	r7, #1
    21e2:	orn	r7, r7, #3
    21e6:	adds	r7, #1
    21e8:	b.n	21a8 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x18c>
      const Index m_per_thread = numext::div_ceil(m, num_threads);
      if(m_cache < m_per_thread && m_cache >= static_cast<Index>(mr)) {
        m = m_cache - (m_cache % mr);
        eigen_internal_assert(m > 0);
      } else {
        m = (numext::mini<Index>)(m, (m_per_thread + mr - 1) - ((m_per_thread + mr - 1) % mr));
    21ea:	subs	r2, #1
    21ec:	orn	r2, r2, #1
    21f0:	adds	r2, #1
    21f2:	b.n	21b8 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x19c>
    if(k>max_kc)
    {
      // We are really blocking on the third dimension:
      // -> reduce blocking size to make sure the last block is as large as possible
      //    while keeping the same number of sweeps over the result.
      k = (k%max_kc)==0 ? max_kc
    21f4:	sdiv	r7, lr, fp
    21f8:	mls	r9, fp, r7, lr
    21fc:	cmp.w	r9, #0
    2200:	beq.n	22e4 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2c8>
    2202:	add.w	ip, fp, #4294967295
    2206:	adds	r7, #1
    2208:	mov.w	r3, #1572864	; 0x180000
    220c:	str.w	fp, [sp]
    2210:	rsb	ip, r9, ip
    2214:	lsls	r7, r7, #3
    2216:	sdiv	r7, ip, r7
    221a:	sub.w	r7, fp, r7, lsl #3
    221e:	mov.w	r9, r7, lsl #3
    2222:	mov.w	sl, r7, lsl #2
    2226:	mov.w	fp, r7, lsl #4
    222a:	udiv	r9, r3, r9
    222e:	str	r7, [r0, #0]
    2230:	ldr.w	ip, [r2]
    2234:	ldr	r0, [r1, #0]
    2236:	b.n	215e <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x142>
      //    while keeping the same number of sweeps over the packed lhs.
      //    Here we allow one more sweep if this gives us a perfect match, thus the commented "-1"
      n = (n%nc)==0 ? nc
                    : (nc - Traits::nr * ((nc/*-1*/-(n%nc))/(Traits::nr*(n/nc+1))));
    }
    else if(old_k==k)
    2238:	cmp	lr, r7
    223a:	bne.n	21c2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1a6>
    {
      // So far, no blocking at all, i.e., kc==k, and nc==n.
      // In this case, let's perform a blocking over the rows such that the packed lhs data is kept in cache L1/L2
      // TODO: part of this blocking strategy is now implemented within the kernel itself, so the L1-based heuristic here should be obsolete.
      Index problem_size = k*n*sizeof(LhsScalar);
    223c:	mul.w	lr, ip, lr
    2240:	mov.w	lr, lr, lsl #2
      Index actual_lm = actual_l2;
      Index max_mc = m;
      if(problem_size<=1024)
    2244:	cmp.w	lr, #1024	; 0x400
    2248:	ble.n	2308 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2ec>
      {
        // problem is small enough to keep in L1
        // Let's choose m such that lhs's block fit in 1/3 of L1
        actual_lm = l1;
      }
      else if(l3!=0 && problem_size<=32768)
    224a:	cmp	r5, #0
    224c:	beq.n	230c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2f0>
    224e:	cmp.w	lr, #32768	; 0x8000
    2252:	bgt.n	230c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2f0>
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
	return __b;
      return __a;
    2254:	cmp.w	r0, #576	; 0x240
    2258:	mov	r3, r0
    225a:	mov	r4, r6
    225c:	it	ge
    225e:	movge.w	r3, #576	; 0x240
    2262:	add.w	sl, sl, sl, lsl #1
    2266:	udiv	r4, r4, sl
    226a:	cmp	r4, r3
    226c:	it	ge
    226e:	movge	r4, r3
        // Let's choose m such that lhs's block fit in 1/3 of L2
        actual_lm = l2;
        max_mc = (numext::mini<Index>)(576,max_mc);
      }
      Index mc = (numext::mini<Index>)(actual_lm/(3*k*sizeof(LhsScalar)), max_mc);
      if (mc > Traits::mr) mc -= mc % Traits::mr;
    2270:	cmp	r4, #2
    2272:	ble.n	2300 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2e4>
    2274:	bic.w	r4, r4, #1
      else if (mc==0) return;
      m = (m%mc)==0 ? mc
    2278:	sdiv	r3, r0, r4
    227c:	mls	r0, r4, r3, r0
    2280:	cbz	r0, 2290 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x274>
    2282:	adds	r3, #1
    2284:	subs	r0, r4, r0
    2286:	lsls	r3, r3, #1
    2288:	sdiv	r3, r0, r3
    228c:	sub.w	r4, r4, r3, lsl #1
    2290:	str	r4, [r1, #0]
    2292:	b.n	21c2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1a6>
      max_nc = remaining_l1 / (k*sizeof(RhsScalar));
    }
    else
    {
      // L2 blocking
      max_nc = (3*actual_l2)/(2*2*max_kc*sizeof(RhsScalar));
    2294:	ldr	r3, [sp, #0]
    2296:	mov.w	r8, r3, lsl #4
    229a:	mov.w	r3, #4718592	; 0x480000
    229e:	udiv	r3, r3, r8
    22a2:	b.n	2170 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x154>
    // We also include a register-level block of the result (mx x nr).
    // (In an ideal world only the lhs panel would stay in L1)
    // Moreover, kc has to be a multiple of 8 to be compatible with loop peeling, leading to a maximum blocking size of:
    const Index max_kc = numext::maxi<Index>(((l1-k_sub)/k_div) & (~(k_peeling-1)),1);
    const Index old_k = k;
    if(k>max_kc)
    22a4:	cmp.w	lr, #1
    22a8:	bgt.n	22d0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x2b4>
    22aa:	mov.w	r3, lr, lsl #3
    22ae:	mov.w	r9, #1572864	; 0x180000
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
    22b2:	mov	r0, r7
    22b4:	mov.w	sl, lr, lsl #2
    22b8:	str	r3, [sp, #4]
	return __b;
    22ba:	movs	r3, #1
    22bc:	mov.w	fp, lr, lsl #4
    22c0:	mov	r7, lr
    22c2:	str	r3, [sp, #0]
    22c4:	ldr	r3, [sp, #4]
    22c6:	udiv	r9, r9, r3
    22ca:	b.n	215e <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x142>
    22cc:	mov	r3, r9
    22ce:	b.n	219c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x180>
    22d0:	movs	r3, #1
    22d2:	mov.w	r9, #196608	; 0x30000
    22d6:	mov.w	fp, #16
    22da:	mov.w	sl, #4
    22de:	str	r3, [sp, #0]
    22e0:	mov	r7, r3
    22e2:	b.n	222e <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x212>
    22e4:	mov.w	r3, fp, lsl #3
    22e8:	mov.w	r9, #1572864	; 0x180000
    {
      // We are really blocking on the third dimension:
      // -> reduce blocking size to make sure the last block is as large as possible
      //    while keeping the same number of sweeps over the result.
      k = (k%max_kc)==0 ? max_kc
    22ec:	mov	r7, fp
    22ee:	str.w	fp, [sp]
    22f2:	mov.w	sl, fp, lsl #2
    22f6:	mov.w	fp, fp, lsl #4
    22fa:	udiv	r9, r9, r3
    22fe:	b.n	222e <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x212>
        actual_lm = l2;
        max_mc = (numext::mini<Index>)(576,max_mc);
      }
      Index mc = (numext::mini<Index>)(actual_lm/(3*k*sizeof(LhsScalar)), max_mc);
      if (mc > Traits::mr) mc -= mc % Traits::mr;
      else if (mc==0) return;
    2300:	cmp	r4, #0
    2302:	beq.w	21c2 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x1a6>
    2306:	b.n	2278 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x25c>
      // In this case, let's perform a blocking over the rows such that the packed lhs data is kept in cache L1/L2
      // TODO: part of this blocking strategy is now implemented within the kernel itself, so the L1-based heuristic here should be obsolete.
      Index problem_size = k*n*sizeof(LhsScalar);
      Index actual_lm = actual_l2;
      Index max_mc = m;
      if(problem_size<=1024)
    2308:	mov	r3, r0
    230a:	b.n	2262 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x246>
    230c:	mov	r3, r0
    230e:	mov.w	r4, #1572864	; 0x180000
    2312:	b.n	2262 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)+0x246>
    2314:	.word	0x2000095c
    2318:	.word	0x20000960
    231c:	.word	0x2aaaaaab
    2320:	.word	0x80000003
    2324:	.word	0x80000001
    2328:	.word	0x80000007

0000232c <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)>:
    *
    * \note This very low level interface using pointers, etc. is to:
    *   1 - reduce the number of instanciations to the strict minimum
    *   2 - avoid infinite recursion of the instanciations with Block<Block<Block<...> > >
    */
  static Index blocked_lu(Index rows, Index cols, Scalar* lu_data, Index luStride, PivIndex* row_transpositions, PivIndex& nb_transpositions, Index maxBlockSize=256)
    232c:	cmp	r0, r1
    232e:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    2332:	mov	r4, r0
    2334:	sub	sp, #180	; 0xb4
    2336:	it	ge
    2338:	movge	r4, r1
    233a:	mov	r5, r3
    233c:	str	r3, [sp, #72]	; 0x48
    233e:	mov	r3, r4
    2340:	str	r4, [sp, #68]	; 0x44
template<typename T> class variable_if_dynamic<T, Dynamic>
{
    T m_value;
    EIGEN_DEVICE_FUNC variable_if_dynamic() { eigen_assert(false); }
  public:
    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T value) : m_value(value) {}
    2342:	movs	r4, #0
    2344:	str	r1, [sp, #144]	; 0x90
    MatrixType lu(lu1,0,0,rows,cols);

    const Index size = (std::min)(rows,cols);

    // if the matrix is too small, no blocking:
    if(size<=16)
    2346:	cmp	r3, #16
  *
  * This class is the return type of PlainObjectBase::Map() but can also be used directly.
  *
  * \sa PlainObjectBase::Map(), \ref TopicStorageOrders
  */
template<typename PlainObjectType, int MapOptions, typename StrideType> class Map
    2348:	str	r1, [sp, #156]	; 0x9c
    234a:	str	r0, [sp, #140]	; 0x8c
    }

    /** \internal Constructor for dynamically sized matrices */
    EIGEN_DEVICE_FUNC
    inline MapBase(PointerType dataPtr, Index rows, Index cols)
            : m_data(dataPtr), m_rows(rows), m_cols(cols)
    234c:	str	r2, [sp, #136]	; 0x88
    234e:	str	r2, [sp, #148]	; 0x94
    2350:	str	r5, [sp, #152]	; 0x98

  protected:
    EIGEN_DEVICE_FUNC
    void init()
    {
      m_outerStride = internal::traits<BlockType>::HasSameStorageOrderAsXprType
    2352:	str	r5, [sp, #172]	; 0xac
    2354:	str	r4, [sp, #164]	; 0xa4
    2356:	str	r4, [sp, #168]	; 0xa8
    *
    * \note This very low level interface using pointers, etc. is to:
    *   1 - reduce the number of instanciations to the strict minimum
    *   2 - avoid infinite recursion of the instanciations with Block<Block<Block<...> > >
    */
  static Index blocked_lu(Index rows, Index cols, Scalar* lu_data, Index luStride, PivIndex* row_transpositions, PivIndex& nb_transpositions, Index maxBlockSize=256)
    2358:	ldr	r1, [sp, #224]	; 0xe0
    MatrixType lu(lu1,0,0,rows,cols);

    const Index size = (std::min)(rows,cols);

    // if the matrix is too small, no blocking:
    if(size<=16)
    235a:	ble.w	2662 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x336>
    // automatically adjust the number of subdivisions to the size
    // of the matrix so that there is enough sub blocks:
    Index blockSize;
    {
      blockSize = size/8;
      blockSize = (blockSize/16)*16;
    235e:	ldr	r5, [sp, #68]	; 0x44
      blockSize = (std::min)((std::max)(blockSize,Index(8)), maxBlockSize);
    }

    nb_transpositions = 0;
    2360:	mov	sl, r2
    2362:	ldr	r2, [sp, #72]	; 0x48
    Index first_zero_pivot = -1;
    for(Index k = 0; k < size; k+=blockSize)
    2364:	mov	r6, r4
    // automatically adjust the number of subdivisions to the size
    // of the matrix so that there is enough sub blocks:
    Index blockSize;
    {
      blockSize = size/8;
      blockSize = (blockSize/16)*16;
    2366:	asrs	r3, r5, #7
    2368:	subs	r0, r0, r5
      blockSize = (std::min)((std::max)(blockSize,Index(8)), maxBlockSize);
    }

    nb_transpositions = 0;
    236a:	str	r2, [sp, #44]	; 0x2c
    Index first_zero_pivot = -1;
    236c:	mov.w	r2, #4294967295
    // automatically adjust the number of subdivisions to the size
    // of the matrix so that there is enough sub blocks:
    Index blockSize;
    {
      blockSize = size/8;
      blockSize = (blockSize/16)*16;
    2370:	lsls	r3, r3, #4
    2372:	str	r0, [sp, #88]	; 0x58
      blockSize = (std::min)((std::max)(blockSize,Index(8)), maxBlockSize);
    }

    nb_transpositions = 0;
    Index first_zero_pivot = -1;
    2374:	str	r2, [sp, #64]	; 0x40
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
    2376:	cmp	r3, #8
    2378:	ldr	r0, [sp, #216]	; 0xd8
      blockSize = size/8;
      blockSize = (blockSize/16)*16;
      blockSize = (std::min)((std::max)(blockSize,Index(8)), maxBlockSize);
    }

    nb_transpositions = 0;
    237a:	ldr	r2, [sp, #220]	; 0xdc
    237c:	it	lt
    237e:	movlt	r3, #8
    2380:	str	r0, [sp, #36]	; 0x24
    2382:	str	r5, [sp, #48]	; 0x30
    2384:	cmp	r3, r1
    2386:	str	r4, [r2, #0]
    2388:	it	ge
    238a:	movge	r3, r1
    238c:	str	r3, [sp, #60]	; 0x3c
    238e:	lsls	r3, r3, #2
    2390:	str	r3, [sp, #84]	; 0x54
      */
    EIGEN_DEVICE_FUNC
    inline BlockImpl_dense(XprType& xpr,
          Index startRow, Index startCol,
          Index blockRows, Index blockCols)
      : Base(xpr.data()+xpr.innerStride()*(XprTypeIsRowMajor?startCol:startRow) + xpr.outerStride()*(XprTypeIsRowMajor?startRow:startCol), blockRows, blockCols),
    2392:	ldr	r7, [sp, #44]	; 0x2c
    2394:	ldr	r4, [sp, #48]	; 0x30
    2396:	ldr	r1, [sp, #60]	; 0x3c
    2398:	mov	r3, r7
    239a:	cmp	r4, r1
    239c:	mul.w	r3, r3, r6
    23a0:	mov	r2, r3
    23a2:	str	r3, [sp, #76]	; 0x4c
    23a4:	mov	r3, r4
    23a6:	it	ge
    23a8:	movge	r3, r1
    23aa:	ldr	r1, [sp, #88]	; 0x58
    23ac:	mov	r5, r3
    23ae:	adds	r3, r1, r4
      // partition the matrix:
      //                          A00 | A01 | A02
      // lu  = A_0 | A_1 | A_2 =  A10 | A11 | A12
      //                          A20 | A21 | A22
      BlockType A_0(lu,0,0,rows,k);
      BlockType A_2(lu,0,k+bs,rows,tsize);
    23b0:	add.w	r8, r5, r6

      PivIndex nb_transpositions_in_panel;
      // recursively call the blocked LU algorithm on [A11^T A21^T]^T
      // with a very small blocking size:
      Index ret = blocked_lu(trows+bs, bs, &lu.coeffRef(k,k), luStride,
                   row_transpositions+k, nb_transpositions_in_panel, 16);
    23b4:	mov	r1, r5
    23b6:	mov	r0, r3
    23b8:	str	r3, [sp, #80]	; 0x50
    23ba:	movs	r3, #16
    23bc:	mul.w	r7, r7, r8
    Index first_zero_pivot = -1;
    for(Index k = 0; k < size; k+=blockSize)
    {
      Index bs = (std::min)(size-k,blockSize); // actual size of the block
      Index trows = rows - k - bs; // trailing rows
      Index tsize = size - k - bs; // trailing size
    23c0:	subs	r4, r4, r5

      PivIndex nb_transpositions_in_panel;
      // recursively call the blocked LU algorithm on [A11^T A21^T]^T
      // with a very small blocking size:
      Index ret = blocked_lu(trows+bs, bs, &lu.coeffRef(k,k), luStride,
                   row_transpositions+k, nb_transpositions_in_panel, 16);
    23c2:	str	r3, [sp, #8]
    23c4:	mov	r3, r2
    23c6:	add	r2, sp, #100	; 0x64
    23c8:	str	r7, [sp, #56]	; 0x38
    23ca:	add	r3, r6
    nb_transpositions = 0;
    Index first_zero_pivot = -1;
    for(Index k = 0; k < size; k+=blockSize)
    {
      Index bs = (std::min)(size-k,blockSize); // actual size of the block
      Index trows = rows - k - bs; // trailing rows
    23cc:	subs	r7, r0, r5

      PivIndex nb_transpositions_in_panel;
      // recursively call the blocked LU algorithm on [A11^T A21^T]^T
      // with a very small blocking size:
      Index ret = blocked_lu(trows+bs, bs, &lu.coeffRef(k,k), luStride,
                   row_transpositions+k, nb_transpositions_in_panel, 16);
    23ce:	str	r2, [sp, #4]
    23d0:	ldr	r2, [sp, #36]	; 0x24
    23d2:	str	r3, [sp, #92]	; 0x5c
    23d4:	str	r2, [sp, #0]
    23d6:	add.w	r2, sl, r3, lsl #2
    23da:	ldr	r3, [sp, #72]	; 0x48
    nb_transpositions = 0;
    Index first_zero_pivot = -1;
    for(Index k = 0; k < size; k+=blockSize)
    {
      Index bs = (std::min)(size-k,blockSize); // actual size of the block
      Index trows = rows - k - bs; // trailing rows
    23dc:	str	r7, [sp, #40]	; 0x28

      PivIndex nb_transpositions_in_panel;
      // recursively call the blocked LU algorithm on [A11^T A21^T]^T
      // with a very small blocking size:
      Index ret = blocked_lu(trows+bs, bs, &lu.coeffRef(k,k), luStride,
                   row_transpositions+k, nb_transpositions_in_panel, 16);
    23de:	bl	232c <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)>
      if(ret>=0 && first_zero_pivot==-1)
    23e2:	cmp	r0, #0
    23e4:	blt.n	23f0 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0xc4>
    23e6:	ldr	r3, [sp, #64]	; 0x40
    23e8:	adds	r3, #1
    23ea:	bne.n	23f0 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0xc4>
        first_zero_pivot = k+ret;
    23ec:	adds	r3, r0, r6
    23ee:	str	r3, [sp, #64]	; 0x40

      nb_transpositions += nb_transpositions_in_panel;
    23f0:	ldr	r3, [sp, #220]	; 0xdc
      // update permutations and apply them to A_0
      for(Index i=k; i<k+bs; ++i)
    23f2:	cmp	r8, r6
      Index ret = blocked_lu(trows+bs, bs, &lu.coeffRef(k,k), luStride,
                   row_transpositions+k, nb_transpositions_in_panel, 16);
      if(ret>=0 && first_zero_pivot==-1)
        first_zero_pivot = k+ret;

      nb_transpositions += nb_transpositions_in_panel;
    23f4:	ldr	r2, [r3, #0]
    23f6:	ldr	r3, [sp, #100]	; 0x64
    23f8:	add	r3, r2
    23fa:	ldr	r2, [sp, #220]	; 0xdc
    23fc:	str	r3, [r2, #0]
      // update permutations and apply them to A_0
      for(Index i=k; i<k+bs; ++i)
    23fe:	ble.w	2650 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x324>
    2402:	mov.w	lr, r6, lsl #2
    2406:	ldr	r3, [sp, #44]	; 0x2c
    2408:	mov.w	r9, r8, lsl #2
    240c:	ldr	r7, [sp, #36]	; 0x24
    240e:	add.w	r0, sl, lr
    2412:	lsls	r1, r3, #2
    2414:	add.w	ip, sl, r9
      {
        Index piv = (row_transpositions[i] += internal::convert_index<PivIndex>(k));
    2418:	ldr	r3, [r7, #0]
    241a:	cmp	r6, #0
    241c:	add	r3, r6
    241e:	str.w	r3, [r7], #4
                                || ((BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) && ( XprTypeIsRowMajor)) ? xpr.innerStride() : xpr.outerStride()),
             BlockRows==1 ? 1 : xpr.rows(),
             BlockCols==1 ? 1 : xpr.cols()),
        m_xpr(xpr),
        m_startRow( (BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) ? i : 0),
        m_startCol( (BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) ? i : 0)
    2422:	mov.w	r3, r3, lsl #2
    2426:	ble.n	244c <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x120>
    2428:	add	r3, sl
    242a:	mov	r2, r0
    242c:	mov.w	fp, #0
    2430:	add.w	fp, fp, #1
#endif
    {
      // concept requirements
      __glibcxx_function_requires(_SGIAssignableConcept<_Tp>)

      _Tp __tmp = _GLIBCXX_MOVE(__a);
    2434:	vldr	s15, [r2]
      __a = _GLIBCXX_MOVE(__b);
    2438:	vldr	s14, [r3]
    243c:	cmp	r6, fp
    243e:	vstr	s14, [r2]
    2442:	add	r2, r1
      __b = _GLIBCXX_MOVE(__tmp);
    2444:	vstr	s15, [r3]
    2448:	add	r3, r1
    244a:	bne.n	2430 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x104>
    244c:	adds	r0, #4
      if(ret>=0 && first_zero_pivot==-1)
        first_zero_pivot = k+ret;

      nb_transpositions += nb_transpositions_in_panel;
      // update permutations and apply them to A_0
      for(Index i=k; i<k+bs; ++i)
    244e:	cmp	ip, r0
    2450:	bne.n	2418 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0xec>
      {
        Index piv = (row_transpositions[i] += internal::convert_index<PivIndex>(k));
        A_0.row(i).swap(A_0.row(piv));
      }

      if(trows)
    2452:	ldr	r3, [sp, #40]	; 0x28
    2454:	cbz	r3, 24a2 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x176>
    EIGEN_DEVICE_FUNC
    inline BlockImpl_dense(XprType& xpr,
          Index startRow, Index startCol,
          Index blockRows, Index blockCols)
      : Base(xpr.data()+xpr.innerStride()*(XprTypeIsRowMajor?startCol:startRow) + xpr.outerStride()*(XprTypeIsRowMajor?startRow:startCol), blockRows, blockCols),
        m_xpr(xpr), m_startRow(startRow), m_startCol(startCol)
    2456:	ldr	r3, [sp, #56]	; 0x38
    2458:	ldr	r7, [sp, #36]	; 0x24
    245a:	add.w	ip, sl, r3, lsl #2
    245e:	add	lr, ip
    2460:	add	r9, ip
      {
        // apply permutations to A_2
        for(Index i=k;i<k+bs; ++i)
          A_2.row(i).swap(A_2.row(row_transpositions[i]));
    2462:	ldr.w	r3, [r7], #4
    2466:	cmp	r4, #0
                                || ((BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) && ( XprTypeIsRowMajor)) ? xpr.innerStride() : xpr.outerStride()),
             BlockRows==1 ? 1 : xpr.rows(),
             BlockCols==1 ? 1 : xpr.cols()),
        m_xpr(xpr),
        m_startRow( (BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) ? i : 0),
        m_startCol( (BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) ? i : 0)
    2468:	mov.w	r3, r3, lsl #2
    246c:	ble.n	248e <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x162>
    246e:	add	r3, ip
    2470:	mov	r2, lr
    2472:	movs	r0, #0
    2474:	adds	r0, #1
#endif
    {
      // concept requirements
      __glibcxx_function_requires(_SGIAssignableConcept<_Tp>)

      _Tp __tmp = _GLIBCXX_MOVE(__a);
    2476:	ldr.w	fp, [r2]
      __a = _GLIBCXX_MOVE(__b);
    247a:	vldr	s15, [r3]
    247e:	cmp	r4, r0
    2480:	vstr	s15, [r2]
    2484:	add	r2, r1
      __b = _GLIBCXX_MOVE(__tmp);
    2486:	str.w	fp, [r3]
    248a:	add	r3, r1
    248c:	bne.n	2474 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x148>
    248e:	add.w	lr, lr, #4
      }

      if(trows)
      {
        // apply permutations to A_2
        for(Index i=k;i<k+bs; ++i)
    2492:	cmp	r9, lr
    2494:	bne.n	2462 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x136>
    EIGEN_DEVICE_FUNC
    inline BlockImpl_dense(XprType& xpr,
          Index startRow, Index startCol,
          Index blockRows, Index blockCols)
      : Base(xpr.data()+xpr.innerStride()*(XprTypeIsRowMajor?startCol:startRow) + xpr.outerStride()*(XprTypeIsRowMajor?startRow:startCol), blockRows, blockCols),
        m_xpr(xpr), m_startRow(startRow), m_startCol(startCol)
    2496:	ldr	r3, [sp, #56]	; 0x38
    2498:	adds	r3, r6, r3
    249a:	add.w	r3, sl, r3, lsl #2
    249e:	str	r3, [sp, #52]	; 0x34
{
  OtherDerived& other = _other.const_cast_derived();
  eigen_assert( derived().cols() == derived().rows() && ((Side==OnTheLeft && derived().cols() == other.rows()) || (Side==OnTheRight && derived().cols() == other.cols())) );
  eigen_assert((!(Mode & ZeroDiag)) && bool(Mode & (Upper|Lower)));
  // If solving for a 0x0 matrix, nothing to do, simply return.
  if (derived().cols() == 0)
    24a0:	cbnz	r5, 24c6 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x19a>
      blockSize = (std::min)((std::max)(blockSize,Index(8)), maxBlockSize);
    }

    nb_transpositions = 0;
    Index first_zero_pivot = -1;
    for(Index k = 0; k < size; k+=blockSize)
    24a2:	ldr	r2, [sp, #60]	; 0x3c
    24a4:	ldr	r1, [sp, #48]	; 0x30
    24a6:	add	r6, r2
    24a8:	subs	r3, r1, r2
    24aa:	ldr	r2, [sp, #84]	; 0x54
    24ac:	str	r3, [sp, #48]	; 0x30
    24ae:	ldr	r3, [sp, #36]	; 0x24
    24b0:	add	r3, r2
    24b2:	str	r3, [sp, #36]	; 0x24
    24b4:	ldr	r3, [sp, #68]	; 0x44
    24b6:	cmp	r6, r3
    24b8:	bge.w	265a <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x32e>
    24bc:	ldr	r3, [sp, #172]	; 0xac
    24be:	ldr.w	sl, [sp, #136]	; 0x88
    24c2:	str	r3, [sp, #44]	; 0x2c
    24c4:	b.n	2392 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x66>
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    24c6:	movs	r7, #0

template<typename LhsScalar, typename RhsScalar, int KcFactor, typename Index>
void computeProductBlockingSizes(Index& k, Index& m, Index& n, Index num_threads = 1)
{
  if (!useSpecificBlockingSizes(k, m, n)) {
    evaluateProductBlockingSizesHeuristic<LhsScalar, RhsScalar, KcFactor, Index>(k, m, n, num_threads);
    24c8:	movs	r3, #1
    24ca:	add	r2, sp, #104	; 0x68
    24cc:	add	r1, sp, #116	; 0x74
    24ce:	add	r0, sp, #124	; 0x7c
    24d0:	str	r7, [sp, #108]	; 0x6c
    24d2:	str	r7, [sp, #112]	; 0x70

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    24d4:	str	r5, [sp, #116]	; 0x74
      this->m_nc = Transpose ? rows : cols;
    24d6:	str	r4, [sp, #120]	; 0x78
      this->m_kc = depth;
    24d8:	str	r5, [sp, #124]	; 0x7c
      {
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, this->m_nc, num_threads);
      }
      else  // no l3 blocking
      {
        Index n = this->m_nc;
    24da:	str	r4, [sp, #104]	; 0x68
    24dc:	bl	201c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)>
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    24e0:	ldr	r1, [sp, #124]	; 0x7c
    24e2:	ldr	r7, [sp, #116]	; 0x74
      m_sizeB = this->m_kc * this->m_nc;
    24e4:	ldr	r0, [sp, #120]	; 0x78
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    24e6:	mul.w	r9, r1, r7
    typedef internal::gemm_blocking_space<(Rhs::Flags&RowMajorBit) ? RowMajor : ColMajor,Scalar,Scalar,
              Rhs::MaxRowsAtCompileTime, Rhs::MaxColsAtCompileTime, Lhs::MaxRowsAtCompileTime,4> BlockingType;

    BlockingType blocking(rhs.rows(), rhs.cols(), size, 1, false);

    triangular_solve_matrix<Scalar,Index,Side,Mode,LhsProductTraits::NeedToConjugate,(int(Lhs::Flags) & RowMajorBit) ? RowMajor : ColMajor,
    24ea:	ldr	r7, [sp, #52]	; 0x34
    24ec:	ldr	r3, [sp, #92]	; 0x5c
      m_sizeB = this->m_kc * this->m_nc;
    24ee:	mul.w	lr, r1, r0
    24f2:	ldr.w	ip, [sp, #44]	; 0x2c
    24f6:	mov	r1, r4
    24f8:	str	r7, [sp, #0]
    24fa:	add	r7, sp, #108	; 0x6c
    24fc:	add.w	r2, sl, r3, lsl #2
    2500:	str.w	ip, [sp, #4]
    2504:	mov	r3, ip
    2506:	mov	r0, r5
    2508:	str	r7, [sp, #8]
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    250a:	str.w	r9, [sp, #128]	; 0x80
      m_sizeB = this->m_kc * this->m_nc;
    250e:	str.w	lr, [sp, #132]	; 0x84
    2512:	bl	1a8c <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    2516:	ldr	r3, [sp, #108]	; 0x6c
    2518:	cbz	r3, 2522 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x1f6>
    251a:	ldr.w	r0, [r3, #-4]
    251e:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    2522:	ldr	r3, [sp, #112]	; 0x70
    2524:	cbz	r3, 252e <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x202>
    2526:	ldr.w	r0, [r3, #-4]
    252a:	bl	7248 <free>
    252e:	ldr	r3, [sp, #76]	; 0x4c
    2530:	add	r3, r8
    2532:	mov	r7, r3
    2534:	ldr	r3, [sp, #56]	; 0x38
    2536:	add	r3, r8
    2538:	add.w	r2, sl, r7, lsl #2
    253c:	mov	r8, r3
  }

  template<typename Dst>
  static void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
  {
    if((rhs.rows()+dst.rows()+dst.cols())<20 && rhs.rows()>0)
    253e:	ldr	r3, [sp, #80]	; 0x50
    2540:	mov	r9, r2
    2542:	add	r3, r4
    2544:	add.w	r2, sl, r8, lsl #2
    2548:	cmp	r3, #19
    254a:	str	r2, [sp, #56]	; 0x38
    254c:	bgt.n	25d4 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x2a8>
    254e:	cmp	r5, #0
    2550:	ble.n	25d4 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x2a8>
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    2552:	cmp	r4, #0
    2554:	ble.n	24a2 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x176>
    2556:	ldr	r3, [sp, #40]	; 0x28
    2558:	mov.w	fp, #0
    255c:	mov	r7, r9
    255e:	lsls	r2, r5, #2
    2560:	add.w	r9, r9, r3, lsl #2
    2564:	ldr	r3, [sp, #44]	; 0x2c
    2566:	mov	sl, fp
    2568:	str	r2, [sp, #44]	; 0x2c
    256a:	lsls	r1, r3, #2
    256c:	mov	r8, r3
    256e:	str	r6, [sp, #76]	; 0x4c
      for(Index inner = 0; inner < kernel.innerSize(); ++inner) {
    2570:	ldr	r3, [sp, #40]	; 0x28
    2572:	cmp	r3, #0
    2574:	ble.n	25c6 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x29a>
    2576:	mov.w	lr, fp, lsl #2
    257a:	ldr	r3, [sp, #52]	; 0x34
    257c:	mov	r6, r7
    257e:	add.w	ip, r3, lr
    2582:	ldr	r3, [sp, #56]	; 0x38
    2584:	add	lr, r3
    2586:	ldr	r3, [sp, #44]	; 0x2c
    2588:	add.w	r0, ip, r3
#else
  scalar_product_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a * b; }
    258c:	vldr	s14, [r6]
  static EIGEN_STRONG_INLINE Scalar run(const Derived &mat, const Func& func)
  {
    eigen_assert(mat.rows()>0 && mat.cols()>0 && "you are using an empty matrix");
    Scalar res;
    res = mat.coeffByOuterInner(0, 0);
    for(Index i = 1; i < mat.innerSize(); ++i)
    2590:	cmp	r5, #1
    2592:	vldr	s15, [ip]
    2596:	vmul.f32	s15, s14, s15
    259a:	beq.n	25b4 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x288>
    259c:	adds	r2, r1, r6
    259e:	add.w	r3, ip, #4
  }

  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  CoeffReturnType coeff(Index row, Index col) const
  {
    return m_data[col * colStride() + row * rowStride()];
    25a2:	vldmia	r3!, {s14}
#else
  scalar_sum_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a + b; }
    25a6:	vldr	s13, [r2]
    25aa:	add	r2, r1
    25ac:	cmp	r3, r0
    25ae:	vfma.f32	s15, s13, s14
    25b2:	bne.n	25a2 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x276>
    25b4:	vldr	s14, [lr]
    25b8:	adds	r6, #4
    25ba:	vsub.f32	s15, s14, s15
    25be:	cmp	r6, r9
    25c0:	vstmia	lr!, {s15}
    25c4:	bne.n	258c <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x260>
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    25c6:	add.w	sl, sl, #1
    25ca:	add	fp, r8
    25cc:	cmp	r4, sl
    25ce:	bne.n	2570 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x244>
    25d0:	ldr	r6, [sp, #76]	; 0x4c
    25d2:	b.n	24a2 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x176>

  template<typename Dest>
  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
  {
    eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
    if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
    25d4:	cmp	r4, #0
    25d6:	beq.w	24a2 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x176>
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    25da:	movs	r7, #0
    25dc:	add	r1, sp, #116	; 0x74
    25de:	add	r0, sp, #124	; 0x7c
    25e0:	movs	r3, #1
    25e2:	str	r7, [sp, #108]	; 0x6c
    25e4:	add	r2, sp, #120	; 0x78
    25e6:	str	r7, [sp, #112]	; 0x70

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    25e8:	ldr	r7, [sp, #40]	; 0x28
      this->m_nc = Transpose ? rows : cols;
    25ea:	str	r4, [sp, #120]	; 0x78

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    25ec:	str	r7, [sp, #116]	; 0x74
      this->m_nc = Transpose ? rows : cols;
      this->m_kc = depth;
    25ee:	str	r5, [sp, #124]	; 0x7c
    25f0:	bl	1b0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)>
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    25f4:	ldr.w	lr, [sp, #124]	; 0x7c
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    25f8:	mov	r1, r4
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    25fa:	ldr	r0, [sp, #116]	; 0x74
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    25fc:	mov	r2, r5
    25fe:	ldr	r4, [sp, #56]	; 0x38
    2600:	mov	r3, r9
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    2602:	mul.w	ip, lr, r0
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    2606:	mov	r0, r7
    2608:	movs	r7, #0
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
      m_sizeB = this->m_kc * this->m_nc;
    260a:	ldr	r5, [sp, #120]	; 0x78
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    260c:	str	r4, [sp, #12]
    260e:	vmov.f32	s0, #240	; 0xbf800000 -1.0
    2612:	str	r7, [sp, #24]
    2614:	add	r7, sp, #108	; 0x6c
    2616:	ldr	r4, [sp, #52]	; 0x34
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
      m_sizeB = this->m_kc * this->m_nc;
    2618:	mul.w	r5, lr, r5
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    261c:	str	r7, [sp, #20]
    261e:	ldr	r7, [sp, #44]	; 0x2c
    2620:	str	r4, [sp, #4]
    2622:	str	r7, [sp, #16]
    2624:	str	r7, [sp, #8]
    2626:	str	r7, [sp, #0]
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    2628:	str.w	ip, [sp, #128]	; 0x80
      m_sizeB = this->m_kc * this->m_nc;
    262c:	str	r5, [sp, #132]	; 0x84
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    262e:	bl	10b0 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    2632:	ldr	r3, [sp, #108]	; 0x6c
    2634:	cbz	r3, 263e <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x312>
    2636:	ldr.w	r0, [r3, #-4]
    263a:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    263e:	ldr	r3, [sp, #112]	; 0x70
    2640:	cmp	r3, #0
    2642:	beq.w	24a2 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x176>
    2646:	ldr.w	r0, [r3, #-4]
    264a:	bl	7248 <free>
    264e:	b.n	24a2 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x176>
      {
        Index piv = (row_transpositions[i] += internal::convert_index<PivIndex>(k));
        A_0.row(i).swap(A_0.row(piv));
      }

      if(trows)
    2650:	ldr	r3, [sp, #40]	; 0x28
    2652:	cmp	r3, #0
    2654:	bne.w	2496 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x16a>
    2658:	b.n	24a2 <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)+0x176>
    265a:	ldr	r0, [sp, #64]	; 0x40

        A22.noalias() -= A21 * A12;
      }
    }
    return first_zero_pivot;
  }
    265c:	add	sp, #180	; 0xb4
    265e:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    const Index size = (std::min)(rows,cols);

    // if the matrix is too small, no blocking:
    if(size<=16)
    {
      return unblocked_lu(lu, row_transpositions, nb_transpositions);
    2662:	ldr	r2, [sp, #220]	; 0xdc
    2664:	add	r0, sp, #136	; 0x88
    2666:	ldr	r1, [sp, #216]	; 0xd8
    2668:	bl	178c <Eigen::internal::partial_lu_impl<float, 0, int>::unblocked_lu(Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, -1, false>&, int*, int&)>

        A22.noalias() -= A21 * A12;
      }
    }
    return first_zero_pivot;
  }
    266c:	add	sp, #180	; 0xb4
    266e:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    2672:	nop

00002674 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()>:
}

} // end namespace internal

template<typename MatrixType>
void PartialPivLU<MatrixType>::compute()
    2674:	push	{r4, r5, r6, r7, lr}
    2676:	ldr	r6, [r0, #4]
    2678:	sub	sp, #28
    267a:	mov	r4, r0
  */
template<typename Derived>
EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
DenseBase<Derived>::sum() const
{
  if(SizeAtCompileTime==0 || (SizeAtCompileTime==Dynamic && size()==0))
    267c:	cmp	r6, #0
    267e:	bne.n	274a <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0xd6>
    return Scalar(0);
    2680:	vldr	s13, [pc, #444]	; 2840 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x1cc>
    2684:	ldr	r1, [r4, #8]
  static EIGEN_STRONG_INLINE Scalar run(const Derived &mat, const Func& func)
  {
    eigen_assert(mat.rows()>0 && mat.cols()>0 && "you are using an empty matrix");
    Scalar res;
    res = mat.coeffByOuterInner(0, 0);
    for(Index i = 1; i < mat.innerSize(); ++i)
    2686:	cmp	r1, #1
    2688:	ble.n	26aa <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x36>
    268a:	mov	r0, r6
    268c:	movs	r5, #1
  */
template<typename Derived>
EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
DenseBase<Derived>::sum() const
{
  if(SizeAtCompileTime==0 || (SizeAtCompileTime==Dynamic && size()==0))
    268e:	cmp	r6, #0
    2690:	bne.n	271a <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0xa6>
    return Scalar(0);
    2692:	vldr	s14, [pc, #428]	; 2840 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x1cc>
	return __b;
    2696:	vcmp.f32	s14, s13
  static EIGEN_STRONG_INLINE Scalar run(const Derived &mat, const Func& func)
  {
    eigen_assert(mat.rows()>0 && mat.cols()>0 && "you are using an empty matrix");
    Scalar res;
    res = mat.coeffByOuterInner(0, 0);
    for(Index i = 1; i < mat.innerSize(); ++i)
    269a:	adds	r5, #1
    269c:	vmrs	APSR_nzcv, fpscr
    26a0:	it	gt
    26a2:	vmovgt.f32	s13, s14
    26a6:	cmp	r5, r1
    26a8:	bne.n	268e <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x1a>
      m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, m_rows*_Cols);
      m_rows = rows;
    }
    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index size, Index rows, Index)
    {
      if(size != m_rows*_Cols)
    26aa:	ldr	r3, [r4, #24]
  check_template_parameters();

  // the row permutation is stored as int indices, so just to be sure:
  eigen_assert(m_lu.rows()<NumTraits<int>::highest());

  m_l1_norm = m_lu.cwiseAbs().colwise().sum().maxCoeff();
    26ac:	vstr	s13, [r4, #28]
    26b0:	cmp	r3, r6
    26b2:	beq.w	27dc <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x168>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Cols*m_rows);
    26b6:	ldr	r3, [r4, #20]
    26b8:	cbz	r3, 26c2 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x4e>
    26ba:	ldr.w	r0, [r3, #-4]
    26be:	bl	7248 <free>
        if (size)
    26c2:	cmp	r6, #0
    26c4:	bne.w	27e2 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x16e>
    26c8:	ldr	r1, [r4, #8]
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
    26ca:	mov	r0, r6
    26cc:	ldr	r3, [r4, #4]
    26ce:	str	r6, [r4, #20]
void partial_lu_inplace(MatrixType& lu, TranspositionType& row_transpositions, typename TranspositionType::StorageIndex& nb_transpositions)
{
  eigen_assert(lu.cols() == row_transpositions.size());
  eigen_assert((&row_transpositions.coeffRef(1)-&row_transpositions.coeffRef(0)) == 1);

  partial_lu_impl
    26d0:	add	r5, sp, #20
    26d2:	mov.w	r7, #256	; 0x100
    26d6:	ldr	r2, [r4, #0]
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    26d8:	str	r6, [r4, #24]
    26da:	stmia.w	sp, {r0, r5, r7}
    26de:	mov	r0, r3
    26e0:	bl	232c <Eigen::internal::partial_lu_impl<float, 0, int>::blocked_lu(int, int, float*, int, int*, int&, int)>

  m_rowsTranspositions.resize(size);

  typename TranspositionType::StorageIndex nb_transpositions;
  internal::partial_lu_inplace(m_lu, m_rowsTranspositions, nb_transpositions);
  m_det_p = (nb_transpositions%2) ? -1 : 1;
    26e4:	ldr	r3, [sp, #20]
    26e6:	ldr	r5, [r4, #24]
    26e8:	tst.w	r3, #1
      m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, m_rows*_Cols);
      m_rows = rows;
    }
    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index size, Index rows, Index)
    {
      if(size != m_rows*_Cols)
    26ec:	ldr	r3, [r4, #16]
    26ee:	ite	eq
    26f0:	moveq	r2, #1
    26f2:	movne.w	r2, #4294967295
    26f6:	cmp	r5, r3
    26f8:	strb.w	r2, [r4, #32]
    26fc:	beq.n	2794 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x120>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Cols*m_rows);
    26fe:	ldr	r3, [r4, #12]
    2700:	cbz	r3, 270a <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x96>
    2702:	ldr.w	r0, [r3, #-4]
    2706:	bl	7248 <free>
        if (size)
    270a:	cbnz	r5, 2770 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0xfc>
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
    270c:	str	r5, [r4, #12]
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    270e:	str	r5, [r4, #16]

  m_p = m_rowsTranspositions;

  m_isInitialized = true;
    2710:	movs	r3, #1
    2712:	strb.w	r3, [r4, #33]	; 0x21
}
    2716:	add	sp, #28
    2718:	pop	{r4, r5, r6, r7, pc}
    271a:	ldr	r2, [r4, #0]
    271c:	cmp	r6, #1
    271e:	add.w	r3, r2, r0, lsl #2
    2722:	vldr	s14, [r3]
    2726:	vabs.f32	s14, s14
    272a:	ble.n	27d8 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x164>
    272c:	adds	r3, r0, #1
    272e:	add	r0, r6
    2730:	add.w	r3, r2, r3, lsl #2
    2734:	add.w	r2, r2, r0, lsl #2
    2738:	vldmia	r3!, {s15}
    273c:	vabs.f32	s15, s15
    2740:	cmp	r3, r2
    2742:	vadd.f32	s14, s14, s15
    2746:	bne.n	2738 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0xc4>
    2748:	b.n	2696 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x22>
    274a:	ldr	r2, [r0, #0]
    274c:	cmp	r6, #1
    274e:	vldr	s13, [r2]
    2752:	vabs.f32	s13, s13
    2756:	ble.n	2684 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x10>
    2758:	adds	r3, r2, #4
    275a:	add.w	r2, r2, r6, lsl #2
    275e:	vldmia	r3!, {s15}
    2762:	vabs.f32	s15, s15
    2766:	cmp	r2, r3
    2768:	vadd.f32	s13, s13, s15
    276c:	bne.n	275e <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0xea>
    276e:	b.n	2684 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x10>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    2770:	cmp.w	r5, #1073741824	; 0x40000000
    2774:	bcs.n	2808 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x194>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    2776:	lsls	r6, r5, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    2778:	add.w	r0, r6, #16
    277c:	bl	7238 <malloc>
  if (original == 0) return 0;
    2780:	mov	r7, r0
    2782:	cmp	r0, #0
    2784:	beq.n	282a <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x1b6>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2786:	bic.w	r2, r0, #15
    278a:	add.w	r3, r2, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    278e:	str.w	r0, [r3, #-4]
    {
      if(size != m_rows*_Cols)
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Cols*m_rows);
        if (size)
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
    2792:	str	r3, [r4, #12]

    /** Sets *this to be the identity permutation matrix */
    void setIdentity()
    {
      StorageIndex n = StorageIndex(size());
      for(StorageIndex i = 0; i < n; ++i)
    2794:	cmp	r5, #0
        else
          m_data = 0;
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    2796:	str	r5, [r4, #16]
    2798:	ble.n	2710 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x9c>
    279a:	ldr	r2, [r4, #12]
    279c:	movs	r3, #0
    279e:	subs	r1, r2, #4
        indices().coeffRef(i) = i;
    27a0:	str.w	r3, [r1, #4]!

    /** Sets *this to be the identity permutation matrix */
    void setIdentity()
    {
      StorageIndex n = StorageIndex(size());
      for(StorageIndex i = 0; i < n; ++i)
    27a4:	adds	r3, #1
    27a6:	cmp	r5, r3
    27a8:	bne.n	27a0 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x12c>
    27aa:	ldr	r5, [r4, #16]
    /** Assignment from the Transpositions \a tr */
    template<typename OtherDerived>
    Derived& operator=(const TranspositionsBase<OtherDerived>& tr)
    {
      setIdentity(tr.size());
      for(Index k=size()-1; k>=0; --k)
    27ac:	cmp	r5, #0
    27ae:	ble.n	2710 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x9c>
    27b0:	lsls	r5, r5, #2
    27b2:	ldr	r0, [r4, #20]
    27b4:	adds	r3, r2, r5
    27b6:	add	r0, r5
      *
      * See DenseCoeffsBase<Derived,WriteAccessors>::coeffRef(Index) const for details. */
    EIGEN_DEVICE_FUNC
    EIGEN_STRONG_INLINE Scalar& coeffRef(Index index)
    {
      return m_storage.data()[index];
    27b8:	ldr.w	r1, [r0, #-4]!
#endif
    {
      // concept requirements
      __glibcxx_function_requires(_SGIAssignableConcept<_Tp>)

      _Tp __tmp = _GLIBCXX_MOVE(__a);
    27bc:	ldr.w	r5, [r3, #-4]!
      __a = _GLIBCXX_MOVE(__b);
    27c0:	ldr.w	r6, [r2, r1, lsl #2]
    27c4:	cmp	r2, r3
    27c6:	str	r6, [r3, #0]
      __b = _GLIBCXX_MOVE(__tmp);
    27c8:	str.w	r5, [r2, r1, lsl #2]
    27cc:	bne.n	27b8 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x144>
  internal::partial_lu_inplace(m_lu, m_rowsTranspositions, nb_transpositions);
  m_det_p = (nb_transpositions%2) ? -1 : 1;

  m_p = m_rowsTranspositions;

  m_isInitialized = true;
    27ce:	movs	r3, #1
    27d0:	strb.w	r3, [r4, #33]	; 0x21
}
    27d4:	add	sp, #28
    27d6:	pop	{r4, r5, r6, r7, pc}
    27d8:	add	r0, r6
    27da:	b.n	2696 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x22>
    27dc:	ldr	r0, [r4, #20]
      m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, m_rows*_Cols);
      m_rows = rows;
    }
    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index size, Index rows, Index)
    {
      if(size != m_rows*_Cols)
    27de:	mov	r3, r6
    27e0:	b.n	26d0 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x5c>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    27e2:	cmp.w	r6, #1073741824	; 0x40000000
    27e6:	bcs.n	2812 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x19e>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    27e8:	lsls	r5, r6, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    27ea:	add.w	r0, r5, #16
    27ee:	bl	7238 <malloc>
  if (original == 0) return 0;
    27f2:	mov	r7, r0
    27f4:	cbz	r0, 281c <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x1a8>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    27f6:	bic.w	r0, r0, #15
    27fa:	adds	r0, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    27fc:	str.w	r7, [r0, #-4]
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Cols*m_rows);
        if (size)
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
    2800:	str	r0, [r4, #20]
    2802:	ldr	r1, [r4, #8]
    2804:	ldr	r3, [r4, #4]
    2806:	b.n	26d0 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x5c>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    2808:	mov.w	r0, #4294967295
    280c:	bl	6d9c <operator new(unsigned int)>
    2810:	b.n	2776 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x102>
    2812:	mov.w	r0, #4294967295
    2816:	bl	6d9c <operator new(unsigned int)>
    281a:	b.n	27e8 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x174>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    281c:	cbz	r5, 2838 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x1c4>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    281e:	mov.w	r0, #4294967295
    2822:	bl	6d9c <operator new(unsigned int)>
    2826:	mov	r0, r7
    2828:	b.n	2800 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x18c>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    282a:	cbz	r6, 283c <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x1c8>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    282c:	mov.w	r0, #4294967295
    2830:	bl	6d9c <operator new(unsigned int)>
    2834:	mov	r3, r7
    2836:	b.n	2792 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x11e>
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
    2838:	mov	r0, r5
    283a:	b.n	2800 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x18c>
    283c:	mov	r3, r6
    283e:	b.n	2792 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()+0x11e>
    2840:	.word	0x00000000

00002844 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)>:
    const Scalar* _tri, Index triStride,
    Scalar* _other, Index otherStride,
    level3_blocking<Scalar,Scalar>& blocking);
};
template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
EIGEN_DONT_INLINE void triangular_solve_matrix<Scalar,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor>::run(
    2844:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    2848:	vpush	{d8}
    284c:	sub	sp, #236	; 0xec
    284e:	mov	sl, r2
    2850:	mov	r6, r0
    2852:	add	r7, sp, #32
    2854:	ldr.w	r5, [r7, #256]	; 0x100
    2858:	str.w	r3, [r7, #164]	; 0xa4
    285c:	ldr	r2, [r5, #8]
    285e:	ldr	r3, [r5, #16]
    2860:	cmp	r2, r0
    2862:	str	r1, [r7, #124]	; 0x7c
    2864:	str	r3, [r7, #80]	; 0x50
    2866:	it	ge
    2868:	movge	r2, r0

    Index kc = blocking.kc();                   // cache block size along the K direction
    Index mc = (std::min)(size,blocking.mc());  // cache block size along the M direction

    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*cols;
    286a:	mul.w	r4, r3, r1
    286e:	mov	r0, r2
    2870:	str	r2, [r7, #52]	; 0x34
    };

    Index kc = blocking.kc();                   // cache block size along the K direction
    Index mc = (std::min)(size,blocking.mc());  // cache block size along the M direction

    std::size_t sizeA = kc*mc;
    2872:	mul.w	r8, r0, r3
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    2876:	cmp.w	r8, #1073741824	; 0x40000000
    287a:	bcc.n	2884 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x40>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    287c:	mov.w	r0, #4294967295
    2880:	bl	6d9c <operator new(unsigned int)>
    2884:	ldr	r3, [r5, #0]
    2886:	str.w	r3, [r7, #140]	; 0x8c
    std::size_t sizeB = kc*cols;

    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
    288a:	cmp	r3, #0
    288c:	beq.w	2d36 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4f2>
    2890:	movs	r3, #0
    2892:	str	r3, [r7, #104]	; 0x68
    2894:	str	r3, [r7, #120]	; 0x78
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    2896:	cmp.w	r4, #1073741824	; 0x40000000
    289a:	bcc.n	28a4 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x60>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    289c:	mov.w	r0, #4294967295
    28a0:	bl	6d9c <operator new(unsigned int)>
    28a4:	ldr	r3, [r5, #4]
    28a6:	str.w	r3, [r7, #136]	; 0x88
    ei_declare_aligned_stack_constructed_variable(Scalar, blockB, sizeB, blocking.blockB());
    28aa:	cmp	r3, #0
    28ac:	beq.w	2d0e <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4ca>
    28b0:	movs	r3, #0
    28b2:	str	r3, [r7, #100]	; 0x64
    28b4:	str	r3, [r7, #116]	; 0x74


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    28b6:	ldr	r0, [pc, #544]	; (2ad8 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x294>)
    28b8:	ldr	r3, [r0, #0]
    28ba:	lsls	r3, r3, #31
    28bc:	bpl.w	2cf6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4b2>
    28c0:	ldr	r3, [pc, #536]	; (2adc <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x298>)
    28c2:	ldr	r3, [r3, #4]

    // the goal here is to subdivise the Rhs panels such that we keep some cache
    // coherence when accessing the rhs elements
    std::ptrdiff_t l1, l2, l3;
    manage_caching_sizes(GetAction, &l1, &l2, &l3);
    Index subcols = cols>0 ? l2/(4 * sizeof(Scalar) * std::max<Index>(otherStride,size)) : 0;
    28c4:	ldr	r2, [r7, #124]	; 0x7c
    28c6:	cmp	r2, #0
    28c8:	ble.w	2cee <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4aa>
    subcols = std::max<Index>((subcols/Traits::nr)*Traits::nr, Traits::nr);
    28cc:	ldr.w	r2, [r7, #252]	; 0xfc
    28d0:	cmp	r2, r6
    28d2:	it	lt
    28d4:	movlt	r2, r6
    28d6:	lsls	r2, r2, #4
    28d8:	udiv	r3, r3, r2
    28dc:	cmp	r3, #0
    28de:	it	lt
    28e0:	addlt	r3, #3
    28e2:	bic.w	r3, r3, #3
    max(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
    28e6:	cmp	r3, #4
    28e8:	it	lt
    28ea:	movlt	r3, #4
    28ec:	str.w	r3, [r7, #132]	; 0x84

    for(Index k2=IsLower ? 0 : size;
    28f0:	cmp	r6, #0
    28f2:	ble.w	2dd0 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x58c>
    28f6:	ldr.w	r1, [r7, #164]	; 0xa4
    28fa:	mvn.w	r3, #3221225472	; 0xc0000000
    28fe:	ldr	r4, [r7, #80]	; 0x50
    2900:	subs	r0, r6, #1
    2902:	mov	r2, r1
    2904:	add	r3, r6
    2906:	rsb	r9, r4, r6
    290a:	rsb	fp, r4, #0
    290e:	adds	r2, #1
    2910:	lsls	r3, r3, #2
    2912:	rsb	r0, r9, r0
    2916:	mov.w	ip, r4, lsl #2
    291a:	mla	r3, r2, r3, sl
    291e:	rsb	r5, r2, r2, lsl #28
    2922:	mov	r4, r1
    2924:	mvn.w	lr, r1
    2928:	str	r3, [r7, #64]	; 0x40
    292a:	lsls	r3, r5, #4
    292c:	rsb	r8, r1, r1, lsl #30
    2930:	ldr.w	r2, [r7, #132]	; 0x84
    2934:	str	r3, [r7, #0]
            Index i  = IsLower ? k2+k1+k : k2-k1-k-1;
            Index rs = actualPanelWidth - k - 1; // remaining size
            Index s  = TriStorageOrder==RowMajor ? (IsLower ? k2+k1 : i+1)
                                                 :  IsLower ? i+1 : i-rs;

            Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(tri(i,i));
    2936:	vmov.f32	s16, #112	; 0x3f800000  1.0
    293a:	mul.w	r3, r1, r0
    std::ptrdiff_t l1, l2, l3;
    manage_caching_sizes(GetAction, &l1, &l2, &l3);
    Index subcols = cols>0 ? l2/(4 * sizeof(Scalar) * std::max<Index>(otherStride,size)) : 0;
    subcols = std::max<Index>((subcols/Traits::nr)*Traits::nr, Traits::nr);

    for(Index k2=IsLower ? 0 : size;
    293e:	str.w	r6, [r7, #144]	; 0x90
    2942:	str	r3, [r7, #12]
    2944:	mul.w	r3, r1, r9
    2948:	mov	r1, fp
    294a:	str.w	r3, [r7, #128]	; 0x80
    294e:	mov	r3, r4
    2950:	mul.w	r3, r3, r1
    2954:	str	r3, [r7, #32]
    2956:	mov.w	r3, lr, lsl #2
    295a:	str.w	r3, [r7, #156]	; 0x9c
    295e:	mul.w	r3, ip, lr
    2962:	str	r3, [r7, #16]
    2964:	mov.w	r3, r8, lsl #2
    2968:	str	r3, [r7, #4]
    296a:	ldr.w	r3, [r7, #252]	; 0xfc
    296e:	mul.w	r3, r3, r2
    2972:	str	r3, [r7, #44]	; 0x2c
    2974:	ldr.w	r3, [r7, #252]	; 0xfc
    2978:	lsls	r6, r3, #2
    297a:	ldr	r3, [r7, #52]	; 0x34
    297c:	lsls	r3, r3, #2
    297e:	str	r3, [r7, #24]
    2980:	ldr	r3, [r7, #80]	; 0x50
    2982:	ldr.w	r2, [r7, #144]	; 0x90
    2986:	cmp	r3, r2
    2988:	it	ge
    298a:	movge	r3, r2
    298c:	str.w	r3, [r7, #148]	; 0x94

      // The tricky part: compute R1 = A11^-1 B while updating B from R1
      // The idea is to split A11 into multiple small vertical panels.
      // Each panel can be split into a small triangular part T1k which is processed without optimization,
      // and the remaining small part T2k which is processed using gebp with appropriate block strides
      for(Index j2=0; j2<cols; j2+=subcols)
    2990:	ldr	r3, [r7, #124]	; 0x7c
    2992:	cmp	r3, #0
    2994:	ble.w	2c1c <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x3d8>
    2998:	ldr.w	r1, [r7, #148]	; 0x94
    299c:	mov	fp, sl
    299e:	ldr.w	r0, [r7, #144]	; 0x90
    29a2:	subs	r3, r1, #1
    29a4:	subs	r2, r1, #4
    29a6:	subs	r0, r0, r1
    29a8:	ldr	r5, [r7, #124]	; 0x7c
    29aa:	bic.w	r3, r3, #3
    29ae:	mov	r4, r0
    29b0:	str	r0, [r7, #40]	; 0x28
    29b2:	subs	r3, r2, r3
    29b4:	movs	r0, #0
    29b6:	ldr	r2, [r7, #12]
    29b8:	str	r3, [r7, #36]	; 0x24
    29ba:	ldr.w	r3, [r7, #132]	; 0x84
    29be:	str	r0, [r7, #96]	; 0x60
    29c0:	str	r0, [r7, #84]	; 0x54
    29c2:	str.w	r0, [r7, #168]	; 0xa8
    29c6:	mov	r0, r3
    29c8:	mov	r3, r1
    29ca:	str	r5, [r7, #76]	; 0x4c
    29cc:	str	r4, [r7, #108]	; 0x6c
    29ce:	mul.w	r3, r0, r3
    29d2:	str	r3, [r7, #20]
    29d4:	ldr.w	r3, [r7, #128]	; 0x80
    29d8:	add	r3, r2
    29da:	str	r3, [r7, #8]
    29dc:	ldr	r3, [r7, #76]	; 0x4c
    29de:	ldr.w	r2, [r7, #132]	; 0x84
    29e2:	cmp	r3, r2
    29e4:	it	ge
    29e6:	movge	r3, r2
    29e8:	str	r3, [r7, #72]	; 0x48
      {
        Index actual_cols = (std::min)(cols-j2,subcols);
        // for each small vertical panels [T1k^T, T2k^T]^T of lhs
        for (Index k1=0; k1<actual_kc; k1+=SmallPanelWidth)
    29ea:	ldr.w	r3, [r7, #148]	; 0x94
    29ee:	cmp	r3, #0
    29f0:	ble.w	2be4 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x3a0>
    29f4:	ldr	r2, [r7, #96]	; 0x60
    29f6:	ldr.w	r3, [r7, #136]	; 0x88
          // GEBP
          if (lengthTarget>0)
          {
            Index startTarget  = IsLower ? k2+k1+actualPanelWidth : k2-actual_kc;

            pack_lhs(blockA, tri.getSubMapper(startTarget,startBlock), actualPanelWidth, lengthTarget);
    29fa:	str	r6, [r7, #60]	; 0x3c
    29fc:	add.w	r3, r3, r2, lsl #2
    2a00:	ldr	r2, [r7, #72]	; 0x48
    2a02:	str	r3, [r7, #48]	; 0x30
    2a04:	ldr.w	r3, [r7, #168]	; 0xa8
    2a08:	add.w	r9, r3, r2
  }


  EIGEN_DEVICE_FUNC
  EIGEN_ALWAYS_INLINE Scalar& operator()(Index i, Index j) const {
    return m_data[StorageOrder==RowMajor ? j + i*m_stride : i + j*m_stride];
    2a0c:	ldr.w	r3, [r7, #248]	; 0xf8
    2a10:	ldr	r2, [r7, #108]	; 0x6c
    2a12:	add.w	r3, r3, r2, lsl #2
    2a16:	str	r3, [r7, #28]
    2a18:	ldr	r3, [r7, #64]	; 0x40
    2a1a:	str	r3, [r7, #88]	; 0x58
    2a1c:	ldr	r3, [r7, #8]
    2a1e:	str	r3, [r7, #68]	; 0x44
    2a20:	ldr.w	r3, [r7, #144]	; 0x90
    2a24:	str	r3, [r7, #92]	; 0x5c
    2a26:	ldr.w	r3, [r7, #148]	; 0x94
    2a2a:	str	r3, [r7, #112]	; 0x70
    2a2c:	ldr	r1, [r7, #112]	; 0x70
      {
        Index actual_cols = (std::min)(cols-j2,subcols);
        // for each small vertical panels [T1k^T, T2k^T]^T of lhs
        for (Index k1=0; k1<actual_kc; k1+=SmallPanelWidth)
        {
          Index actualPanelWidth = std::min<Index>(actual_kc-k1, SmallPanelWidth);
    2a2e:	mov.w	r8, #0
    2a32:	ldr	r0, [r7, #108]	; 0x6c
    2a34:	cmp	r1, #4
    2a36:	mov	r3, r1
    2a38:	ldr.w	sl, [r7, #88]	; 0x58
    2a3c:	it	ge
    2a3e:	movge	r3, #4
    2a40:	ldr	r6, [r7, #60]	; 0x3c
    2a42:	mov	r2, r3
    2a44:	str.w	r3, [r7, #160]	; 0xa0
    2a48:	adds	r3, r0, r1
    2a4a:	ldr	r1, [r7, #92]	; 0x5c
    2a4c:	str.w	r3, [r7, #152]	; 0x98
    2a50:	mov	r3, r2
    2a52:	subs	r2, r1, r2
    2a54:	mov	r0, r2
    2a56:	str	r2, [r7, #56]	; 0x38
    2a58:	mov	r2, r3
    2a5a:	rsb	lr, r1, r0
    2a5e:	mov	r3, r0
    2a60:	subs	r5, r2, #1
    2a62:	ldr	r2, [r7, #68]	; 0x44
    2a64:	mov.w	lr, lr, lsl #2
    2a68:	add	r3, r2
    2a6a:	str.w	r3, [r7, #172]	; 0xac
            Index rs = actualPanelWidth - k - 1; // remaining size
            Index s  = TriStorageOrder==RowMajor ? (IsLower ? k2+k1 : i+1)
                                                 :  IsLower ? i+1 : i-rs;

            Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(tri(i,i));
            for (Index j=j2; j<j2+actual_cols; ++j)
    2a6e:	ldr.w	r3, [r7, #168]	; 0xa8
            Index i  = IsLower ? k2+k1+k : k2-k1-k-1;
            Index rs = actualPanelWidth - k - 1; // remaining size
            Index s  = TriStorageOrder==RowMajor ? (IsLower ? k2+k1 : i+1)
                                                 :  IsLower ? i+1 : i-rs;

            Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(tri(i,i));
    2a72:	vldr	s15, [sl]
            for (Index j=j2; j<j2+actual_cols; ++j)
    2a76:	cmp	r3, r9
            Index i  = IsLower ? k2+k1+k : k2-k1-k-1;
            Index rs = actualPanelWidth - k - 1; // remaining size
            Index s  = TriStorageOrder==RowMajor ? (IsLower ? k2+k1 : i+1)
                                                 :  IsLower ? i+1 : i-rs;

            Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(tri(i,i));
    2a78:	vdiv.f32	s12, s16, s15
            for (Index j=j2; j<j2+actual_cols; ++j)
    2a7c:	bge.n	2ae0 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x29c>
    2a7e:	ldr.w	r3, [r7, #152]	; 0x98
    2a82:	ldr.w	r4, [r7, #168]	; 0xa8
    2a86:	rsb	r0, r8, r3
    2a8a:	ldr.w	r3, [r7, #172]	; 0xac
    2a8e:	mov.w	ip, r3, lsl #2
    2a92:	ldr.w	r3, [r7, #248]	; 0xf8
    2a96:	add.w	r0, r3, r0, lsl #2

                other(i,j) = (other(i,j) - b)*a;
              }
              else
              {
                Scalar b = (other(i,j) *= a);
    2a9a:	vldr	s13, [r0, #-4]
                Scalar* r = &other(s,j);
                const Scalar* l = &tri(s,i);
                for (Index i3=0;i3<rs;++i3)
    2a9e:	cmp	r5, #0

                other(i,j) = (other(i,j) - b)*a;
              }
              else
              {
                Scalar b = (other(i,j) *= a);
    2aa0:	vmul.f32	s13, s12, s13
    2aa4:	vstr	s13, [r0, #-4]
                Scalar* r = &other(s,j);
                const Scalar* l = &tri(s,i);
                for (Index i3=0;i3<rs;++i3)
    2aa8:	ble.n	2acc <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x288>
    2aaa:	vneg.f32	s13, s13
    2aae:	add.w	r2, fp, ip
    2ab2:	add.w	r3, lr, r0
    2ab6:	subs	r1, r0, #4
                  r[i3] -= b * conj(l[i3]);
    2ab8:	vldmia	r2!, {s14}
    2abc:	vldr	s15, [r3]
    2ac0:	vfma.f32	s15, s13, s14
    2ac4:	vstmia	r3!, {s15}
              else
              {
                Scalar b = (other(i,j) *= a);
                Scalar* r = &other(s,j);
                const Scalar* l = &tri(s,i);
                for (Index i3=0;i3<rs;++i3)
    2ac8:	cmp	r1, r3
    2aca:	bne.n	2ab8 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x274>
            Index rs = actualPanelWidth - k - 1; // remaining size
            Index s  = TriStorageOrder==RowMajor ? (IsLower ? k2+k1 : i+1)
                                                 :  IsLower ? i+1 : i-rs;

            Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(tri(i,i));
            for (Index j=j2; j<j2+actual_cols; ++j)
    2acc:	adds	r4, #1
    2ace:	add	r0, r6
    2ad0:	cmp	r4, r9
    2ad2:	bne.n	2a9a <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x256>
    2ad4:	b.n	2ae0 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x29c>
    2ad6:	nop
    2ad8:	.word	0x2000095c
    2adc:	.word	0x20000960
    2ae0:	ldr.w	r3, [r7, #156]	; 0x9c
    2ae4:	add.w	r8, r8, #1
    2ae8:	ldr.w	r2, [r7, #164]	; 0xa4
    2aec:	subs	r5, #1
    2aee:	add	sl, r3
    2af0:	ldr.w	r3, [r7, #172]	; 0xac
    2af4:	add.w	lr, lr, #4
    2af8:	subs	r3, r3, r2
    2afa:	str.w	r3, [r7, #172]	; 0xac
        // for each small vertical panels [T1k^T, T2k^T]^T of lhs
        for (Index k1=0; k1<actual_kc; k1+=SmallPanelWidth)
        {
          Index actualPanelWidth = std::min<Index>(actual_kc-k1, SmallPanelWidth);
          // tr solve
          for (Index k=0; k<actualPanelWidth; ++k)
    2afe:	ldr.w	r3, [r7, #160]	; 0xa0
    2b02:	cmp	r8, r3
    2b04:	blt.n	2a6e <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x22a>
  typedef typename packet_traits<Scalar>::half HalfPacket;

  typedef BlasLinearMapper<Scalar, Index, AlignmentType> LinearMapper;
  typedef BlasVectorMapper<Scalar, Index> VectorMapper;

  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE blas_data_mapper(Scalar* data, Index stride) : m_data(data), m_stride(stride) {}
    2b06:	ldr	r3, [r7, #56]	; 0x38
    2b08:	ldr	r2, [r7, #84]	; 0x54
    2b0a:	ldr.w	r0, [r7, #248]	; 0xf8
    2b0e:	adds	r5, r3, r2
                  r[i3] -= b * conj(l[i3]);
              }
            }
          }

          Index lengthTarget = actual_kc-k1-actualPanelWidth;
    2b10:	ldr	r1, [r7, #112]	; 0x70
    2b12:	ldr.w	r2, [r7, #160]	; 0xa0
    2b16:	str	r6, [r7, #60]	; 0x3c
    2b18:	add.w	r5, r0, r5, lsl #2
          Index startBlock   = IsLower ? k2+k1 : k2-k1-actualPanelWidth;
          Index blockBOffset = IsLower ? k1 : lengthTarget;

          // update the respective rows of B from other
          pack_rhs(blockB+actual_kc*j2, other.getSubMapper(startBlock,j2), actualPanelWidth, actual_cols, actual_kc, blockBOffset);
    2b1c:	add.w	r6, r7, #188	; 0xbc
    2b20:	ldr	r0, [r7, #72]	; 0x48
                  r[i3] -= b * conj(l[i3]);
              }
            }
          }

          Index lengthTarget = actual_kc-k1-actualPanelWidth;
    2b22:	subs	r4, r1, r2
          Index startBlock   = IsLower ? k2+k1 : k2-k1-actualPanelWidth;
          Index blockBOffset = IsLower ? k1 : lengthTarget;

          // update the respective rows of B from other
          pack_rhs(blockB+actual_kc*j2, other.getSubMapper(startBlock,j2), actualPanelWidth, actual_cols, actual_kc, blockBOffset);
    2b24:	ldr.w	r1, [r7, #148]	; 0x94
    2b28:	str	r0, [sp, #0]
    2b2a:	mov	r0, r6
    2b2c:	ldr.w	r6, [r7, #252]	; 0xfc
    2b30:	mov	r3, r2
    2b32:	str	r1, [sp, #4]
    2b34:	mov	r8, r2
    2b36:	str	r4, [sp, #8]
    2b38:	add.w	r2, r7, #192	; 0xc0
    2b3c:	ldr	r1, [r7, #48]	; 0x30
    2b3e:	str.w	r6, [r7, #196]	; 0xc4
    2b42:	str.w	r5, [r7, #192]	; 0xc0
    2b46:	bl	1974 <Eigen::internal::gemm_pack_rhs<float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 4, 0, false, true>::operator()(float*, Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, int, int, int, int)>

          // GEBP
          if (lengthTarget>0)
    2b4a:	cmp	r4, #0
    2b4c:	ble.n	2bbe <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x37a>
    2b4e:	ldr.w	r6, [r7, #164]	; 0xa4
          {
            Index startTarget  = IsLower ? k2+k1+actualPanelWidth : k2-actual_kc;

            pack_lhs(blockA, tri.getSubMapper(startTarget,startBlock), actualPanelWidth, lengthTarget);
    2b52:	add.w	ip, r7, #184	; 0xb8
    2b56:	ldr	r3, [r7, #56]	; 0x38
    2b58:	add.w	r2, r7, #192	; 0xc0
    2b5c:	ldr	r5, [r7, #40]	; 0x28
    2b5e:	mov	r0, ip
    2b60:	ldr.w	sl, [r7, #140]	; 0x8c
    2b64:	mla	lr, r3, r6, r5
    2b68:	movs	r5, #0
    2b6a:	str	r4, [sp, #0]
    2b6c:	mov	r3, r8
    2b6e:	add.w	lr, fp, lr, lsl #2
    2b72:	str	r5, [sp, #8]
    2b74:	str	r5, [sp, #4]
    2b76:	mov	r1, sl
    2b78:	str.w	lr, [r7, #192]	; 0xc0
    2b7c:	str.w	r6, [r7, #196]	; 0xc4
    2b80:	bl	550 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)>

            gebp_kernel(other.getSubMapper(startTarget,j2), blockA, blockB+actual_kc*j2, lengthTarget, actualPanelWidth, actual_cols, Scalar(-1),
    2b84:	str	r5, [sp, #20]
    2b86:	mov	r5, r8
    2b88:	str	r4, [sp, #24]
    2b8a:	vmov.f32	s0, #240	; 0xbf800000 -1.0
    2b8e:	ldr.w	r1, [r7, #148]	; 0x94
    2b92:	mov	r2, sl
    2b94:	ldr	r0, [r7, #72]	; 0x48
    2b96:	str	r1, [sp, #16]
    2b98:	add.w	r1, r7, #192	; 0xc0
    2b9c:	str	r0, [sp, #8]
    2b9e:	add.w	r0, r7, #180	; 0xb4
    2ba2:	ldr	r3, [r7, #48]	; 0x30
    2ba4:	str.w	r8, [sp, #12]
    2ba8:	stmia.w	sp, {r4, r5}
    2bac:	ldr	r4, [r7, #28]
    2bae:	str.w	r4, [r7, #192]	; 0xc0
    2bb2:	ldr.w	r4, [r7, #252]	; 0xfc
    2bb6:	str.w	r4, [r7, #196]	; 0xc4
    2bba:	bl	6e4 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)>
    2bbe:	ldr	r2, [r7, #92]	; 0x5c
    2bc0:	ldr	r1, [r7, #4]
    2bc2:	subs	r2, #4
    2bc4:	ldr	r3, [r7, #112]	; 0x70
    2bc6:	str	r2, [r7, #92]	; 0x5c
    2bc8:	subs	r3, #4
    2bca:	ldr	r2, [r7, #68]	; 0x44
    2bcc:	str	r3, [r7, #112]	; 0x70
    2bce:	add	r2, r1
    2bd0:	ldr	r1, [r7, #0]
    2bd2:	str	r2, [r7, #68]	; 0x44
    2bd4:	ldr	r2, [r7, #88]	; 0x58
    2bd6:	add	r2, r1
    2bd8:	str	r2, [r7, #88]	; 0x58
      // and the remaining small part T2k which is processed using gebp with appropriate block strides
      for(Index j2=0; j2<cols; j2+=subcols)
      {
        Index actual_cols = (std::min)(cols-j2,subcols);
        // for each small vertical panels [T1k^T, T2k^T]^T of lhs
        for (Index k1=0; k1<actual_kc; k1+=SmallPanelWidth)
    2bda:	ldr	r2, [r7, #36]	; 0x24
    2bdc:	cmp	r2, r3
    2bde:	bne.w	2a2c <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x1e8>
    2be2:	ldr	r6, [r7, #60]	; 0x3c

      // The tricky part: compute R1 = A11^-1 B while updating B from R1
      // The idea is to split A11 into multiple small vertical panels.
      // Each panel can be split into a small triangular part T1k which is processed without optimization,
      // and the remaining small part T2k which is processed using gebp with appropriate block strides
      for(Index j2=0; j2<cols; j2+=subcols)
    2be4:	ldr.w	r1, [r7, #132]	; 0x84
    2be8:	ldr	r0, [r7, #76]	; 0x4c
    2bea:	ldr.w	r3, [r7, #168]	; 0xa8
    2bee:	subs	r2, r0, r1
    2bf0:	add	r3, r1
    2bf2:	ldr	r1, [r7, #44]	; 0x2c
    2bf4:	str	r2, [r7, #76]	; 0x4c
    2bf6:	ldr	r2, [r7, #84]	; 0x54
    2bf8:	str.w	r3, [r7, #168]	; 0xa8
    2bfc:	mov	r0, r2
    2bfe:	ldr	r2, [r7, #108]	; 0x6c
    2c00:	add	r0, r1
    2c02:	str	r0, [r7, #84]	; 0x54
    2c04:	mov	r0, r2
    2c06:	ldr	r2, [r7, #96]	; 0x60
    2c08:	add	r0, r1
    2c0a:	ldr	r1, [r7, #20]
    2c0c:	add	r2, r1
    2c0e:	str	r0, [r7, #108]	; 0x6c
    2c10:	str	r2, [r7, #96]	; 0x60
    2c12:	ldr	r2, [r7, #124]	; 0x7c
    2c14:	cmp	r2, r3
    2c16:	bgt.w	29dc <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x198>
    2c1a:	mov	sl, fp
      }
      
      // R2 -= A21 * B => GEPP
      {
        Index start = IsLower ? k2+kc : 0;
        Index end   = IsLower ? size : k2-kc;
    2c1c:	ldr.w	r3, [r7, #144]	; 0x90
    2c20:	ldr	r2, [r7, #80]	; 0x50
    2c22:	subs	r3, r3, r2
        for(Index i2=start; i2<end; i2+=mc)
    2c24:	cmp	r3, #0
      }
      
      // R2 -= A21 * B => GEPP
      {
        Index start = IsLower ? k2+kc : 0;
        Index end   = IsLower ? size : k2-kc;
    2c26:	str.w	r3, [r7, #144]	; 0x90
        for(Index i2=start; i2<end; i2+=mc)
    2c2a:	ble.w	2dd0 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x58c>
    2c2e:	ldr.w	r4, [r7, #144]	; 0x90
        {
          const Index actual_mc = (std::min)(mc,end-i2);
          if (actual_mc>0)
          {
            pack_lhs(blockA, tri.getSubMapper(i2, IsLower ? k2 : k2-kc), actual_kc, actual_mc);
    2c32:	mov.w	r8, #0
    2c36:	str.w	r6, [r7, #168]	; 0xa8
    2c3a:	ldr.w	r9, [r7, #248]	; 0xf8
      
      // R2 -= A21 * B => GEPP
      {
        Index start = IsLower ? k2+kc : 0;
        Index end   = IsLower ? size : k2-kc;
        for(Index i2=start; i2<end; i2+=mc)
    2c3e:	ldr.w	fp, [r7, #128]	; 0x80
        {
          const Index actual_mc = (std::min)(mc,end-i2);
          if (actual_mc>0)
          {
            pack_lhs(blockA, tri.getSubMapper(i2, IsLower ? k2 : k2-kc), actual_kc, actual_mc);
    2c42:	str.w	r4, [r7, #172]	; 0xac
    2c46:	ldr	r6, [r7, #52]	; 0x34
    2c48:	b.n	2c72 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x42e>
        Index start = IsLower ? k2+kc : 0;
        Index end   = IsLower ? size : k2-kc;
        for(Index i2=start; i2<end; i2+=mc)
        {
          const Index actual_mc = (std::min)(mc,end-i2);
          if (actual_mc>0)
    2c4a:	cmp	r6, #0
    2c4c:	bgt.w	2e12 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x5ce>
    2c50:	ldr.w	r3, [r7, #172]	; 0xac
    2c54:	add	fp, r6
      
      // R2 -= A21 * B => GEPP
      {
        Index start = IsLower ? k2+kc : 0;
        Index end   = IsLower ? size : k2-kc;
        for(Index i2=start; i2<end; i2+=mc)
    2c56:	ldr.w	r2, [r7, #144]	; 0x90
    2c5a:	subs	r3, r3, r6
    2c5c:	str.w	r3, [r7, #172]	; 0xac
    2c60:	ldr	r3, [r7, #24]
    2c62:	add	r9, r3
    2c64:	ldr.w	r3, [r7, #128]	; 0x80
    2c68:	rsb	r3, r3, fp
    2c6c:	cmp	r2, r3
    2c6e:	ble.w	2df8 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x5b4>
    min(const _Tp& __a, const _Tp& __b)
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return __b < __a ? __b : __a;
      if (__b < __a)
    2c72:	ldr.w	r5, [r7, #172]	; 0xac
    2c76:	cmp	r5, r6
    2c78:	bge.n	2c4a <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x406>
    2c7a:	add.w	lr, sl, fp, lsl #2
    2c7e:	ldr.w	r4, [r7, #164]	; 0xa4
        {
          const Index actual_mc = (std::min)(mc,end-i2);
          if (actual_mc>0)
          {
            pack_lhs(blockA, tri.getSubMapper(i2, IsLower ? k2 : k2-kc), actual_kc, actual_mc);
    2c82:	ldr.w	r3, [r7, #148]	; 0x94
    2c86:	add.w	r2, r7, #192	; 0xc0
    2c8a:	ldr.w	r1, [r7, #140]	; 0x8c
    2c8e:	add.w	r0, r7, #184	; 0xb8
    2c92:	str.w	r8, [sp, #8]
    2c96:	str.w	r8, [sp, #4]
    2c9a:	str	r5, [sp, #0]
    2c9c:	str.w	r4, [r7, #196]	; 0xc4
    2ca0:	str.w	lr, [r7, #192]	; 0xc0
    2ca4:	bl	550 <Eigen::internal::gemm_pack_lhs<float, int, Eigen::internal::const_blas_data_mapper<float, int, 0>, 2, 1, 0, false, false>::operator()(float*, Eigen::internal::const_blas_data_mapper<float, int, 0> const&, int, int, int, int)>

            gebp_kernel(other.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc, cols, Scalar(-1), -1, -1, 0, 0);
    2ca8:	mov.w	lr, #4294967295
    2cac:	ldr	r3, [r7, #124]	; 0x7c
    2cae:	ldr.w	r1, [r7, #148]	; 0x94
    2cb2:	vmov.f32	s0, #240	; 0xbf800000 -1.0
    2cb6:	ldr.w	r4, [r7, #252]	; 0xfc
    2cba:	add.w	r0, r7, #180	; 0xb4
    2cbe:	str	r3, [sp, #8]
    2cc0:	str	r1, [sp, #4]
    2cc2:	add.w	r1, r7, #192	; 0xc0
    2cc6:	str.w	r8, [sp, #24]
    2cca:	str.w	r8, [sp, #20]
    2cce:	ldr.w	r3, [r7, #136]	; 0x88
    2cd2:	ldr.w	r2, [r7, #140]	; 0x8c
    2cd6:	str	r5, [sp, #0]
    2cd8:	str.w	lr, [sp, #16]
    2cdc:	str.w	lr, [sp, #12]
    2ce0:	str.w	r9, [r7, #192]	; 0xc0
    2ce4:	str.w	r4, [r7, #196]	; 0xc4
    2ce8:	bl	6e4 <Eigen::internal::gebp_kernel<float, float, int, Eigen::internal::blas_data_mapper<float, int, 0, 0>, 2, 4, false, false>::operator()(Eigen::internal::blas_data_mapper<float, int, 0, 0> const&, float const*, float const*, int, int, int, float, int, int, int, int)>
    2cec:	b.n	2c50 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x40c>
    {
      // concept requirements
      __glibcxx_function_requires(_LessThanComparableConcept<_Tp>)
      //return  __a < __b ? __b : __a;
      if (__a < __b)
	return __b;
    2cee:	movs	r3, #4
    2cf0:	str.w	r3, [r7, #132]	; 0x84
    2cf4:	b.n	28f0 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0xac>
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
    2cf6:	mov.w	r1, #524288	; 0x80000
/** \internal */
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    2cfa:	ldr	r2, [pc, #284]	; (2e18 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x5d4>)
    2cfc:	mov.w	r5, #16384	; 0x4000


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    2d00:	movs	r4, #1
    2d02:	mov	r3, r1
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    m_l2 = manage_caching_sizes_helper(l2CacheSize, defaultL2CacheSize);
    2d04:	str	r1, [r2, #4]
    m_l3 = manage_caching_sizes_helper(l3CacheSize, defaultL3CacheSize);
    2d06:	str	r1, [r2, #8]
/** \internal */
struct CacheSizes {
  CacheSizes(): m_l1(-1),m_l2(-1),m_l3(-1) {
    int l1CacheSize, l2CacheSize, l3CacheSize;
    queryCacheSizes(l1CacheSize, l2CacheSize, l3CacheSize);
    m_l1 = manage_caching_sizes_helper(l1CacheSize, defaultL1CacheSize);
    2d08:	str	r5, [r2, #0]


/** \internal */
inline void manage_caching_sizes(Action action, std::ptrdiff_t* l1, std::ptrdiff_t* l2, std::ptrdiff_t* l3)
{
  static CacheSizes m_cacheSizes;
    2d0a:	str	r4, [r0, #0]
    2d0c:	b.n	28c4 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x80>

    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*cols;

    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
    ei_declare_aligned_stack_constructed_variable(Scalar, blockB, sizeB, blocking.blockB());
    2d0e:	lsls	r0, r4, #2
    2d10:	cmp.w	r0, #131072	; 0x20000
    2d14:	bhi.n	2d60 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x51c>
    2d16:	add.w	r3, r0, #29
    2d1a:	movs	r2, #0
    2d1c:	bic.w	r3, r3, #7
    2d20:	str	r2, [r7, #100]	; 0x64
    2d22:	sub.w	sp, sp, r3
    2d26:	add.w	r3, sp, #47	; 0x2f
    2d2a:	bic.w	r3, r3, #15
    2d2e:	str.w	r3, [r7, #136]	; 0x88
    2d32:	str	r3, [r7, #116]	; 0x74
    2d34:	b.n	28b6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x72>
    Index mc = (std::min)(size,blocking.mc());  // cache block size along the M direction

    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*cols;

    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
    2d36:	mov.w	r0, r8, lsl #2
    2d3a:	cmp.w	r0, #131072	; 0x20000
    2d3e:	bhi.n	2d8e <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x54a>
    2d40:	add.w	r3, r0, #29
    2d44:	movs	r2, #0
    2d46:	bic.w	r3, r3, #7
    2d4a:	str	r2, [r7, #104]	; 0x68
    2d4c:	sub.w	sp, sp, r3
    2d50:	add.w	r3, sp, #47	; 0x2f
    2d54:	bic.w	r3, r3, #15
    2d58:	str.w	r3, [r7, #140]	; 0x8c
    2d5c:	str	r3, [r7, #120]	; 0x78
    2d5e:	b.n	2896 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x52>
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    2d60:	adds	r0, #16
    2d62:	bl	7238 <malloc>
  if (original == 0) return 0;
    2d66:	cbz	r0, 2dbc <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x578>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2d68:	bic.w	r3, r0, #15
    2d6c:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    2d6e:	str.w	r0, [r3, #-4]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2d72:	str.w	r3, [r7, #136]	; 0x88
    ei_declare_aligned_stack_constructed_variable(Scalar, blockB, sizeB, blocking.blockB());
    2d76:	ldr	r3, [r5, #4]
    2d78:	cmp	r3, #0
    2d7a:	bne.w	28b0 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x6c>
    2d7e:	ldr.w	r2, [r7, #136]	; 0x88
    2d82:	adds	r3, r2, #0
    2d84:	str	r2, [r7, #116]	; 0x74
    2d86:	it	ne
    2d88:	movne	r3, #1
    2d8a:	str	r3, [r7, #100]	; 0x64
    2d8c:	b.n	28b6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x72>
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    2d8e:	adds	r0, #16
    2d90:	bl	7238 <malloc>
  if (original == 0) return 0;
    2d94:	cbz	r0, 2dc6 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x582>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2d96:	bic.w	r3, r0, #15
    2d9a:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    2d9c:	str.w	r0, [r3, #-4]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2da0:	str.w	r3, [r7, #140]	; 0x8c
    Index mc = (std::min)(size,blocking.mc());  // cache block size along the M direction

    std::size_t sizeA = kc*mc;
    std::size_t sizeB = kc*cols;

    ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
    2da4:	ldr	r3, [r5, #0]
    2da6:	cmp	r3, #0
    2da8:	bne.w	2890 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x4c>
    2dac:	ldr.w	r2, [r7, #140]	; 0x8c
    2db0:	adds	r3, r2, #0
    2db2:	str	r2, [r7, #120]	; 0x78
    2db4:	it	ne
    2db6:	movne	r3, #1
    2db8:	str	r3, [r7, #104]	; 0x68
    2dba:	b.n	2896 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x52>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    2dbc:	mov.w	r0, #4294967295
    2dc0:	bl	6d9c <operator new(unsigned int)>
    2dc4:	b.n	2d76 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x532>
    2dc6:	mov.w	r0, #4294967295
    2dca:	bl	6d9c <operator new(unsigned int)>
    2dce:	b.n	2da4 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x560>
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    2dd0:	ldr	r3, [r7, #100]	; 0x64
    2dd2:	cbz	r3, 2dde <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x59a>
    2dd4:	ldr	r3, [r7, #116]	; 0x74
    2dd6:	ldr.w	r0, [r3, #-4]
    2dda:	bl	7248 <free>
    2dde:	ldr	r3, [r7, #104]	; 0x68
    2de0:	cbz	r3, 2dec <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x5a8>
    2de2:	ldr	r3, [r7, #120]	; 0x78
    2de4:	ldr.w	r0, [r3, #-4]
    2de8:	bl	7248 <free>
            gebp_kernel(other.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc, cols, Scalar(-1), -1, -1, 0, 0);
          }
        }
      }
    }
  }
    2dec:	adds	r7, #204	; 0xcc
    2dee:	mov	sp, r7
    2df0:	vpop	{d8}
    2df4:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    2df8:	ldr.w	r3, [r7, #128]	; 0x80
    2dfc:	ldr	r2, [r7, #32]
    2dfe:	ldr.w	r6, [r7, #168]	; 0xa8
    2e02:	add	r3, r2
    2e04:	ldr	r2, [r7, #16]
    2e06:	str.w	r3, [r7, #128]	; 0x80
    2e0a:	ldr	r3, [r7, #64]	; 0x40
    2e0c:	add	r3, r2
    2e0e:	str	r3, [r7, #64]	; 0x40
    2e10:	b.n	2980 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x13c>
    2e12:	mov	r5, r6
    2e14:	b.n	2c7a <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)+0x436>
    2e16:	nop
    2e18:	.word	0x20000960

00002e1c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]>:
// Specialization for "dense = dense_xpr.inverse()"
template<typename DstXprType, typename XprType>
struct Assignment<DstXprType, Inverse<XprType>, internal::assign_op<typename DstXprType::Scalar,typename XprType::Scalar>, Dense2Dense>
{
  typedef Inverse<XprType> SrcXprType;
  static void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<typename DstXprType::Scalar,typename XprType::Scalar> &)
    2e1c:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
  
  explicit EIGEN_DEVICE_FUNC Inverse(const XprType &xpr)
    : m_xpr(xpr)
  {}

  EIGEN_DEVICE_FUNC Index rows() const { return m_xpr.rows(); }
    2e20:	ldr	r6, [r1, #0]
    2e22:	sub	sp, #100	; 0x64
    2e24:	ldr	r3, [r0, #4]
    2e26:	mov	r9, r1
    2e28:	ldr	r4, [r6, #4]
    2e2a:	mov	r5, r0
    2e2c:	ldr	r7, [r6, #8]
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    2e2e:	cmp	r4, r3
    2e30:	beq.w	31aa <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x38e>
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
    2e34:	cbz	r4, 2e46 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2a>
    2e36:	cbz	r7, 2e46 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2a>
    2e38:	mvn.w	r2, #2147483648	; 0x80000000
    2e3c:	sdiv	r2, r2, r7
    2e40:	cmp	r4, r2
    2e42:	bgt.w	330c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4f0>
      m_rows = rows;
      m_cols = cols;
    }
    EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
    {
      if(size != m_rows*m_cols)
    2e46:	ldr	r2, [r5, #8]
        Index size = rows*cols;
        bool size_changed = size != this->size();
        m_storage.resize(size, rows, cols);
        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
      #else
        m_storage.resize(rows*cols, rows, cols);
    2e48:	mul.w	r6, r7, r4
    2e4c:	mul.w	r3, r2, r3
    2e50:	cmp	r6, r3
    2e52:	beq.n	2e68 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4c>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
    2e54:	ldr	r3, [r5, #0]
    2e56:	cbz	r3, 2e60 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x44>
    2e58:	ldr.w	r0, [r3, #-4]
    2e5c:	bl	7248 <free>
        if (size)
    2e60:	cmp	r6, #0
    2e62:	bne.w	33d2 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x5b6>
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
    2e66:	str	r6, [r5, #0]
    2e68:	ldr.w	r6, [r9]
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    2e6c:	str	r4, [r5, #4]
      m_cols = cols;
    2e6e:	str	r7, [r5, #8]
    2e70:	ldr	r4, [r6, #4]
    2e72:	ldr.w	r8, [r6, #8]
{
    T *m_data;
    Index m_rows;
    Index m_cols;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0), m_cols(0) {}
    2e76:	movs	r3, #0
    2e78:	str	r3, [sp, #60]	; 0x3c
    2e7a:	str	r3, [sp, #64]	; 0x40
    2e7c:	str	r3, [sp, #68]	; 0x44
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
    2e7e:	cmp	r4, #0
    2e80:	beq.w	32c0 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4a4>
    2e84:	cmp.w	r8, #0
    2e88:	beq.w	32c0 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4a4>
    2e8c:	mvn.w	r3, #2147483648	; 0x80000000
    2e90:	sdiv	r3, r3, r8
    2e94:	cmp	r3, r4
    2e96:	bge.w	32c0 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4a4>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    2e9a:	mov.w	r0, #4294967295
        Index size = rows*cols;
        bool size_changed = size != this->size();
        m_storage.resize(size, rows, cols);
        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
      #else
        m_storage.resize(rows*cols, rows, cols);
    2e9e:	mul.w	r7, r8, r4
    2ea2:	bl	6d9c <operator new(unsigned int)>
      m_rows = rows;
      m_cols = cols;
    }
    EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
    {
      if(size != m_rows*m_cols)
    2ea6:	ldr	r2, [sp, #64]	; 0x40
    2ea8:	ldr	r3, [sp, #68]	; 0x44
    2eaa:	mul.w	r3, r3, r2
    2eae:	cmp	r7, r3
    2eb0:	beq.n	2ec6 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xaa>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
    2eb2:	ldr	r3, [sp, #60]	; 0x3c
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    2eb4:	cbz	r3, 2ebe <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xa2>
    2eb6:	ldr.w	r0, [r3, #-4]
    2eba:	bl	7248 <free>
        if (size)
    2ebe:	cmp	r7, #0
    2ec0:	bne.w	32ca <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4ae>
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
    2ec4:	str	r7, [sp, #60]	; 0x3c
template<typename T, int _Cols, int _Options> class DenseStorage<T, Dynamic, Dynamic, _Cols, _Options>
{
    T *m_data;
    Index m_rows;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0) {}
    2ec6:	movs	r3, #0
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    2ec8:	str	r4, [sp, #64]	; 0x40
      m_cols = cols;
    2eca:	str.w	r8, [sp, #68]	; 0x44
    2ece:	ldr	r4, [r6, #4]
template<typename T, int _Cols, int _Options> class DenseStorage<T, Dynamic, Dynamic, _Cols, _Options>
{
    T *m_data;
    Index m_rows;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0) {}
    2ed0:	str	r3, [sp, #72]	; 0x48
    2ed2:	str	r3, [sp, #76]	; 0x4c
      m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, m_rows*_Cols);
      m_rows = rows;
    }
    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index size, Index rows, Index)
    {
      if(size != m_rows*_Cols)
    2ed4:	cbz	r4, 2efc <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xe0>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    2ed6:	cmp.w	r4, #1073741824	; 0x40000000
    2eda:	bcs.w	3406 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x5ea>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    2ede:	lsls	r7, r4, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    2ee0:	add.w	r0, r7, #16
    2ee4:	bl	7238 <malloc>
  if (original == 0) return 0;
    2ee8:	mov	r8, r0
    2eea:	cmp	r0, #0
    2eec:	beq.w	34ae <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x692>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2ef0:	bic.w	r3, r0, #15
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    2ef4:	str	r0, [r3, #12]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2ef6:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    2ef8:	mov	r7, r3
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Cols*m_rows);
        if (size)
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
    2efa:	str	r7, [sp, #72]	; 0x48
template<typename T, int _Cols, int _Options> class DenseStorage<T, Dynamic, Dynamic, _Cols, _Options>
{
    T *m_data;
    Index m_rows;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0) {}
    2efc:	movs	r3, #0
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    2efe:	str	r4, [sp, #76]	; 0x4c
    2f00:	ldr	r4, [r6, #4]
template<typename T, int _Cols, int _Options> class DenseStorage<T, Dynamic, Dynamic, _Cols, _Options>
{
    T *m_data;
    Index m_rows;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0) {}
    2f02:	str	r3, [sp, #80]	; 0x50
    2f04:	str	r3, [sp, #84]	; 0x54
      m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, m_rows*_Cols);
      m_rows = rows;
    }
    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index size, Index rows, Index)
    {
      if(size != m_rows*_Cols)
    2f06:	cbz	r4, 2f2e <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x112>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    2f08:	cmp.w	r4, #1073741824	; 0x40000000
    2f0c:	bcs.w	33fc <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x5e0>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    2f10:	lsls	r7, r4, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    2f12:	add.w	r0, r7, #16
    2f16:	bl	7238 <malloc>
  if (original == 0) return 0;
    2f1a:	mov	r8, r0
    2f1c:	cmp	r0, #0
    2f1e:	beq.w	34c0 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x6a4>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2f22:	bic.w	r3, r0, #15
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    2f26:	str	r0, [r3, #12]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2f28:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    2f2a:	mov	r7, r3
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Cols*m_rows);
        if (size)
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
    2f2c:	str	r7, [sp, #80]	; 0x50
  : m_lu(matrix.rows(),matrix.cols()),
    m_p(matrix.rows()),
    m_rowsTranspositions(matrix.rows()),
    m_l1_norm(0),
    m_det_p(0),
    m_isInitialized(false)
    2f2e:	movs	r2, #0
        else
          m_data = 0;
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    2f30:	str	r4, [sp, #84]	; 0x54
    2f32:	ldr	r3, [sp, #64]	; 0x40
    2f34:	movs	r1, #0
    2f36:	strb.w	r2, [sp, #92]	; 0x5c
    2f3a:	ldr.w	r8, [r6, #4]
    2f3e:	ldr	r4, [r6, #0]
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    2f40:	cmp	r8, r3
    2f42:	ldr.w	r9, [r6, #8]
    2f46:	strb.w	r2, [sp, #93]	; 0x5d
    2f4a:	str	r1, [sp, #88]	; 0x58
    2f4c:	beq.w	31b6 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x39a>
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
    2f50:	cmp.w	r8, #0
    2f54:	beq.n	2f6a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x14e>
    2f56:	cmp.w	r9, #0
    2f5a:	beq.n	2f6a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x14e>
    2f5c:	mvn.w	r2, #2147483648	; 0x80000000
    2f60:	sdiv	r2, r2, r9
    2f64:	cmp	r8, r2
    2f66:	bgt.w	332e <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x512>
      m_rows = rows;
      m_cols = cols;
    }
    EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
    {
      if(size != m_rows*m_cols)
    2f6a:	ldr	r2, [sp, #68]	; 0x44
        Index size = rows*cols;
        bool size_changed = size != this->size();
        m_storage.resize(size, rows, cols);
        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
      #else
        m_storage.resize(rows*cols, rows, cols);
    2f6c:	mul.w	r7, r9, r8
    2f70:	mul.w	r3, r2, r3
    2f74:	cmp	r7, r3
    2f76:	beq.w	3348 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x52c>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
    2f7a:	ldr	r3, [sp, #60]	; 0x3c
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    2f7c:	cbz	r3, 2f86 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x16a>
    2f7e:	ldr.w	r0, [r3, #-4]
    2f82:	bl	7248 <free>
        if (size)
    2f86:	cmp	r7, #0
    2f88:	bne.w	334c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x530>
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
    2f8c:	mov	r2, r7
    2f8e:	str	r7, [sp, #60]	; 0x3c
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    2f90:	str.w	r8, [sp, #64]	; 0x40
      m_cols = cols;
    2f94:	str.w	r9, [sp, #68]	; 0x44
struct dense_assignment_loop<Kernel, LinearTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
  {
    const Index size = kernel.size();
    for(Index i = 0; i < size; ++i)
    2f98:	cmp	r7, #0
    2f9a:	ble.n	2fae <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x192>
    2f9c:	mov	r3, r4
    2f9e:	add.w	r0, r4, r7, lsl #2
    2fa2:	ldr.w	r1, [r3], #4
    2fa6:	cmp	r3, r0
  *
  */
template<typename DstScalar,typename SrcScalar> struct assign_op {

  EIGEN_EMPTY_STRUCT_CTOR(assign_op)
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(DstScalar& a, const SrcScalar& b) const { a = b; }
    2fa8:	str.w	r1, [r2], #4
    2fac:	bne.n	2fa2 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x186>
    explicit PartialPivLU(EigenBase<InputType>& matrix);

    template<typename InputType>
    PartialPivLU& compute(const EigenBase<InputType>& matrix) {
      m_lu = matrix.derived();
      compute();
    2fae:	add	r0, sp, #60	; 0x3c
    2fb0:	bl	2674 <Eigen::PartialPivLU<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::compute()>
    {
      EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      eigen_internal_assert(size==rows*cols && rows>=0 && cols >=0);
    }
    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other)
      : m_data(internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(other.m_rows*other.m_cols))
    2fb4:	ldr	r4, [sp, #64]	; 0x40
    2fb6:	ldr	r7, [sp, #68]	; 0x44
    2fb8:	mul.w	r6, r7, r4
}


template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    2fbc:	cbz	r6, 2ff8 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x1dc>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    2fbe:	cmp.w	r6, #1073741824	; 0x40000000
    2fc2:	bcs.w	3302 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4e6>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    2fc6:	lsls	r6, r6, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    2fc8:	add.w	r0, r6, #16
    2fcc:	bl	7238 <malloc>
  if (original == 0) return 0;
    2fd0:	mov	r2, r0
    2fd2:	cmp	r0, #0
    2fd4:	beq.w	3410 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x5f4>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    2fd8:	bic.w	r3, r0, #15
    2fdc:	ldr	r4, [sp, #64]	; 0x40
    2fde:	ldr	r7, [sp, #68]	; 0x44
    2fe0:	add.w	r6, r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    2fe4:	str.w	r0, [r6, #-4]
    2fe8:	mul.w	r3, r7, r4

template<typename T> struct smart_copy_helper<T,true> {
  EIGEN_DEVICE_FUNC static inline void run(const T* start, const T* end, T* target)
  {
    IntPtr size = IntPtr(end)-IntPtr(start);
    if(size==0) return;
    2fec:	lsls	r2, r3, #2
    2fee:	beq.n	2ff8 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x1dc>
    eigen_internal_assert(start!=0 && end!=0 && target!=0);
    std::memcpy(target, start, size);
    2ff0:	ldr	r1, [sp, #60]	; 0x3c
    2ff2:	mov	r0, r6
    2ff4:	bl	5318 <memcpy>
      EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      eigen_internal_assert(size==rows*cols && rows>=0 && cols == _Cols);
      EIGEN_UNUSED_VARIABLE(cols);
    }
    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other)
      : m_data(internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(other.m_rows*_Cols))
    2ff8:	ldr.w	sl, [sp, #76]	; 0x4c
}


template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    2ffc:	cmp.w	sl, #0
    3000:	beq.w	3344 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x528>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    3004:	cmp.w	sl, #1073741824	; 0x40000000
    3008:	bcs.w	32f8 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4dc>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    300c:	mov.w	sl, sl, lsl #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    3010:	add.w	r0, sl, #16
    3014:	bl	7238 <malloc>
  if (original == 0) return 0;
    3018:	mov	r2, r0
    301a:	cmp	r0, #0
    301c:	beq.w	342c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x610>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    3020:	bic.w	r3, r0, #15
    3024:	ldr.w	sl, [sp, #76]	; 0x4c
    3028:	add.w	r9, r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    302c:	str.w	r0, [r9, #-4]

template<typename T> struct smart_copy_helper<T,true> {
  EIGEN_DEVICE_FUNC static inline void run(const T* start, const T* end, T* target)
  {
    IntPtr size = IntPtr(end)-IntPtr(start);
    if(size==0) return;
    3030:	movs.w	r2, sl, lsl #2
    3034:	beq.n	303e <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x222>
    eigen_internal_assert(start!=0 && end!=0 && target!=0);
    std::memcpy(target, start, size);
    3036:	ldr	r1, [sp, #72]	; 0x48
    3038:	mov	r0, r9
    303a:	bl	5318 <memcpy>
    303e:	ldr.w	r8, [sp, #84]	; 0x54
}


template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    3042:	cmp.w	r8, #0
    3046:	beq.n	307e <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x262>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    3048:	cmp.w	r8, #1073741824	; 0x40000000
    304c:	bcs.w	32ee <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4d2>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    3050:	mov.w	r8, r8, lsl #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    3054:	add.w	r0, r8, #16
    3058:	bl	7238 <malloc>
  if (original == 0) return 0;
    305c:	mov	r1, r0
    305e:	cmp	r0, #0
    3060:	beq.w	3442 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x626>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    3064:	bic.w	r2, r0, #15
    3068:	ldr	r3, [sp, #84]	; 0x54
    306a:	add.w	r8, r2, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    306e:	str.w	r0, [r8, #-4]

template<typename T> struct smart_copy_helper<T,true> {
  EIGEN_DEVICE_FUNC static inline void run(const T* start, const T* end, T* target)
  {
    IntPtr size = IntPtr(end)-IntPtr(start);
    if(size==0) return;
    3072:	lsls	r2, r3, #2
    3074:	beq.n	307e <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x262>
    eigen_internal_assert(start!=0 && end!=0 && target!=0);
    std::memcpy(target, start, size);
    3076:	ldr	r1, [sp, #80]	; 0x50
    3078:	mov	r0, r8
    307a:	bl	5318 <memcpy>
    307e:	ldr	r3, [r5, #4]
  typedef Solve<DecType,RhsType> SrcXprType;
  static void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    3080:	cmp	r3, r7
    3082:	beq.w	31c6 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x3aa>
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
    3086:	cbz	r7, 3096 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x27a>
    3088:	mvn.w	r2, #2147483648	; 0x80000000
    308c:	sdiv	r2, r2, r7
    3090:	cmp	r2, r7
    3092:	blt.w	3322 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x506>
      m_rows = rows;
      m_cols = cols;
    }
    EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
    {
      if(size != m_rows*m_cols)
    3096:	ldr	r2, [r5, #8]
        Index size = rows*cols;
        bool size_changed = size != this->size();
        m_storage.resize(size, rows, cols);
        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
      #else
        m_storage.resize(rows*cols, rows, cols);
    3098:	mul.w	fp, r7, r7
    309c:	mul.w	r3, r2, r3
    30a0:	cmp	fp, r3
    30a2:	beq.n	30bc <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2a0>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
    30a4:	ldr	r3, [r5, #0]
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    30a6:	cbz	r3, 30b0 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x294>
    30a8:	ldr.w	r0, [r3, #-4]
    30ac:	bl	7248 <free>
        if (size)
    30b0:	cmp.w	fp, #0
    30b4:	bne.w	337a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x55e>
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
    30b8:	str.w	fp, [r5]
  static EIGEN_STRONG_INLINE
  void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    30bc:	cmp	r7, sl
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    30be:	str	r7, [r5, #4]
      m_cols = cols;
    30c0:	str	r7, [r5, #8]
    30c2:	beq.n	3108 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2ec>
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
    30c4:	cmp.w	sl, #0
    30c8:	beq.n	30da <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2be>
    30ca:	cbz	r7, 30da <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2be>
    30cc:	mvn.w	r3, #2147483648	; 0x80000000
    30d0:	sdiv	r3, r3, r7
    30d4:	cmp	r3, sl
    30d6:	blt.w	3318 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4fc>
      m_rows = rows;
      m_cols = cols;
    }
    EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
    {
      if(size != m_rows*m_cols)
    30da:	ldr	r2, [r5, #4]
        Index size = rows*cols;
        bool size_changed = size != this->size();
        m_storage.resize(size, rows, cols);
        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
      #else
        m_storage.resize(rows*cols, rows, cols);
    30dc:	mul.w	fp, sl, r7
    30e0:	ldr	r3, [r5, #8]
    30e2:	mul.w	r3, r3, r2
    30e6:	cmp	fp, r3
    30e8:	beq.n	3102 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2e6>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
    30ea:	ldr	r3, [r5, #0]
    30ec:	cbz	r3, 30f6 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2da>
    30ee:	ldr.w	r0, [r3, #-4]
    30f2:	bl	7248 <free>
        if (size)
    30f6:	cmp.w	fp, #0
    30fa:	bne.w	33a6 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x58a>
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
    30fe:	str.w	fp, [r5]
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    3102:	str.w	sl, [r5, #4]
      m_cols = cols;
    3106:	str	r7, [r5, #8]
          }
        }
      }
      else
      {
        for(Index i = 0; i < n; ++i)
    3108:	cmp	r4, #0
    310a:	ble.n	3156 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x33a>
    310c:	ldr	r3, [r5, #4]
         PacketAccess = packet_traits<Scalar>::Vectorizable, IsRepeatable = true }; };

template<typename Scalar> struct scalar_identity_op {
  EIGEN_EMPTY_STRUCT_CTOR(scalar_identity_op)
  template<typename IndexType>
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (IndexType row, IndexType col) const { return row==col ? Scalar(1) : Scalar(0); }
    310e:	vmov.f32	s13, #112	; 0x3f800000  1.0
    3112:	ldr.w	sl, [r5]
    3116:	sub.w	ip, r9, #4
    311a:	mov.w	lr, r3, lsl #2
    311e:	ldr	r0, [r5, #8]
    3120:	movs	r1, #0
    3122:	vldr	s14, [pc, #772]	; 3428 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x60c>
                                || ((BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) && ( XprTypeIsRowMajor)) ? xpr.innerStride() : xpr.outerStride()),
             BlockRows==1 ? 1 : xpr.rows(),
             BlockCols==1 ? 1 : xpr.cols()),
        m_xpr(xpr),
        m_startRow( (BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) ? i : 0),
        m_startCol( (BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) ? i : 0)
    3126:	ldr.w	r2, [ip, #4]!
    312a:	cmp	r0, #0
    312c:	mov.w	r2, r2, lsl #2
    3130:	ble.n	3150 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x334>
    3132:	add	r2, sl
    3134:	movs	r3, #0
    3136:	cmp	r1, r3
    3138:	add.w	r3, r3, #1
    313c:	ite	eq
    313e:	vmoveq.f32	s15, s13
    3142:	vmovne.f32	s15, s14
    3146:	cmp	r3, r0
    3148:	vstr	s15, [r2]
    314c:	add	r2, lr
    314e:	bne.n	3136 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x31a>
    3150:	adds	r1, #1
    3152:	cmp	r1, r4
    3154:	bne.n	3126 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x30a>
{
  OtherDerived& other = _other.const_cast_derived();
  eigen_assert( derived().cols() == derived().rows() && ((Side==OnTheLeft && derived().cols() == other.rows()) || (Side==OnTheRight && derived().cols() == other.cols())) );
  eigen_assert((!(Mode & ZeroDiag)) && bool(Mode & (Upper|Lower)));
  // If solving for a 0x0 matrix, nothing to do, simply return.
  if (derived().cols() == 0)
    3156:	cmp	r7, #0
    3158:	bne.n	31d6 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x3ba>
    315a:	cmp.w	r8, #0
    315e:	beq.n	3168 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x34c>
    3160:	ldr.w	r0, [r8, #-4]
    3164:	bl	7248 <free>
    3168:	cmp.w	r9, #0
    316c:	beq.n	3176 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x35a>
    316e:	ldr.w	r0, [r9, #-4]
    3172:	bl	7248 <free>
    3176:	cbz	r6, 3180 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x364>
    3178:	ldr.w	r0, [r6, #-4]
    317c:	bl	7248 <free>
      swap(m_data, other.m_data);
      swap(m_rows, other.m_rows);
      return *this;
    }
#endif
    EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Cols*m_rows); }
    3180:	ldr	r3, [sp, #80]	; 0x50
    3182:	cbz	r3, 318c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x370>
    3184:	ldr.w	r0, [r3, #-4]
    3188:	bl	7248 <free>
    318c:	ldr	r3, [sp, #72]	; 0x48
    318e:	cbz	r3, 3198 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x37c>
    3190:	ldr.w	r0, [r3, #-4]
    3194:	bl	7248 <free>
      swap(m_rows, other.m_rows);
      swap(m_cols, other.m_cols);
      return *this;
    }
#endif
    EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols); }
    3198:	ldr	r3, [sp, #60]	; 0x3c
    319a:	cbz	r3, 31a4 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x388>
    319c:	ldr.w	r0, [r3, #-4]
    31a0:	bl	7248 <free>
    typedef typename internal::remove_all<ActualXprType>::type                        ActualXprTypeCleanded;
    
    ActualXprType actual_xpr(src.nestedExpression());
    
    compute_inverse<ActualXprTypeCleanded, DstXprType>::run(actual_xpr, dst);
  }
    31a4:	add	sp, #100	; 0x64
    31a6:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    31aa:	ldr.w	r8, [r0, #8]
  typedef Inverse<XprType> SrcXprType;
  static void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<typename DstXprType::Scalar,typename XprType::Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    31ae:	cmp	r7, r8
    31b0:	bne.w	2e34 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x18>
    31b4:	b.n	2e76 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x5a>
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    31b6:	ldr	r2, [sp, #68]	; 0x44
    31b8:	cmp	r9, r2
    31ba:	bne.w	2f50 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x134>
    31be:	mul.w	r7, r9, r8
    31c2:	ldr	r2, [sp, #60]	; 0x3c
    31c4:	b.n	2f98 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x17c>
    31c6:	ldr	r2, [r5, #8]
    31c8:	cmp	r7, r2
    31ca:	bne.w	3086 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x26a>
  static EIGEN_STRONG_INLINE
  void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    31ce:	cmp	r7, sl
    31d0:	bne.w	30c4 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2a8>
    31d4:	b.n	3108 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2ec>
    31d6:	ldr.w	fp, [r5, #8]
      {
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, this->m_nc, num_threads);
      }
      else  // no l3 blocking
      {
        Index n = this->m_nc;
    31da:	add.w	sl, sp, #96	; 0x60
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    31de:	mov.w	lr, #0

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    31e2:	ldr	r7, [r5, #4]
      {
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, this->m_nc, num_threads);
      }
      else  // no l3 blocking
      {
        Index n = this->m_nc;
    31e4:	str.w	fp, [sl, #-68]!

template<typename LhsScalar, typename RhsScalar, int KcFactor, typename Index>
void computeProductBlockingSizes(Index& k, Index& m, Index& n, Index num_threads = 1)
{
  if (!useSpecificBlockingSizes(k, m, n)) {
    evaluateProductBlockingSizesHeuristic<LhsScalar, RhsScalar, KcFactor, Index>(k, m, n, num_threads);
    31e8:	add	r1, sp, #40	; 0x28
    31ea:	mov	r2, sl
    31ec:	add	r0, sp, #48	; 0x30
    31ee:	movs	r3, #1

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    31f0:	str	r7, [sp, #40]	; 0x28
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    31f2:	str.w	lr, [sp, #32]
    31f6:	str.w	lr, [sp, #36]	; 0x24

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
      this->m_kc = depth;
    31fa:	str	r4, [sp, #48]	; 0x30
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    31fc:	str.w	fp, [sp, #44]	; 0x2c
    3200:	bl	201c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)>
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    3204:	ldr.w	lr, [sp, #48]	; 0x30
    typedef internal::gemm_blocking_space<(Rhs::Flags&RowMajorBit) ? RowMajor : ColMajor,Scalar,Scalar,
              Rhs::MaxRowsAtCompileTime, Rhs::MaxColsAtCompileTime, Lhs::MaxRowsAtCompileTime,4> BlockingType;

    BlockingType blocking(rhs.rows(), rhs.cols(), size, 1, false);

    triangular_solve_matrix<Scalar,Index,Side,Mode,LhsProductTraits::NeedToConjugate,(int(Lhs::Flags) & RowMajorBit) ? RowMajor : ColMajor,
    3208:	mov	r3, r4
    320a:	ldr	r2, [sp, #40]	; 0x28
    320c:	mov	r1, fp
      m_sizeB = this->m_kc * this->m_nc;
    320e:	ldr	r7, [sp, #44]	; 0x2c
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    3210:	mul.w	r0, lr, r2
    3214:	ldr	r2, [r5, #4]
      m_sizeB = this->m_kc * this->m_nc;
    3216:	mul.w	lr, lr, r7
    321a:	ldr	r7, [r5, #0]
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    321c:	str	r0, [sp, #52]	; 0x34
    321e:	mov	r0, r4
    3220:	str	r7, [sp, #0]
    3222:	add	r7, sp, #32
    3224:	str	r2, [sp, #4]
    3226:	mov	r2, r6
    3228:	str	r7, [sp, #8]
      m_sizeB = this->m_kc * this->m_nc;
    322a:	str.w	lr, [sp, #56]	; 0x38
    322e:	bl	1a8c <Eigen::internal::triangular_solve_matrix<float, int, 1, 5, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    3232:	ldr	r3, [sp, #32]
    3234:	cbz	r3, 323e <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x422>
    3236:	ldr.w	r0, [r3, #-4]
    323a:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    323e:	ldr	r3, [sp, #36]	; 0x24
    3240:	cbz	r3, 324a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x42e>
    3242:	ldr.w	r0, [r3, #-4]
    3246:	bl	7248 <free>
    324a:	ldr.w	fp, [r5, #8]
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    324e:	mov.w	lr, #0

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    3252:	ldr	r7, [r5, #4]
    3254:	mov	r2, sl
    3256:	add	r1, sp, #40	; 0x28
    3258:	add	r0, sp, #48	; 0x30
    325a:	movs	r3, #1
      this->m_nc = Transpose ? rows : cols;
      this->m_kc = depth;
    325c:	str	r4, [sp, #48]	; 0x30

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    325e:	str	r7, [sp, #40]	; 0x28
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    3260:	str.w	lr, [sp, #32]
    3264:	str.w	lr, [sp, #36]	; 0x24
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    3268:	str.w	fp, [sp, #44]	; 0x2c
      {
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, this->m_nc, num_threads);
      }
      else  // no l3 blocking
      {
        Index n = this->m_nc;
    326c:	str.w	fp, [sp, #28]
    3270:	bl	201c <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 4, int>(int&, int&, int&, int)>
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    3274:	ldr	r2, [sp, #48]	; 0x30
    3276:	mov	r3, r4
    3278:	ldr	r7, [sp, #40]	; 0x28
    327a:	mov	r1, fp
      m_sizeB = this->m_kc * this->m_nc;
    327c:	ldr	r4, [sp, #44]	; 0x2c
    327e:	mov	r0, r3
    3280:	ldr.w	ip, [r5, #4]
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    3284:	mul.w	sl, r2, r7
    3288:	ldr	r5, [r5, #0]
      m_sizeB = this->m_kc * this->m_nc;
    328a:	mul.w	r4, r2, r4
    328e:	add	r2, sp, #32
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    3290:	str.w	sl, [sp, #52]	; 0x34
      m_sizeB = this->m_kc * this->m_nc;
    3294:	str	r4, [sp, #56]	; 0x38
    3296:	str	r2, [sp, #8]
    3298:	mov	r2, r6
    329a:	stmia.w	sp, {r5, ip}
    329e:	bl	2844 <Eigen::internal::triangular_solve_matrix<float, int, 1, 2, false, 0, 0>::run(int, int, float const*, int, float*, int, Eigen::internal::level3_blocking<float, float>&)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    32a2:	ldr	r3, [sp, #32]
    32a4:	cbz	r3, 32ae <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x492>
    32a6:	ldr.w	r0, [r3, #-4]
    32aa:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    32ae:	ldr	r3, [sp, #36]	; 0x24
    32b0:	cmp	r3, #0
    32b2:	beq.w	315a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x33e>
    32b6:	ldr.w	r0, [r3, #-4]
    32ba:	bl	7248 <free>
    32be:	b.n	315a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x33e>
    32c0:	mul.w	r7, r8, r4
      m_rows = rows;
      m_cols = cols;
    }
    EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
    {
      if(size != m_rows*m_cols)
    32c4:	cmp	r7, #0
    32c6:	beq.w	2ec6 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xaa>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    32ca:	cmp.w	r7, #1073741824	; 0x40000000
    32ce:	bcs.n	333a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x51e>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    32d0:	lsls	r7, r7, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    32d2:	add.w	r0, r7, #16
    32d6:	bl	7238 <malloc>
  if (original == 0) return 0;
    32da:	mov	r9, r0
    32dc:	cmp	r0, #0
    32de:	beq.w	3498 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x67c>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    32e2:	bic.w	r3, r0, #15
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    32e6:	str	r0, [r3, #12]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    32e8:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    32ea:	mov	r7, r3
    32ec:	b.n	2ec4 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xa8>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    32ee:	mov.w	r0, #4294967295
    32f2:	bl	6d9c <operator new(unsigned int)>
    32f6:	b.n	3050 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x234>
    32f8:	mov.w	r0, #4294967295
    32fc:	bl	6d9c <operator new(unsigned int)>
    3300:	b.n	300c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x1f0>
    3302:	mov.w	r0, #4294967295
    3306:	bl	6d9c <operator new(unsigned int)>
    330a:	b.n	2fc6 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x1aa>
    330c:	mov.w	r0, #4294967295
    3310:	bl	6d9c <operator new(unsigned int)>
    3314:	ldr	r3, [r5, #4]
    3316:	b.n	2e46 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2a>
    3318:	mov.w	r0, #4294967295
    331c:	bl	6d9c <operator new(unsigned int)>
    3320:	b.n	30da <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2be>
    3322:	mov.w	r0, #4294967295
    3326:	bl	6d9c <operator new(unsigned int)>
    332a:	ldr	r3, [r5, #4]
    332c:	b.n	3096 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x27a>
    332e:	mov.w	r0, #4294967295
    3332:	bl	6d9c <operator new(unsigned int)>
    3336:	ldr	r3, [sp, #64]	; 0x40
    3338:	b.n	2f6a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x14e>
    333a:	mov.w	r0, #4294967295
    333e:	bl	6d9c <operator new(unsigned int)>
    3342:	b.n	32d0 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4b4>


template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
    3344:	mov	r9, sl
    3346:	b.n	303e <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x222>
    3348:	ldr	r2, [sp, #60]	; 0x3c
    334a:	b.n	2f90 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x174>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    334c:	cmp.w	r7, #1073741824	; 0x40000000
    3350:	bcc.n	335a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x53e>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    3352:	mov.w	r0, #4294967295
    3356:	bl	6d9c <operator new(unsigned int)>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    335a:	lsls	r6, r7, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    335c:	add.w	r0, r6, #16
    3360:	bl	7238 <malloc>
  if (original == 0) return 0;
    3364:	mov	sl, r0
    3366:	cmp	r0, #0
    3368:	beq.w	348a <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x66e>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    336c:	bic.w	r3, r0, #15
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    3370:	str	r0, [r3, #12]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    3372:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    3374:	mov	r2, r3
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
        if (size)
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
    3376:	str	r2, [sp, #60]	; 0x3c
    3378:	b.n	2f90 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x174>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    337a:	cmp.w	fp, #1073741824	; 0x40000000
    337e:	blt.n	3388 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x56c>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    3380:	mov.w	r0, #4294967295
    3384:	bl	6d9c <operator new(unsigned int)>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    3388:	mov.w	fp, fp, lsl #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    338c:	add.w	r0, fp, #16
    3390:	bl	7238 <malloc>
  if (original == 0) return 0;
    3394:	cmp	r0, #0
    3396:	beq.n	346c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x650>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    3398:	bic.w	r3, r0, #15
    339c:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    339e:	str.w	r0, [r3, #-4]
    33a2:	str	r3, [r5, #0]
    33a4:	b.n	30bc <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2a0>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    33a6:	cmp.w	fp, #1073741824	; 0x40000000
    33aa:	bcc.n	33b4 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x598>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    33ac:	mov.w	r0, #4294967295
    33b0:	bl	6d9c <operator new(unsigned int)>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    33b4:	mov.w	fp, fp, lsl #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    33b8:	add.w	r0, fp, #16
    33bc:	bl	7238 <malloc>
  if (original == 0) return 0;
    33c0:	cmp	r0, #0
    33c2:	beq.n	3456 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x63a>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    33c4:	bic.w	r3, r0, #15
    33c8:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    33ca:	str.w	r0, [r3, #-4]
    33ce:	str	r3, [r5, #0]
    33d0:	b.n	3102 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x2e6>
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    33d2:	cmp.w	r6, #1073741824	; 0x40000000
    33d6:	bcc.n	33e0 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x5c4>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    33d8:	mov.w	r0, #4294967295
    33dc:	bl	6d9c <operator new(unsigned int)>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    33e0:	lsls	r6, r6, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    33e2:	add.w	r0, r6, #16
    33e6:	bl	7238 <malloc>
  if (original == 0) return 0;
    33ea:	mov	r8, r0
    33ec:	cmp	r0, #0
    33ee:	beq.n	34d2 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x6b6>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    33f0:	bic.w	r3, r0, #15
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    33f4:	str	r0, [r3, #12]
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    33f6:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    33f8:	mov	r6, r3
    33fa:	b.n	2e66 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4a>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    33fc:	mov.w	r0, #4294967295
    3400:	bl	6d9c <operator new(unsigned int)>
    3404:	b.n	2f10 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xf4>
    3406:	mov.w	r0, #4294967295
    340a:	bl	6d9c <operator new(unsigned int)>
    340e:	b.n	2ede <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xc2>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    3410:	cbz	r6, 341c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x600>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    3412:	mov.w	r0, #4294967295
    3416:	mov	r6, r2
    3418:	bl	6d9c <operator new(unsigned int)>
    341c:	ldr	r4, [sp, #64]	; 0x40
    341e:	ldr	r7, [sp, #68]	; 0x44
    3420:	mul.w	r3, r7, r4
    3424:	b.n	2fec <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x1d0>
    3426:	nop
    3428:	.word	0x00000000
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    342c:	cmp.w	sl, #0
    3430:	beq.n	34e4 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x6c8>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    3432:	mov.w	r0, #4294967295
    3436:	mov	r9, r2
    3438:	bl	6d9c <operator new(unsigned int)>
    343c:	ldr.w	sl, [sp, #76]	; 0x4c
    3440:	b.n	3030 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x214>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    3442:	cmp.w	r8, #0
    3446:	beq.n	3452 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x636>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    3448:	mov.w	r0, #4294967295
    344c:	mov	r8, r1
    344e:	bl	6d9c <operator new(unsigned int)>
    3452:	ldr	r3, [sp, #84]	; 0x54
    3454:	b.n	3072 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x256>
    3456:	str	r0, [sp, #20]
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    3458:	cmp.w	fp, #0
    345c:	beq.n	3482 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x666>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    345e:	mov.w	r0, #4294967295
    3462:	bl	6d9c <operator new(unsigned int)>
    3466:	ldr	r2, [sp, #20]
    3468:	mov	r3, r2
    346a:	b.n	33ce <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x5b2>
    346c:	str	r0, [sp, #20]
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    346e:	cmp.w	fp, #0
    3472:	beq.n	3486 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x66a>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    3474:	mov.w	r0, #4294967295
    3478:	bl	6d9c <operator new(unsigned int)>
    347c:	ldr	r2, [sp, #20]
    347e:	mov	r3, r2
    3480:	b.n	33a2 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x586>
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
    3482:	mov	r3, fp
    3484:	b.n	33ce <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x5b2>
    3486:	mov	r3, fp
    3488:	b.n	33a2 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x586>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    348a:	cbz	r6, 34aa <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x68e>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    348c:	mov.w	r0, #4294967295
    3490:	bl	6d9c <operator new(unsigned int)>
    3494:	mov	r2, sl
    3496:	b.n	3376 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x55a>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    3498:	cmp	r7, #0
    349a:	beq.w	2ec4 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xa8>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    349e:	mov.w	r0, #4294967295
    34a2:	mov	r7, r9
    34a4:	bl	6d9c <operator new(unsigned int)>
    34a8:	b.n	2ec4 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xa8>
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
    34aa:	mov	r2, r6
    34ac:	b.n	3376 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x55a>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    34ae:	cmp	r7, #0
    34b0:	beq.w	2efa <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xde>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    34b4:	mov.w	r0, #4294967295
    34b8:	mov	r7, r8
    34ba:	bl	6d9c <operator new(unsigned int)>
    34be:	b.n	2efa <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0xde>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    34c0:	cmp	r7, #0
    34c2:	beq.w	2f2c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x110>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    34c6:	mov.w	r0, #4294967295
    34ca:	mov	r7, r8
    34cc:	bl	6d9c <operator new(unsigned int)>
    34d0:	b.n	2f2c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x110>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    34d2:	cmp	r6, #0
    34d4:	beq.w	2e66 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4a>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    34d8:	mov.w	r0, #4294967295
    34dc:	mov	r6, r8
    34de:	bl	6d9c <operator new(unsigned int)>
    34e2:	b.n	2e66 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x4a>
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
    34e4:	mov	r9, sl
    34e6:	ldr.w	sl, [sp, #76]	; 0x4c
    34ea:	b.n	3030 <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]+0x214>

000034ec <loop>:
   
    
   
}

void loop() {
    34ec:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    EIGEN_STRONG_INLINE void _init2(Index rows, Index cols, typename internal::enable_if<Base::SizeAtCompileTime!=2,T0>::type* = 0)
    {
      EIGEN_STATIC_ASSERT(bool(NumTraits<T0>::IsInteger) &&
                          bool(NumTraits<T1>::IsInteger),
                          FLOATING_POINT_ARGUMENT_PASSED__INTEGER_WAS_EXPECTED)
      resize(rows,cols);
    34f0:	movs	r2, #6
    34f2:	sub	sp, #252	; 0xfc
{
    T *m_data;
    Index m_rows;
    Index m_cols;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0), m_cols(0) {}
    34f4:	movs	r4, #0
    34f6:	mov	r1, r2
    34f8:	add	r0, sp, #48	; 0x30
    34fa:	str	r4, [sp, #48]	; 0x30
    34fc:	str	r4, [sp, #52]	; 0x34
    34fe:	str	r4, [sp, #56]	; 0x38
    3500:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    3504:	movs	r2, #6
    3506:	add	r0, sp, #60	; 0x3c
    3508:	str	r4, [sp, #60]	; 0x3c
    350a:	mov	r1, r2
    350c:	str	r4, [sp, #64]	; 0x40
    350e:	str	r4, [sp, #68]	; 0x44
    3510:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    3514:	movs	r2, #6
    3516:	add	r0, sp, #72	; 0x48
    3518:	str	r4, [sp, #72]	; 0x48
    351a:	mov	r1, r2
    351c:	str	r4, [sp, #76]	; 0x4c
    351e:	str	r4, [sp, #80]	; 0x50
    3520:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    3524:	movs	r2, #6
    3526:	add	r0, sp, #84	; 0x54
    3528:	str	r4, [sp, #84]	; 0x54
    352a:	mov	r1, r2
    352c:	str	r4, [sp, #88]	; 0x58
    352e:	str	r4, [sp, #92]	; 0x5c
    3530:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    3534:	movs	r2, #6
    3536:	add	r0, sp, #96	; 0x60
    3538:	str	r4, [sp, #96]	; 0x60
    353a:	mov	r1, r2
    353c:	str	r4, [sp, #100]	; 0x64
    353e:	str	r4, [sp, #104]	; 0x68
    3540:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    3544:	movs	r2, #6
    3546:	add	r0, sp, #108	; 0x6c
    3548:	str	r4, [sp, #108]	; 0x6c
    354a:	mov	r1, r2
    354c:	str	r4, [sp, #112]	; 0x70
    354e:	str	r4, [sp, #116]	; 0x74
    3550:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    3554:	ldr	r2, [sp, #56]	; 0x38
    3556:	ldr	r1, [sp, #48]	; 0x30

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
  {
    m_xpr.coeffRef(0,0) = s;
    3558:	ldr	r3, [pc, #844]	; (38a8 <loop+0x3bc>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    355a:	cmp	r2, #1

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
  {
    m_xpr.coeffRef(0,0) = s;
    355c:	str	r3, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    355e:	beq.w	4cfe <loop+0x1812>
    3562:	ldr	r0, [sp, #52]	; 0x34
    3564:	cmp	r2, #2
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3566:	ldr	r5, [pc, #836]	; (38ac <loop+0x3c0>)
    3568:	add.w	r3, r1, r0, lsl #2
    356c:	str	r5, [r3, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    356e:	beq.w	52d2 <loop+0x1de6>
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3572:	add.w	r3, r1, r0, lsl #3
    3576:	ldr	r5, [pc, #824]	; (38b0 <loop+0x3c4>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3578:	cmp	r2, #3
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    357a:	str	r5, [r3, #0]
{
  typedef typename XprType::Scalar Scalar;

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
    357c:	mov	r3, r4

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    357e:	beq.w	4d0a <loop+0x181e>
    3582:	movs	r5, #3
    3584:	adds	r4, r5, #1
    3586:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    358a:	add	r5, r3
    358c:	ldr	r6, [pc, #804]	; (38b4 <loop+0x3c8>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    358e:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3590:	add.w	r5, r1, r5, lsl #2
    3594:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3596:	beq.w	4cf4 <loop+0x1808>
    359a:	adds	r5, r4, #1
    359c:	mul.w	r4, r0, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35a0:	add	r4, r3
    35a2:	ldr	r6, [pc, #788]	; (38b8 <loop+0x3cc>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    35a4:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35a6:	add.w	r4, r1, r4, lsl #2
    35aa:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    35ac:	beq.w	4cea <loop+0x17fe>
    35b0:	adds	r4, r5, #1
    35b2:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35b6:	add	r5, r3
    35b8:	ldr	r6, [pc, #768]	; (38bc <loop+0x3d0>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    35ba:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35bc:	add.w	r5, r1, r5, lsl #2
    35c0:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    35c2:	beq.w	4ce0 <loop+0x17f4>
    35c6:	adds	r5, r4, #1
    35c8:	mul.w	r4, r0, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35cc:	add	r4, r3
    35ce:	ldr	r6, [pc, #752]	; (38c0 <loop+0x3d4>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    35d0:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35d2:	add.w	r4, r1, r4, lsl #2
    35d6:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    35d8:	beq.w	4cd6 <loop+0x17ea>
    35dc:	adds	r4, r5, #1
    35de:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35e2:	add	r5, r3
    35e4:	ldr	r6, [pc, #732]	; (38c4 <loop+0x3d8>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    35e6:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35e8:	add.w	r5, r1, r5, lsl #2
    35ec:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    35ee:	beq.w	4ccc <loop+0x17e0>
    35f2:	adds	r5, r4, #1
    35f4:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35f8:	add	r4, r3
    35fa:	ldr	r6, [pc, #716]	; (38c8 <loop+0x3dc>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    35fc:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    35fe:	add.w	r4, r1, r4, lsl #2
    3602:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3604:	beq.w	4cc2 <loop+0x17d6>
    3608:	adds	r4, r5, #1
    360a:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    360e:	add	r5, r3
    3610:	ldr	r6, [pc, #696]	; (38cc <loop+0x3e0>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3612:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3614:	add.w	r5, r1, r5, lsl #2
    3618:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    361a:	beq.w	4cb8 <loop+0x17cc>
    361e:	adds	r5, r4, #1
    3620:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3624:	add	r4, r3
    3626:	ldr	r6, [pc, #680]	; (38d0 <loop+0x3e4>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3628:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    362a:	add.w	r4, r1, r4, lsl #2
    362e:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3630:	beq.w	4cae <loop+0x17c2>
    3634:	adds	r4, r5, #1
    3636:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    363a:	add	r5, r3
    363c:	ldr	r6, [pc, #660]	; (38d4 <loop+0x3e8>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    363e:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3640:	add.w	r5, r1, r5, lsl #2
    3644:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3646:	beq.w	4ca4 <loop+0x17b8>
    364a:	adds	r5, r4, #1
    364c:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3650:	add	r4, r3
    3652:	ldr	r6, [pc, #644]	; (38d8 <loop+0x3ec>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3654:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3656:	add.w	r4, r1, r4, lsl #2
    365a:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    365c:	beq.w	4c9a <loop+0x17ae>
    3660:	adds	r4, r5, #1
    3662:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3666:	add	r5, r3
    3668:	ldr	r6, [pc, #624]	; (38dc <loop+0x3f0>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    366a:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    366c:	add.w	r5, r1, r5, lsl #2
    3670:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3672:	beq.w	4c90 <loop+0x17a4>
    3676:	adds	r5, r4, #1
    3678:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    367c:	add	r4, r3
    367e:	ldr	r6, [pc, #608]	; (38e0 <loop+0x3f4>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3680:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3682:	add.w	r4, r1, r4, lsl #2
    3686:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3688:	beq.w	4c86 <loop+0x179a>
    368c:	adds	r4, r5, #1
    368e:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3692:	add	r5, r3
    3694:	ldr	r6, [pc, #588]	; (38e4 <loop+0x3f8>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3696:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3698:	add.w	r5, r1, r5, lsl #2
    369c:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    369e:	beq.w	4c7c <loop+0x1790>
    36a2:	adds	r5, r4, #1
    36a4:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    36a8:	add	r4, r3
    36aa:	ldr	r6, [pc, #572]	; (38e8 <loop+0x3fc>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    36ac:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    36ae:	add.w	r4, r1, r4, lsl #2
    36b2:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    36b4:	beq.w	4c72 <loop+0x1786>
    36b8:	adds	r4, r5, #1
    36ba:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    36be:	add	r5, r3
    36c0:	ldr	r6, [pc, #552]	; (38ec <loop+0x400>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    36c2:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    36c4:	add.w	r5, r1, r5, lsl #2
    36c8:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    36ca:	beq.w	4c68 <loop+0x177c>
    36ce:	adds	r5, r4, #1
    36d0:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    36d4:	add	r4, r3
    36d6:	ldr	r6, [pc, #536]	; (38f0 <loop+0x404>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    36d8:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    36da:	add.w	r4, r1, r4, lsl #2
    36de:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    36e0:	beq.w	4c5e <loop+0x1772>
    36e4:	adds	r4, r5, #1
    36e6:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    36ea:	add	r5, r3
    36ec:	ldr	r6, [pc, #516]	; (38f4 <loop+0x408>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    36ee:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    36f0:	add.w	r5, r1, r5, lsl #2
    36f4:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    36f6:	beq.w	4c54 <loop+0x1768>
    36fa:	adds	r5, r4, #1
    36fc:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3700:	add	r4, r3
    3702:	ldr	r6, [pc, #500]	; (38f8 <loop+0x40c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3704:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3706:	add.w	r4, r1, r4, lsl #2
    370a:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    370c:	beq.w	4c4a <loop+0x175e>
    3710:	adds	r4, r5, #1
    3712:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3716:	add	r5, r3
    3718:	ldr	r6, [pc, #480]	; (38fc <loop+0x410>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    371a:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    371c:	add.w	r5, r1, r5, lsl #2
    3720:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3722:	beq.w	4c40 <loop+0x1754>
    3726:	adds	r5, r4, #1
    3728:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    372c:	add	r4, r3
    372e:	ldr	r6, [pc, #464]	; (3900 <loop+0x414>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3730:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3732:	add.w	r4, r1, r4, lsl #2
    3736:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3738:	beq.w	4c36 <loop+0x174a>
    373c:	adds	r4, r5, #1
    373e:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3742:	add	r5, r3
    3744:	ldr	r6, [pc, #444]	; (3904 <loop+0x418>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3746:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3748:	add.w	r5, r1, r5, lsl #2
    374c:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    374e:	beq.w	4c2c <loop+0x1740>
    3752:	adds	r5, r4, #1
    3754:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3758:	add	r4, r3
    375a:	ldr	r6, [pc, #428]	; (3908 <loop+0x41c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    375c:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    375e:	add.w	r4, r1, r4, lsl #2
    3762:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3764:	beq.w	4c22 <loop+0x1736>
    3768:	adds	r4, r5, #1
    376a:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    376e:	add	r5, r3
    3770:	ldr	r6, [pc, #408]	; (390c <loop+0x420>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3772:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3774:	add.w	r5, r1, r5, lsl #2
    3778:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    377a:	beq.w	4c18 <loop+0x172c>
    377e:	adds	r5, r4, #1
    3780:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3784:	add	r4, r3
    3786:	ldr	r6, [pc, #392]	; (3910 <loop+0x424>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3788:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    378a:	add.w	r4, r1, r4, lsl #2
    378e:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3790:	beq.w	4c0e <loop+0x1722>
    3794:	adds	r4, r5, #1
    3796:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    379a:	add	r5, r3
    379c:	ldr	r6, [pc, #372]	; (3914 <loop+0x428>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    379e:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    37a0:	add.w	r5, r1, r5, lsl #2
    37a4:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    37a6:	beq.w	4c04 <loop+0x1718>
    37aa:	adds	r5, r4, #1
    37ac:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    37b0:	add	r4, r3
    37b2:	ldr	r6, [pc, #356]	; (3918 <loop+0x42c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    37b4:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    37b6:	add.w	r4, r1, r4, lsl #2
    37ba:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    37bc:	beq.w	4bfa <loop+0x170e>
    37c0:	adds	r4, r5, #1
    37c2:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    37c6:	add	r5, r3
    37c8:	ldr	r6, [pc, #336]	; (391c <loop+0x430>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    37ca:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    37cc:	add.w	r5, r1, r5, lsl #2
    37d0:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    37d2:	beq.w	4bf0 <loop+0x1704>
    37d6:	adds	r5, r4, #1
    37d8:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    37dc:	add	r4, r3
    37de:	ldr	r6, [pc, #320]	; (3920 <loop+0x434>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    37e0:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    37e2:	add.w	r4, r1, r4, lsl #2
    37e6:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    37e8:	beq.w	4be6 <loop+0x16fa>
    37ec:	adds	r4, r5, #1
    37ee:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    37f2:	add	r5, r3
    37f4:	ldr	r6, [pc, #300]	; (3924 <loop+0x438>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    37f6:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    37f8:	add.w	r5, r1, r5, lsl #2
    37fc:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    37fe:	beq.w	4bdc <loop+0x16f0>
    3802:	adds	r5, r4, #1
    3804:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3808:	add	r4, r3
    380a:	ldr	r6, [pc, #284]	; (3928 <loop+0x43c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    380c:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    380e:	add.w	r4, r1, r4, lsl #2
    3812:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3814:	beq.w	4bd2 <loop+0x16e6>
    3818:	adds	r4, r5, #1
    381a:	mul.w	r5, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    381e:	add	r5, r3
    3820:	ldr	r6, [pc, #264]	; (392c <loop+0x440>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3822:	cmp	r2, r4
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3824:	add.w	r5, r1, r5, lsl #2
    3828:	str	r6, [r5, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    382a:	beq.w	4bc8 <loop+0x16dc>
    382e:	adds	r5, r4, #1
    3830:	mul.w	r4, r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3834:	add	r4, r3
    3836:	ldr	r6, [pc, #248]	; (3930 <loop+0x444>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3838:	cmp	r2, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    383a:	add.w	r4, r1, r4, lsl #2
    383e:	str	r6, [r4, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3840:	beq.w	4bc0 <loop+0x16d4>
    3844:	mul.w	r0, r5, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3848:	add	r3, r0
    384a:	ldr	r4, [sp, #68]	; 0x44
    384c:	ldr	r6, [sp, #60]	; 0x3c
    384e:	add.w	r1, r1, r3, lsl #2
    3852:	ldr	r0, [pc, #224]	; (3934 <loop+0x448>)

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
  {
    m_xpr.coeffRef(0,0) = s;
    3854:	ldr	r3, [pc, #224]	; (3938 <loop+0x44c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3856:	cmp	r4, #1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3858:	str	r0, [r1, #0]

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
  {
    m_xpr.coeffRef(0,0) = s;
    385a:	str	r3, [r6, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    385c:	beq.w	4baa <loop+0x16be>
    3860:	ldr	r5, [sp, #64]	; 0x40
    3862:	cmp	r4, #2
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3864:	ldr	r1, [pc, #212]	; (393c <loop+0x450>)
    3866:	add.w	r3, r6, r5, lsl #2
    386a:	str	r1, [r3, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    386c:	beq.w	52f6 <loop+0x1e0a>
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3870:	add.w	r3, r6, r5, lsl #3
    3874:	ldr	r1, [pc, #200]	; (3940 <loop+0x454>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3876:	cmp	r4, #3
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3878:	str	r1, [r3, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    387a:	beq.w	52f2 <loop+0x1e06>
    387e:	movs	r0, #3
{
  typedef typename XprType::Scalar Scalar;

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
    3880:	movs	r3, #0
    3882:	adds	r1, r0, #1
    3884:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3888:	add	r0, r3
    388a:	ldr	r7, [pc, #184]	; (3944 <loop+0x458>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    388c:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    388e:	add.w	r0, r6, r0, lsl #2
    3892:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3894:	beq.w	4ba0 <loop+0x16b4>
    3898:	adds	r0, r1, #1
    389a:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    389e:	add	r1, r3
    38a0:	ldr	r7, [pc, #164]	; (3948 <loop+0x45c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    38a2:	cmp	r4, r0
    38a4:	b.n	394c <loop+0x460>
    38a6:	nop
    38a8:	.word	0x3ea6809d
    38ac:	.word	0x3ea36e2f
    38b0:	.word	0x3f8bf141
    38b4:	.word	0xbbded289
    38b8:	.word	0xbf8b67a1
    38bc:	.word	0xbfbeecc0
    38c0:	.word	0xbf414120
    38c4:	.word	0x3ea0346e
    38c8:	.word	0x3f8dfd8b
    38cc:	.word	0x3fc42c3d
    38d0:	.word	0x3d058794
    38d4:	.word	0xbf3e075f
    38d8:	.word	0x3faf65fe
    38dc:	.word	0xbf5d6a16
    38e0:	.word	0xbf5d1b71
    38e4:	.word	0xbf450b0f
    38e8:	.word	0x3f0d70a4
    38ec:	.word	0xbf87e282
    38f0:	.word	0xbfdb126f
    38f4:	.word	0xbcf69446
    38f8:	.word	0x3d9e83e4
    38fc:	.word	0x3ebe2824
    3900:	.word	0x3f8ce076
    3904:	.word	0x40166e98
    3908:	.word	0xbdd14e3c
    390c:	.word	0xbe28db8c
    3910:	.word	0xbf9b67a1
    3914:	.word	0xbe6703b0
    3918:	.word	0x3fc5a858
    391c:	.word	0xbf1d97f6
    3920:	.word	0xbe773190
    3924:	.word	0x3f20b0f2
    3928:	.word	0xbf8e872b
    392c:	.word	0x3f8f06f7
    3930:	.word	0x3dafec57
    3934:	.word	0x3f3f837b
    3938:	.word	0x3f50902e
    393c:	.word	0x3e8e978d
    3940:	.word	0x3f750b0f
    3944:	.word	0x3f4acd9f
    3948:	.word	0x3f2dbf48
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    394c:	add.w	r1, r6, r1, lsl #2
    3950:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3952:	beq.w	4b96 <loop+0x16aa>
    3956:	adds	r1, r0, #1
    3958:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    395c:	add	r0, r3
    395e:	ldr	r7, [pc, #872]	; (3cc8 <loop+0x7dc>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3960:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3962:	add.w	r0, r6, r0, lsl #2
    3966:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3968:	beq.w	4b8c <loop+0x16a0>
    396c:	adds	r0, r1, #1
    396e:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3972:	add	r1, r3
    3974:	ldr	r7, [pc, #852]	; (3ccc <loop+0x7e0>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3976:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3978:	add.w	r1, r6, r1, lsl #2
    397c:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    397e:	beq.w	4b82 <loop+0x1696>
    3982:	adds	r1, r0, #1
    3984:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3988:	add	r0, r3
    398a:	ldr	r7, [pc, #836]	; (3cd0 <loop+0x7e4>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    398c:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    398e:	add.w	r0, r6, r0, lsl #2
    3992:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3994:	beq.w	4b78 <loop+0x168c>
    3998:	adds	r0, r1, #1
    399a:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    399e:	add	r1, r3
    39a0:	ldr	r7, [pc, #816]	; (3cd4 <loop+0x7e8>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    39a2:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    39a4:	add.w	r1, r6, r1, lsl #2
    39a8:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    39aa:	beq.w	4b6e <loop+0x1682>
    39ae:	adds	r1, r0, #1
    39b0:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    39b4:	add	r0, r3
    39b6:	ldr	r7, [pc, #800]	; (3cd8 <loop+0x7ec>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    39b8:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    39ba:	add.w	r0, r6, r0, lsl #2
    39be:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    39c0:	beq.w	4b64 <loop+0x1678>
    39c4:	adds	r0, r1, #1
    39c6:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    39ca:	add	r1, r3
    39cc:	ldr	r7, [pc, #780]	; (3cdc <loop+0x7f0>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    39ce:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    39d0:	add.w	r1, r6, r1, lsl #2
    39d4:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    39d6:	beq.w	4b5a <loop+0x166e>
    39da:	adds	r1, r0, #1
    39dc:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    39e0:	add	r0, r3
    39e2:	ldr	r7, [pc, #764]	; (3ce0 <loop+0x7f4>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    39e4:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    39e6:	add.w	r0, r6, r0, lsl #2
    39ea:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    39ec:	beq.w	4b50 <loop+0x1664>
    39f0:	adds	r0, r1, #1
    39f2:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    39f6:	add	r1, r3
    39f8:	ldr	r7, [pc, #744]	; (3ce4 <loop+0x7f8>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    39fa:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    39fc:	add.w	r1, r6, r1, lsl #2
    3a00:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a02:	beq.w	4b46 <loop+0x165a>
    3a06:	adds	r1, r0, #1
    3a08:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a0c:	add	r0, r3
    3a0e:	ldr	r7, [pc, #728]	; (3ce8 <loop+0x7fc>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a10:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a12:	add.w	r0, r6, r0, lsl #2
    3a16:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a18:	beq.w	4b3c <loop+0x1650>
    3a1c:	adds	r0, r1, #1
    3a1e:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a22:	add	r1, r3
    3a24:	ldr	r7, [pc, #708]	; (3cec <loop+0x800>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a26:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a28:	add.w	r1, r6, r1, lsl #2
    3a2c:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a2e:	beq.w	4b32 <loop+0x1646>
    3a32:	adds	r1, r0, #1
    3a34:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a38:	add	r0, r3
    3a3a:	ldr	r7, [pc, #692]	; (3cf0 <loop+0x804>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a3c:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a3e:	add.w	r0, r6, r0, lsl #2
    3a42:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a44:	beq.w	4b28 <loop+0x163c>
    3a48:	adds	r0, r1, #1
    3a4a:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a4e:	add	r1, r3
    3a50:	ldr	r7, [pc, #672]	; (3cf4 <loop+0x808>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a52:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a54:	add.w	r1, r6, r1, lsl #2
    3a58:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a5a:	beq.w	4b1e <loop+0x1632>
    3a5e:	adds	r1, r0, #1
    3a60:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a64:	add	r0, r3
    3a66:	ldr	r7, [pc, #656]	; (3cf8 <loop+0x80c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a68:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a6a:	add.w	r0, r6, r0, lsl #2
    3a6e:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a70:	beq.w	4b14 <loop+0x1628>
    3a74:	adds	r0, r1, #1
    3a76:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a7a:	add	r1, r3
    3a7c:	ldr	r7, [pc, #636]	; (3cfc <loop+0x810>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a7e:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a80:	add.w	r1, r6, r1, lsl #2
    3a84:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a86:	beq.w	4b0a <loop+0x161e>
    3a8a:	adds	r1, r0, #1
    3a8c:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a90:	add	r0, r3
    3a92:	ldr	r7, [pc, #620]	; (3d00 <loop+0x814>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a94:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3a96:	add.w	r0, r6, r0, lsl #2
    3a9a:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3a9c:	beq.w	4b00 <loop+0x1614>
    3aa0:	adds	r0, r1, #1
    3aa2:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3aa6:	add	r1, r3
    3aa8:	ldr	r7, [pc, #600]	; (3d04 <loop+0x818>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3aaa:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3aac:	add.w	r1, r6, r1, lsl #2
    3ab0:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ab2:	beq.w	4af6 <loop+0x160a>
    3ab6:	adds	r1, r0, #1
    3ab8:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3abc:	add	r0, r3
    3abe:	ldr	r7, [pc, #584]	; (3d08 <loop+0x81c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ac0:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3ac2:	add.w	r0, r6, r0, lsl #2
    3ac6:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ac8:	beq.w	4aec <loop+0x1600>
    3acc:	adds	r0, r1, #1
    3ace:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3ad2:	add	r1, r3
    3ad4:	ldr	r7, [pc, #564]	; (3d0c <loop+0x820>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ad6:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3ad8:	add.w	r1, r6, r1, lsl #2
    3adc:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ade:	beq.w	4ae2 <loop+0x15f6>
    3ae2:	adds	r1, r0, #1
    3ae4:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3ae8:	add	r0, r3
    3aea:	ldr	r7, [pc, #548]	; (3d10 <loop+0x824>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3aec:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3aee:	add.w	r0, r6, r0, lsl #2
    3af2:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3af4:	beq.w	4ad8 <loop+0x15ec>
    3af8:	adds	r0, r1, #1
    3afa:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3afe:	add	r1, r3
    3b00:	ldr	r7, [pc, #528]	; (3d14 <loop+0x828>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b02:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b04:	add.w	r1, r6, r1, lsl #2
    3b08:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b0a:	beq.w	4ace <loop+0x15e2>
    3b0e:	adds	r1, r0, #1
    3b10:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b14:	add	r0, r3
    3b16:	ldr	r7, [pc, #512]	; (3d18 <loop+0x82c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b18:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b1a:	add.w	r0, r6, r0, lsl #2
    3b1e:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b20:	beq.w	4ac4 <loop+0x15d8>
    3b24:	adds	r0, r1, #1
    3b26:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b2a:	add	r1, r3
    3b2c:	ldr	r7, [pc, #492]	; (3d1c <loop+0x830>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b2e:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b30:	add.w	r1, r6, r1, lsl #2
    3b34:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b36:	beq.w	4aba <loop+0x15ce>
    3b3a:	adds	r1, r0, #1
    3b3c:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b40:	add	r0, r3
    3b42:	ldr	r7, [pc, #476]	; (3d20 <loop+0x834>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b44:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b46:	add.w	r0, r6, r0, lsl #2
    3b4a:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b4c:	beq.w	4ab0 <loop+0x15c4>
    3b50:	adds	r0, r1, #1
    3b52:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b56:	add	r1, r3
    3b58:	ldr	r7, [pc, #456]	; (3d24 <loop+0x838>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b5a:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b5c:	add.w	r1, r6, r1, lsl #2
    3b60:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b62:	beq.w	4aa6 <loop+0x15ba>
    3b66:	adds	r1, r0, #1
    3b68:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b6c:	add	r0, r3
    3b6e:	ldr	r7, [pc, #440]	; (3d28 <loop+0x83c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b70:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b72:	add.w	r0, r6, r0, lsl #2
    3b76:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b78:	beq.w	4a9c <loop+0x15b0>
    3b7c:	adds	r0, r1, #1
    3b7e:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b82:	add	r1, r3
    3b84:	ldr	r7, [pc, #420]	; (3d2c <loop+0x840>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b86:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b88:	add.w	r1, r6, r1, lsl #2
    3b8c:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b8e:	beq.w	4a92 <loop+0x15a6>
    3b92:	adds	r1, r0, #1
    3b94:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b98:	add	r0, r3
    3b9a:	ldr	r7, [pc, #404]	; (3d30 <loop+0x844>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3b9c:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3b9e:	add.w	r0, r6, r0, lsl #2
    3ba2:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ba4:	beq.w	4a88 <loop+0x159c>
    3ba8:	adds	r0, r1, #1
    3baa:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3bae:	add	r1, r3
    3bb0:	ldr	r7, [pc, #384]	; (3d34 <loop+0x848>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3bb2:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3bb4:	add.w	r1, r6, r1, lsl #2
    3bb8:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3bba:	beq.w	4a7e <loop+0x1592>
    3bbe:	adds	r1, r0, #1
    3bc0:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3bc4:	add	r0, r3
    3bc6:	ldr	r7, [pc, #368]	; (3d38 <loop+0x84c>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3bc8:	cmp	r4, r1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3bca:	add.w	r0, r6, r0, lsl #2
    3bce:	str	r7, [r0, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3bd0:	beq.w	4a74 <loop+0x1588>
    3bd4:	adds	r0, r1, #1
    3bd6:	mul.w	r1, r1, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3bda:	add	r1, r3
    3bdc:	ldr	r7, [pc, #348]	; (3d3c <loop+0x850>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3bde:	cmp	r4, r0
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3be0:	add.w	r1, r6, r1, lsl #2
    3be4:	str	r7, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3be6:	beq.w	4a6c <loop+0x1580>
    3bea:	mul.w	r0, r0, r5
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3bee:	add	r3, r0
    3bf0:	ldr	r0, [sp, #80]	; 0x50
    3bf2:	ldr	r1, [sp, #72]	; 0x48
    3bf4:	add.w	r6, r6, r3, lsl #2
    3bf8:	ldr	r7, [pc, #324]	; (3d40 <loop+0x854>)

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
  {
    m_xpr.coeffRef(0,0) = s;
    3bfa:	ldr	r3, [pc, #328]	; (3d44 <loop+0x858>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3bfc:	cmp	r0, #1
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3bfe:	str	r7, [r6, #0]

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
  {
    m_xpr.coeffRef(0,0) = s;
    3c00:	str	r3, [r1, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c02:	beq.w	4a50 <loop+0x1564>
    3c06:	ldr	r6, [sp, #76]	; 0x4c
    3c08:	cmp	r0, #2
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c0a:	ldr	r7, [pc, #316]	; (3d48 <loop+0x85c>)
    3c0c:	add.w	r3, r1, r6, lsl #2
    3c10:	str	r7, [r3, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c12:	beq.w	52e4 <loop+0x1df8>
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c16:	add.w	r3, r1, r6, lsl #3
    3c1a:	ldr	r7, [pc, #304]	; (3d4c <loop+0x860>)

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c1c:	cmp	r0, #3
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c1e:	str	r7, [r3, #0]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c20:	beq.w	52de <loop+0x1df2>
    3c24:	mov.w	lr, #3
{
  typedef typename XprType::Scalar Scalar;

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
    3c28:	movs	r3, #0
    3c2a:	add.w	r7, lr, #1
    3c2e:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c32:	add	lr, r3
    3c34:	ldr.w	ip, [pc, #280]	; 3d50 <loop+0x864>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c38:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c3a:	add.w	lr, r1, lr, lsl #2
    3c3e:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c42:	beq.w	4a44 <loop+0x1558>
    3c46:	add.w	lr, r7, #1
    3c4a:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c4e:	add	r7, r3
    3c50:	ldr.w	ip, [pc, #256]	; 3d54 <loop+0x868>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c54:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c56:	add.w	r7, r1, r7, lsl #2
    3c5a:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c5e:	beq.w	4a38 <loop+0x154c>
    3c62:	add.w	r7, lr, #1
    3c66:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c6a:	add	lr, r3
    3c6c:	ldr.w	ip, [pc, #232]	; 3d58 <loop+0x86c>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c70:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c72:	add.w	lr, r1, lr, lsl #2
    3c76:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c7a:	beq.w	4a2c <loop+0x1540>
    3c7e:	add.w	lr, r7, #1
    3c82:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c86:	add	r7, r3
    3c88:	ldr.w	ip, [pc, #208]	; 3d5c <loop+0x870>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c8c:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3c8e:	add.w	r7, r1, r7, lsl #2
    3c92:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3c96:	beq.w	4a20 <loop+0x1534>
    3c9a:	add.w	r7, lr, #1
    3c9e:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3ca2:	add	lr, r3
    3ca4:	ldr.w	ip, [pc, #184]	; 3d60 <loop+0x874>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ca8:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3caa:	add.w	lr, r1, lr, lsl #2
    3cae:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3cb2:	beq.w	4a14 <loop+0x1528>
    3cb6:	add.w	lr, r7, #1
    3cba:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3cbe:	add	r7, r3
    3cc0:	ldr.w	ip, [pc, #160]	; 3d64 <loop+0x878>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3cc4:	cmp	r0, lr
    3cc6:	b.n	3d68 <loop+0x87c>
    3cc8:	.word	0x3f34bc6a
    3ccc:	.word	0x3f67e282
    3cd0:	.word	0x3f0c01a3
    3cd4:	.word	0x3ef88659
    3cd8:	.word	0x3f75a1cb
    3cdc:	.word	0x3f41f8a1
    3ce0:	.word	0x3d0240b8
    3ce4:	.word	0x3e020c4a
    3ce8:	.word	0x3f751eb8
    3cec:	.word	0x3f4ce076
    3cf0:	.word	0x3f27dbf5
    3cf4:	.word	0x3f3e3bcd
    3cf8:	.word	0x3e8dc5d6
    3cfc:	.word	0x3f69d495
    3d00:	.word	0x3f7703b0
    3d04:	.word	0x3e114e3c
    3d08:	.word	0x3d123a2a
    3d0c:	.word	0x3ec8ce70
    3d10:	.word	0x3d3d3c36
    3d14:	.word	0x3f21e4f7
    3d18:	.word	0x3e2161e5
    3d1c:	.word	0x3ed7f62b
    3d20:	.word	0x3f595e9e
    3d24:	.word	0x3f27ced9
    3d28:	.word	0x3dc6dc5d
    3d2c:	.word	0x3dc7ae14
    3d30:	.word	0x3f78793e
    3d34:	.word	0x3f6a6b51
    3d38:	.word	0x3f6f1aa0
    3d3c:	.word	0x3e2f4f0e
    3d40:	.word	0x3f52d0e5
    3d44:	.word	0x3ea6809d
    3d48:	.word	0x3ea36e2f
    3d4c:	.word	0x3f8bf141
    3d50:	.word	0xbbded289
    3d54:	.word	0xbf8b67a1
    3d58:	.word	0xbfbeecc0
    3d5c:	.word	0xbf414120
    3d60:	.word	0x3ea0346e
    3d64:	.word	0x3f8dfd8b
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3d68:	add.w	r7, r1, r7, lsl #2
    3d6c:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3d70:	beq.w	4a08 <loop+0x151c>
    3d74:	add.w	r7, lr, #1
    3d78:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3d7c:	add	lr, r3
    3d7e:	ldr.w	ip, [pc, #1056]	; 41a0 <loop+0xcb4>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3d82:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3d84:	add.w	lr, r1, lr, lsl #2
    3d88:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3d8c:	beq.w	49fc <loop+0x1510>
    3d90:	add.w	lr, r7, #1
    3d94:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3d98:	add	r7, r3
    3d9a:	ldr.w	ip, [pc, #1032]	; 41a4 <loop+0xcb8>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3d9e:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3da0:	add.w	r7, r1, r7, lsl #2
    3da4:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3da8:	beq.w	49f0 <loop+0x1504>
    3dac:	add.w	r7, lr, #1
    3db0:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3db4:	add	lr, r3
    3db6:	ldr.w	ip, [pc, #1008]	; 41a8 <loop+0xcbc>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3dba:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3dbc:	add.w	lr, r1, lr, lsl #2
    3dc0:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3dc4:	beq.w	49e4 <loop+0x14f8>
    3dc8:	add.w	lr, r7, #1
    3dcc:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3dd0:	add	r7, r3
    3dd2:	ldr.w	ip, [pc, #984]	; 41ac <loop+0xcc0>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3dd6:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3dd8:	add.w	r7, r1, r7, lsl #2
    3ddc:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3de0:	beq.w	49d8 <loop+0x14ec>
    3de4:	add.w	r7, lr, #1
    3de8:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3dec:	add	lr, r3
    3dee:	ldr.w	ip, [pc, #960]	; 41b0 <loop+0xcc4>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3df2:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3df4:	add.w	lr, r1, lr, lsl #2
    3df8:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3dfc:	beq.w	49cc <loop+0x14e0>
    3e00:	add.w	lr, r7, #1
    3e04:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e08:	add	r7, r3
    3e0a:	ldr.w	ip, [pc, #936]	; 41b4 <loop+0xcc8>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e0e:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e10:	add.w	r7, r1, r7, lsl #2
    3e14:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e18:	beq.w	49c0 <loop+0x14d4>
    3e1c:	add.w	r7, lr, #1
    3e20:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e24:	add	lr, r3
    3e26:	ldr.w	ip, [pc, #912]	; 41b8 <loop+0xccc>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e2a:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e2c:	add.w	lr, r1, lr, lsl #2
    3e30:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e34:	beq.w	49b4 <loop+0x14c8>
    3e38:	add.w	lr, r7, #1
    3e3c:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e40:	add	r7, r3
    3e42:	ldr.w	ip, [pc, #888]	; 41bc <loop+0xcd0>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e46:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e48:	add.w	r7, r1, r7, lsl #2
    3e4c:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e50:	beq.w	49a8 <loop+0x14bc>
    3e54:	add.w	r7, lr, #1
    3e58:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e5c:	add	lr, r3
    3e5e:	ldr.w	ip, [pc, #864]	; 41c0 <loop+0xcd4>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e62:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e64:	add.w	lr, r1, lr, lsl #2
    3e68:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e6c:	beq.w	499c <loop+0x14b0>
    3e70:	add.w	lr, r7, #1
    3e74:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e78:	add	r7, r3
    3e7a:	ldr.w	ip, [pc, #840]	; 41c4 <loop+0xcd8>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e7e:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e80:	add.w	r7, r1, r7, lsl #2
    3e84:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e88:	beq.w	4990 <loop+0x14a4>
    3e8c:	add.w	r7, lr, #1
    3e90:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e94:	add	lr, r3
    3e96:	ldr.w	ip, [pc, #816]	; 41c8 <loop+0xcdc>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3e9a:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3e9c:	add.w	lr, r1, lr, lsl #2
    3ea0:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ea4:	beq.w	4984 <loop+0x1498>
    3ea8:	add.w	lr, r7, #1
    3eac:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3eb0:	add	r7, r3
    3eb2:	ldr.w	ip, [pc, #792]	; 41cc <loop+0xce0>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3eb6:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3eb8:	add.w	r7, r1, r7, lsl #2
    3ebc:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ec0:	beq.w	4978 <loop+0x148c>
    3ec4:	add.w	r7, lr, #1
    3ec8:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3ecc:	add	lr, r3
    3ece:	ldr.w	ip, [pc, #768]	; 41d0 <loop+0xce4>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ed2:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3ed4:	add.w	lr, r1, lr, lsl #2
    3ed8:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3edc:	beq.w	496c <loop+0x1480>
    3ee0:	add.w	lr, r7, #1
    3ee4:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3ee8:	add	r7, r3
    3eea:	ldr.w	ip, [pc, #744]	; 41d4 <loop+0xce8>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3eee:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3ef0:	add.w	r7, r1, r7, lsl #2
    3ef4:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ef8:	beq.w	4960 <loop+0x1474>
    3efc:	add.w	r7, lr, #1
    3f00:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f04:	add	lr, r3
    3f06:	ldr.w	ip, [pc, #720]	; 41d8 <loop+0xcec>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f0a:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f0c:	add.w	lr, r1, lr, lsl #2
    3f10:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f14:	beq.w	4954 <loop+0x1468>
    3f18:	add.w	lr, r7, #1
    3f1c:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f20:	add	r7, r3
    3f22:	ldr.w	ip, [pc, #696]	; 41dc <loop+0xcf0>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f26:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f28:	add.w	r7, r1, r7, lsl #2
    3f2c:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f30:	beq.w	4948 <loop+0x145c>
    3f34:	add.w	r7, lr, #1
    3f38:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f3c:	add	lr, r3
    3f3e:	ldr.w	ip, [pc, #672]	; 41e0 <loop+0xcf4>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f42:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f44:	add.w	lr, r1, lr, lsl #2
    3f48:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f4c:	beq.w	493c <loop+0x1450>
    3f50:	add.w	lr, r7, #1
    3f54:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f58:	add	r7, r3
    3f5a:	ldr.w	ip, [pc, #648]	; 41e4 <loop+0xcf8>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f5e:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f60:	add.w	r7, r1, r7, lsl #2
    3f64:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f68:	beq.w	4930 <loop+0x1444>
    3f6c:	add.w	r7, lr, #1
    3f70:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f74:	add	lr, r3
    3f76:	ldr.w	ip, [pc, #624]	; 41e8 <loop+0xcfc>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f7a:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f7c:	add.w	lr, r1, lr, lsl #2
    3f80:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f84:	beq.w	4924 <loop+0x1438>
    3f88:	add.w	lr, r7, #1
    3f8c:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f90:	add	r7, r3
    3f92:	ldr.w	ip, [pc, #600]	; 41ec <loop+0xd00>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3f96:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3f98:	add.w	r7, r1, r7, lsl #2
    3f9c:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3fa0:	beq.w	4918 <loop+0x142c>
    3fa4:	add.w	r7, lr, #1
    3fa8:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3fac:	add	lr, r3
    3fae:	ldr.w	ip, [pc, #576]	; 41f0 <loop+0xd04>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3fb2:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3fb4:	add.w	lr, r1, lr, lsl #2
    3fb8:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3fbc:	beq.w	490c <loop+0x1420>
    3fc0:	add.w	lr, r7, #1
    3fc4:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3fc8:	add	r7, r3
    3fca:	ldr.w	ip, [pc, #552]	; 41f4 <loop+0xd08>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3fce:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3fd0:	add.w	r7, r1, r7, lsl #2
    3fd4:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3fd8:	beq.w	4900 <loop+0x1414>
    3fdc:	add.w	r7, lr, #1
    3fe0:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3fe4:	add	lr, r3
    3fe6:	ldr.w	ip, [pc, #528]	; 41f8 <loop+0xd0c>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3fea:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    3fec:	add.w	lr, r1, lr, lsl #2
    3ff0:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    3ff4:	beq.w	48f4 <loop+0x1408>
    3ff8:	add.w	lr, r7, #1
    3ffc:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    4000:	add	r7, r3
    4002:	ldr.w	ip, [pc, #504]	; 41fc <loop+0xd10>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    4006:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    4008:	add.w	r7, r1, r7, lsl #2
    400c:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    4010:	beq.w	48e4 <loop+0x13f8>
    4014:	add.w	r7, lr, #1
    4018:	mul.w	lr, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    401c:	add	lr, r3
    401e:	ldr.w	ip, [pc, #480]	; 4200 <loop+0xd14>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    4022:	cmp	r0, r7
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    4024:	add.w	lr, r1, lr, lsl #2
    4028:	str.w	ip, [lr]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    402c:	beq.w	48d8 <loop+0x13ec>
    4030:	add.w	lr, r7, #1
    4034:	mul.w	r7, r7, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    4038:	add	r7, r3
    403a:	ldr.w	ip, [pc, #456]	; 4204 <loop+0xd18>

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    403e:	cmp	r0, lr
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    4040:	add.w	r7, r1, r7, lsl #2
    4044:	str.w	ip, [r7]

  /* inserts a scalar value in the target matrix */
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    4048:	beq.w	48c6 <loop+0x13da>
    404c:	mul.w	r6, lr, r6
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    4050:	add	r3, r6
    4052:	ldr	r7, [pc, #328]	; (419c <loop+0xcb0>)
  
  EIGEN_DEVICE_FUNC evaluator()
    : m_data(0),
      m_outerStride(IsVectorAtCompileTime  ? 0 
                                           : int(IsRowMajor) ? ColsAtCompileTime 
                                           : RowsAtCompileTime)
    4054:	movs	r6, #0
    4056:	mov.w	r0, #4294967295
    405a:	add.w	r1, r1, r3, lsl #2
    405e:	str	r7, [r1, #0]
    4060:	str	r6, [sp, #176]	; 0xb0
    4062:	str	r6, [sp, #184]	; 0xb8
    4064:	str	r6, [sp, #188]	; 0xbc
    4066:	str	r6, [sp, #192]	; 0xc0
    4068:	str	r0, [sp, #180]	; 0xb4
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
    406a:	cbz	r5, 40a8 <loop+0xbbc>
    406c:	mvn.w	r3, #2147483648	; 0x80000000
    4070:	sdiv	r3, r3, r5
    4074:	cmp	r3, r5
    4076:	bge.w	487c <loop+0x1390>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    407a:	bl	6d9c <operator new(unsigned int)>
      m_rows = rows;
      m_cols = cols;
    }
    EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
    {
      if(size != m_rows*m_cols)
    407e:	ldr	r2, [sp, #188]	; 0xbc
    4080:	ldr	r3, [sp, #192]	; 0xc0
        Index size = rows*cols;
        bool size_changed = size != this->size();
        m_storage.resize(size, rows, cols);
        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
      #else
        m_storage.resize(rows*cols, rows, cols);
    4082:	mul.w	r6, r5, r5
    4086:	mul.w	r3, r3, r2
    408a:	cmp	r6, r3
    408c:	beq.w	420c <loop+0xd20>
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
    4090:	ldr	r3, [sp, #184]	; 0xb8
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    4092:	cbz	r3, 409c <loop+0xbb0>
    4094:	ldr.w	r0, [r3, #-4]
    4098:	bl	7248 <free>
        if (size)
    409c:	cmp	r6, #0
    409e:	bne.w	4880 <loop+0x1394>
    40a2:	ldr	r2, [sp, #56]	; 0x38
    40a4:	ldr	r4, [sp, #68]	; 0x44
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
    40a6:	str	r6, [sp, #184]	; 0xb8
  typedef generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode> lazyproduct;

  template<typename Dst>
  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
  {
    if((rhs.rows()+dst.rows()+dst.cols())<20 && rhs.rows()>0)
    40a8:	add.w	r3, r4, r5, lsl #1
  {
    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  }
  
  EIGEN_DEVICE_FUNC explicit evaluator(const PlainObjectType& m)
    : m_data(m.data()), m_outerStride(IsVectorAtCompileTime ? 0 : m.outerStride()) 
    40ac:	movs	r1, #0
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    40ae:	str	r5, [sp, #188]	; 0xbc
    40b0:	cmp	r3, #19
      m_cols = cols;
    40b2:	str	r5, [sp, #192]	; 0xc0
    40b4:	str	r5, [sp, #180]	; 0xb4
    40b6:	str	r1, [sp, #176]	; 0xb0
    40b8:	bgt.w	423a <loop+0xd4e>
    40bc:	cmp	r4, r1
    40be:	ble.w	423a <loop+0xd4e>
{
    T *m_data;
    Index m_rows;
    Index m_cols;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0), m_cols(0) {}
    40c2:	movs	r3, #0
    40c4:	ldr.w	r8, [sp, #64]	; 0x40
    40c8:	str	r3, [sp, #204]	; 0xcc
    40ca:	str	r3, [sp, #208]	; 0xd0
    40cc:	str	r3, [sp, #212]	; 0xd4
    40ce:	cmp.w	r8, #0
    40d2:	bne.n	40e0 <loop+0xbf4>
    40d4:	subs	r1, r2, r3
    40d6:	it	ne
    40d8:	movne	r1, #1
    40da:	cmp	r1, #0
    40dc:	beq.w	4fca <loop+0x1ade>
      dst.resize(dstRows, dstCols);
    40e0:	add	r4, sp, #204	; 0xcc
    40e2:	mov	r1, r8
    40e4:	mov	r0, r4
    40e6:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    40ea:	ldr	r3, [sp, #212]	; 0xd4
    40ec:	ldr.w	ip, [sp, #208]	; 0xd0
    40f0:	ldr	r2, [sp, #52]	; 0x34
    40f2:	mov	r1, r3
    40f4:	str	r3, [sp, #32]
    40f6:	add.w	r3, r2, ip
    40fa:	ldr	r0, [sp, #56]	; 0x38
    40fc:	add	r3, r1
    40fe:	str	r0, [sp, #36]	; 0x24
    4100:	cmp	r3, #19
    4102:	bgt.w	4e24 <loop+0x1938>
    4106:	cmp	r2, #0
    4108:	ble.w	4e24 <loop+0x1938>
    410c:	ldr	r3, [sp, #32]
    410e:	ldr	r2, [sp, #36]	; 0x24
    4110:	ldr.w	r8, [sp, #64]	; 0x40
    4114:	cmp	r3, r2
    4116:	beq.w	4fea <loop+0x1afe>
    dst.resize(dstRows, dstCols);
    411a:	mov	r1, r8
    411c:	ldr	r2, [sp, #36]	; 0x24
    411e:	mov	r0, r4
    4120:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    4124:	ldr	r3, [sp, #212]	; 0xd4
    4126:	ldr.w	ip, [sp, #208]	; 0xd0
    412a:	str	r3, [sp, #32]
    412c:	ldr.w	r8, [sp, #64]	; 0x40
    4130:	ldr	r3, [sp, #56]	; 0x38
    4132:	str	r3, [sp, #36]	; 0x24
    4134:	ldr	r3, [sp, #204]	; 0xcc
    4136:	str	r3, [sp, #44]	; 0x2c
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    4138:	ldr	r3, [sp, #32]
    413a:	cmp	r3, #0
    413c:	ble.w	4e4c <loop+0x1960>
    4140:	mov.w	sl, #0
    4144:	ldr	r6, [sp, #60]	; 0x3c
    4146:	mov.w	r0, r8, lsl #2
    414a:	str.w	r8, [sp, #40]	; 0x28
    414e:	mov	r9, sl
    4150:	add.w	lr, r6, ip, lsl #2
    4154:	ldr.w	r8, [sp, #44]	; 0x2c
      for(Index inner = 0; inner < kernel.innerSize(); ++inner) {
    4158:	cmp.w	ip, #0
    415c:	ble.n	4188 <loop+0xc9c>
    415e:	ldr	r7, [sp, #52]	; 0x34
    4160:	add.w	r5, r8, sl, lsl #2
    4164:	ldr	r3, [sp, #48]	; 0x30
    4166:	mov	r4, r6
    4168:	mul.w	fp, r7, r9
    416c:	add.w	fp, r3, fp, lsl #2
    4170:	add.w	r1, fp, r7, lsl #2
  */
template<typename Derived>
EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
DenseBase<Derived>::sum() const
{
  if(SizeAtCompileTime==0 || (SizeAtCompileTime==Dynamic && size()==0))
    4174:	cmp	r7, #0
    4176:	bne.w	4ffe <loop+0x1b12>
    return Scalar(0);
    417a:	vldr	s15, [pc, #140]	; 4208 <loop+0xd1c>
    417e:	adds	r4, #4
    4180:	vstmia	r5!, {s15}
    4184:	cmp	r4, lr
    4186:	bne.n	4174 <loop+0xc88>
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    4188:	add.w	r9, r9, #1
    418c:	ldr	r3, [sp, #32]
    418e:	add	sl, ip
    4190:	cmp	r9, r3
    4192:	bne.n	4158 <loop+0xc6c>
    4194:	ldr.w	r8, [sp, #40]	; 0x28
    4198:	b.w	4e4e <loop+0x1962>
    419c:	.word	0x3f3f837b
    41a0:	.word	0x3fc42c3d
    41a4:	.word	0x3d058794
    41a8:	.word	0xbf3e075f
    41ac:	.word	0x3faf65fe
    41b0:	.word	0xbf5d6a16
    41b4:	.word	0xbf5d1b71
    41b8:	.word	0xbf450b0f
    41bc:	.word	0x3f0d70a4
    41c0:	.word	0xbf87e282
    41c4:	.word	0xbfdb126f
    41c8:	.word	0xbcf69446
    41cc:	.word	0x3d9e83e4
    41d0:	.word	0x3ebe2824
    41d4:	.word	0x3f8ce076
    41d8:	.word	0x40166e98
    41dc:	.word	0xbdd14e3c
    41e0:	.word	0xbe28db8c
    41e4:	.word	0xbf9b67a1
    41e8:	.word	0xbe6703b0
    41ec:	.word	0x3fc5a858
    41f0:	.word	0xbf1d97f6
    41f4:	.word	0xbe773190
    41f8:	.word	0x3f20b0f2
    41fc:	.word	0xbf8e872b
    4200:	.word	0x3f8f06f7
    4204:	.word	0x3dafec57
    4208:	.word	0x00000000
    420c:	ldr	r4, [sp, #68]	; 0x44
    420e:	ldr	r3, [sp, #184]	; 0xb8
    4210:	add.w	r2, r4, r5, lsl #1
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
        else
          m_data = 0;
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    4214:	str	r5, [sp, #188]	; 0xbc
      m_cols = cols;
    4216:	str	r5, [sp, #192]	; 0xc0
    4218:	cmp	r2, #19
    421a:	str	r5, [sp, #180]	; 0xb4
    421c:	str	r3, [sp, #176]	; 0xb0
    421e:	bgt.n	4226 <loop+0xd3a>
    4220:	cmp	r4, #0
    4222:	bgt.w	48c0 <loop+0x13d4>
struct dense_assignment_loop<Kernel, LinearTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
  {
    const Index size = kernel.size();
    for(Index i = 0; i < size; ++i)
    4226:	cmp	r6, #0
    4228:	ble.n	4238 <loop+0xd4c>
    422a:	lsls	r6, r6, #2
    422c:	movs	r1, #0
    422e:	adds	r2, r3, r6
    4230:	str.w	r1, [r3], #4
    4234:	cmp	r3, r2
    4236:	bne.n	4230 <loop+0xd44>
    4238:	ldr	r2, [sp, #56]	; 0x38

  template<typename Dest>
  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
  {
    eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
    if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
    423a:	cmp	r2, #0
    423c:	bne.w	4718 <loop+0x122c>
    4240:	ldr	r1, [sp, #76]	; 0x4c
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    4242:	ldr	r2, [sp, #88]	; 0x58
    4244:	ldr	r3, [sp, #72]	; 0x48
    4246:	cmp	r1, r2
    4248:	str	r1, [sp, #200]	; 0xc8
    424a:	str	r3, [sp, #196]	; 0xc4
    424c:	ldr	r3, [sp, #80]	; 0x50
    424e:	beq.w	48ce <loop+0x13e2>
    dst.resize(dstRows, dstCols);
    4252:	mov	r2, r3
    4254:	add	r0, sp, #84	; 0x54
    4256:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    425a:	ldr	r1, [sp, #88]	; 0x58
    425c:	ldr	r2, [sp, #92]	; 0x5c
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    425e:	cmp	r2, #0
    4260:	ldr.w	fp, [sp, #84]	; 0x54
    4264:	ble.n	42b8 <loop+0xdcc>
    4266:	mov.w	lr, #0
    426a:	ldr	r6, [sp, #180]	; 0xb4
    426c:	ldr.w	r9, [sp, #196]	; 0xc4
    4270:	lsls	r6, r6, #2
    4272:	mov	r7, lr
    4274:	mov	ip, lr
    4276:	ldr.w	r8, [sp, #176]	; 0xb0
    427a:	ldr.w	sl, [sp, #200]	; 0xc8
      for(Index inner = 0; inner < kernel.innerSize(); ++inner) {
    427e:	cmp	r1, #0
    4280:	ble.n	42a8 <loop+0xdbc>
    4282:	adds	r5, r7, r1
    4284:	add.w	r0, r9, r7, lsl #2
    4288:	add.w	r4, fp, lr, lsl #2
    428c:	mov	r3, r8
    428e:	add.w	r5, r9, r5, lsl #2
    4292:	vldmia	r0!, {s15}
    4296:	vldr	s14, [r3]
    429a:	add	r3, r6
    429c:	cmp	r0, r5
    429e:	vadd.f32	s15, s14, s15
    42a2:	vstmia	r4!, {s15}
    42a6:	bne.n	4292 <loop+0xda6>
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    42a8:	add.w	ip, ip, #1
    42ac:	add.w	r8, r8, #4
    42b0:	add	r7, sl
    42b2:	add	lr, r1
    42b4:	cmp	ip, r2
    42b6:	bne.n	427e <loop+0xd92>
      swap(m_rows, other.m_rows);
      swap(m_cols, other.m_cols);
      return *this;
    }
#endif
    EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols); }
    42b8:	ldr	r3, [sp, #184]	; 0xb8
    42ba:	cbz	r3, 42c6 <loop+0xdda>
    42bc:	ldr.w	r0, [r3, #-4]
    42c0:	bl	7248 <free>
    42c4:	ldr	r2, [sp, #92]	; 0x5c
    typedef typename internal::ref_selector<Lhs>::type LhsNested;
    typedef typename internal::ref_selector<Rhs>::type RhsNested;
    typedef typename internal::remove_all<LhsNested>::type LhsNestedCleaned;
    typedef typename internal::remove_all<RhsNested>::type RhsNestedCleaned;

    EIGEN_DEVICE_FUNC Product(const Lhs& lhs, const Rhs& rhs) : m_lhs(lhs), m_rhs(rhs)
    42c6:	add	r0, sp, #48	; 0x30
{
    T *m_data;
    Index m_rows;
    Index m_cols;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0), m_cols(0) {}
    42c8:	movs	r3, #0
    42ca:	ldr	r1, [sp, #52]	; 0x34
    42cc:	str	r0, [sp, #120]	; 0x78
    42ce:	add	r0, sp, #60	; 0x3c
    42d0:	str	r3, [sp, #132]	; 0x84
    42d2:	str	r0, [sp, #124]	; 0x7c
    42d4:	add	r0, sp, #84	; 0x54
    42d6:	str	r3, [sp, #136]	; 0x88
    42d8:	str	r0, [sp, #128]	; 0x80
    42da:	str	r3, [sp, #140]	; 0x8c
  static EIGEN_STRONG_INLINE
  void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    42dc:	cbnz	r1, 42ea <loop+0xdfe>
    42de:	subs	r0, r2, r3
    42e0:	it	ne
    42e2:	movne	r0, #1
    42e4:	cmp	r0, #0
    42e6:	beq.w	4874 <loop+0x1388>
      dst.resize(dstRows, dstCols);
    42ea:	add	r0, sp, #132	; 0x84
    42ec:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    42f0:	ldr	r6, [sp, #128]	; 0x80
    42f2:	ldr	r1, [sp, #136]	; 0x88
    42f4:	ldr	r2, [sp, #140]	; 0x8c
    42f6:	ldr	r0, [r6, #4]
  typedef generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode> lazyproduct;

  template<typename Dst>
  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
  {
    if((rhs.rows()+dst.rows()+dst.cols())<20 && rhs.rows()>0)
    42f8:	adds	r3, r0, r1
    42fa:	add	r3, r2
    42fc:	cmp	r3, #19
    42fe:	bgt.w	4526 <loop+0x103a>
    4302:	cmp	r0, #0
    4304:	ble.w	4526 <loop+0x103a>
    4308:	add	r1, sp, #120	; 0x78
    430a:	movs	r3, #0
    430c:	add	r2, sp, #144	; 0x90
    430e:	ldr	r4, [sp, #128]	; 0x80
    4310:	str	r3, [sp, #208]	; 0xd0
    4312:	str	r3, [sp, #212]	; 0xd4
    4314:	str	r4, [sp, #152]	; 0x98
    4316:	str	r3, [sp, #204]	; 0xcc
    4318:	ldmia	r1, {r0, r1}
    431a:	stmia.w	r2, {r0, r1}
    431e:	ldr	r1, [r0, #4]
    4320:	mov	r7, r0
    explicit inline Transpose(MatrixType& matrix) : m_matrix(matrix) {}

    EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Transpose)

    EIGEN_DEVICE_FUNC inline Index rows() const { return m_matrix.cols(); }
    EIGEN_DEVICE_FUNC inline Index cols() const { return m_matrix.rows(); }
    4322:	ldr	r6, [sp, #148]	; 0x94
    4324:	ldr	r2, [r6, #4]
  static EIGEN_STRONG_INLINE
  void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    4326:	cbnz	r1, 4334 <loop+0xe48>
    4328:	subs	r3, r2, r3
    432a:	it	ne
    432c:	movne	r3, #1
    432e:	cmp	r3, #0
    4330:	beq.w	4fe2 <loop+0x1af6>
      dst.resize(dstRows, dstCols);
    4334:	add	r0, sp, #204	; 0xcc
    4336:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    433a:	ldr	r3, [sp, #208]	; 0xd0
    433c:	ldr	r7, [sp, #144]	; 0x90
    433e:	str	r3, [sp, #32]
    4340:	ldr	r6, [sp, #148]	; 0x94
    4342:	ldr	r3, [sp, #212]	; 0xd4
    4344:	str	r3, [sp, #36]	; 0x24
    4346:	ldr	r2, [r6, #8]
    4348:	ldr	r3, [sp, #32]
    434a:	ldr	r1, [sp, #36]	; 0x24
    434c:	adds	r3, r2, r3
    434e:	add	r3, r1
    4350:	cmp	r3, #19
    4352:	bgt.w	4d38 <loop+0x184c>
    4356:	cmp	r2, #0
    4358:	ble.w	4d38 <loop+0x184c>
    435c:	ldr	r1, [r7, #4]
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    435e:	ldr	r3, [sp, #32]
    4360:	ldr	r2, [r6, #4]
    4362:	cmp	r1, r3
    4364:	bne.n	436c <loop+0xe80>
    4366:	ldr	r3, [sp, #36]	; 0x24
    4368:	cmp	r2, r3
    436a:	beq.n	437a <loop+0xe8e>
    dst.resize(dstRows, dstCols);
    436c:	add	r0, sp, #204	; 0xcc
    436e:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    4372:	ldr	r3, [sp, #208]	; 0xd0
    4374:	str	r3, [sp, #32]
    4376:	ldr	r3, [sp, #212]	; 0xd4
    4378:	str	r3, [sp, #36]	; 0x24
    437a:	ldr	r3, [sp, #204]	; 0xcc
    437c:	str	r3, [sp, #44]	; 0x2c
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    437e:	ldr	r3, [sp, #36]	; 0x24
    4380:	cmp	r3, #0
    4382:	ble.n	43d4 <loop+0xee8>
    4384:	mov.w	fp, #0
    4388:	ldr	r3, [sp, #32]
    438a:	mov	r9, r6
    438c:	lsls	r3, r3, #2
    438e:	mov	sl, fp
    4390:	str	r3, [sp, #40]	; 0x28
      for(Index inner = 0; inner < kernel.innerSize(); ++inner) {
    4392:	ldr	r3, [sp, #32]
    4394:	cmp	r3, #0
    4396:	ble.n	43c6 <loop+0xeda>
    4398:	ldr.w	r3, [r9]
    439c:	ldr	r2, [sp, #44]	; 0x2c
    439e:	ldr	r6, [r7, #0]
    43a0:	add.w	r8, r3, sl, lsl #2
    43a4:	ldr	r3, [sp, #40]	; 0x28
    43a6:	add.w	lr, r2, fp, lsl #2
    43aa:	ldr.w	r0, [r9, #8]
    43ae:	add.w	ip, r6, r3
  */
template<typename Derived>
EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
DenseBase<Derived>::sum() const
{
  if(SizeAtCompileTime==0 || (SizeAtCompileTime==Dynamic && size()==0))
    43b2:	cmp	r0, #0
    43b4:	bne.w	502c <loop+0x1b40>
    return Scalar(0);
    43b8:	vldr	s15, [pc, #-436]	; 4208 <loop+0xd1c>
    43bc:	adds	r6, #4
    43be:	vstmia	lr!, {s15}
    43c2:	cmp	ip, r6
    43c4:	bne.n	43b2 <loop+0xec6>
    43c6:	ldr	r3, [sp, #32]
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    43c8:	add.w	sl, sl, #1
    43cc:	add	fp, r3
    43ce:	ldr	r3, [sp, #36]	; 0x24
    43d0:	cmp	sl, r3
    43d2:	bne.n	4392 <loop+0xea6>
    43d4:	movs	r3, #0
  // TODO check whether this is the right place to perform these checks:
  EIGEN_STATIC_ASSERT_LVALUE(Dst)
  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(ActualDstTypeCleaned,Src)
  EIGEN_CHECK_BINARY_COMPATIBILIY(Func,typename ActualDstTypeCleaned::Scalar,typename Src::Scalar);
  
  Assignment<ActualDstTypeCleaned,Src,Func>::run(actualDst, src, func);
    43d6:	add	r1, sp, #152	; 0x98
    43d8:	add	r0, sp, #216	; 0xd8
    43da:	str	r3, [sp, #216]	; 0xd8
    43dc:	str	r3, [sp, #220]	; 0xdc
    43de:	str	r3, [sp, #224]	; 0xe0
    43e0:	bl	2e1c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]>
    43e4:	ldr	r1, [sp, #208]	; 0xd0
    43e6:	ldr	r3, [sp, #220]	; 0xdc
    43e8:	ldr	r2, [sp, #148]	; 0x94
    43ea:	str	r3, [sp, #240]	; 0xf0
    43ec:	str	r1, [sp, #232]	; 0xe8
    43ee:	ldr	r3, [sp, #144]	; 0x90
    43f0:	ldr	r1, [r2, #4]
    43f2:	ldr	r0, [sp, #204]	; 0xcc
    : m_lhs(xpr.lhs()),
      m_rhs(xpr.rhs()),
      m_lhsImpl(m_lhs),     // FIXME the creation of the evaluator objects should result in a no-op, but check that!
      m_rhsImpl(m_rhs),     //       Moreover, they are only useful for the packet path, so we could completely disable them when not needed,
                            //       or perhaps declare them on the fly on the packet method... We have experiment to check what's best.
      m_innerDim(xpr.lhs().cols())
    43f4:	str	r1, [sp, #244]	; 0xf4
    43f6:	ldr	r1, [r3, #4]
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    43f8:	ldr	r3, [sp, #136]	; 0x88
    43fa:	ldr	r2, [sp, #152]	; 0x98
    43fc:	ldr.w	sl, [sp, #216]	; 0xd8
    4400:	cmp	r1, r3
    4402:	ldr	r2, [r2, #8]
    4404:	str	r0, [sp, #228]	; 0xe4
    4406:	str.w	sl, [sp, #236]	; 0xec
    440a:	beq.w	50ea <loop+0x1bfe>
    dst.resize(dstRows, dstCols);
    440e:	add	r0, sp, #132	; 0x84
    4410:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    4414:	ldr	r1, [sp, #136]	; 0x88
    4416:	ldr.w	sl, [sp, #216]	; 0xd8
    441a:	ldr.w	fp, [sp, #140]	; 0x8c
    441e:	ldr	r3, [sp, #132]	; 0x84
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    4420:	cmp.w	fp, #0
    4424:	str	r3, [sp, #36]	; 0x24
    4426:	ble.n	4470 <loop+0xf84>
    4428:	mov.w	r9, #0
    442c:	lsls	r3, r1, #2
    442e:	mov	r8, r9
    4430:	str	r3, [sp, #32]
      for(Index inner = 0; inner < kernel.innerSize(); ++inner) {
    4432:	cmp	r1, #0
    4434:	ble.n	4466 <loop+0xf7a>
    4436:	ldr	r7, [sp, #220]	; 0xdc
    4438:	ldr	r3, [sp, #36]	; 0x24
    443a:	mul.w	lr, r7, r8
    443e:	ldr	r5, [sp, #204]	; 0xcc
    4440:	add.w	r6, r3, r9, lsl #2
    4444:	ldr	r3, [sp, #32]
    4446:	add.w	lr, sl, lr, lsl #2
    444a:	add.w	ip, r5, r3
    444e:	add.w	r4, lr, r7, lsl #2
  */
template<typename Derived>
EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
DenseBase<Derived>::sum() const
{
  if(SizeAtCompileTime==0 || (SizeAtCompileTime==Dynamic && size()==0))
    4452:	cmp	r7, #0
    4454:	bne.w	4df2 <loop+0x1906>
    return Scalar(0);
    4458:	vldr	s15, [pc, #-596]	; 4208 <loop+0xd1c>
    445c:	adds	r5, #4
    445e:	vstmia	r6!, {s15}
    4462:	cmp	r5, ip
    4464:	bne.n	4452 <loop+0xf66>
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    4466:	add.w	r8, r8, #1
    446a:	add	r9, r1
    446c:	cmp	r8, fp
    446e:	bne.n	4432 <loop+0xf46>
    4470:	cmp.w	sl, #0
    4474:	beq.n	447e <loop+0xf92>
    4476:	ldr.w	r0, [sl, #-4]
    447a:	bl	7248 <free>
      swap(m_rows, other.m_rows);
      swap(m_cols, other.m_cols);
      return *this;
    }
#endif
    EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols); }
    447e:	ldr	r3, [sp, #204]	; 0xcc
    4480:	cbz	r3, 448a <loop+0xf9e>
    4482:	ldr.w	r0, [r3, #-4]
    4486:	bl	7248 <free>
    448a:	ldr	r4, [sp, #132]	; 0x84
    448c:	ldr	r1, [sp, #136]	; 0x88
    448e:	ldr	r2, [sp, #140]	; 0x8c
    4490:	ldr	r3, [sp, #100]	; 0x64
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    4492:	cmp	r3, r1
    4494:	beq.w	4d14 <loop+0x1828>
    dst.resize(dstRows, dstCols);
    4498:	add	r0, sp, #96	; 0x60
    449a:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    449e:	ldr	r5, [sp, #132]	; 0x84
    44a0:	ldr	r3, [sp, #100]	; 0x64
    44a2:	ldr	r2, [sp, #104]	; 0x68
  EIGEN_DEVICE_FUNC
  inline Index cols() const { return derived().cols(); }
  /** \returns the number of coefficients, which is rows()*cols().
    * \sa rows(), cols(), SizeAtCompileTime. */
  EIGEN_DEVICE_FUNC
  inline Index size() const { return rows() * cols(); }
    44a4:	mul.w	r0, r2, r3
    44a8:	ldr	r2, [sp, #96]	; 0x60
struct dense_assignment_loop<Kernel, LinearTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
  {
    const Index size = kernel.size();
    for(Index i = 0; i < size; ++i)
    44aa:	cmp	r0, #0
    44ac:	ble.n	44c0 <loop+0xfd4>
    44ae:	mov	r3, r4
    44b0:	add.w	r0, r4, r0, lsl #2
    44b4:	ldr.w	r1, [r3], #4
    44b8:	cmp	r3, r0
    44ba:	str.w	r1, [r2], #4
    44be:	bne.n	44b4 <loop+0xfc8>
    44c0:	cbz	r5, 44ca <loop+0xfde>
    44c2:	ldr.w	r0, [r5, #-4]
    44c6:	bl	7248 <free>
  X  = H * Pp * H.transpose() + R;   
  K  = Pp * H.transpose() * X.inverse();

  // Print Result
  //----------------------------
  print_mtxf(K);      // Print Matrix Result (passed by reference)
    44ca:	add	r0, sp, #96	; 0x60
    44cc:	bl	80 <print_mtxf(Eigen::Matrix<float, -1, -1, 0, -1, -1> const&)>
 
  delay(1000);
    44d0:	mov.w	r0, #1000	; 0x3e8
    44d4:	bl	64a8 <delay>
    44d8:	ldr	r3, [sp, #108]	; 0x6c
    44da:	cbz	r3, 44e4 <loop+0xff8>
    44dc:	ldr.w	r0, [r3, #-4]
    44e0:	bl	7248 <free>
    44e4:	ldr	r3, [sp, #96]	; 0x60
    44e6:	cbz	r3, 44f0 <loop+0x1004>
    44e8:	ldr.w	r0, [r3, #-4]
    44ec:	bl	7248 <free>
    44f0:	ldr	r3, [sp, #84]	; 0x54
    44f2:	cbz	r3, 44fc <loop+0x1010>
    44f4:	ldr.w	r0, [r3, #-4]
    44f8:	bl	7248 <free>
    44fc:	ldr	r3, [sp, #72]	; 0x48
    44fe:	cbz	r3, 4508 <loop+0x101c>
    4500:	ldr.w	r0, [r3, #-4]
    4504:	bl	7248 <free>
    4508:	ldr	r3, [sp, #60]	; 0x3c
    450a:	cbz	r3, 4514 <loop+0x1028>
    450c:	ldr.w	r0, [r3, #-4]
    4510:	bl	7248 <free>
    4514:	ldr	r3, [sp, #48]	; 0x30
    4516:	cbz	r3, 4520 <loop+0x1034>
    4518:	ldr.w	r0, [r3, #-4]
    451c:	bl	7248 <free>
}
    4520:	add	sp, #252	; 0xfc
    4522:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    4526:	mul.w	r5, r2, r1
    452a:	ldr	r4, [sp, #132]	; 0x84
    452c:	cmp	r5, #0
    452e:	ble.n	4540 <loop+0x1054>
    4530:	add.w	r5, r4, r5, lsl #2
    4534:	mov	r3, r4
    4536:	movs	r0, #0
    4538:	str.w	r0, [r3], #4
    453c:	cmp	r5, r3
    453e:	bne.n	4538 <loop+0x104c>
    4540:	ldr	r3, [sp, #124]	; 0x7c

  template<typename Dest>
  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
  {
    eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
    if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
    4542:	ldr	r0, [r3, #4]
    4544:	cmp	r0, #0
    4546:	beq.n	4490 <loop+0xfa4>
    4548:	ldr	r5, [sp, #120]	; 0x78
    454a:	ldr	r0, [r5, #4]
    454c:	cmp	r0, #0
    454e:	beq.n	4490 <loop+0xfa4>
    4550:	ldr	r0, [r6, #8]
    4552:	cmp	r0, #0
    4554:	beq.n	4490 <loop+0xfa4>
{
    T *m_data;
    Index m_rows;
    Index m_cols;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0), m_cols(0) {}
    4556:	movs	r0, #0
    4558:	str	r0, [sp, #148]	; 0x94
    455a:	str	r0, [sp, #152]	; 0x98
    455c:	ldr	r1, [r5, #4]
    455e:	ldr	r2, [r3, #4]
    4560:	str	r0, [sp, #144]	; 0x90
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
    4562:	cbz	r1, 4582 <loop+0x1096>
    4564:	cbz	r2, 4582 <loop+0x1096>
    4566:	mvn.w	r3, #2147483648	; 0x80000000
    456a:	sdiv	r3, r3, r2
    456e:	cmp	r1, r3
    4570:	ble.n	4582 <loop+0x1096>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    4572:	mov.w	r0, #4294967295
    4576:	bl	6d9c <operator new(unsigned int)>
    457a:	ldr	r2, [sp, #120]	; 0x78
    457c:	ldr	r3, [sp, #124]	; 0x7c
    457e:	ldr	r1, [r2, #4]
    4580:	ldr	r2, [r3, #4]
      else if(ColsAtCompileTime == 1)
      {
        eigen_assert(other.rows() == 1 || other.cols() == 1);
        resize(othersize, 1);
      }
      else resize(other.rows(), other.cols());
    4582:	add	r4, sp, #144	; 0x90
    4584:	mov	r0, r4
    4586:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    458a:	ldr.w	r8, [sp, #120]	; 0x78
  static EIGEN_STRONG_INLINE
  void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    458e:	ldr	r3, [sp, #148]	; 0x94
    4590:	ldr.w	sl, [r8, #4]
    4594:	ldr	r7, [sp, #124]	; 0x7c
    4596:	cmp	sl, r3
    4598:	ldr	r2, [r7, #4]
    459a:	beq.w	52ae <loop+0x1dc2>
      dst.resize(dstRows, dstCols);
    459e:	mov	r1, sl
    45a0:	mov	r0, r4
    45a2:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    45a6:	ldr	r3, [sp, #152]	; 0x98
    45a8:	ldr.w	r8, [sp, #120]	; 0x78
    45ac:	ldr	r7, [sp, #124]	; 0x7c
    45ae:	ldr.w	sl, [sp, #148]	; 0x94
    45b2:	str	r3, [sp, #36]	; 0x24
    45b4:	ldr	r2, [r7, #8]
  typedef generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode> lazyproduct;

  template<typename Dst>
  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
  {
    if((rhs.rows()+dst.rows()+dst.cols())<20 && rhs.rows()>0)
    45b6:	ldr	r1, [sp, #36]	; 0x24
    45b8:	add.w	r3, r2, sl
    45bc:	add	r3, r1
    45be:	cmp	r3, #19
    45c0:	bgt.w	51c8 <loop+0x1cdc>
    45c4:	cmp	r2, #0
    45c6:	ble.w	51c8 <loop+0x1cdc>
    45ca:	ldr	r2, [r7, #4]
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    45cc:	ldr	r3, [sp, #36]	; 0x24
    45ce:	ldr.w	r1, [r8, #4]
    45d2:	cmp	r2, r3
    45d4:	bne.n	45da <loop+0x10ee>
    45d6:	cmp	r1, sl
    45d8:	beq.n	45e8 <loop+0x10fc>
    dst.resize(dstRows, dstCols);
    45da:	mov	r0, r4
    45dc:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    45e0:	ldr	r3, [sp, #152]	; 0x98
    45e2:	ldr.w	sl, [sp, #148]	; 0x94
    45e6:	str	r3, [sp, #36]	; 0x24
    45e8:	ldr	r3, [sp, #144]	; 0x90
    45ea:	str	r3, [sp, #44]	; 0x2c
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    45ec:	ldr	r3, [sp, #36]	; 0x24
    45ee:	cmp	r3, #0
    45f0:	ble.n	4642 <loop+0x1156>
    45f2:	movs	r3, #0
    45f4:	mov.w	r2, sl, lsl #2
    45f8:	mov	fp, r3
    45fa:	str	r3, [sp, #32]
    45fc:	str	r2, [sp, #40]	; 0x28
      for(Index inner = 0; inner < kernel.innerSize(); ++inner) {
    45fe:	cmp.w	sl, #0
    4602:	ble.n	4632 <loop+0x1146>
    4604:	ldr	r3, [r7, #0]
    4606:	ldr	r2, [sp, #44]	; 0x2c
    4608:	ldr	r1, [sp, #32]
    460a:	add.w	r9, r3, fp, lsl #2
    460e:	ldr.w	r6, [r8]
    4612:	ldr	r3, [sp, #40]	; 0x28
    4614:	add.w	lr, r2, r1, lsl #2
    4618:	ldr	r0, [r7, #8]
    461a:	add.w	ip, r6, r3
  */
template<typename Derived>
EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
DenseBase<Derived>::sum() const
{
  if(SizeAtCompileTime==0 || (SizeAtCompileTime==Dynamic && size()==0))
    461e:	cmp	r0, #0
    4620:	bne.w	506a <loop+0x1b7e>
    return Scalar(0);
    4624:	vldr	s15, [pc, #712]	; 48f0 <loop+0x1404>
    4628:	adds	r6, #4
    462a:	vstmia	lr!, {s15}
    462e:	cmp	ip, r6
    4630:	bne.n	461e <loop+0x1132>
    4632:	ldr	r3, [sp, #32]
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    4634:	add.w	fp, fp, #1
    4638:	add	r3, sl
    463a:	str	r3, [sp, #32]
    463c:	ldr	r3, [sp, #36]	; 0x24
    463e:	cmp	fp, r3
    4640:	bne.n	45fe <loop+0x1112>
    4642:	add	r4, sp, #204	; 0xcc
    4644:	add	r6, sp, #216	; 0xd8
    4646:	add.w	fp, sp, #212	; 0xd4
    464a:	add.w	r9, sp, #220	; 0xdc
    464e:	movs	r3, #0
    4650:	ldr	r2, [sp, #128]	; 0x80
    4652:	str	r3, [sp, #176]	; 0xb0
    4654:	str	r3, [sp, #180]	; 0xb4
    4656:	ldr	r1, [r2, #4]
    4658:	str	r3, [sp, #172]	; 0xac
    465a:	ldr	r2, [r2, #8]
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
    465c:	cbz	r1, 467a <loop+0x118e>
    465e:	cbz	r2, 467a <loop+0x118e>
    4660:	mvn.w	r3, #2147483648	; 0x80000000
    4664:	sdiv	r3, r3, r2
    4668:	cmp	r1, r3
    466a:	ble.n	467a <loop+0x118e>
    466c:	mov.w	r0, #4294967295
    4670:	bl	6d9c <operator new(unsigned int)>
    4674:	ldr	r3, [sp, #128]	; 0x80
    4676:	ldr	r1, [r3, #4]
    4678:	ldr	r2, [r3, #8]
      else if(ColsAtCompileTime == 1)
      {
        eigen_assert(other.rows() == 1 || other.cols() == 1);
        resize(othersize, 1);
      }
      else resize(other.rows(), other.cols());
    467a:	add	r0, sp, #172	; 0xac
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    467c:	movs	r7, #0
    467e:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
  // TODO check whether this is the right place to perform these checks:
  EIGEN_STATIC_ASSERT_LVALUE(Dst)
  EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(ActualDstTypeCleaned,Src)
  EIGEN_CHECK_BINARY_COMPATIBILIY(Func,typename ActualDstTypeCleaned::Scalar,typename Src::Scalar);
  
  Assignment<ActualDstTypeCleaned,Src,Func>::run(actualDst, src, func);
    4682:	add	r0, sp, #172	; 0xac
    4684:	add	r1, sp, #128	; 0x80
    4686:	bl	2e1c <Eigen::internal::Assignment<Eigen::Matrix<float, -1, -1, 0, -1, -1>, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> >, Eigen::internal::assign_op<float, float>, Eigen::internal::Dense2Dense, void>::run(Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Inverse<Eigen::Matrix<float, -1, -1, 0, -1, -1> > const&, Eigen::internal::assign_op<float, float> const&) [clone .isra.395]>

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    468a:	ldr	r5, [sp, #136]	; 0x88
    468c:	mov	r2, r6
    468e:	mov	r1, fp
    4690:	str	r5, [sp, #212]	; 0xd4
    4692:	mov	r0, r9
      this->m_nc = Transpose ? rows : cols;
    4694:	ldr	r5, [sp, #140]	; 0x8c
    4696:	movs	r3, #1
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    4698:	str	r7, [sp, #204]	; 0xcc
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    469a:	movs	r6, #0
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    469c:	str	r5, [sp, #216]	; 0xd8
      this->m_kc = depth;
    469e:	ldr	r5, [sp, #152]	; 0x98
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    46a0:	str	r7, [sp, #208]	; 0xd0

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
      this->m_kc = depth;
    46a2:	str	r5, [sp, #220]	; 0xdc
    46a4:	bl	1b0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)>
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    46a8:	ldr	r3, [sp, #220]	; 0xdc
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    46aa:	vmov.f32	s0, #112	; 0x3f800000  1.0
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
      m_sizeB = this->m_kc * this->m_nc;
    46ae:	ldr	r0, [sp, #216]	; 0xd8
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    46b0:	ldr	r2, [sp, #212]	; 0xd4
    46b2:	ldr	r1, [sp, #128]	; 0x80
    46b4:	mul.w	r2, r3, r2
      m_sizeB = this->m_kc * this->m_nc;
    46b8:	mul.w	r3, r3, r0
    46bc:	ldr	r0, [sp, #120]	; 0x78
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    46be:	str	r2, [sp, #224]	; 0xe0
      m_sizeB = this->m_kc * this->m_nc;
    46c0:	str	r3, [sp, #228]	; 0xe4
    46c2:	ldr	r1, [r1, #8]
    46c4:	ldr	r0, [r0, #4]
    m_blocking.allocateA();
  }

  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
    46c6:	adds	r5, r1, #1
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    46c8:	str	r4, [sp, #20]
    46ca:	ldr	r5, [sp, #136]	; 0x88
    46cc:	ldr	r4, [sp, #132]	; 0x84
    46ce:	str	r6, [sp, #24]
    46d0:	str	r5, [sp, #16]
    46d2:	ldr	r6, [sp, #176]	; 0xb0
    46d4:	ldr	r5, [sp, #172]	; 0xac
    46d6:	str	r4, [sp, #12]
    46d8:	ldr	r4, [sp, #148]	; 0x94
    46da:	ldr	r3, [sp, #144]	; 0x90
    46dc:	it	eq
    46de:	ldreq	r1, [sp, #180]	; 0xb4
    46e0:	ldr	r2, [sp, #152]	; 0x98
    46e2:	stmia.w	sp, {r4, r5, r6}
    46e6:	bl	10b0 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    46ea:	ldr	r3, [sp, #204]	; 0xcc
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    46ec:	cbz	r3, 46f6 <loop+0x120a>
    46ee:	ldr.w	r0, [r3, #-4]
    46f2:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    46f6:	ldr	r3, [sp, #208]	; 0xd0
    46f8:	cbz	r3, 4702 <loop+0x1216>
    46fa:	ldr.w	r0, [r3, #-4]
    46fe:	bl	7248 <free>
      swap(m_rows, other.m_rows);
      swap(m_cols, other.m_cols);
      return *this;
    }
#endif
    EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols); }
    4702:	ldr	r3, [sp, #172]	; 0xac
    4704:	cbz	r3, 470e <loop+0x1222>
    4706:	ldr.w	r0, [r3, #-4]
    470a:	bl	7248 <free>
    470e:	ldr	r3, [sp, #144]	; 0x90
    4710:	cmp	r3, #0
    4712:	bne.w	4482 <loop+0xf96>
    4716:	b.n	448a <loop+0xf9e>
    4718:	ldr	r1, [sp, #64]	; 0x40

  template<typename Dest>
  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
  {
    eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
    if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
    471a:	cmp	r1, #0
    471c:	beq.w	4240 <loop+0xd54>
  {
    // http://hg.mozilla.org/mozilla-central/file/6c8a909977d3/xpcom/ds/CheckedInt.h#l242
    // we assume Index is signed
    Index max_index = (std::size_t(1) << (8 * sizeof(Index) - 1)) - 1; // assume Index is signed
    bool error = (rows == 0 || cols == 0) ? false
               : (rows > max_index / cols);
    4720:	mvn.w	r3, #2147483648	; 0x80000000
{
    T *m_data;
    Index m_rows;
    Index m_cols;
  public:
    EIGEN_DEVICE_FUNC DenseStorage() : m_data(0), m_rows(0), m_cols(0) {}
    4724:	movs	r0, #0
    4726:	sdiv	r3, r3, r2
    472a:	cmp	r1, r3
    472c:	str	r0, [sp, #144]	; 0x90
    472e:	str	r0, [sp, #148]	; 0x94
    4730:	str	r0, [sp, #152]	; 0x98
    4732:	ble.n	4740 <loop+0x1254>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    4734:	mov.w	r0, #4294967295
    4738:	bl	6d9c <operator new(unsigned int)>
    473c:	ldr	r1, [sp, #64]	; 0x40
    473e:	ldr	r2, [sp, #56]	; 0x38
      else if(ColsAtCompileTime == 1)
      {
        eigen_assert(other.rows() == 1 || other.cols() == 1);
        resize(othersize, 1);
      }
      else resize(other.rows(), other.cols());
    4740:	add	r4, sp, #144	; 0x90
    4742:	mov	r0, r4
    4744:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    4748:	ldr.w	lr, [sp, #64]	; 0x40
  static EIGEN_STRONG_INLINE
  void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    474c:	ldr	r3, [sp, #148]	; 0x94
    474e:	ldr	r2, [sp, #56]	; 0x38
    4750:	cmp	lr, r3
    4752:	beq.w	50f8 <loop+0x1c0c>
      dst.resize(dstRows, dstCols);
    4756:	mov	r1, lr
    4758:	mov	r0, r4
    475a:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    475e:	ldr.w	lr, [sp, #148]	; 0x94
    4762:	ldr	r2, [sp, #52]	; 0x34
    4764:	ldr	r7, [sp, #152]	; 0x98
  typedef generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode> lazyproduct;

  template<typename Dst>
  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
  {
    if((rhs.rows()+dst.rows()+dst.cols())<20 && rhs.rows()>0)
    4766:	add.w	r3, r2, lr
    476a:	add	r3, r7
    476c:	cmp	r3, #19
    476e:	bgt.w	5112 <loop+0x1c26>
    4772:	cmp	r2, #0
    4774:	ble.w	5112 <loop+0x1c26>
    4778:	ldr	r2, [sp, #56]	; 0x38
    477a:	ldr	r1, [sp, #64]	; 0x40
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    477c:	cmp	r2, r7
    477e:	bne.n	4784 <loop+0x1298>
    4780:	cmp	r1, lr
    4782:	beq.n	4790 <loop+0x12a4>
    dst.resize(dstRows, dstCols);
    4784:	mov	r0, r4
    4786:	bl	120 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 0, -1, -1> >::resize(int, int)>
    478a:	ldr.w	lr, [sp, #148]	; 0x94
    478e:	ldr	r7, [sp, #152]	; 0x98
    4790:	ldr	r3, [sp, #144]	; 0x90
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    4792:	cmp	r7, #0
    4794:	str	r3, [sp, #32]
    4796:	ble.n	47e2 <loop+0x12f6>
    4798:	mov.w	r9, #0
    479c:	mov.w	fp, lr, lsl #2
    47a0:	mov	r8, r9
      for(Index inner = 0; inner < kernel.innerSize(); ++inner) {
    47a2:	cmp.w	lr, #0
    47a6:	ble.n	47d8 <loop+0x12ec>
    47a8:	ldr	r6, [sp, #52]	; 0x34
    47aa:	ldr	r3, [sp, #32]
    47ac:	mul.w	sl, r6, r8
    47b0:	ldr	r4, [sp, #60]	; 0x3c
    47b2:	add.w	r5, r3, r9, lsl #2
    47b6:	ldr	r3, [sp, #48]	; 0x30
    47b8:	add.w	ip, r4, fp
    47bc:	add.w	sl, r3, sl, lsl #2
    47c0:	add.w	r0, sl, r6, lsl #2
  */
template<typename Derived>
EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
DenseBase<Derived>::sum() const
{
  if(SizeAtCompileTime==0 || (SizeAtCompileTime==Dynamic && size()==0))
    47c4:	cmp	r6, #0
    47c6:	bne.w	50a8 <loop+0x1bbc>
    return Scalar(0);
    47ca:	vldr	s15, [pc, #292]	; 48f0 <loop+0x1404>
    47ce:	adds	r4, #4
    47d0:	vstmia	r5!, {s15}
    47d4:	cmp	r4, ip
    47d6:	bne.n	47c4 <loop+0x12d8>
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    47d8:	add.w	r8, r8, #1
    47dc:	add	r9, lr
    47de:	cmp	r8, r7
    47e0:	bne.n	47a2 <loop+0x12b6>
    47e2:	add	r4, sp, #204	; 0xcc
    47e4:	add	r6, sp, #216	; 0xd8
    47e6:	add.w	fp, sp, #212	; 0xd4
    47ea:	add.w	r9, sp, #220	; 0xdc
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    47ee:	mov.w	r8, #0
    47f2:	mov	r2, r6
    47f4:	ldr	r5, [sp, #192]	; 0xc0
    47f6:	mov	r1, fp
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    47f8:	ldr	r6, [sp, #188]	; 0xbc
    47fa:	mov	r0, r9
    47fc:	movs	r3, #1
      this->m_kc = depth;
    47fe:	str	r7, [sp, #220]	; 0xdc
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    4800:	str	r6, [sp, #216]	; 0xd8

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    4802:	str	r5, [sp, #212]	; 0xd4
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    4804:	str.w	r8, [sp, #204]	; 0xcc
    4808:	str.w	r8, [sp, #208]	; 0xd0
    480c:	bl	1b0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)>
    ResScalar alpha,
    level3_blocking<RhsScalar,LhsScalar>& blocking,
    GemmParallelInfo<Index>* info = 0)
  {
    // transpose the product such that the result is column major
    general_matrix_matrix_product<Index,
    4810:	ldr	r5, [sp, #192]	; 0xc0
    4812:	vmov.f32	s0, #112	; 0x3f800000  1.0
    4816:	str	r4, [sp, #20]
    4818:	ldr	r4, [sp, #148]	; 0x94
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    481a:	ldr	r2, [sp, #220]	; 0xdc
    481c:	ldr	r6, [sp, #212]	; 0xd4
      m_sizeB = this->m_kc * this->m_nc;
    481e:	ldr	r7, [sp, #216]	; 0xd8
    4820:	ldr	r1, [sp, #64]	; 0x40
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    4822:	mul.w	r6, r2, r6
    ResScalar alpha,
    level3_blocking<RhsScalar,LhsScalar>& blocking,
    GemmParallelInfo<Index>* info = 0)
  {
    // transpose the product such that the result is column major
    general_matrix_matrix_product<Index,
    4826:	str	r5, [sp, #16]
    4828:	str	r4, [sp, #8]
    482a:	mov	r0, r1
    482c:	ldr	r5, [sp, #184]	; 0xb8
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
      m_sizeB = this->m_kc * this->m_nc;
    482e:	mul.w	r7, r2, r7
    ResScalar alpha,
    level3_blocking<RhsScalar,LhsScalar>& blocking,
    GemmParallelInfo<Index>* info = 0)
  {
    // transpose the product such that the result is column major
    general_matrix_matrix_product<Index,
    4832:	ldr	r4, [sp, #144]	; 0x90
    4834:	ldr	r3, [sp, #60]	; 0x3c
    4836:	ldr	r2, [sp, #152]	; 0x98
    4838:	str.w	r8, [sp, #24]
    483c:	str	r1, [sp, #0]
    483e:	str	r5, [sp, #12]
    4840:	str	r4, [sp, #4]
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    4842:	str	r6, [sp, #224]	; 0xe0
      m_sizeB = this->m_kc * this->m_nc;
    4844:	str	r7, [sp, #228]	; 0xe4
    ResScalar alpha,
    level3_blocking<RhsScalar,LhsScalar>& blocking,
    GemmParallelInfo<Index>* info = 0)
  {
    // transpose the product such that the result is column major
    general_matrix_matrix_product<Index,
    4846:	bl	146c <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    484a:	ldr	r3, [sp, #204]	; 0xcc
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    484c:	cbz	r3, 4856 <loop+0x136a>
    484e:	ldr.w	r0, [r3, #-4]
    4852:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    4856:	ldr	r3, [sp, #208]	; 0xd0
    4858:	cbz	r3, 4862 <loop+0x1376>
    485a:	ldr.w	r0, [r3, #-4]
    485e:	bl	7248 <free>
      swap(m_rows, other.m_rows);
      swap(m_cols, other.m_cols);
      return *this;
    }
#endif
    EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols); }
    4862:	ldr	r3, [sp, #144]	; 0x90
    4864:	cmp	r3, #0
    4866:	beq.w	4240 <loop+0xd54>
    486a:	ldr.w	r0, [r3, #-4]
    486e:	bl	7248 <free>
    4872:	b.n	4240 <loop+0xd54>
  static EIGEN_STRONG_INLINE
  void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    4874:	mov	r2, r0
    4876:	add	r6, sp, #84	; 0x54
    4878:	mov	r1, r0
    487a:	b.n	42f6 <loop+0xe0a>
        Index size = rows*cols;
        bool size_changed = size != this->size();
        m_storage.resize(size, rows, cols);
        if(size_changed) EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
      #else
        m_storage.resize(rows*cols, rows, cols);
    487c:	mul.w	r6, r5, r5
*****************************************************************************/

template<typename T>
EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void check_size_for_overflow(std::size_t size)
{
  if(size > std::size_t(-1) / sizeof(T))
    4880:	cmp.w	r6, #1073741824	; 0x40000000
    4884:	bge.w	4ff4 <loop+0x1b08>
template<typename T, bool Align> EIGEN_DEVICE_FUNC inline T* conditional_aligned_new_auto(std::size_t size)
{
  if(size==0)
    return 0; // short-cut. Also fixes Bug 884
  check_size_for_overflow<T>(size);
  T *result = reinterpret_cast<T*>(conditional_aligned_malloc<Align>(sizeof(T)*size));
    4888:	lsls	r6, r6, #2
/** \internal Like malloc, but the returned pointer is guaranteed to be 16-byte aligned.
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
    488a:	add.w	r0, r6, #16
    488e:	bl	7238 <malloc>
  if (original == 0) return 0;
    4892:	mov	r4, r0
    4894:	cmp	r0, #0
    4896:	beq.w	52bc <loop+0x1dd0>
  void *aligned = reinterpret_cast<void*>((reinterpret_cast<std::size_t>(original) & ~(std::size_t(EIGEN_DEFAULT_ALIGN_BYTES-1))) + EIGEN_DEFAULT_ALIGN_BYTES);
    489a:	bic.w	r3, r0, #15
    489e:	adds	r3, #16
  *(reinterpret_cast<void**>(aligned) - 1) = original;
    48a0:	str.w	r0, [r3, #-4]
    48a4:	ldr	r4, [sp, #68]	; 0x44
    {
      if(size != m_rows*m_cols)
      {
        internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols);
        if (size)
          m_data = internal::conditional_aligned_new_auto<T,(_Options&DontAlign)==0>(size);
    48a6:	str	r3, [sp, #184]	; 0xb8
  typedef generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode> lazyproduct;

  template<typename Dst>
  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
  {
    if((rhs.rows()+dst.rows()+dst.cols())<20 && rhs.rows()>0)
    48a8:	add.w	r2, r4, r5, lsl #1
        else
          m_data = 0;
        EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
      }
      m_rows = rows;
    48ac:	str	r5, [sp, #188]	; 0xbc
      m_cols = cols;
    48ae:	str	r5, [sp, #192]	; 0xc0
    48b0:	cmp	r2, #19
    48b2:	str	r3, [sp, #176]	; 0xb0
    48b4:	str	r5, [sp, #180]	; 0xb4
    48b6:	bgt.w	422c <loop+0xd40>
    48ba:	cmp	r4, #0
    48bc:	ble.w	422c <loop+0xd40>
    48c0:	ldr	r2, [sp, #56]	; 0x38
    48c2:	b.w	40c2 <loop+0xbd6>
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    {
      m_row+=m_currentBlockRows;
    48c6:	adds	r3, #1
    48c8:	movs	r6, #0
    48ca:	b.w	4050 <loop+0xb64>
    48ce:	ldr	r2, [sp, #92]	; 0x5c
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    48d0:	cmp	r3, r2
    48d2:	bne.w	4252 <loop+0xd66>
    48d6:	b.n	425e <loop+0xd72>
    48d8:	adds	r3, #1
    48da:	movs	r7, #0
    48dc:	mov.w	lr, #1
    48e0:	b.w	4038 <loop+0xb4c>
    48e4:	adds	r3, #1
    48e6:	mov.w	lr, #0
    48ea:	movs	r7, #1
    48ec:	b.w	401c <loop+0xb30>
    48f0:	.word	0x00000000
    48f4:	adds	r3, #1
    48f6:	movs	r7, #0
    48f8:	mov.w	lr, #1
    48fc:	b.w	4000 <loop+0xb14>
    4900:	adds	r3, #1
    4902:	mov.w	lr, #0
    4906:	movs	r7, #1
    4908:	b.w	3fe4 <loop+0xaf8>
    490c:	adds	r3, #1
    490e:	movs	r7, #0
    4910:	mov.w	lr, #1
    4914:	b.w	3fc8 <loop+0xadc>
    4918:	adds	r3, #1
    491a:	mov.w	lr, #0
    491e:	movs	r7, #1
    4920:	b.w	3fac <loop+0xac0>
    4924:	adds	r3, #1
    4926:	movs	r7, #0
    4928:	mov.w	lr, #1
    492c:	b.w	3f90 <loop+0xaa4>
    4930:	adds	r3, #1
    4932:	mov.w	lr, #0
    4936:	movs	r7, #1
    4938:	b.w	3f74 <loop+0xa88>
    493c:	adds	r3, #1
    493e:	movs	r7, #0
    4940:	mov.w	lr, #1
    4944:	b.w	3f58 <loop+0xa6c>
    4948:	adds	r3, #1
    494a:	mov.w	lr, #0
    494e:	movs	r7, #1
    4950:	b.w	3f3c <loop+0xa50>
    4954:	adds	r3, #1
    4956:	movs	r7, #0
    4958:	mov.w	lr, #1
    495c:	b.w	3f20 <loop+0xa34>
    4960:	adds	r3, #1
    4962:	mov.w	lr, #0
    4966:	movs	r7, #1
    4968:	b.w	3f04 <loop+0xa18>
    496c:	adds	r3, #1
    496e:	movs	r7, #0
    4970:	mov.w	lr, #1
    4974:	b.w	3ee8 <loop+0x9fc>
    4978:	adds	r3, #1
    497a:	mov.w	lr, #0
    497e:	movs	r7, #1
    4980:	b.w	3ecc <loop+0x9e0>
    4984:	adds	r3, #1
    4986:	movs	r7, #0
    4988:	mov.w	lr, #1
    498c:	b.w	3eb0 <loop+0x9c4>
    4990:	adds	r3, #1
    4992:	mov.w	lr, #0
    4996:	movs	r7, #1
    4998:	b.w	3e94 <loop+0x9a8>
    499c:	adds	r3, #1
    499e:	movs	r7, #0
    49a0:	mov.w	lr, #1
    49a4:	b.w	3e78 <loop+0x98c>
    49a8:	adds	r3, #1
    49aa:	mov.w	lr, #0
    49ae:	movs	r7, #1
    49b0:	b.w	3e5c <loop+0x970>
    49b4:	adds	r3, #1
    49b6:	movs	r7, #0
    49b8:	mov.w	lr, #1
    49bc:	b.w	3e40 <loop+0x954>
    49c0:	adds	r3, #1
    49c2:	mov.w	lr, #0
    49c6:	movs	r7, #1
    49c8:	b.w	3e24 <loop+0x938>
    49cc:	adds	r3, #1
    49ce:	movs	r7, #0
    49d0:	mov.w	lr, #1
    49d4:	b.w	3e08 <loop+0x91c>
    49d8:	adds	r3, #1
    49da:	mov.w	lr, #0
    49de:	movs	r7, #1
    49e0:	b.w	3dec <loop+0x900>
    49e4:	adds	r3, #1
    49e6:	movs	r7, #0
    49e8:	mov.w	lr, #1
    49ec:	b.w	3dd0 <loop+0x8e4>
    49f0:	adds	r3, #1
    49f2:	mov.w	lr, #0
    49f6:	movs	r7, #1
    49f8:	b.w	3db4 <loop+0x8c8>
    49fc:	adds	r3, #1
    49fe:	movs	r7, #0
    4a00:	mov.w	lr, #1
    4a04:	b.w	3d98 <loop+0x8ac>
    4a08:	adds	r3, #1
    4a0a:	mov.w	lr, #0
    4a0e:	movs	r7, #1
    4a10:	b.w	3d7c <loop+0x890>
    4a14:	adds	r3, #1
    4a16:	movs	r7, #0
    4a18:	mov.w	lr, #1
    4a1c:	b.w	3cbe <loop+0x7d2>
    4a20:	adds	r3, #1
    4a22:	mov.w	lr, #0
    4a26:	movs	r7, #1
    4a28:	b.w	3ca2 <loop+0x7b6>
    4a2c:	adds	r3, #1
    4a2e:	movs	r7, #0
    4a30:	mov.w	lr, #1
    4a34:	b.w	3c86 <loop+0x79a>
    4a38:	adds	r3, #1
    4a3a:	mov.w	lr, #0
    4a3e:	movs	r7, #1
    4a40:	b.w	3c6a <loop+0x77e>
    4a44:	adds	r3, #1
    4a46:	movs	r7, #0
    4a48:	mov.w	lr, #1
    4a4c:	b.w	3c4e <loop+0x762>
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    4a50:	ldr	r7, [pc, #720]	; (4d24 <loop+0x1838>)
    4a52:	movs	r3, #2
    4a54:	ldr.w	lr, [pc, #728]	; 4d30 <loop+0x1844>
    4a58:	ldr	r6, [sp, #76]	; 0x4c
    4a5a:	str.w	lr, [r1, #8]
    4a5e:	str	r7, [r1, #4]
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    {
      m_row+=m_currentBlockRows;
    4a60:	adds	r3, #1
    4a62:	mov.w	lr, #0
    4a66:	movs	r7, #1
    4a68:	b.w	3c32 <loop+0x746>
    4a6c:	adds	r3, #1
    4a6e:	movs	r0, #0
    4a70:	b.w	3bee <loop+0x702>
    4a74:	adds	r3, #1
    4a76:	movs	r1, #0
    4a78:	movs	r0, #1
    4a7a:	b.w	3bda <loop+0x6ee>
    4a7e:	adds	r3, #1
    4a80:	movs	r0, #0
    4a82:	movs	r1, #1
    4a84:	b.w	3bc4 <loop+0x6d8>
    4a88:	adds	r3, #1
    4a8a:	movs	r1, #0
    4a8c:	movs	r0, #1
    4a8e:	b.w	3bae <loop+0x6c2>
    4a92:	adds	r3, #1
    4a94:	movs	r0, #0
    4a96:	movs	r1, #1
    4a98:	b.w	3b98 <loop+0x6ac>
    4a9c:	adds	r3, #1
    4a9e:	movs	r1, #0
    4aa0:	movs	r0, #1
    4aa2:	b.w	3b82 <loop+0x696>
    4aa6:	adds	r3, #1
    4aa8:	movs	r0, #0
    4aaa:	movs	r1, #1
    4aac:	b.w	3b6c <loop+0x680>
    4ab0:	adds	r3, #1
    4ab2:	movs	r1, #0
    4ab4:	movs	r0, #1
    4ab6:	b.w	3b56 <loop+0x66a>
    4aba:	adds	r3, #1
    4abc:	movs	r0, #0
    4abe:	movs	r1, #1
    4ac0:	b.w	3b40 <loop+0x654>
    4ac4:	adds	r3, #1
    4ac6:	movs	r1, #0
    4ac8:	movs	r0, #1
    4aca:	b.w	3b2a <loop+0x63e>
    4ace:	adds	r3, #1
    4ad0:	movs	r0, #0
    4ad2:	movs	r1, #1
    4ad4:	b.w	3b14 <loop+0x628>
    4ad8:	adds	r3, #1
    4ada:	movs	r1, #0
    4adc:	movs	r0, #1
    4ade:	b.w	3afe <loop+0x612>
    4ae2:	adds	r3, #1
    4ae4:	movs	r0, #0
    4ae6:	movs	r1, #1
    4ae8:	b.w	3ae8 <loop+0x5fc>
    4aec:	adds	r3, #1
    4aee:	movs	r1, #0
    4af0:	movs	r0, #1
    4af2:	b.w	3ad2 <loop+0x5e6>
    4af6:	adds	r3, #1
    4af8:	movs	r0, #0
    4afa:	movs	r1, #1
    4afc:	b.w	3abc <loop+0x5d0>
    4b00:	adds	r3, #1
    4b02:	movs	r1, #0
    4b04:	movs	r0, #1
    4b06:	b.w	3aa6 <loop+0x5ba>
    4b0a:	adds	r3, #1
    4b0c:	movs	r0, #0
    4b0e:	movs	r1, #1
    4b10:	b.w	3a90 <loop+0x5a4>
    4b14:	adds	r3, #1
    4b16:	movs	r1, #0
    4b18:	movs	r0, #1
    4b1a:	b.w	3a7a <loop+0x58e>
    4b1e:	adds	r3, #1
    4b20:	movs	r0, #0
    4b22:	movs	r1, #1
    4b24:	b.w	3a64 <loop+0x578>
    4b28:	adds	r3, #1
    4b2a:	movs	r1, #0
    4b2c:	movs	r0, #1
    4b2e:	b.w	3a4e <loop+0x562>
    4b32:	adds	r3, #1
    4b34:	movs	r0, #0
    4b36:	movs	r1, #1
    4b38:	b.w	3a38 <loop+0x54c>
    4b3c:	adds	r3, #1
    4b3e:	movs	r1, #0
    4b40:	movs	r0, #1
    4b42:	b.w	3a22 <loop+0x536>
    4b46:	adds	r3, #1
    4b48:	movs	r0, #0
    4b4a:	movs	r1, #1
    4b4c:	b.w	3a0c <loop+0x520>
    4b50:	adds	r3, #1
    4b52:	movs	r1, #0
    4b54:	movs	r0, #1
    4b56:	b.w	39f6 <loop+0x50a>
    4b5a:	adds	r3, #1
    4b5c:	movs	r0, #0
    4b5e:	movs	r1, #1
    4b60:	b.w	39e0 <loop+0x4f4>
    4b64:	adds	r3, #1
    4b66:	movs	r1, #0
    4b68:	movs	r0, #1
    4b6a:	b.w	39ca <loop+0x4de>
    4b6e:	adds	r3, #1
    4b70:	movs	r0, #0
    4b72:	movs	r1, #1
    4b74:	b.w	39b4 <loop+0x4c8>
    4b78:	adds	r3, #1
    4b7a:	movs	r1, #0
    4b7c:	movs	r0, #1
    4b7e:	b.w	399e <loop+0x4b2>
    4b82:	adds	r3, #1
    4b84:	movs	r0, #0
    4b86:	movs	r1, #1
    4b88:	b.w	3988 <loop+0x49c>
    4b8c:	adds	r3, #1
    4b8e:	movs	r1, #0
    4b90:	movs	r0, #1
    4b92:	b.w	3972 <loop+0x486>
    4b96:	adds	r3, #1
    4b98:	movs	r0, #0
    4b9a:	movs	r1, #1
    4b9c:	b.w	395c <loop+0x470>
    4ba0:	adds	r3, #1
    4ba2:	movs	r1, #0
    4ba4:	movs	r0, #1
    4ba6:	b.w	389e <loop+0x3b2>
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    4baa:	ldr	r1, [pc, #380]	; (4d28 <loop+0x183c>)
    4bac:	movs	r3, #2
    4bae:	ldr	r0, [pc, #380]	; (4d2c <loop+0x1840>)
    4bb0:	ldr	r5, [sp, #64]	; 0x40
    4bb2:	str	r0, [r6, #8]
    4bb4:	str	r1, [r6, #4]
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    {
      m_row+=m_currentBlockRows;
    4bb6:	adds	r3, #1
    4bb8:	movs	r0, #0
    4bba:	movs	r1, #1
    4bbc:	b.w	3888 <loop+0x39c>
    4bc0:	adds	r3, #1
    4bc2:	movs	r0, #0
    4bc4:	b.w	3848 <loop+0x35c>
    4bc8:	adds	r3, #1
    4bca:	movs	r4, #0
    4bcc:	movs	r5, #1
    4bce:	b.w	3834 <loop+0x348>
    4bd2:	adds	r3, #1
    4bd4:	movs	r5, #0
    4bd6:	movs	r4, #1
    4bd8:	b.w	381e <loop+0x332>
    4bdc:	adds	r3, #1
    4bde:	movs	r4, #0
    4be0:	movs	r5, #1
    4be2:	b.w	3808 <loop+0x31c>
    4be6:	adds	r3, #1
    4be8:	movs	r5, #0
    4bea:	movs	r4, #1
    4bec:	b.w	37f2 <loop+0x306>
    4bf0:	adds	r3, #1
    4bf2:	movs	r4, #0
    4bf4:	movs	r5, #1
    4bf6:	b.w	37dc <loop+0x2f0>
    4bfa:	adds	r3, #1
    4bfc:	movs	r5, #0
    4bfe:	movs	r4, #1
    4c00:	b.w	37c6 <loop+0x2da>
    4c04:	adds	r3, #1
    4c06:	movs	r4, #0
    4c08:	movs	r5, #1
    4c0a:	b.w	37b0 <loop+0x2c4>
    4c0e:	adds	r3, #1
    4c10:	movs	r5, #0
    4c12:	movs	r4, #1
    4c14:	b.w	379a <loop+0x2ae>
    4c18:	adds	r3, #1
    4c1a:	movs	r4, #0
    4c1c:	movs	r5, #1
    4c1e:	b.w	3784 <loop+0x298>
    4c22:	adds	r3, #1
    4c24:	movs	r5, #0
    4c26:	movs	r4, #1
    4c28:	b.w	376e <loop+0x282>
    4c2c:	adds	r3, #1
    4c2e:	movs	r4, #0
    4c30:	movs	r5, #1
    4c32:	b.w	3758 <loop+0x26c>
    4c36:	adds	r3, #1
    4c38:	movs	r5, #0
    4c3a:	movs	r4, #1
    4c3c:	b.w	3742 <loop+0x256>
    4c40:	adds	r3, #1
    4c42:	movs	r4, #0
    4c44:	movs	r5, #1
    4c46:	b.w	372c <loop+0x240>
    4c4a:	adds	r3, #1
    4c4c:	movs	r5, #0
    4c4e:	movs	r4, #1
    4c50:	b.w	3716 <loop+0x22a>
    4c54:	adds	r3, #1
    4c56:	movs	r4, #0
    4c58:	movs	r5, #1
    4c5a:	b.w	3700 <loop+0x214>
    4c5e:	adds	r3, #1
    4c60:	movs	r5, #0
    4c62:	movs	r4, #1
    4c64:	b.w	36ea <loop+0x1fe>
    4c68:	adds	r3, #1
    4c6a:	movs	r4, #0
    4c6c:	movs	r5, #1
    4c6e:	b.w	36d4 <loop+0x1e8>
    4c72:	adds	r3, #1
    4c74:	movs	r5, #0
    4c76:	movs	r4, #1
    4c78:	b.w	36be <loop+0x1d2>
    4c7c:	adds	r3, #1
    4c7e:	movs	r4, #0
    4c80:	movs	r5, #1
    4c82:	b.w	36a8 <loop+0x1bc>
    4c86:	adds	r3, #1
    4c88:	movs	r5, #0
    4c8a:	movs	r4, #1
    4c8c:	b.w	3692 <loop+0x1a6>
    4c90:	adds	r3, #1
    4c92:	movs	r4, #0
    4c94:	movs	r5, #1
    4c96:	b.w	367c <loop+0x190>
    4c9a:	adds	r3, #1
    4c9c:	movs	r5, #0
    4c9e:	movs	r4, #1
    4ca0:	b.w	3666 <loop+0x17a>
    4ca4:	adds	r3, #1
    4ca6:	movs	r4, #0
    4ca8:	movs	r5, #1
    4caa:	b.w	3650 <loop+0x164>
    4cae:	adds	r3, #1
    4cb0:	movs	r5, #0
    4cb2:	movs	r4, #1
    4cb4:	b.w	363a <loop+0x14e>
    4cb8:	adds	r3, #1
    4cba:	movs	r4, #0
    4cbc:	movs	r5, #1
    4cbe:	b.w	3624 <loop+0x138>
    4cc2:	adds	r3, #1
    4cc4:	movs	r5, #0
    4cc6:	movs	r4, #1
    4cc8:	b.w	360e <loop+0x122>
    4ccc:	adds	r3, #1
    4cce:	movs	r4, #0
    4cd0:	movs	r5, #1
    4cd2:	b.w	35f8 <loop+0x10c>
    4cd6:	adds	r3, #1
    4cd8:	movs	r5, #0
    4cda:	movs	r4, #1
    4cdc:	b.w	35e2 <loop+0xf6>
    4ce0:	adds	r3, #1
    4ce2:	movs	r4, #0
    4ce4:	movs	r5, #1
    4ce6:	b.w	35cc <loop+0xe0>
    4cea:	adds	r3, #1
    4cec:	movs	r5, #0
    4cee:	movs	r4, #1
    4cf0:	b.w	35b6 <loop+0xca>
    4cf4:	adds	r3, #1
    4cf6:	movs	r4, #0
    4cf8:	movs	r5, #1
    4cfa:	b.w	35a0 <loop+0xb4>
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    4cfe:	ldr	r4, [pc, #36]	; (4d24 <loop+0x1838>)
    4d00:	movs	r3, #2
    4d02:	ldr	r5, [pc, #44]	; (4d30 <loop+0x1844>)
    4d04:	ldr	r0, [sp, #52]	; 0x34
    4d06:	str	r5, [r1, #8]
    4d08:	str	r4, [r1, #4]
  EIGEN_DEVICE_FUNC
  CommaInitializer& operator,(const Scalar& s)
  {
    if (m_col==m_xpr.cols())
    {
      m_row+=m_currentBlockRows;
    4d0a:	adds	r3, #1
    4d0c:	movs	r5, #0
    4d0e:	movs	r4, #1
    4d10:	b.w	358a <loop+0x9e>
    4d14:	ldr	r0, [sp, #104]	; 0x68
    4d16:	cmp	r0, r2
    4d18:	bne.w	4498 <loop+0xfac>
    4d1c:	mov	r5, r4
    4d1e:	b.w	44a4 <loop+0xfb8>
    4d22:	nop
    4d24:	.word	0x3ea36e2f
    4d28:	.word	0x3e8e978d
    4d2c:	.word	0x3f750b0f
    4d30:	.word	0x3f8bf141
    4d34:	.word	0x00000000
    4d38:	ldr	r3, [sp, #36]	; 0x24
    4d3a:	ldr	r2, [sp, #32]
    4d3c:	mul.w	r2, r3, r2
    4d40:	ldr	r3, [sp, #204]	; 0xcc
struct dense_assignment_loop<Kernel, LinearTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
  {
    const Index size = kernel.size();
    for(Index i = 0; i < size; ++i)
    4d42:	cmp	r2, #0
    4d44:	ble.n	4d54 <loop+0x1868>
    4d46:	movs	r1, #0
    4d48:	add.w	r2, r3, r2, lsl #2
    4d4c:	str.w	r1, [r3], #4
    4d50:	cmp	r2, r3
    4d52:	bne.n	4d4c <loop+0x1860>
    4d54:	ldr	r0, [r7, #8]

  template<typename Dest>
  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
  {
    eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
    if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
    4d56:	cmp	r0, #0
    4d58:	beq.w	43d4 <loop+0xee8>
    4d5c:	ldr	r3, [r7, #4]
    4d5e:	cmp	r3, #0
    4d60:	beq.w	43d4 <loop+0xee8>
    4d64:	ldr	r3, [r6, #4]
    4d66:	cmp	r3, #0
    4d68:	beq.w	43d4 <loop+0xee8>

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    4d6c:	ldr	r2, [sp, #32]
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    4d6e:	movs	r4, #0
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    4d70:	ldr	r1, [sp, #36]	; 0x24
    4d72:	movs	r3, #1

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    4d74:	str	r2, [sp, #180]	; 0xb4
    4d76:	add	r2, sp, #184	; 0xb8
      this->m_nc = Transpose ? rows : cols;
    4d78:	str	r1, [sp, #184]	; 0xb8
    4d7a:	add	r1, sp, #180	; 0xb4
      this->m_kc = depth;
    4d7c:	str	r0, [sp, #188]	; 0xbc
    4d7e:	add	r0, sp, #188	; 0xbc
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    4d80:	str	r4, [sp, #172]	; 0xac
    4d82:	str	r4, [sp, #176]	; 0xb0
    4d84:	bl	1b0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)>
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    4d88:	ldr	r3, [sp, #188]	; 0xbc
    4d8a:	ldr	r2, [sp, #180]	; 0xb4
      m_sizeB = this->m_kc * this->m_nc;
    4d8c:	ldr	r0, [sp, #184]	; 0xb8
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    4d8e:	mul.w	r2, r3, r2
    4d92:	ldr	r1, [sp, #148]	; 0x94
      m_sizeB = this->m_kc * this->m_nc;
    4d94:	mul.w	r3, r3, r0
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    4d98:	str	r2, [sp, #192]	; 0xc0
      m_sizeB = this->m_kc * this->m_nc;
    4d9a:	str	r3, [sp, #196]	; 0xc4
    4d9c:	ldr	r1, [r1, #4]
    4d9e:	ldr	r5, [r7, #4]
    m_blocking.allocateA();
  }

  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
    4da0:	adds	r2, r1, #1
    4da2:	beq.w	52cc <loop+0x1de0>
    4da6:	ldr	r0, [r6, #4]
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    4da8:	add	r4, sp, #172	; 0xac
    4daa:	ldr	r3, [r7, #0]
    4dac:	ldr	r2, [r7, #8]
    4dae:	mov.w	ip, #0
    4db2:	str	r4, [sp, #20]
    4db4:	vmov.f32	s0, #112	; 0x3f800000  1.0
    4db8:	ldr	r4, [sp, #208]	; 0xd0
    4dba:	ldr	r7, [sp, #204]	; 0xcc
    4dbc:	str	r0, [sp, #8]
    4dbe:	mov	r0, r5
    4dc0:	str.w	ip, [sp, #24]
    4dc4:	str	r4, [sp, #16]
    4dc6:	str	r7, [sp, #12]
    4dc8:	ldr	r4, [r6, #0]
    4dca:	str	r5, [sp, #0]
    4dcc:	str	r4, [sp, #4]
    4dce:	bl	146c <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    4dd2:	ldr	r3, [sp, #172]	; 0xac
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    4dd4:	cbz	r3, 4dde <loop+0x18f2>
    4dd6:	ldr.w	r0, [r3, #-4]
    4dda:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    4dde:	ldr	r3, [sp, #176]	; 0xb0
    4de0:	cmp	r3, #0
    4de2:	beq.w	43d4 <loop+0xee8>
    4de6:	ldr.w	r0, [r3, #-4]
    4dea:	bl	7248 <free>
    4dee:	b.w	43d4 <loop+0xee8>
#else
  scalar_product_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a * b; }
    4df2:	vldr	s14, [r5]
  static EIGEN_STRONG_INLINE Scalar run(const Derived &mat, const Func& func)
  {
    eigen_assert(mat.rows()>0 && mat.cols()>0 && "you are using an empty matrix");
    Scalar res;
    res = mat.coeffByOuterInner(0, 0);
    for(Index i = 1; i < mat.innerSize(); ++i)
    4df6:	cmp	r7, #1
    4df8:	vldr	s15, [lr]
    4dfc:	ldr	r0, [sp, #208]	; 0xd0
    4dfe:	vmul.f32	s15, s14, s15
    4e02:	ble.w	445c <loop+0xf70>
    4e06:	lsls	r0, r0, #2
    4e08:	add.w	r2, lr, #4
    4e0c:	adds	r3, r5, r0
  }

  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  CoeffReturnType coeff(Index row, Index col) const
  {
    return m_data[col * colStride() + row * rowStride()];
    4e0e:	vldmia	r2!, {s14}
#else
  scalar_sum_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a + b; }
    4e12:	vldr	s13, [r3]
    4e16:	add	r3, r0
    4e18:	cmp	r2, r4
    4e1a:	vfma.f32	s15, s13, s14
    4e1e:	bne.n	4e0e <loop+0x1922>
    4e20:	b.w	445c <loop+0xf70>
    4e24:	ldr	r3, [sp, #32]
    4e26:	mul.w	r2, r3, ip
    4e2a:	ldr	r3, [sp, #204]	; 0xcc
    4e2c:	cmp	r2, #0
    4e2e:	str	r3, [sp, #44]	; 0x2c
    4e30:	ble.n	4e42 <loop+0x1956>
    4e32:	ldr	r3, [sp, #44]	; 0x2c
    4e34:	movs	r1, #0
    4e36:	add.w	r2, r3, r2, lsl #2
    4e3a:	str.w	r1, [r3], #4
    4e3e:	cmp	r3, r2
    4e40:	bne.n	4e3a <loop+0x194e>
    4e42:	ldr	r4, [sp, #68]	; 0x44
    4e44:	ldr.w	r8, [sp, #64]	; 0x40

  template<typename Dest>
  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
  {
    eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
    if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
    4e48:	cmp	r4, #0
    4e4a:	bne.n	4f3a <loop+0x1a4e>
    4e4c:	ldr	r6, [sp, #60]	; 0x3c
    : m_lhs(xpr.lhs()),
      m_rhs(xpr.rhs()),
      m_lhsImpl(m_lhs),     // FIXME the creation of the evaluator objects should result in a no-op, but check that!
      m_rhsImpl(m_rhs),     //       Moreover, they are only useful for the packet path, so we could completely disable them when not needed,
                            //       or perhaps declare them on the fly on the packet method... We have experiment to check what's best.
      m_innerDim(xpr.lhs().cols())
    4e4e:	add	r2, sp, #60	; 0x3c
    4e50:	ldr	r3, [sp, #188]	; 0xbc
    4e52:	str.w	ip, [sp, #224]	; 0xe0
    4e56:	str	r2, [sp, #216]	; 0xd8
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    4e58:	cmp	r3, r8
  {
    EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
  }
  
  EIGEN_DEVICE_FUNC explicit evaluator(const PlainObjectType& m)
    : m_data(m.data()), m_outerStride(IsVectorAtCompileTime ? 0 : m.outerStride()) 
    4e5a:	ldr	r2, [sp, #44]	; 0x2c
    4e5c:	str	r6, [sp, #232]	; 0xe8
    4e5e:	str	r2, [sp, #220]	; 0xdc
    4e60:	ldr	r2, [sp, #36]	; 0x24
    4e62:	str.w	r8, [sp, #236]	; 0xec
    4e66:	str	r2, [sp, #240]	; 0xf0
    4e68:	beq.w	50da <loop+0x1bee>
    dst.resize(dstRows, dstCols);
    4e6c:	mov	r2, r8
    4e6e:	mov	r1, r8
    4e70:	add	r0, sp, #184	; 0xb8
    4e72:	bl	4c0 <Eigen::PlainObjectBase<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::resize(int, int)>
    4e76:	ldr	r3, [sp, #204]	; 0xcc
    4e78:	ldr.w	fp, [sp, #192]	; 0xc0
    4e7c:	str	r3, [sp, #44]	; 0x2c
    4e7e:	ldr	r3, [sp, #188]	; 0xbc
    4e80:	str	r3, [sp, #32]
    4e82:	ldr	r3, [sp, #184]	; 0xb8
    4e84:	str	r3, [sp, #36]	; 0x24
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    4e86:	ldr	r3, [sp, #32]
    4e88:	cmp	r3, #0
    4e8a:	ble.n	4f24 <loop+0x1a38>
    4e8c:	mov.w	sl, #0
    4e90:	mov.w	r3, fp, lsl #2
    4e94:	ldr.w	r8, [sp, #44]	; 0x2c
    4e98:	mov	r9, sl
    4e9a:	str	r3, [sp, #40]	; 0x28
      for(Index inner = 0; inner < kernel.innerSize(); ++inner) {
    4e9c:	cmp.w	fp, #0
    4ea0:	ble.n	4f14 <loop+0x1a28>
    4ea2:	ldr.w	lr, [sp, #216]	; 0xd8
    4ea6:	ldr	r3, [sp, #36]	; 0x24
    4ea8:	ldr.w	r6, [lr]
    4eac:	add.w	r7, r3, sl, lsl #2
    4eb0:	ldr	r3, [sp, #40]	; 0x28
    4eb2:	ldr.w	r0, [lr, #8]
    4eb6:	add.w	ip, r6, r3
    4eba:	b.n	4eca <loop+0x19de>
template<typename Derived>
EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
DenseBase<Derived>::sum() const
{
  if(SizeAtCompileTime==0 || (SizeAtCompileTime==Dynamic && size()==0))
    return Scalar(0);
    4ebc:	vldr	s15, [pc, #-396]	; 4d34 <loop+0x1848>
    4ec0:	adds	r6, #4
    4ec2:	vstmia	r7!, {s15}
    4ec6:	cmp	r6, ip
    4ec8:	beq.n	4f14 <loop+0x1a28>
    4eca:	str.w	lr, [sp, #156]	; 0x9c
  */
template<typename Derived>
EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
DenseBase<Derived>::sum() const
{
  if(SizeAtCompileTime==0 || (SizeAtCompileTime==Dynamic && size()==0))
    4ece:	cmp	r0, #0
    4ed0:	beq.n	4ebc <loop+0x19d0>
#else
  scalar_product_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a * b; }
    4ed2:	vldr	s14, [r8]
  static EIGEN_STRONG_INLINE Scalar run(const Derived &mat, const Func& func)
  {
    eigen_assert(mat.rows()>0 && mat.cols()>0 && "you are using an empty matrix");
    Scalar res;
    res = mat.coeffByOuterInner(0, 0);
    for(Index i = 1; i < mat.innerSize(); ++i)
    4ed6:	cmp	r0, #1
    4ed8:	vldr	s15, [r6]
    4edc:	ldr	r5, [sp, #208]	; 0xd0
    4ede:	vmul.f32	s15, s14, s15
    4ee2:	ldr.w	r4, [lr, #4]
    4ee6:	ble.n	4ec0 <loop+0x19d4>
    4ee8:	lsls	r5, r5, #2
    4eea:	movs	r1, #1
    4eec:	lsls	r4, r4, #2
    4eee:	add.w	r2, r8, r5
    4ef2:	adds	r3, r6, r4
    4ef4:	adds	r1, #1
#else
  scalar_sum_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a + b; }
    4ef6:	vldr	s13, [r2]
    4efa:	vldr	s14, [r3]
    4efe:	add	r2, r5
    4f00:	cmp	r1, r0
    4f02:	add	r3, r4
    4f04:	vfma.f32	s15, s13, s14
    4f08:	bne.n	4ef4 <loop+0x1a08>
    4f0a:	adds	r6, #4
    4f0c:	vstmia	r7!, {s15}
    4f10:	cmp	r6, ip
    4f12:	bne.n	4eca <loop+0x19de>
template<typename Kernel>
struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
  {
    for(Index outer = 0; outer < kernel.outerSize(); ++outer) {
    4f14:	add.w	r9, r9, #1
    4f18:	ldr	r3, [sp, #32]
    4f1a:	add.w	r8, r8, #4
    4f1e:	add	sl, fp
    4f20:	cmp	r9, r3
    4f22:	bne.n	4e9c <loop+0x19b0>
    4f24:	ldr	r3, [sp, #44]	; 0x2c
    4f26:	cmp	r3, #0
    4f28:	beq.w	4240 <loop+0xd54>
    4f2c:	ldr	r3, [sp, #44]	; 0x2c
    4f2e:	ldr.w	r0, [r3, #-4]
    4f32:	bl	7248 <free>
    4f36:	b.w	4240 <loop+0xd54>
    4f3a:	cmp.w	r8, #0
    4f3e:	beq.n	4e4c <loop+0x1960>
    4f40:	ldr	r3, [sp, #36]	; 0x24
    4f42:	cmp	r3, #0
    4f44:	beq.n	4e4c <loop+0x1960>
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    4f46:	ldr	r0, [sp, #32]
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    4f48:	movs	r5, #0

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
      this->m_kc = depth;
    4f4a:	str	r4, [sp, #160]	; 0xa0
    4f4c:	add	r4, sp, #144	; 0x90
    4f4e:	movs	r3, #1
    4f50:	add	r2, sp, #156	; 0x9c
    4f52:	add	r1, sp, #152	; 0x98
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    4f54:	str	r0, [sp, #156]	; 0x9c
    4f56:	add	r0, sp, #160	; 0xa0

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    4f58:	str.w	ip, [sp, #152]	; 0x98
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    4f5c:	str	r5, [sp, #144]	; 0x90
    4f5e:	str	r5, [sp, #148]	; 0x94
    4f60:	bl	1b0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)>
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    4f64:	str	r4, [sp, #20]
    4f66:	vmov.f32	s0, #112	; 0x3f800000  1.0
    4f6a:	ldr	r4, [sp, #208]	; 0xd0
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    4f6c:	ldr	r3, [sp, #160]	; 0xa0
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    4f6e:	str	r4, [sp, #16]
    4f70:	ldr	r4, [sp, #52]	; 0x34
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    4f72:	ldr	r7, [sp, #152]	; 0x98
      m_sizeB = this->m_kc * this->m_nc;
    4f74:	ldr	r6, [sp, #156]	; 0x9c
    4f76:	ldr	r1, [sp, #64]	; 0x40
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    4f78:	mul.w	r7, r3, r7
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    4f7c:	str	r5, [sp, #24]
    4f7e:	str	r4, [sp, #8]
    4f80:	mov	r0, r1
    4f82:	ldr	r5, [sp, #204]	; 0xcc
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
      m_sizeB = this->m_kc * this->m_nc;
    4f84:	mul.w	r6, r3, r6
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    4f88:	ldr	r4, [sp, #48]	; 0x30
    4f8a:	ldr	r3, [sp, #60]	; 0x3c
    4f8c:	str	r1, [sp, #0]
    4f8e:	ldr	r2, [sp, #68]	; 0x44
    4f90:	ldr	r1, [sp, #56]	; 0x38
    4f92:	str	r5, [sp, #12]
    4f94:	str	r4, [sp, #4]
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    4f96:	str	r7, [sp, #164]	; 0xa4
      m_sizeB = this->m_kc * this->m_nc;
    4f98:	str	r6, [sp, #168]	; 0xa8
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    4f9a:	bl	10b0 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    4f9e:	ldr	r3, [sp, #144]	; 0x90
    4fa0:	cbz	r3, 4faa <loop+0x1abe>
    4fa2:	ldr.w	r0, [r3, #-4]
    4fa6:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    4faa:	ldr	r3, [sp, #148]	; 0x94
    4fac:	cbz	r3, 4fb6 <loop+0x1aca>
    4fae:	ldr.w	r0, [r3, #-4]
    4fb2:	bl	7248 <free>
    4fb6:	ldr	r3, [sp, #204]	; 0xcc
    4fb8:	ldr.w	ip, [sp, #208]	; 0xd0
    4fbc:	str	r3, [sp, #44]	; 0x2c
    4fbe:	ldr	r3, [sp, #56]	; 0x38
    4fc0:	ldr	r6, [sp, #60]	; 0x3c
    4fc2:	str	r3, [sp, #36]	; 0x24
    4fc4:	ldr.w	r8, [sp, #64]	; 0x40
    4fc8:	b.n	4e4e <loop+0x1962>
    4fca:	ldr	r3, [sp, #52]	; 0x34
  typedef generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode> lazyproduct;

  template<typename Dst>
  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
  {
    if((rhs.rows()+dst.rows()+dst.cols())<20 && rhs.rows()>0)
    4fcc:	cmp	r3, #19
    4fce:	bgt.w	5296 <loop+0x1daa>
    4fd2:	cmp	r3, #0
    4fd4:	ble.w	5296 <loop+0x1daa>
    4fd8:	str	r1, [sp, #44]	; 0x2c
    4fda:	mov	ip, r1
    4fdc:	ldr	r6, [sp, #60]	; 0x3c
    4fde:	str	r1, [sp, #36]	; 0x24
    4fe0:	b.n	4e4e <loop+0x1962>
  static EIGEN_STRONG_INLINE
  void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
  {
    Index dstRows = src.rows();
    Index dstCols = src.cols();
    if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
    4fe2:	str	r3, [sp, #36]	; 0x24
    4fe4:	str	r3, [sp, #32]
    4fe6:	b.w	4346 <loop+0xe5a>
EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const internal::assign_op<T1,T2> &/*func*/)
{
  Index dstRows = src.rows();
  Index dstCols = src.cols();
  if(((dst.rows()!=dstRows) || (dst.cols()!=dstCols)))
    4fea:	cmp	r8, ip
    4fec:	bne.w	411a <loop+0xc2e>
    4ff0:	b.w	4134 <loop+0xc48>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    4ff4:	mov.w	r0, #4294967295
    4ff8:	bl	6d9c <operator new(unsigned int)>
    4ffc:	b.n	4888 <loop+0x139c>
#else
  scalar_product_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a * b; }
    4ffe:	vldr	s14, [r4]
    5002:	cmp	r7, #1
    5004:	vldr	s15, [fp]
    5008:	vmul.f32	s15, s14, s15
    500c:	ble.w	417e <loop+0xc92>
    5010:	adds	r2, r4, r0
    5012:	add.w	r3, fp, #4
  }

  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
  CoeffReturnType coeff(Index row, Index col) const
  {
    return m_data[col * colStride() + row * rowStride()];
    5016:	vldmia	r3!, {s14}
#else
  scalar_sum_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a + b; }
    501a:	vldr	s13, [r2]
    501e:	add	r2, r0
    5020:	cmp	r3, r1
    5022:	vfma.f32	s15, s13, s14
    5026:	bne.n	5016 <loop+0x1b2a>
    5028:	b.w	417e <loop+0xc92>
#else
  scalar_product_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a * b; }
    502c:	vldr	s14, [r6]
    5030:	cmp	r0, #1
    5032:	vldr	s15, [r8]
    5036:	ldr	r5, [r7, #4]
    5038:	vmul.f32	s15, s14, s15
    503c:	ldr.w	r4, [r9, #4]
    5040:	ble.w	43bc <loop+0xed0>
    5044:	lsls	r5, r5, #2
    5046:	movs	r1, #1
    5048:	lsls	r4, r4, #2
    504a:	adds	r2, r6, r5
    504c:	add.w	r3, r8, r4
    5050:	adds	r1, #1
#else
  scalar_sum_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a + b; }
    5052:	vldr	s13, [r2]
    5056:	vldr	s14, [r3]
    505a:	add	r2, r5
    505c:	cmp	r1, r0
    505e:	add	r3, r4
    5060:	vfma.f32	s15, s13, s14
    5064:	bne.n	5050 <loop+0x1b64>
    5066:	b.w	43bc <loop+0xed0>
#else
  scalar_product_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a * b; }
    506a:	vldr	s14, [r6]
    506e:	cmp	r0, #1
    5070:	vldr	s15, [r9]
    5074:	ldr.w	r5, [r8, #4]
    5078:	vmul.f32	s15, s14, s15
    507c:	ldr	r4, [r7, #4]
    507e:	ble.w	4628 <loop+0x113c>
    5082:	lsls	r5, r5, #2
    5084:	movs	r1, #1
    5086:	lsls	r4, r4, #2
    5088:	adds	r2, r6, r5
    508a:	add.w	r3, r9, r4
    508e:	adds	r1, #1
#else
  scalar_sum_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a + b; }
    5090:	vldr	s13, [r2]
    5094:	vldr	s14, [r3]
    5098:	add	r2, r5
    509a:	cmp	r1, r0
    509c:	add	r3, r4
    509e:	vfma.f32	s15, s13, s14
    50a2:	bne.n	508e <loop+0x1ba2>
    50a4:	b.w	4628 <loop+0x113c>
#else
  scalar_product_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a * b; }
    50a8:	vldr	s14, [r4]
    50ac:	cmp	r6, #1
    50ae:	vldr	s15, [sl]
    50b2:	ldr	r1, [sp, #64]	; 0x40
    50b4:	vmul.f32	s15, s14, s15
    50b8:	ble.w	47ce <loop+0x12e2>
    50bc:	lsls	r1, r1, #2
    50be:	add.w	r2, sl, #4
    50c2:	adds	r3, r4, r1
    50c4:	vldmia	r2!, {s14}
#else
  scalar_sum_op() {
    EIGEN_SCALAR_BINARY_OP_PLUGIN
  }
#endif
  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a + b; }
    50c8:	vldr	s13, [r3]
    50cc:	add	r3, r1
    50ce:	cmp	r0, r2
    50d0:	vfma.f32	s15, s13, s14
    50d4:	bne.n	50c4 <loop+0x1bd8>
    50d6:	b.w	47ce <loop+0x12e2>
    50da:	ldr.w	fp, [sp, #192]	; 0xc0
    50de:	cmp	r8, fp
    50e0:	bne.w	4e6c <loop+0x1980>
    50e4:	str.w	fp, [sp, #32]
    50e8:	b.n	4e82 <loop+0x1996>
    50ea:	ldr.w	fp, [sp, #140]	; 0x8c
    50ee:	cmp	r2, fp
    50f0:	bne.w	440e <loop+0xf22>
    50f4:	b.w	441e <loop+0xf32>
    50f8:	ldr	r7, [sp, #152]	; 0x98
    50fa:	cmp	r2, r7
    50fc:	bne.w	4756 <loop+0x126a>
    5100:	ldr	r2, [sp, #52]	; 0x34
    5102:	add.w	r3, lr, r2
    5106:	add	r3, r7
    5108:	cmp	r3, #19
    510a:	bgt.n	5112 <loop+0x1c26>
    510c:	cmp	r2, #0
    510e:	bgt.w	4790 <loop+0x12a4>
    5112:	mul.w	r2, lr, r7
    5116:	ldr	r3, [sp, #144]	; 0x90
struct dense_assignment_loop<Kernel, LinearTraversal, NoUnrolling>
{
  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
  {
    const Index size = kernel.size();
    for(Index i = 0; i < size; ++i)
    5118:	cmp	r2, #0
    511a:	ble.n	512a <loop+0x1c3e>
    511c:	movs	r1, #0
    511e:	add.w	r2, r3, r2, lsl #2
    5122:	str.w	r1, [r3], #4
    5126:	cmp	r3, r2
    5128:	bne.n	5122 <loop+0x1c36>
    512a:	ldr	r4, [sp, #68]	; 0x44

  template<typename Dest>
  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
  {
    eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
    if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
    512c:	cmp	r4, #0
    512e:	beq.w	47e2 <loop+0x12f6>
    5132:	ldr	r3, [sp, #64]	; 0x40
    5134:	cmp	r3, #0
    5136:	beq.w	47e2 <loop+0x12f6>
    513a:	ldr	r3, [sp, #56]	; 0x38
    513c:	cmp	r3, #0
    513e:	beq.w	47e2 <loop+0x12f6>
    5142:	add	r6, sp, #216	; 0xd8
    5144:	add.w	fp, sp, #212	; 0xd4
    5148:	add.w	r9, sp, #220	; 0xdc
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    514c:	mov.w	r8, #0
    5150:	mov	r2, r6
    5152:	mov	r1, fp
    5154:	mov	r0, r9
    5156:	movs	r3, #1

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    5158:	str.w	lr, [sp, #212]	; 0xd4
      this->m_nc = Transpose ? rows : cols;
    515c:	str	r7, [sp, #216]	; 0xd8
      this->m_kc = depth;
    515e:	str	r4, [sp, #220]	; 0xdc
    5160:	add	r4, sp, #204	; 0xcc
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    5162:	str.w	r8, [sp, #204]	; 0xcc
    5166:	str.w	r8, [sp, #208]	; 0xd0
    516a:	bl	1b0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)>
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    516e:	ldr	r5, [sp, #148]	; 0x94
    5170:	vmov.f32	s0, #112	; 0x3f800000  1.0
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    5174:	ldr	r2, [sp, #220]	; 0xdc
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    5176:	str	r5, [sp, #16]
    5178:	ldr	r5, [sp, #144]	; 0x90
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    517a:	ldr	r3, [sp, #212]	; 0xd4
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    517c:	str	r5, [sp, #12]
    517e:	ldr	r5, [sp, #52]	; 0x34
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    5180:	mul.w	ip, r2, r3
      m_sizeB = this->m_kc * this->m_nc;
    5184:	ldr	r1, [sp, #216]	; 0xd8
    5186:	ldr	r0, [sp, #64]	; 0x40
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    5188:	str	r5, [sp, #8]
    518a:	ldr	r5, [sp, #48]	; 0x30
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
      m_sizeB = this->m_kc * this->m_nc;
    518c:	mul.w	r7, r2, r1
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    5190:	ldr	r3, [sp, #60]	; 0x3c
    5192:	ldr	r2, [sp, #68]	; 0x44
    5194:	str.w	r8, [sp, #24]
    5198:	ldr	r1, [sp, #56]	; 0x38
    519a:	str	r4, [sp, #20]
    519c:	str	r0, [sp, #0]
    519e:	str	r5, [sp, #4]
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    51a0:	str.w	ip, [sp, #224]	; 0xe0
      m_sizeB = this->m_kc * this->m_nc;
    51a4:	str	r7, [sp, #228]	; 0xe4
  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    51a6:	bl	10b0 <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 0, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    51aa:	ldr	r3, [sp, #204]	; 0xcc
}

/** \internal Frees memory allocated with handmade_aligned_malloc */
inline void handmade_aligned_free(void *ptr)
{
  if (ptr) std::free(*(reinterpret_cast<void**>(ptr) - 1));
    51ac:	cbz	r3, 51b6 <loop+0x1cca>
    51ae:	ldr.w	r0, [r3, #-4]
    51b2:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    51b6:	ldr	r3, [sp, #208]	; 0xd0
    51b8:	cbz	r3, 51c2 <loop+0x1cd6>
    51ba:	ldr.w	r0, [r3, #-4]
    51be:	bl	7248 <free>
    51c2:	ldr	r7, [sp, #152]	; 0x98
    51c4:	b.w	47ee <loop+0x1302>
    51c8:	ldr	r3, [sp, #36]	; 0x24
    51ca:	mul.w	r2, r3, sl
    51ce:	ldr	r3, [sp, #144]	; 0x90
    51d0:	cmp	r2, #0
    51d2:	ble.n	51e2 <loop+0x1cf6>
    51d4:	movs	r1, #0
    51d6:	add.w	r2, r3, r2, lsl #2
    51da:	str.w	r1, [r3], #4
    51de:	cmp	r2, r3
    51e0:	bne.n	51da <loop+0x1cee>
    51e2:	ldr.w	r3, [r8, #8]

  template<typename Dest>
  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
  {
    eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
    if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
    51e6:	cmp	r3, #0
    51e8:	beq.w	4642 <loop+0x1156>
    51ec:	ldr.w	r2, [r8, #4]
    51f0:	cmp	r2, #0
    51f2:	beq.w	4642 <loop+0x1156>
    51f6:	ldr	r2, [r7, #4]
    51f8:	cmp	r2, #0
    51fa:	beq.w	4642 <loop+0x1156>
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    51fe:	ldr	r0, [sp, #36]	; 0x24
    5200:	add	r6, sp, #216	; 0xd8
    5202:	add.w	fp, sp, #212	; 0xd4
    5206:	add.w	r9, sp, #220	; 0xdc
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    520a:	movs	r4, #0
    520c:	mov	r2, r6
    520e:	mov	r1, fp
  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
      this->m_nc = Transpose ? rows : cols;
    5210:	str	r0, [sp, #216]	; 0xd8
      this->m_kc = depth;
    5212:	str	r3, [sp, #220]	; 0xdc
    5214:	mov	r0, r9
    5216:	movs	r3, #1

  public:

    gemm_blocking_space(Index rows, Index cols, Index depth, Index num_threads, bool l3_blocking)
    {
      this->m_mc = Transpose ? cols : rows;
    5218:	str.w	sl, [sp, #212]	; 0xd4
    Index m_kc;

  public:

    level3_blocking()
      : m_blockA(0), m_blockB(0), m_mc(0), m_nc(0), m_kc(0)
    521c:	str	r4, [sp, #204]	; 0xcc
    521e:	str	r4, [sp, #208]	; 0xd0
    5220:	bl	1b0 <void Eigen::internal::evaluateProductBlockingSizesHeuristic<float, float, 1, int>(int&, int&, int&, int)>
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    5224:	ldr	r3, [sp, #220]	; 0xdc
    5226:	ldr	r2, [sp, #212]	; 0xd4
      m_sizeB = this->m_kc * this->m_nc;
    5228:	ldr	r0, [sp, #216]	; 0xd8
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    522a:	mul.w	r2, r3, r2
    522e:	ldr	r1, [sp, #124]	; 0x7c
      m_sizeB = this->m_kc * this->m_nc;
    5230:	mul.w	r3, r3, r0
      {
        Index n = this->m_nc;
        computeProductBlockingSizes<LhsScalar,RhsScalar,KcFactor>(this->m_kc, this->m_mc, n, num_threads);
      }

      m_sizeA = this->m_mc * this->m_kc;
    5234:	str	r2, [sp, #224]	; 0xe0
      m_sizeB = this->m_kc * this->m_nc;
    5236:	str	r3, [sp, #228]	; 0xe4
    5238:	ldr	r1, [r1, #4]
    523a:	ldr.w	lr, [r8, #4]
    m_blocking.allocateA();
  }

  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
    523e:	adds	r3, r1, #1
    5240:	beq.n	5302 <loop+0x1e16>
    5242:	ldr	r2, [r7, #4]
      cols = m_rhs.cols();

    Gemm::run(rows, cols, m_lhs.cols(),
    5244:	ldr.w	r0, [r8, #8]
    5248:	mov.w	sl, #0
    524c:	ldr.w	r3, [r8]
    5250:	add	r4, sp, #204	; 0xcc
    5252:	str	r2, [sp, #8]
    5254:	mov	r2, r0
    5256:	ldr	r5, [sp, #144]	; 0x90
    5258:	vmov.f32	s0, #112	; 0x3f800000  1.0
    525c:	ldr	r0, [sp, #148]	; 0x94
    525e:	str.w	sl, [sp, #24]
    5262:	str	r0, [sp, #16]
    5264:	mov	r0, lr
    5266:	str	r4, [sp, #20]
    5268:	str	r5, [sp, #12]
    526a:	ldr	r7, [r7, #0]
    526c:	str.w	lr, [sp]
    5270:	str	r7, [sp, #4]
    5272:	bl	146c <Eigen::internal::general_matrix_matrix_product<int, float, 0, false, float, 1, false, 0>::run(int, int, int, float const*, int, float const*, int, float*, int, float, Eigen::internal::level3_blocking<float, float>&, Eigen::internal::GemmParallelInfo<int>*)>
      allocateB();
    }

    ~gemm_blocking_space()
    {
      aligned_delete(this->m_blockA, m_sizeA);
    5276:	ldr	r3, [sp, #204]	; 0xcc
    5278:	cbz	r3, 5282 <loop+0x1d96>
    527a:	ldr.w	r0, [r3, #-4]
    527e:	bl	7248 <free>
      aligned_delete(this->m_blockB, m_sizeB);
    5282:	ldr	r3, [sp, #208]	; 0xd0
    5284:	cmp	r3, #0
    5286:	beq.w	464e <loop+0x1162>
    528a:	ldr.w	r0, [r3, #-4]
    528e:	bl	7248 <free>
    5292:	b.w	464e <loop+0x1162>
  typedef generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode> lazyproduct;

  template<typename Dst>
  static void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
  {
    if((rhs.rows()+dst.rows()+dst.cols())<20 && rhs.rows()>0)
    5296:	mov.w	ip, #0
    529a:	ldr	r3, [sp, #204]	; 0xcc
    529c:	str.w	ip, [sp, #32]
    52a0:	str	r3, [sp, #44]	; 0x2c
    52a2:	str.w	ip, [sp, #36]	; 0x24

  template<typename Dest>
  static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
  {
    eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
    if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
    52a6:	cmp	r4, #0
    52a8:	beq.w	4e4c <loop+0x1960>
    52ac:	b.n	4f3a <loop+0x1a4e>
    52ae:	ldr	r3, [sp, #152]	; 0x98
    52b0:	cmp	r2, r3
    52b2:	str	r3, [sp, #36]	; 0x24
    52b4:	bne.w	459e <loop+0x10b2>
    52b8:	b.w	45b4 <loop+0x10c8>
    #endif
  #else
    result = handmade_aligned_malloc(size);
  #endif

  if(!result && size)
    52bc:	cbz	r6, 5308 <loop+0x1e1c>
{
  #ifdef EIGEN_EXCEPTIONS
    throw std::bad_alloc();
  #else
    std::size_t huge = static_cast<std::size_t>(-1);
    ::operator new(huge);
    52be:	mov.w	r0, #4294967295
    52c2:	bl	6d9c <operator new(unsigned int)>
    52c6:	mov	r3, r4
    52c8:	b.w	48a4 <loop+0x13b8>
    52cc:	ldr	r1, [r6, #4]
    m_blocking.allocateA();
  }

  void operator() (Index row, Index rows, Index col=0, Index cols=-1, GemmParallelInfo<Index>* info=0) const
  {
    if(cols==-1)
    52ce:	mov	r0, r1
    52d0:	b.n	4da8 <loop+0x18bc>
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    52d2:	ldr	r3, [pc, #60]	; (5310 <loop+0x1e24>)
    52d4:	movs	r5, #1
    52d6:	str	r3, [r1, #4]
    52d8:	mov	r3, r5
    52da:	b.w	3584 <loop+0x98>
{
  typedef typename XprType::Scalar Scalar;

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
    52de:	movs	r3, #0
    52e0:	b.w	4a60 <loop+0x1574>
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    52e4:	ldr	r3, [pc, #40]	; (5310 <loop+0x1e24>)
    52e6:	mov.w	lr, #1
    52ea:	str	r3, [r1, #4]
    52ec:	mov	r3, lr
    52ee:	b.w	3c2a <loop+0x73e>
{
  typedef typename XprType::Scalar Scalar;

  EIGEN_DEVICE_FUNC
  inline CommaInitializer(XprType& xpr, const Scalar& s)
    : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
    52f2:	movs	r3, #0
    52f4:	b.n	4bb6 <loop+0x16ca>
        && "Too many rows passed to comma initializer (operator<<)");
    }
    eigen_assert(m_col<m_xpr.cols()
      && "Too many coefficients passed to comma initializer (operator<<)");
    eigen_assert(m_currentBlockRows==1);
    m_xpr.coeffRef(m_row, m_col++) = s;
    52f6:	ldr	r3, [pc, #28]	; (5314 <loop+0x1e28>)
    52f8:	movs	r0, #1
    52fa:	str	r3, [r6, #4]
    52fc:	mov	r3, r0
    52fe:	b.w	3882 <loop+0x396>
    5302:	ldr	r1, [r7, #4]
    5304:	mov	r2, r1
    5306:	b.n	5244 <loop+0x1d58>
  * Fast, but wastes 16 additional bytes of memory. Does not throw any exception.
  */
inline void* handmade_aligned_malloc(std::size_t size)
{
  void *original = std::malloc(size+EIGEN_DEFAULT_ALIGN_BYTES);
  if (original == 0) return 0;
    5308:	mov	r3, r6
    530a:	b.w	48a4 <loop+0x13b8>
    530e:	nop
    5310:	.word	0x3f8bf141
    5314:	.word	0x3f750b0f

00005318 <memcpy>:
	@ r1: src
	@ r2: len
#ifdef __ARM_FEATURE_UNALIGNED
	/* In case of UNALIGNED access supported, ip is not used in
	   function body.  */
	mov	ip, r0
    5318:	mov	ip, r0
#else
	push	{r0}
#endif
	orr	r3, r1, r0
    531a:	orr.w	r3, r1, r0
	ands	r3, r3, #3
    531e:	ands.w	r3, r3, #3
	bne	.Lmisaligned_copy
    5322:	bne.n	5400 <memcpy+0xe8>

.Lbig_block:
	subs	r2, __OPT_BIG_BLOCK_SIZE
    5324:	subs	r2, #64	; 0x40
	blo	.Lmid_block
    5326:	bcc.n	53ac <memcpy+0x94>
.Lbig_block_loop:
	BEGIN_UNROLL_BIG_BLOCK
#ifdef __ARM_ARCH_7EM__
	ldr	r3, [r1], #4
	str	r3, [r0], #4
	END_UNROLL
    5328:	ldr.w	r3, [r1], #4
    532c:	str.w	r3, [r0], #4
    5330:	ldr.w	r3, [r1], #4
    5334:	str.w	r3, [r0], #4
    5338:	ldr.w	r3, [r1], #4
    533c:	str.w	r3, [r0], #4
    5340:	ldr.w	r3, [r1], #4
    5344:	str.w	r3, [r0], #4
    5348:	ldr.w	r3, [r1], #4
    534c:	str.w	r3, [r0], #4
    5350:	ldr.w	r3, [r1], #4
    5354:	str.w	r3, [r0], #4
    5358:	ldr.w	r3, [r1], #4
    535c:	str.w	r3, [r0], #4
    5360:	ldr.w	r3, [r1], #4
    5364:	str.w	r3, [r0], #4
    5368:	ldr.w	r3, [r1], #4
    536c:	str.w	r3, [r0], #4
    5370:	ldr.w	r3, [r1], #4
    5374:	str.w	r3, [r0], #4
    5378:	ldr.w	r3, [r1], #4
    537c:	str.w	r3, [r0], #4
    5380:	ldr.w	r3, [r1], #4
    5384:	str.w	r3, [r0], #4
    5388:	ldr.w	r3, [r1], #4
    538c:	str.w	r3, [r0], #4
    5390:	ldr.w	r3, [r1], #4
    5394:	str.w	r3, [r0], #4
    5398:	ldr.w	r3, [r1], #4
    539c:	str.w	r3, [r0], #4
    53a0:	ldr.w	r3, [r1], #4
    53a4:	str.w	r3, [r0], #4
	str	r3, [r0, \offset]
	END_UNROLL
	adds	r0, __OPT_BIG_BLOCK_SIZE
	adds	r1, __OPT_BIG_BLOCK_SIZE
#endif
	subs	r2, __OPT_BIG_BLOCK_SIZE
    53a8:	subs	r2, #64	; 0x40
	bhs .Lbig_block_loop
    53aa:	bcs.n	5328 <memcpy+0x10>

.Lmid_block:
	adds	r2, __OPT_BIG_BLOCK_SIZE - __OPT_MID_BLOCK_SIZE
    53ac:	adds	r2, #48	; 0x30
	blo	.Lcopy_word_by_word
    53ae:	bcc.n	53d4 <memcpy+0xbc>
.Lmid_block_loop:
	BEGIN_UNROLL_MID_BLOCK
#ifdef __ARM_ARCH_7EM__
	ldr	r3, [r1], #4
	str	r3, [r0], #4
	END_UNROLL
    53b0:	ldr.w	r3, [r1], #4
    53b4:	str.w	r3, [r0], #4
    53b8:	ldr.w	r3, [r1], #4
    53bc:	str.w	r3, [r0], #4
    53c0:	ldr.w	r3, [r1], #4
    53c4:	str.w	r3, [r0], #4
    53c8:	ldr.w	r3, [r1], #4
    53cc:	str.w	r3, [r0], #4
	str	r3, [r0, \offset]
	END_UNROLL
	adds    r0, __OPT_MID_BLOCK_SIZE
	adds    r1, __OPT_MID_BLOCK_SIZE
#endif
	subs	r2, __OPT_MID_BLOCK_SIZE
    53d0:	subs	r2, #16
	bhs	.Lmid_block_loop
    53d2:	bcs.n	53b0 <memcpy+0x98>

.Lcopy_word_by_word:
	adds	r2, __OPT_MID_BLOCK_SIZE - 4
    53d4:	adds	r2, #12
	blo	.Lcopy_less_than_4
    53d6:	bcc.n	53e4 <memcpy+0xcc>

	/* Kernel loop for small block copy */
	.align 2
.Lcopy_word_by_word_loop:
	ldr	r3, [r1], #4
    53d8:	ldr.w	r3, [r1], #4
	str	r3, [r0], #4
    53dc:	str.w	r3, [r0], #4
	subs	r2, #4
    53e0:	subs	r2, #4
	bhs	.Lcopy_word_by_word_loop
    53e2:	bcs.n	53d8 <memcpy+0xc0>

.Lcopy_less_than_4:
	adds	r2, #4
    53e4:	adds	r2, #4
	beq	.Ldone
    53e6:	beq.n	53fa <memcpy+0xe2>

	lsls	r2, r2, #31
    53e8:	lsls	r2, r2, #31
	itt ne
    53ea:	itt	ne
	ldrbne  r3, [r1], #1
    53ec:	ldrbne.w	r3, [r1], #1
	strbne  r3, [r0], #1
    53f0:	strbne.w	r3, [r0], #1

	bcc	.Ldone
    53f4:	bcc.n	53fa <memcpy+0xe2>
#ifdef __ARM_FEATURE_UNALIGNED
	ldrh	r3, [r1]
    53f6:	ldrh	r3, [r1, #0]
	strh	r3, [r0]
    53f8:	strh	r3, [r0, #0]
	strb	r3, [r0, #1]
#endif /* __ARM_FEATURE_UNALIGNED */

.Ldone:
#ifdef __ARM_FEATURE_UNALIGNED
	mov	r0, ip
    53fa:	mov	r0, ip
#else
	pop	{r0}
#endif
	bx	lr
    53fc:	bx	lr
    53fe:	nop
#define Ldst_aligned Lbig_block

	/* Copy word by word using LDR when alignment can be done in hardware,
	i.e., SCTLR.A is set, supporting unaligned access in LDR and STR.  */

	cmp	r2, #8
    5400:	cmp	r2, #8
	blo	.Lbyte_copy
    5402:	bcc.n	542c <memcpy+0x114>

	/* if src is aligned, just go to the big block loop.  */
	lsls	r3, r1, #30
    5404:	lsls	r3, r1, #30
	beq	.Ldst_aligned
    5406:	beq.n	5324 <memcpy+0xc>
	handling of aligned src and misaligned dst need more overhead than
	otherwise.  By doing this the worst case is when initial src is aligned,
	additional up to 4 byte additional copy will executed, which is
	acceptable.  */

	ands	r3, r0, #3
    5408:	ands.w	r3, r0, #3
	beq	.Ldst_aligned
    540c:	beq.n	5324 <memcpy+0xc>

	rsb	r3, #4
    540e:	rsb	r3, r3, #4
	subs	r2, r3
    5412:	subs	r2, r2, r3

	lsls    r3, r3, #31
    5414:	lsls	r3, r3, #31
	itt ne
    5416:	itt	ne
	ldrbne  r3, [r1], #1
    5418:	ldrbne.w	r3, [r1], #1
	strbne  r3, [r0], #1
    541c:	strbne.w	r3, [r0], #1

	bcc .Ldst_aligned
    5420:	bcc.n	5324 <memcpy+0xc>

#ifdef __ARM_FEATURE_UNALIGNED
	ldrh    r3, [r1], #2
    5422:	ldrh.w	r3, [r1], #2
	strh    r3, [r0], #2
    5426:	strh.w	r3, [r0], #2
	b	.Ldst_aligned
    542a:	b.n	5324 <memcpy+0xc>
	pop	{r4, r5}

#endif /* __ARM_FEATURE_UNALIGNED */

.Lbyte_copy:
	subs	r2, #4
    542c:	subs	r2, #4
	blo	.Lcopy_less_than_4
    542e:	bcc.n	53e4 <memcpy+0xcc>

.Lbyte_copy_loop:
	subs    r2, #1
    5430:	subs	r2, #1
	ldrb    r3, [r1], #1
    5432:	ldrb.w	r3, [r1], #1
	strb    r3, [r0], #1
    5436:	strb.w	r3, [r0], #1
	bhs	.Lbyte_copy_loop
    543a:	bcs.n	5430 <memcpy+0x118>

	ldrb	r3, [r1]
    543c:	ldrb	r3, [r1, #0]
	strb	r3, [r0]
    543e:	strb	r3, [r0, #0]
	ldrb	r3, [r1, #1]
    5440:	ldrb	r3, [r1, #1]
	strb	r3, [r0, #1]
    5442:	strb	r3, [r0, #1]
	ldrb	r3, [r1, #2]
    5444:	ldrb	r3, [r1, #2]
	strb	r3, [r0, #2]
    5446:	strb	r3, [r0, #2]

#ifdef __ARM_FEATURE_UNALIGNED
	mov	r0, ip
    5448:	mov	r0, ip
#else
	pop	{r0}
#endif
	bx	lr
    544a:	bx	lr

0000544c <rx_queue_transfer>:
/*************************************************************************/
/**                               Receive                               **/
/*************************************************************************/

static void rx_queue_transfer(int i)
{
    544c:	push	{r3, r4, r5, r6, r7, lr}
	NVIC_DISABLE_IRQ(IRQ_USB1);
	printf("rx queue i=%d\n", i);
	void *buffer = rx_buffer + i * CDC_RX_SIZE_480;
    544e:	ldr	r1, [pc, #80]	; (54a0 <rx_queue_transfer+0x54>)
/**                               Receive                               **/
/*************************************************************************/

static void rx_queue_transfer(int i)
{
	NVIC_DISABLE_IRQ(IRQ_USB1);
    5450:	mov.w	r7, #131072	; 0x20000
	printf("rx queue i=%d\n", i);
	void *buffer = rx_buffer + i * CDC_RX_SIZE_480;
	usb_prepare_transfer(rx_transfer + i, buffer, rx_packet_size, i);
    5454:	ldr	r5, [pc, #76]	; (54a4 <rx_queue_transfer+0x58>)
/*************************************************************************/
/**                               Receive                               **/
/*************************************************************************/

static void rx_queue_transfer(int i)
{
    5456:	mov	r3, r0
	NVIC_DISABLE_IRQ(IRQ_USB1);
	printf("rx queue i=%d\n", i);
	void *buffer = rx_buffer + i * CDC_RX_SIZE_480;
    5458:	add.w	r4, r1, r0, lsl #9
	usb_prepare_transfer(rx_transfer + i, buffer, rx_packet_size, i);
    545c:	ldr	r6, [pc, #72]	; (54a8 <rx_queue_transfer+0x5c>)
/**                               Receive                               **/
/*************************************************************************/

static void rx_queue_transfer(int i)
{
	NVIC_DISABLE_IRQ(IRQ_USB1);
    545e:	ldr	r2, [pc, #76]	; (54ac <rx_queue_transfer+0x60>)
	printf("rx queue i=%d\n", i);
	void *buffer = rx_buffer + i * CDC_RX_SIZE_480;
	usb_prepare_transfer(rx_transfer + i, buffer, rx_packet_size, i);
    5460:	add.w	r5, r5, r0, lsl #5
    5464:	mov	r1, r4
/**                               Receive                               **/
/*************************************************************************/

static void rx_queue_transfer(int i)
{
	NVIC_DISABLE_IRQ(IRQ_USB1);
    5466:	str	r7, [r2, #0]
	printf("rx queue i=%d\n", i);
	void *buffer = rx_buffer + i * CDC_RX_SIZE_480;
	usb_prepare_transfer(rx_transfer + i, buffer, rx_packet_size, i);
    5468:	mov	r0, r5
    546a:	ldrh	r2, [r6, #0]
    546c:	bl	6428 <usb_prepare_transfer>
// read is certain to access the physical memory.
__attribute__((always_inline, unused))
static inline void arm_dcache_delete(void *addr, uint32_t size)
{
	uint32_t location = (uint32_t)addr & 0xFFFFFFE0;
	uint32_t end_addr = (uint32_t)addr + size;
    5470:	ldrh	r1, [r6, #0]
// want to delete anything the cache may have stored, so your next
// read is certain to access the physical memory.
__attribute__((always_inline, unused))
static inline void arm_dcache_delete(void *addr, uint32_t size)
{
	uint32_t location = (uint32_t)addr & 0xFFFFFFE0;
    5472:	bic.w	r3, r4, #31
	uint32_t end_addr = (uint32_t)addr + size;
    5476:	add	r1, r4
	asm("dsb");
    5478:	dsb	sy
	do {
		SCB_CACHE_DCIMVAC = location;
    547c:	ldr	r2, [pc, #48]	; (54b0 <rx_queue_transfer+0x64>)
    547e:	str	r3, [r2, #0]
		location += 32;
    5480:	adds	r3, #32
	} while (location < end_addr);
    5482:	cmp	r1, r3
    5484:	bhi.n	547e <rx_queue_transfer+0x32>
	asm("dsb");
    5486:	dsb	sy
	asm("isb");
    548a:	isb	sy
	arm_dcache_delete(buffer, rx_packet_size);
	usb_receive(CDC_RX_ENDPOINT, rx_transfer + i);
    548e:	movs	r0, #3
    5490:	mov	r1, r5
    5492:	bl	6480 <usb_receive>
	NVIC_ENABLE_IRQ(IRQ_USB1);
    5496:	ldr	r3, [pc, #28]	; (54b4 <rx_queue_transfer+0x68>)
    5498:	mov.w	r2, #131072	; 0x20000
    549c:	str	r2, [r3, #0]
    549e:	pop	{r3, r4, r5, r6, r7, pc}
    54a0:	.word	0x20200000
    54a4:	.word	0x20000980
    54a8:	.word	0x20000a8e
    54ac:	.word	0xe000e18c
    54b0:	.word	0xe000ef5c
    54b4:	.word	0xe000e10c

000054b8 <rx_event>:
}

// called by USB interrupt when any packet is received
static void rx_event(transfer_t *t)
{
	int len = rx_packet_size - ((t->status >> 16) & 0x7FFF);
    54b8:	ldr	r2, [pc, #144]	; (554c <rx_event+0x94>)
    54ba:	ldr	r3, [r0, #4]
	NVIC_ENABLE_IRQ(IRQ_USB1);
}

// called by USB interrupt when any packet is received
static void rx_event(transfer_t *t)
{
    54bc:	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	int len = rx_packet_size - ((t->status >> 16) & 0x7FFF);
    54c0:	ubfx	r3, r3, #16, #15
    54c4:	ldrh	r4, [r2, #0]
	int i = t->callback_param;
    54c6:	ldr	r5, [r0, #28]
}

// called by USB interrupt when any packet is received
static void rx_event(transfer_t *t)
{
	int len = rx_packet_size - ((t->status >> 16) & 0x7FFF);
    54c8:	subs	r4, r4, r3
	int i = t->callback_param;
	printf("rx event, len=%d, i=%d\n", len, i);
	if (len > 0) {
    54ca:	cmp	r4, #0
    54cc:	ble.n	5540 <rx_event+0x88>
		// received a packet with data
		uint32_t head = rx_head;
    54ce:	ldr	r1, [pc, #128]	; (5550 <rx_event+0x98>)
		if (head != rx_tail) {
    54d0:	ldr	r2, [pc, #128]	; (5554 <rx_event+0x9c>)
	int len = rx_packet_size - ((t->status >> 16) & 0x7FFF);
	int i = t->callback_param;
	printf("rx event, len=%d, i=%d\n", len, i);
	if (len > 0) {
		// received a packet with data
		uint32_t head = rx_head;
    54d2:	ldrb	r3, [r1, #0]
		if (head != rx_tail) {
    54d4:	ldrb	r2, [r2, #0]
	int len = rx_packet_size - ((t->status >> 16) & 0x7FFF);
	int i = t->callback_param;
	printf("rx event, len=%d, i=%d\n", len, i);
	if (len > 0) {
		// received a packet with data
		uint32_t head = rx_head;
    54d6:	uxtb	r3, r3
		if (head != rx_tail) {
			// a previous packet is still buffered
			uint32_t ii = rx_list[head];
    54d8:	ldr	r0, [pc, #124]	; (5558 <rx_event+0xa0>)
			uint32_t count = rx_count[ii];
    54da:	ldr	r6, [pc, #128]	; (555c <rx_event+0xa4>)
	int i = t->callback_param;
	printf("rx event, len=%d, i=%d\n", len, i);
	if (len > 0) {
		// received a packet with data
		uint32_t head = rx_head;
		if (head != rx_tail) {
    54dc:	cmp	r3, r2
    54de:	beq.n	54f0 <rx_event+0x38>
			// a previous packet is still buffered
			uint32_t ii = rx_list[head];
    54e0:	ldrb.w	r8, [r0, r3]
			uint32_t count = rx_count[ii];
    54e4:	ldrh.w	r7, [r6, r8, lsl #1]
			if (len <= CDC_RX_SIZE_480 - count) {
    54e8:	rsb	r2, r7, #512	; 0x200
    54ec:	cmp	r4, r2
    54ee:	bls.n	5516 <rx_event+0x5e>
			}
		}
		// add this packet to rx_list
		rx_count[i] = len;
		rx_index[i] = 0;
		if (++head > RX_NUM) head = 0;
    54f0:	adds	r3, #1
				return;
			}
		}
		// add this packet to rx_list
		rx_count[i] = len;
		rx_index[i] = 0;
    54f2:	movs	r2, #0
    54f4:	ldr	r7, [pc, #104]	; (5560 <rx_event+0xa8>)
		if (++head > RX_NUM) head = 0;
    54f6:	cmp	r3, #8
				// TODO: trigger serialEvent
				return;
			}
		}
		// add this packet to rx_list
		rx_count[i] = len;
    54f8:	strh.w	r4, [r6, r5, lsl #1]
		rx_index[i] = 0;
    54fc:	strh.w	r2, [r7, r5, lsl #1]
		if (++head > RX_NUM) head = 0;
		rx_list[head] = i;
		rx_head = head;
		rx_available += len;
    5500:	ldr	r6, [pc, #96]	; (5564 <rx_event+0xac>)
    5502:	ite	ls
    5504:	uxtbls	r2, r3
			}
		}
		// add this packet to rx_list
		rx_count[i] = len;
		rx_index[i] = 0;
		if (++head > RX_NUM) head = 0;
    5506:	movhi	r3, r2
		rx_list[head] = i;
		rx_head = head;
    5508:	strb	r2, [r1, #0]
		rx_available += len;
    550a:	ldr	r2, [r6, #0]
		}
		// add this packet to rx_list
		rx_count[i] = len;
		rx_index[i] = 0;
		if (++head > RX_NUM) head = 0;
		rx_list[head] = i;
    550c:	strb	r5, [r0, r3]
		rx_head = head;
		rx_available += len;
    550e:	add	r4, r2
    5510:	str	r4, [r6, #0]
    5512:	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
			// a previous packet is still buffered
			uint32_t ii = rx_list[head];
			uint32_t count = rx_count[ii];
			if (len <= CDC_RX_SIZE_480 - count) {
				// previous buffer has enough free space for this packet's data
				memcpy(rx_buffer + ii * CDC_RX_SIZE_480 + count,
    5516:	ldr	r3, [pc, #80]	; (5568 <rx_event+0xb0>)
    5518:	add.w	r0, r7, r8, lsl #9
    551c:	mov	r2, r4
					rx_buffer + i * CDC_RX_SIZE_480, len);
				rx_count[ii] = count + len;
    551e:	add	r7, r4
			// a previous packet is still buffered
			uint32_t ii = rx_list[head];
			uint32_t count = rx_count[ii];
			if (len <= CDC_RX_SIZE_480 - count) {
				// previous buffer has enough free space for this packet's data
				memcpy(rx_buffer + ii * CDC_RX_SIZE_480 + count,
    5520:	add.w	r1, r3, r5, lsl #9
    5524:	add	r0, r3
    5526:	bl	5318 <memcpy>
					rx_buffer + i * CDC_RX_SIZE_480, len);
				rx_count[ii] = count + len;
				rx_available += len;
    552a:	ldr	r2, [pc, #56]	; (5564 <rx_event+0xac>)
				rx_queue_transfer(i);
    552c:	mov	r0, r5
			uint32_t count = rx_count[ii];
			if (len <= CDC_RX_SIZE_480 - count) {
				// previous buffer has enough free space for this packet's data
				memcpy(rx_buffer + ii * CDC_RX_SIZE_480 + count,
					rx_buffer + i * CDC_RX_SIZE_480, len);
				rx_count[ii] = count + len;
    552e:	strh.w	r7, [r6, r8, lsl #1]
				rx_available += len;
    5532:	ldr	r3, [r2, #0]
    5534:	add	r4, r3
    5536:	str	r4, [r2, #0]
		// TODO: trigger serialEvent
	} else {
		// received a zero length packet
		rx_queue_transfer(i);
	}
}
    5538:	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
				// previous buffer has enough free space for this packet's data
				memcpy(rx_buffer + ii * CDC_RX_SIZE_480 + count,
					rx_buffer + i * CDC_RX_SIZE_480, len);
				rx_count[ii] = count + len;
				rx_available += len;
				rx_queue_transfer(i);
    553c:	b.w	544c <rx_queue_transfer>
		rx_head = head;
		rx_available += len;
		// TODO: trigger serialEvent
	} else {
		// received a zero length packet
		rx_queue_transfer(i);
    5540:	mov	r0, r5
	}
}
    5542:	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
		rx_head = head;
		rx_available += len;
		// TODO: trigger serialEvent
	} else {
		// received a zero length packet
		rx_queue_transfer(i);
    5546:	b.w	544c <rx_queue_transfer>
    554a:	nop
    554c:	.word	0x20000a8e
    5550:	.word	0x20000aa4
    5554:	.word	0x20000a80
    5558:	.word	0x20000a84
    555c:	.word	0x20000a90
    5560:	.word	0x2000096c
    5564:	.word	0x20000aa0
    5568:	.word	0x20200000

0000556c <usb_serial_flush_callback>:
	tx_noautoflush = 0;
}

static void usb_serial_flush_callback(void)
{
	if (tx_noautoflush) return;
    556c:	ldr	r3, [pc, #120]	; (55e8 <usb_serial_flush_callback+0x7c>)
    556e:	ldrb	r2, [r3, #0]
    5570:	cbnz	r2, 558a <usb_serial_flush_callback+0x1e>
    5572:	and.w	r3, r2, #255	; 0xff
	if (!usb_configuration) return;
    5576:	ldr	r2, [pc, #116]	; (55ec <usb_serial_flush_callback+0x80>)
    5578:	ldrb	r2, [r2, #0]
    557a:	cbz	r2, 558a <usb_serial_flush_callback+0x1e>
	tx_available = 0;
	tx_noautoflush = 0;
}

static void usb_serial_flush_callback(void)
{
    557c:	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	if (tx_noautoflush) return;
	if (!usb_configuration) return;
	if (tx_available == 0) return;
    5580:	ldr	r5, [pc, #108]	; (55f0 <usb_serial_flush_callback+0x84>)
    5582:	ldrh	r2, [r5, #0]
    5584:	cbnz	r2, 558c <usb_serial_flush_callback+0x20>
    5586:	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    558a:	bx	lr
	//printf("flush callback, %d bytes\n", TX_SIZE - tx_available);
	transfer_t *xfer = tx_transfer + tx_head;
    558c:	ldr	r6, [pc, #100]	; (55f4 <usb_serial_flush_callback+0x88>)
	uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
	uint32_t txnum = TX_SIZE - tx_available;
    558e:	rsb	r8, r2, #2048	; 0x800
{
	if (tx_noautoflush) return;
	if (!usb_configuration) return;
	if (tx_available == 0) return;
	//printf("flush callback, %d bytes\n", TX_SIZE - tx_available);
	transfer_t *xfer = tx_transfer + tx_head;
    5592:	ldr	r7, [pc, #100]	; (55f8 <usb_serial_flush_callback+0x8c>)
    5594:	ldrb	r1, [r6, #0]
	uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
	uint32_t txnum = TX_SIZE - tx_available;
	usb_prepare_transfer(xfer, txbuf, txnum, 0);
    5596:	mov	r2, r8
	if (tx_noautoflush) return;
	if (!usb_configuration) return;
	if (tx_available == 0) return;
	//printf("flush callback, %d bytes\n", TX_SIZE - tx_available);
	transfer_t *xfer = tx_transfer + tx_head;
	uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
    5598:	ldr	r4, [pc, #96]	; (55fc <usb_serial_flush_callback+0x90>)
{
	if (tx_noautoflush) return;
	if (!usb_configuration) return;
	if (tx_available == 0) return;
	//printf("flush callback, %d bytes\n", TX_SIZE - tx_available);
	transfer_t *xfer = tx_transfer + tx_head;
    559a:	add.w	r7, r7, r1, lsl #5
	uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
    559e:	add.w	r4, r4, r1, lsl #11
	uint32_t txnum = TX_SIZE - tx_available;
	usb_prepare_transfer(xfer, txbuf, txnum, 0);
    55a2:	mov	r0, r7
    55a4:	mov	r1, r4
    55a6:	bl	6428 <usb_prepare_transfer>
// because you no longer need to access the data after transmission.
__attribute__((always_inline, unused))
static inline void arm_dcache_flush_delete(void *addr, uint32_t size)
{
	uint32_t location = (uint32_t)addr & 0xFFFFFFE0;
	uint32_t end_addr = (uint32_t)addr + size;
    55aa:	add.w	r2, r8, r4
// any cached data written to memory, and then removed from the cache,
// because you no longer need to access the data after transmission.
__attribute__((always_inline, unused))
static inline void arm_dcache_flush_delete(void *addr, uint32_t size)
{
	uint32_t location = (uint32_t)addr & 0xFFFFFFE0;
    55ae:	bic.w	r1, r4, #31
	uint32_t end_addr = (uint32_t)addr + size;
	asm("dsb");
    55b2:	dsb	sy
	do {
		SCB_CACHE_DCCIMVAC = location;
    55b6:	ldr	r3, [pc, #72]	; (5600 <usb_serial_flush_callback+0x94>)
    55b8:	str	r1, [r3, #0]
		location += 32;
    55ba:	adds	r1, #32
	} while (location < end_addr);
    55bc:	cmp	r2, r1
    55be:	bhi.n	55b8 <usb_serial_flush_callback+0x4c>
	asm("dsb");
    55c0:	dsb	sy
	asm("isb");
    55c4:	isb	sy
	arm_dcache_flush_delete(txbuf, txnum);
	usb_transmit(CDC_TX_ENDPOINT, xfer);
    55c8:	movs	r0, #4
    55ca:	mov	r1, r7
    55cc:	bl	6458 <usb_transmit>
	if (++tx_head >= TX_NUM) tx_head = 0;
    55d0:	ldrb	r3, [r6, #0]
    55d2:	ldr	r2, [pc, #32]	; (55f4 <usb_serial_flush_callback+0x88>)
    55d4:	adds	r3, #1
    55d6:	uxtb	r3, r3
    55d8:	cmp	r3, #3
    55da:	it	hi
    55dc:	movhi	r3, #0
    55de:	strb	r3, [r2, #0]
	tx_available = 0;
    55e0:	movs	r3, #0
    55e2:	strh	r3, [r5, #0]
    55e4:	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    55e8:	.word	0x2000097e
    55ec:	.word	0x20000b78
    55f0:	.word	0x20000aa6
    55f4:	.word	0x2000097f
    55f8:	.word	0x20000ac0
    55fc:	.word	0x20201000
    5600:	.word	0xe000ef70

00005604 <usb_serial_write.part.1>:
{
	USB1_GPTIMER0CTRL = 0;
}


int usb_serial_write(const void *buffer, uint32_t size)
    5604:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    5608:	sub	sp, #20
    560a:	str	r0, [sp, #8]
{
	uint32_t sent=0;
	const uint8_t *data = (const uint8_t *)buffer;

	if (!usb_configuration) return 0;
	while (size > 0) {
    560c:	str	r1, [sp, #4]
    560e:	cmp	r1, #0
    5610:	beq.w	5758 <usb_serial_write.part.1+0x154>
    5614:	movs	r3, #0
    5616:	ldr.w	r8, [pc, #348]	; 5774 <usb_serial_write.part.1+0x170>
    561a:	ldr.w	r9, [pc, #332]	; 5768 <usb_serial_write.part.1+0x164>
    561e:	str	r3, [sp, #0]
				tx_available = TX_SIZE;
				transmit_previous_timeout = 0;
				break;
			}
			if (!waiting) {
				wait_begin_at = systick_millis_count;
    5620:	ldr	r6, [pc, #312]	; (575c <usb_serial_write.part.1+0x158>)
    5622:	ldrh.w	r3, [r8]
				//printf("tx head=%d\n", tx_head);
				//printf("TXFILLTUNING=%08lX\n", USB1_TXFILLTUNING);
				//usb_print_transfer_log();
				//while (1) ;
			}
			if (!usb_configuration) return sent;
    5626:	ldr.w	sl, [pc, #336]	; 5778 <usb_serial_write.part.1+0x174>
{
	uint32_t location = (uint32_t)addr & 0xFFFFFFE0;
	uint32_t end_addr = (uint32_t)addr + size;
	asm("dsb");
	do {
		SCB_CACHE_DCCIMVAC = location;
    562a:	ldr.w	fp, [pc, #336]	; 577c <usb_serial_write.part.1+0x178>
	uint32_t sent=0;
	const uint8_t *data = (const uint8_t *)buffer;

	if (!usb_configuration) return 0;
	while (size > 0) {
		transfer_t *xfer = tx_transfer + tx_head;
    562e:	ldr	r2, [pc, #304]	; (5760 <usb_serial_write.part.1+0x15c>)
    5630:	ldrb	r4, [r2, #0]
    5632:	ldr	r2, [pc, #304]	; (5764 <usb_serial_write.part.1+0x160>)
    5634:	add.w	r7, r2, r4, lsl #5
		int waiting=0;
		uint32_t wait_begin_at=0;
		while (!tx_available) {
    5638:	cmp	r3, #0
    563a:	bne.n	571a <usb_serial_write.part.1+0x116>
    563c:	mov	r5, r3
    563e:	mov	r4, r3
    5640:	b.n	566c <usb_serial_write.part.1+0x68>
			}
			if (!waiting) {
				wait_begin_at = systick_millis_count;
				waiting = 1;
			}
			if (transmit_previous_timeout) return sent;
    5642:	ldrb.w	r3, [r9]
				}
				tx_available = TX_SIZE;
				transmit_previous_timeout = 0;
				break;
			}
			if (!waiting) {
    5646:	cbnz	r4, 564a <usb_serial_write.part.1+0x46>
				wait_begin_at = systick_millis_count;
    5648:	ldr	r5, [r6, #0]
    564a:	movs	r4, #1
				waiting = 1;
			}
			if (transmit_previous_timeout) return sent;
    564c:	cmp	r3, #0
    564e:	bne.n	570e <usb_serial_write.part.1+0x10a>
			if (systick_millis_count - wait_begin_at > TX_TIMEOUT_MSEC) {
    5650:	ldr	r3, [r6, #0]
    5652:	subs	r3, r3, r5
    5654:	cmp	r3, #120	; 0x78
    5656:	bhi.n	574c <usb_serial_write.part.1+0x148>
				//printf("tx head=%d\n", tx_head);
				//printf("TXFILLTUNING=%08lX\n", USB1_TXFILLTUNING);
				//usb_print_transfer_log();
				//while (1) ;
			}
			if (!usb_configuration) return sent;
    5658:	ldrb.w	r3, [sl]
    565c:	cmp	r3, #0
    565e:	beq.n	570e <usb_serial_write.part.1+0x10a>
			yield();
    5660:	bl	6894 <yield>
	if (!usb_configuration) return 0;
	while (size > 0) {
		transfer_t *xfer = tx_transfer + tx_head;
		int waiting=0;
		uint32_t wait_begin_at=0;
		while (!tx_available) {
    5664:	ldrh.w	r3, [r8]
    5668:	cmp	r3, #0
    566a:	bne.n	5716 <usb_serial_write.part.1+0x112>
			//digitalWriteFast(3, HIGH);
			uint32_t status = usb_transfer_status(xfer);
    566c:	mov	r0, r7
    566e:	bl	64a4 <usb_transfer_status>
			if (!(status & 0x80)) {
    5672:	ands.w	r0, r0, #128	; 0x80
			}
			if (!waiting) {
				wait_begin_at = systick_millis_count;
				waiting = 1;
			}
			if (transmit_previous_timeout) return sent;
    5676:	ldr	r2, [pc, #240]	; (5768 <usb_serial_write.part.1+0x164>)
		int waiting=0;
		uint32_t wait_begin_at=0;
		while (!tx_available) {
			//digitalWriteFast(3, HIGH);
			uint32_t status = usb_transfer_status(xfer);
			if (!(status & 0x80)) {
    5678:	bne.n	5642 <usb_serial_write.part.1+0x3e>
				if (status & 0x68) {
					// TODO: what if status has errors???
					printf("ERROR status = %x, i=%d, ms=%u\n",
						status, tx_head, systick_millis_count);
				}
				tx_available = TX_SIZE;
    567a:	mov.w	r3, #2048	; 0x800
    567e:	ldr	r2, [pc, #224]	; (5760 <usb_serial_write.part.1+0x15c>)
				transmit_previous_timeout = 0;
    5680:	strb.w	r0, [r9]
    5684:	ldrb	r4, [r2, #0]
    5686:	mov	r2, r3
				if (status & 0x68) {
					// TODO: what if status has errors???
					printf("ERROR status = %x, i=%d, ms=%u\n",
						status, tx_head, systick_millis_count);
				}
				tx_available = TX_SIZE;
    5688:	strh.w	r3, [r8]
			}
			if (!usb_configuration) return sent;
			yield();
		}
		//digitalWriteFast(3, LOW);
		uint8_t *txdata = txbuffer + (tx_head * TX_SIZE) + (TX_SIZE - tx_available);
    568c:	lsls	r4, r4, #11
		if (size >= tx_available) {
    568e:	ldr	r5, [sp, #4]
			}
			if (!usb_configuration) return sent;
			yield();
		}
		//digitalWriteFast(3, LOW);
		uint8_t *txdata = txbuffer + (tx_head * TX_SIZE) + (TX_SIZE - tx_available);
    5690:	ldr	r1, [pc, #216]	; (576c <usb_serial_write.part.1+0x168>)
    5692:	add	r0, r4
		if (size >= tx_available) {
    5694:	cmp	r5, r2
			}
			if (!usb_configuration) return sent;
			yield();
		}
		//digitalWriteFast(3, LOW);
		uint8_t *txdata = txbuffer + (tx_head * TX_SIZE) + (TX_SIZE - tx_available);
    5696:	add	r0, r1
		if (size >= tx_available) {
    5698:	bcc.n	5722 <usb_serial_write.part.1+0x11e>
			memcpy(txdata, data, tx_available);
			//*(txbuffer + (tx_head * TX_SIZE)) = 'A' + tx_head; // to see which buffer
			//*(txbuffer + (tx_head * TX_SIZE) + 1) = ' '; // really see it
			uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
    569a:	add	r4, r1
			yield();
		}
		//digitalWriteFast(3, LOW);
		uint8_t *txdata = txbuffer + (tx_head * TX_SIZE) + (TX_SIZE - tx_available);
		if (size >= tx_available) {
			memcpy(txdata, data, tx_available);
    569c:	ldr	r1, [sp, #8]
    569e:	bl	5318 <memcpy>
			//*(txbuffer + (tx_head * TX_SIZE)) = 'A' + tx_head; // to see which buffer
			//*(txbuffer + (tx_head * TX_SIZE) + 1) = ' '; // really see it
			uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
			usb_prepare_transfer(xfer, txbuf, TX_SIZE, 0);
    56a2:	movs	r3, #0
    56a4:	mov	r1, r4
    56a6:	mov.w	r2, #2048	; 0x800
    56aa:	mov	r0, r7
    56ac:	bl	6428 <usb_prepare_transfer>
// any cached data written to memory, and then removed from the cache,
// because you no longer need to access the data after transmission.
__attribute__((always_inline, unused))
static inline void arm_dcache_flush_delete(void *addr, uint32_t size)
{
	uint32_t location = (uint32_t)addr & 0xFFFFFFE0;
    56b0:	bic.w	r3, r4, #31
	uint32_t end_addr = (uint32_t)addr + size;
    56b4:	add.w	r4, r4, #2048	; 0x800
	asm("dsb");
    56b8:	dsb	sy
	do {
		SCB_CACHE_DCCIMVAC = location;
    56bc:	str.w	r3, [fp]
		location += 32;
    56c0:	adds	r3, #32
	} while (location < end_addr);
    56c2:	cmp	r4, r3
    56c4:	bhi.n	56bc <usb_serial_write.part.1+0xb8>
	asm("dsb");
    56c6:	dsb	sy
	asm("isb");
    56ca:	isb	sy
			arm_dcache_flush_delete(txbuf, TX_SIZE);
			usb_transmit(CDC_TX_ENDPOINT, xfer);
    56ce:	movs	r0, #4
    56d0:	mov	r1, r7
    56d2:	bl	6458 <usb_transmit>
			if (++tx_head >= TX_NUM) tx_head = 0;
    56d6:	ldr	r3, [pc, #136]	; (5760 <usb_serial_write.part.1+0x15c>)
    56d8:	ldr	r2, [pc, #132]	; (5760 <usb_serial_write.part.1+0x15c>)
			size -= tx_available;
			sent += tx_available;
			data += tx_available;
			tx_available = 0;
    56da:	movs	r1, #0
			//*(txbuffer + (tx_head * TX_SIZE) + 1) = ' '; // really see it
			uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
			usb_prepare_transfer(xfer, txbuf, TX_SIZE, 0);
			arm_dcache_flush_delete(txbuf, TX_SIZE);
			usb_transmit(CDC_TX_ENDPOINT, xfer);
			if (++tx_head >= TX_NUM) tx_head = 0;
    56dc:	ldrb	r3, [r3, #0]
	USB1_GPTIMER0CTRL = USB_GPTIMERCTRL_GPTRUN | USB_GPTIMERCTRL_GPTRST;
}

static void timer_stop(void)
{
	USB1_GPTIMER0CTRL = 0;
    56de:	ldr	r0, [pc, #144]	; (5770 <usb_serial_write.part.1+0x16c>)
			//*(txbuffer + (tx_head * TX_SIZE) + 1) = ' '; // really see it
			uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
			usb_prepare_transfer(xfer, txbuf, TX_SIZE, 0);
			arm_dcache_flush_delete(txbuf, TX_SIZE);
			usb_transmit(CDC_TX_ENDPOINT, xfer);
			if (++tx_head >= TX_NUM) tx_head = 0;
    56e0:	adds	r3, #1
    56e2:	uxtb	r3, r3
    56e4:	cmp	r3, #3
    56e6:	it	hi
    56e8:	movhi	r3, #0
    56ea:	strb	r3, [r2, #0]
			size -= tx_available;
    56ec:	ldrh.w	r2, [r8]
			sent += tx_available;
    56f0:	ldr	r3, [sp, #0]
			data += tx_available;
			tx_available = 0;
    56f2:	strh.w	r1, [r8]
			usb_prepare_transfer(xfer, txbuf, TX_SIZE, 0);
			arm_dcache_flush_delete(txbuf, TX_SIZE);
			usb_transmit(CDC_TX_ENDPOINT, xfer);
			if (++tx_head >= TX_NUM) tx_head = 0;
			size -= tx_available;
			sent += tx_available;
    56f6:	add	r3, r2
    56f8:	str	r3, [sp, #0]
			data += tx_available;
    56fa:	ldr	r3, [sp, #8]
    56fc:	add	r3, r2
    56fe:	str	r3, [sp, #8]
    5700:	mov	r3, r1
	USB1_GPTIMER0CTRL = USB_GPTIMERCTRL_GPTRUN | USB_GPTIMERCTRL_GPTRST;
}

static void timer_stop(void)
{
	USB1_GPTIMER0CTRL = 0;
    5702:	str.w	r1, [r0, #132]	; 0x84
{
	uint32_t sent=0;
	const uint8_t *data = (const uint8_t *)buffer;

	if (!usb_configuration) return 0;
	while (size > 0) {
    5706:	ldr	r1, [sp, #4]
    5708:	subs	r2, r1, r2
    570a:	str	r2, [sp, #4]
    570c:	bne.n	562e <usb_serial_write.part.1+0x2a>
    570e:	ldr	r0, [sp, #0]
			size = 0;
			timer_start_oneshot();
		}
	}
	return sent;
}
    5710:	add	sp, #20
    5712:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    5716:	ldr	r2, [pc, #72]	; (5760 <usb_serial_write.part.1+0x15c>)
    5718:	ldrb	r4, [r2, #0]
    571a:	mov	r2, r3
    571c:	rsb	r0, r3, #2048	; 0x800
    5720:	b.n	568c <usb_serial_write.part.1+0x88>
			sent += tx_available;
			data += tx_available;
			tx_available = 0;
			timer_stop();
		} else {
			memcpy(txdata, data, size);
    5722:	ldr	r4, [sp, #4]
    5724:	ldr	r1, [sp, #8]
    5726:	mov	r2, r4
    5728:	str	r3, [sp, #12]
    572a:	bl	5318 <memcpy>
			tx_available -= size;
    572e:	ldr	r3, [sp, #12]
}

static void timer_start_oneshot(void)
{
	// restarts timer if already running (retriggerable one-shot)
	USB1_GPTIMER0CTRL = USB_GPTIMERCTRL_GPTRUN | USB_GPTIMERCTRL_GPTRST;
    5730:	ldr	r2, [pc, #60]	; (5770 <usb_serial_write.part.1+0x16c>)
    5732:	mov.w	r1, #3221225472	; 0xc0000000
			data += tx_available;
			tx_available = 0;
			timer_stop();
		} else {
			memcpy(txdata, data, size);
			tx_available -= size;
    5736:	subs	r3, r3, r4
    5738:	strh.w	r3, [r8]
    573c:	ldr	r3, [sp, #0]
}

static void timer_start_oneshot(void)
{
	// restarts timer if already running (retriggerable one-shot)
	USB1_GPTIMER0CTRL = USB_GPTIMERCTRL_GPTRUN | USB_GPTIMERCTRL_GPTRST;
    573e:	str.w	r1, [r2, #132]	; 0x84
    5742:	mov	r0, r3
    5744:	add	r0, r4
			size = 0;
			timer_start_oneshot();
		}
	}
	return sent;
}
    5746:	add	sp, #20
    5748:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
				waiting = 1;
			}
			if (transmit_previous_timeout) return sent;
			if (systick_millis_count - wait_begin_at > TX_TIMEOUT_MSEC) {
				// waited too long, assume the USB host isn't listening
				transmit_previous_timeout = 1;
    574c:	movs	r3, #1
				return sent;
    574e:	ldr	r0, [sp, #0]
				waiting = 1;
			}
			if (transmit_previous_timeout) return sent;
			if (systick_millis_count - wait_begin_at > TX_TIMEOUT_MSEC) {
				// waited too long, assume the USB host isn't listening
				transmit_previous_timeout = 1;
    5750:	strb	r3, [r2, #0]
			size = 0;
			timer_start_oneshot();
		}
	}
	return sent;
}
    5752:	add	sp, #20
    5754:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
{
	uint32_t sent=0;
	const uint8_t *data = (const uint8_t *)buffer;

	if (!usb_configuration) return 0;
	while (size > 0) {
    5758:	ldr	r0, [sp, #4]
    575a:	b.n	5710 <usb_serial_write.part.1+0x10c>
    575c:	.word	0x20000b84
    5760:	.word	0x2000097f
    5764:	.word	0x20000ac0
    5768:	.word	0x20000aa5
    576c:	.word	0x20201000
    5770:	.word	0x402e0000
    5774:	.word	0x20000aa6
    5778:	.word	0x20000b78
    577c:	.word	0xe000ef70

00005780 <usb_serial_reset>:
static void rx_queue_transfer(int i);
static void rx_event(transfer_t *t);


void usb_serial_reset(void)
{
    5780:	bx	lr
    5782:	nop

00005784 <usb_serial_configure>:
void usb_serial_configure(void)
{
	int i;

	printf("usb_serial_configure\n");
	if (usb_high_speed) {
    5784:	ldr	r3, [pc, #196]	; (584c <usb_serial_configure+0xc8>)
	printf("usb_serial_reset\n");
	// deallocate all transfer descriptors
}

void usb_serial_configure(void)
{
    5786:	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	int i;

	printf("usb_serial_configure\n");
	if (usb_high_speed) {
    578a:	ldrb	r3, [r3, #0]
		tx_packet_size = CDC_TX_SIZE_480;
    578c:	ldr	r7, [pc, #192]	; (5850 <usb_serial_configure+0xcc>)
void usb_serial_configure(void)
{
	int i;

	printf("usb_serial_configure\n");
	if (usb_high_speed) {
    578e:	cmp	r3, #0
    5790:	beq.n	583c <usb_serial_configure+0xb8>
		tx_packet_size = CDC_TX_SIZE_480;
    5792:	mov.w	r3, #512	; 0x200
		rx_packet_size = CDC_RX_SIZE_480;
    5796:	ldr.w	r8, [pc, #236]	; 5884 <usb_serial_configure+0x100>
{
	int i;

	printf("usb_serial_configure\n");
	if (usb_high_speed) {
		tx_packet_size = CDC_TX_SIZE_480;
    579a:	strh	r3, [r7, #0]
		rx_packet_size = CDC_RX_SIZE_480;
    579c:	strh.w	r3, [r8]
	} else {
		tx_packet_size = CDC_TX_SIZE_12;
		rx_packet_size = CDC_RX_SIZE_12;
	}
	memset(tx_transfer, 0, sizeof(tx_transfer));
    57a0:	movs	r1, #0
    57a2:	movs	r2, #128	; 0x80
    57a4:	ldr	r0, [pc, #172]	; (5854 <usb_serial_configure+0xd0>)
	tx_head = 0;
    57a6:	mov	r5, r1
	tx_available = 0;
	memset(rx_transfer, 0, sizeof(rx_transfer));
	memset(rx_count, 0, sizeof(rx_count));
    57a8:	ldr	r6, [pc, #172]	; (5858 <usb_serial_configure+0xd4>)
		rx_packet_size = CDC_RX_SIZE_480;
	} else {
		tx_packet_size = CDC_TX_SIZE_12;
		rx_packet_size = CDC_RX_SIZE_12;
	}
	memset(tx_transfer, 0, sizeof(tx_transfer));
    57aa:	bl	77c8 <memset>
	tx_head = 0;
    57ae:	ldr	r4, [pc, #172]	; (585c <usb_serial_configure+0xd8>)
	tx_available = 0;
    57b0:	ldr	r3, [pc, #172]	; (5860 <usb_serial_configure+0xdc>)
	memset(rx_transfer, 0, sizeof(rx_transfer));
    57b2:	mov	r1, r5
    57b4:	mov.w	r2, #256	; 0x100
    57b8:	ldr	r0, [pc, #168]	; (5864 <usb_serial_configure+0xe0>)
	} else {
		tx_packet_size = CDC_TX_SIZE_12;
		rx_packet_size = CDC_RX_SIZE_12;
	}
	memset(tx_transfer, 0, sizeof(tx_transfer));
	tx_head = 0;
    57ba:	strb	r5, [r4, #0]
	rx_tail = 0;
	rx_available = 0;
	usb_config_tx(CDC_ACM_ENDPOINT, CDC_ACM_SIZE, 0, NULL); // size same 12 & 480
	usb_config_rx(CDC_RX_ENDPOINT, rx_packet_size, 0, rx_event);
	usb_config_tx(CDC_TX_ENDPOINT, tx_packet_size, 1, NULL);
	for (i=0; i < RX_NUM; i++) rx_queue_transfer(i);
    57bc:	mov	r4, r5
		tx_packet_size = CDC_TX_SIZE_12;
		rx_packet_size = CDC_RX_SIZE_12;
	}
	memset(tx_transfer, 0, sizeof(tx_transfer));
	tx_head = 0;
	tx_available = 0;
    57be:	strh	r5, [r3, #0]
	memset(rx_transfer, 0, sizeof(rx_transfer));
    57c0:	bl	77c8 <memset>
	memset(rx_count, 0, sizeof(rx_count));
    57c4:	str	r5, [r6, #0]
	memset(rx_index, 0, sizeof(rx_index));
	rx_head = 0;
	rx_tail = 0;
	rx_available = 0;
	usb_config_tx(CDC_ACM_ENDPOINT, CDC_ACM_SIZE, 0, NULL); // size same 12 & 480
    57c6:	mov	r3, r5
	}
	memset(tx_transfer, 0, sizeof(tx_transfer));
	tx_head = 0;
	tx_available = 0;
	memset(rx_transfer, 0, sizeof(rx_transfer));
	memset(rx_count, 0, sizeof(rx_count));
    57c8:	str	r5, [r6, #4]
	memset(rx_index, 0, sizeof(rx_index));
	rx_head = 0;
	rx_tail = 0;
	rx_available = 0;
	usb_config_tx(CDC_ACM_ENDPOINT, CDC_ACM_SIZE, 0, NULL); // size same 12 & 480
    57ca:	mov	r2, r5
	}
	memset(tx_transfer, 0, sizeof(tx_transfer));
	tx_head = 0;
	tx_available = 0;
	memset(rx_transfer, 0, sizeof(rx_transfer));
	memset(rx_count, 0, sizeof(rx_count));
    57cc:	str	r5, [r6, #8]
    57ce:	str	r5, [r6, #12]
	memset(rx_index, 0, sizeof(rx_index));
	rx_head = 0;
    57d0:	ldr	r1, [pc, #148]	; (5868 <usb_serial_configure+0xe4>)
	memset(tx_transfer, 0, sizeof(tx_transfer));
	tx_head = 0;
	tx_available = 0;
	memset(rx_transfer, 0, sizeof(rx_transfer));
	memset(rx_count, 0, sizeof(rx_count));
	memset(rx_index, 0, sizeof(rx_index));
    57d2:	ldr	r6, [pc, #152]	; (586c <usb_serial_configure+0xe8>)
	rx_head = 0;
	rx_tail = 0;
    57d4:	ldr	r0, [pc, #152]	; (5870 <usb_serial_configure+0xec>)
	rx_available = 0;
    57d6:	ldr.w	lr, [pc, #176]	; 5888 <usb_serial_configure+0x104>
	tx_head = 0;
	tx_available = 0;
	memset(rx_transfer, 0, sizeof(rx_transfer));
	memset(rx_count, 0, sizeof(rx_count));
	memset(rx_index, 0, sizeof(rx_index));
	rx_head = 0;
    57da:	strb	r5, [r1, #0]
	rx_tail = 0;
	rx_available = 0;
	usb_config_tx(CDC_ACM_ENDPOINT, CDC_ACM_SIZE, 0, NULL); // size same 12 & 480
    57dc:	movs	r1, #16
	tx_available = 0;
	memset(rx_transfer, 0, sizeof(rx_transfer));
	memset(rx_count, 0, sizeof(rx_count));
	memset(rx_index, 0, sizeof(rx_index));
	rx_head = 0;
	rx_tail = 0;
    57de:	strb	r5, [r0, #0]
	rx_available = 0;
	usb_config_tx(CDC_ACM_ENDPOINT, CDC_ACM_SIZE, 0, NULL); // size same 12 & 480
    57e0:	movs	r0, #2
	memset(tx_transfer, 0, sizeof(tx_transfer));
	tx_head = 0;
	tx_available = 0;
	memset(rx_transfer, 0, sizeof(rx_transfer));
	memset(rx_count, 0, sizeof(rx_count));
	memset(rx_index, 0, sizeof(rx_index));
    57e2:	str	r5, [r6, #0]
    57e4:	str	r5, [r6, #4]
    57e6:	str	r5, [r6, #8]
    57e8:	str	r5, [r6, #12]
	rx_head = 0;
	rx_tail = 0;
	rx_available = 0;
    57ea:	str.w	r5, [lr]
	usb_config_tx(CDC_ACM_ENDPOINT, CDC_ACM_SIZE, 0, NULL); // size same 12 & 480
    57ee:	bl	63c0 <usb_config_tx>
	usb_config_rx(CDC_RX_ENDPOINT, rx_packet_size, 0, rx_event);
    57f2:	ldrh.w	r1, [r8]
    57f6:	mov	r2, r5
    57f8:	ldr	r3, [pc, #120]	; (5874 <usb_serial_configure+0xf0>)
    57fa:	movs	r0, #3
    57fc:	bl	635c <usb_config_rx>
	usb_config_tx(CDC_TX_ENDPOINT, tx_packet_size, 1, NULL);
    5800:	mov	r3, r5
    5802:	ldrh	r1, [r7, #0]
    5804:	movs	r2, #1
    5806:	movs	r0, #4
    5808:	bl	63c0 <usb_config_tx>
	for (i=0; i < RX_NUM; i++) rx_queue_transfer(i);
    580c:	mov	r0, r4
    580e:	adds	r4, #1
    5810:	bl	544c <rx_queue_transfer>
    5814:	cmp	r4, #8
    5816:	bne.n	580c <usb_serial_configure+0x88>
static void timer_stop();

static void timer_config(void (*callback)(void), uint32_t microseconds)
{
	usb_timer0_callback = callback;
	USB1_GPTIMER0CTRL = 0;
    5818:	ldr	r3, [pc, #92]	; (5878 <usb_serial_configure+0xf4>)
	USB1_GPTIMER0LD = microseconds - 1;
    581a:	movs	r2, #74	; 0x4a
static void timer_start_oneshot();
static void timer_stop();

static void timer_config(void (*callback)(void), uint32_t microseconds)
{
	usb_timer0_callback = callback;
    581c:	ldr	r0, [pc, #92]	; (587c <usb_serial_configure+0xf8>)
	USB1_GPTIMER0CTRL = 0;
    581e:	movs	r1, #0
static void timer_start_oneshot();
static void timer_stop();

static void timer_config(void (*callback)(void), uint32_t microseconds)
{
	usb_timer0_callback = callback;
    5820:	ldr	r4, [pc, #92]	; (5880 <usb_serial_configure+0xfc>)
    5822:	str	r4, [r0, #0]
	USB1_GPTIMER0CTRL = 0;
    5824:	str.w	r1, [r3, #132]	; 0x84
	USB1_GPTIMER0LD = microseconds - 1;
    5828:	str.w	r2, [r3, #128]	; 0x80
	USB1_USBINTR |= USB_USBINTR_TIE0;
    582c:	ldr.w	r2, [r3, #328]	; 0x148
    5830:	orr.w	r2, r2, #16777216	; 0x1000000
    5834:	str.w	r2, [r3, #328]	; 0x148
    5838:	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
	printf("usb_serial_configure\n");
	if (usb_high_speed) {
		tx_packet_size = CDC_TX_SIZE_480;
		rx_packet_size = CDC_RX_SIZE_480;
	} else {
		tx_packet_size = CDC_TX_SIZE_12;
    583c:	movs	r3, #64	; 0x40
		rx_packet_size = CDC_RX_SIZE_12;
    583e:	ldr.w	r8, [pc, #68]	; 5884 <usb_serial_configure+0x100>
	printf("usb_serial_configure\n");
	if (usb_high_speed) {
		tx_packet_size = CDC_TX_SIZE_480;
		rx_packet_size = CDC_RX_SIZE_480;
	} else {
		tx_packet_size = CDC_TX_SIZE_12;
    5842:	strh	r3, [r7, #0]
		rx_packet_size = CDC_RX_SIZE_12;
    5844:	strh.w	r3, [r8]
    5848:	b.n	57a0 <usb_serial_configure+0x1c>
    584a:	nop
    584c:	.word	0x20000b50
    5850:	.word	0x2000097c
    5854:	.word	0x20000ac0
    5858:	.word	0x20000a90
    585c:	.word	0x2000097f
    5860:	.word	0x20000aa6
    5864:	.word	0x20000980
    5868:	.word	0x20000aa4
    586c:	.word	0x2000096c
    5870:	.word	0x20000a80
    5874:	.word	0x000054b9
    5878:	.word	0x402e0000
    587c:	.word	0x20000b40
    5880:	.word	0x0000556d
    5884:	.word	0x20000a8e
    5888:	.word	0x20000aa0

0000588c <usb_serial_read>:
int usb_serial_read(void *buffer, uint32_t size)
{
	uint8_t *p = (uint8_t *)buffer;
	uint32_t count=0;

	NVIC_DISABLE_IRQ(IRQ_USB1);
    588c:	ldr	r3, [pc, #196]	; (5954 <usb_serial_read+0xc8>)
    588e:	mov.w	r2, #131072	; 0x20000

//static int maxtimes=0;

// read a block of bytes to a buffer
int usb_serial_read(void *buffer, uint32_t size)
{
    5892:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
	uint8_t *p = (uint8_t *)buffer;
	uint32_t count=0;

	NVIC_DISABLE_IRQ(IRQ_USB1);
    5896:	str	r2, [r3, #0]

//static int maxtimes=0;

// read a block of bytes to a buffer
int usb_serial_read(void *buffer, uint32_t size)
{
    5898:	sub	sp, #12
	uint8_t *p = (uint8_t *)buffer;
	uint32_t count=0;

	NVIC_DISABLE_IRQ(IRQ_USB1);
	//if (++maxtimes > 15) while (1) ;
	uint32_t tail = rx_tail;
    589a:	ldr	r3, [pc, #188]	; (5958 <usb_serial_read+0xcc>)
	//printf("usb_serial_read, size=%d, tail=%d, head=%d\n", size, tail, rx_head);
	while (count < size && tail != rx_head) {
    589c:	mov	r9, r1
	uint8_t *p = (uint8_t *)buffer;
	uint32_t count=0;

	NVIC_DISABLE_IRQ(IRQ_USB1);
	//if (++maxtimes > 15) while (1) ;
	uint32_t tail = rx_tail;
    589e:	ldrb	r4, [r3, #0]
	//printf("usb_serial_read, size=%d, tail=%d, head=%d\n", size, tail, rx_head);
	while (count < size && tail != rx_head) {
    58a0:	cmp	r1, #0
    58a2:	beq.n	594c <usb_serial_read+0xc0>
    58a4:	ldr	r3, [pc, #180]	; (595c <usb_serial_read+0xd0>)
    58a6:	uxtb	r4, r4
    58a8:	ldrb	r3, [r3, #0]
    58aa:	cmp	r4, r3
    58ac:	beq.n	5950 <usb_serial_read+0xc4>
    58ae:	mov	sl, r0
    58b0:	movs	r7, #0
    58b2:	ldr.w	fp, [pc, #192]	; 5974 <usb_serial_read+0xe8>
		if (++tail > RX_NUM) tail = 0;
    58b6:	adds	r4, #1
		uint32_t i = rx_list[tail];
		uint32_t len = size - count;
		uint32_t avail = rx_count[i] - rx_index[i];
    58b8:	ldr	r3, [pc, #164]	; (5960 <usb_serial_read+0xd4>)
	uint32_t tail = rx_tail;
	//printf("usb_serial_read, size=%d, tail=%d, head=%d\n", size, tail, rx_head);
	while (count < size && tail != rx_head) {
		if (++tail > RX_NUM) tail = 0;
		uint32_t i = rx_list[tail];
		uint32_t len = size - count;
    58ba:	rsb	r8, r7, r9
			rx_available -= len;
			rx_index[i] += len;
			count += len;
		} else {
			// fully consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], avail);
    58be:	mov	r0, sl
	NVIC_DISABLE_IRQ(IRQ_USB1);
	//if (++maxtimes > 15) while (1) ;
	uint32_t tail = rx_tail;
	//printf("usb_serial_read, size=%d, tail=%d, head=%d\n", size, tail, rx_head);
	while (count < size && tail != rx_head) {
		if (++tail > RX_NUM) tail = 0;
    58c0:	cmp	r4, #9
		uint32_t i = rx_list[tail];
		uint32_t len = size - count;
		uint32_t avail = rx_count[i] - rx_index[i];
    58c2:	str	r3, [sp, #4]
	//if (++maxtimes > 15) while (1) ;
	uint32_t tail = rx_tail;
	//printf("usb_serial_read, size=%d, tail=%d, head=%d\n", size, tail, rx_head);
	while (count < size && tail != rx_head) {
		if (++tail > RX_NUM) tail = 0;
		uint32_t i = rx_list[tail];
    58c4:	ldr	r3, [pc, #156]	; (5964 <usb_serial_read+0xd8>)
	NVIC_DISABLE_IRQ(IRQ_USB1);
	//if (++maxtimes > 15) while (1) ;
	uint32_t tail = rx_tail;
	//printf("usb_serial_read, size=%d, tail=%d, head=%d\n", size, tail, rx_head);
	while (count < size && tail != rx_head) {
		if (++tail > RX_NUM) tail = 0;
    58c6:	it	cs
    58c8:	movcs	r4, #0
		uint32_t i = rx_list[tail];
    58ca:	ldrb	r5, [r3, r4]
		uint32_t len = size - count;
		uint32_t avail = rx_count[i] - rx_index[i];
    58cc:	ldr	r3, [pc, #144]	; (5960 <usb_serial_read+0xd4>)
    58ce:	ldrh.w	lr, [r3, r5, lsl #1]
    58d2:	ldr	r3, [pc, #148]	; (5968 <usb_serial_read+0xdc>)
			rx_available -= len;
			rx_index[i] += len;
			count += len;
		} else {
			// fully consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], avail);
    58d4:	add.w	r1, lr, r5, lsl #9
	//printf("usb_serial_read, size=%d, tail=%d, head=%d\n", size, tail, rx_head);
	while (count < size && tail != rx_head) {
		if (++tail > RX_NUM) tail = 0;
		uint32_t i = rx_list[tail];
		uint32_t len = size - count;
		uint32_t avail = rx_count[i] - rx_index[i];
    58d8:	ldrh.w	r6, [r3, r5, lsl #1]
			rx_available -= len;
			rx_index[i] += len;
			count += len;
		} else {
			// fully consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], avail);
    58dc:	ldr	r3, [pc, #140]	; (596c <usb_serial_read+0xe0>)
	//printf("usb_serial_read, size=%d, tail=%d, head=%d\n", size, tail, rx_head);
	while (count < size && tail != rx_head) {
		if (++tail > RX_NUM) tail = 0;
		uint32_t i = rx_list[tail];
		uint32_t len = size - count;
		uint32_t avail = rx_count[i] - rx_index[i];
    58de:	rsb	r6, lr, r6
			rx_available -= len;
			rx_index[i] += len;
			count += len;
		} else {
			// fully consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], avail);
    58e2:	add	r1, r3
		uint32_t i = rx_list[tail];
		uint32_t len = size - count;
		uint32_t avail = rx_count[i] - rx_index[i];
		 //printf("usb_serial_read, count=%d, size=%d, i=%d, index=%d, len=%d, avail=%d, c=%c\n",
		  //count, size, i, rx_index[i], len, avail, rx_buffer[i * CDC_RX_SIZE_480]);
		if (avail > len) {
    58e4:	cmp	r8, r6
			rx_available -= len;
			rx_index[i] += len;
			count += len;
		} else {
			// fully consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], avail);
    58e6:	mov	r2, r6
			p += avail;
			rx_available -= avail;
			count += avail;
    58e8:	add	r7, r6
		uint32_t i = rx_list[tail];
		uint32_t len = size - count;
		uint32_t avail = rx_count[i] - rx_index[i];
		 //printf("usb_serial_read, count=%d, size=%d, i=%d, index=%d, len=%d, avail=%d, c=%c\n",
		  //count, size, i, rx_index[i], len, avail, rx_buffer[i * CDC_RX_SIZE_480]);
		if (avail > len) {
    58ea:	bcs.n	5920 <usb_serial_read+0x94>
			// partially consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], len);
    58ec:	add.w	r1, lr, r5, lsl #9
    58f0:	mov	r2, r8
    58f2:	add	r1, r3
    58f4:	bl	5318 <memcpy>
			rx_available -= len;
			rx_index[i] += len;
    58f8:	ldr	r3, [sp, #4]
		 //printf("usb_serial_read, count=%d, size=%d, i=%d, index=%d, len=%d, avail=%d, c=%c\n",
		  //count, size, i, rx_index[i], len, avail, rx_buffer[i * CDC_RX_SIZE_480]);
		if (avail > len) {
			// partially consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], len);
			rx_available -= len;
    58fa:	ldr.w	r1, [fp]
    58fe:	mov	r0, r9
			rx_index[i] += len;
    5900:	ldrh.w	r2, [r3, r5, lsl #1]
		 //printf("usb_serial_read, count=%d, size=%d, i=%d, index=%d, len=%d, avail=%d, c=%c\n",
		  //count, size, i, rx_index[i], len, avail, rx_buffer[i * CDC_RX_SIZE_480]);
		if (avail > len) {
			// partially consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], len);
			rx_available -= len;
    5904:	rsb	r1, r8, r1
			rx_index[i] += len;
    5908:	add	r8, r2
		 //printf("usb_serial_read, count=%d, size=%d, i=%d, index=%d, len=%d, avail=%d, c=%c\n",
		  //count, size, i, rx_index[i], len, avail, rx_buffer[i * CDC_RX_SIZE_480]);
		if (avail > len) {
			// partially consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], len);
			rx_available -= len;
    590a:	str.w	r1, [fp]
			rx_index[i] += len;
    590e:	strh.w	r8, [r3, r5, lsl #1]
			count += avail;
			rx_tail = tail;
			rx_queue_transfer(i);
		}
	}
	NVIC_ENABLE_IRQ(IRQ_USB1);
    5912:	ldr	r3, [pc, #92]	; (5970 <usb_serial_read+0xe4>)
    5914:	mov.w	r2, #131072	; 0x20000
    5918:	str	r2, [r3, #0]
	return count;
}
    591a:	add	sp, #12
    591c:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
			rx_available -= len;
			rx_index[i] += len;
			count += len;
		} else {
			// fully consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], avail);
    5920:	bl	5318 <memcpy>
			p += avail;
			rx_available -= avail;
    5924:	ldr.w	r2, [fp]
			count += avail;
			rx_tail = tail;
    5928:	uxtb	r3, r4
			rx_queue_transfer(i);
    592a:	mov	r0, r5
			count += len;
		} else {
			// fully consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], avail);
			p += avail;
			rx_available -= avail;
    592c:	subs	r2, r2, r6
			rx_index[i] += len;
			count += len;
		} else {
			// fully consume this packet
			memcpy(p, rx_buffer + i * CDC_RX_SIZE_480 + rx_index[i], avail);
			p += avail;
    592e:	add	sl, r6
			rx_available -= avail;
    5930:	str.w	r2, [fp]
			count += avail;
			rx_tail = tail;
    5934:	ldr	r2, [pc, #32]	; (5958 <usb_serial_read+0xcc>)
    5936:	strb	r3, [r2, #0]
			rx_queue_transfer(i);
    5938:	bl	544c <rx_queue_transfer>

	NVIC_DISABLE_IRQ(IRQ_USB1);
	//if (++maxtimes > 15) while (1) ;
	uint32_t tail = rx_tail;
	//printf("usb_serial_read, size=%d, tail=%d, head=%d\n", size, tail, rx_head);
	while (count < size && tail != rx_head) {
    593c:	cmp	r9, r7
    593e:	bls.n	5948 <usb_serial_read+0xbc>
    5940:	ldr	r3, [pc, #24]	; (595c <usb_serial_read+0xd0>)
    5942:	ldrb	r3, [r3, #0]
    5944:	cmp	r4, r3
    5946:	bne.n	58b6 <usb_serial_read+0x2a>
    5948:	mov	r0, r7
    594a:	b.n	5912 <usb_serial_read+0x86>
    594c:	mov	r0, r1
    594e:	b.n	5912 <usb_serial_read+0x86>
    5950:	movs	r0, #0
    5952:	b.n	5912 <usb_serial_read+0x86>
    5954:	.word	0xe000e18c
    5958:	.word	0x20000a80
    595c:	.word	0x20000aa4
    5960:	.word	0x2000096c
    5964:	.word	0x20000a84
    5968:	.word	0x20000a90
    596c:	.word	0x20200000
    5970:	.word	0xe000e10c
    5974:	.word	0x20000aa0

00005978 <usb_serial_peekchar>:
}

// peek at the next character, or -1 if nothing received
int usb_serial_peekchar(void)
{
	uint32_t tail = rx_tail;
    5978:	ldr	r3, [pc, #44]	; (59a8 <usb_serial_peekchar+0x30>)
	if (tail == rx_head) return -1;
    597a:	ldr	r2, [pc, #48]	; (59ac <usb_serial_peekchar+0x34>)
}

// peek at the next character, or -1 if nothing received
int usb_serial_peekchar(void)
{
	uint32_t tail = rx_tail;
    597c:	ldrb	r3, [r3, #0]
	if (tail == rx_head) return -1;
    597e:	ldrb	r2, [r2, #0]
}

// peek at the next character, or -1 if nothing received
int usb_serial_peekchar(void)
{
	uint32_t tail = rx_tail;
    5980:	uxtb	r3, r3
	if (tail == rx_head) return -1;
    5982:	cmp	r3, r2
    5984:	beq.n	59a2 <usb_serial_peekchar+0x2a>
	if (++tail > RX_NUM) tail = 0;
    5986:	adds	r3, #1
	uint32_t i = rx_list[tail];
    5988:	ldr	r0, [pc, #36]	; (59b0 <usb_serial_peekchar+0x38>)
	return rx_buffer[i * CDC_RX_SIZE_480 + rx_index[i]];
    598a:	ldr	r2, [pc, #40]	; (59b4 <usb_serial_peekchar+0x3c>)
// peek at the next character, or -1 if nothing received
int usb_serial_peekchar(void)
{
	uint32_t tail = rx_tail;
	if (tail == rx_head) return -1;
	if (++tail > RX_NUM) tail = 0;
    598c:	cmp	r3, #9
	uint32_t i = rx_list[tail];
	return rx_buffer[i * CDC_RX_SIZE_480 + rx_index[i]];
    598e:	ldr	r1, [pc, #40]	; (59b8 <usb_serial_peekchar+0x40>)
// peek at the next character, or -1 if nothing received
int usb_serial_peekchar(void)
{
	uint32_t tail = rx_tail;
	if (tail == rx_head) return -1;
	if (++tail > RX_NUM) tail = 0;
    5990:	it	cs
    5992:	movcs	r3, #0
	uint32_t i = rx_list[tail];
    5994:	ldrb	r3, [r0, r3]
	return rx_buffer[i * CDC_RX_SIZE_480 + rx_index[i]];
    5996:	ldrh.w	r1, [r1, r3, lsl #1]
    599a:	add.w	r3, r2, r3, lsl #9
    599e:	ldrb	r0, [r3, r1]
    59a0:	bx	lr

// peek at the next character, or -1 if nothing received
int usb_serial_peekchar(void)
{
	uint32_t tail = rx_tail;
	if (tail == rx_head) return -1;
    59a2:	mov.w	r0, #4294967295
	if (++tail > RX_NUM) tail = 0;
	uint32_t i = rx_list[tail];
	return rx_buffer[i * CDC_RX_SIZE_480 + rx_index[i]];
}
    59a6:	bx	lr
    59a8:	.word	0x20000a80
    59ac:	.word	0x20000aa4
    59b0:	.word	0x20000a84
    59b4:	.word	0x20200000
    59b8:	.word	0x2000096c

000059bc <usb_serial_available>:

// number of bytes available in the receive buffer
int usb_serial_available(void)
{
	return rx_available;
    59bc:	ldr	r3, [pc, #4]	; (59c4 <usb_serial_available+0x8>)
    59be:	ldr	r0, [r3, #0]
}
    59c0:	bx	lr
    59c2:	nop
    59c4:	.word	0x20000aa0

000059c8 <usb_serial_flush_input>:

// discard any buffered input
void usb_serial_flush_input(void)
{
    59c8:	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, lr}
	uint32_t tail = rx_tail;
    59cc:	ldr	r6, [pc, #84]	; (5a24 <usb_serial_flush_input+0x5c>)
	while (tail != rx_head) {
    59ce:	ldr	r5, [pc, #88]	; (5a28 <usb_serial_flush_input+0x60>)
}

// discard any buffered input
void usb_serial_flush_input(void)
{
	uint32_t tail = rx_tail;
    59d0:	ldrb	r4, [r6, #0]
	while (tail != rx_head) {
    59d2:	ldrb	r3, [r5, #0]
}

// discard any buffered input
void usb_serial_flush_input(void)
{
	uint32_t tail = rx_tail;
    59d4:	uxtb	r4, r4
	while (tail != rx_head) {
    59d6:	cmp	r4, r3
    59d8:	beq.n	5a1e <usb_serial_flush_input+0x56>
    59da:	ldr.w	r9, [pc, #84]	; 5a30 <usb_serial_flush_input+0x68>
    59de:	ldr.w	fp, [pc, #84]	; 5a34 <usb_serial_flush_input+0x6c>
    59e2:	ldr.w	r8, [pc, #84]	; 5a38 <usb_serial_flush_input+0x70>
    59e6:	ldr	r7, [pc, #68]	; (5a2c <usb_serial_flush_input+0x64>)
		if (++tail > RX_NUM) tail = 0;
    59e8:	adds	r4, #1
    59ea:	cmp	r4, #8
    59ec:	uxtb.w	sl, r4
    59f0:	bls.n	59f6 <usb_serial_flush_input+0x2e>
    59f2:	movs	r4, #0
    59f4:	mov	sl, r4
		uint32_t i = rx_list[tail];
    59f6:	ldrb.w	r1, [r9, r4]
		rx_available -= rx_count[i] - rx_index[i];
    59fa:	ldr.w	r2, [fp]
    59fe:	ldrh.w	r3, [r8, r1, lsl #1]
		rx_queue_transfer(i);
    5a02:	mov	r0, r1
{
	uint32_t tail = rx_tail;
	while (tail != rx_head) {
		if (++tail > RX_NUM) tail = 0;
		uint32_t i = rx_list[tail];
		rx_available -= rx_count[i] - rx_index[i];
    5a04:	ldrh.w	r1, [r7, r1, lsl #1]
    5a08:	subs	r3, r3, r1
    5a0a:	subs	r3, r2, r3
    5a0c:	str.w	r3, [fp]
		rx_queue_transfer(i);
    5a10:	bl	544c <rx_queue_transfer>
		rx_tail = tail;
    5a14:	strb.w	sl, [r6]

// discard any buffered input
void usb_serial_flush_input(void)
{
	uint32_t tail = rx_tail;
	while (tail != rx_head) {
    5a18:	ldrb	r3, [r5, #0]
    5a1a:	cmp	r4, r3
    5a1c:	bne.n	59e8 <usb_serial_flush_input+0x20>
    5a1e:	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, sl, fp, pc}
    5a22:	nop
    5a24:	.word	0x20000a80
    5a28:	.word	0x20000aa4
    5a2c:	.word	0x2000096c
    5a30:	.word	0x20000a84
    5a34:	.word	0x20000aa0
    5a38:	.word	0x20000a90

00005a3c <usb_serial_getchar>:
}


// get the next character, or -1 if nothing received
int usb_serial_getchar(void)
{
    5a3c:	push	{lr}
    5a3e:	sub	sp, #12
	uint8_t c;
	if (usb_serial_read(&c, 1)) return c;
    5a40:	movs	r1, #1
    5a42:	add.w	r0, sp, #7
    5a46:	bl	588c <usb_serial_read>
    5a4a:	cbz	r0, 5a56 <usb_serial_getchar+0x1a>
    5a4c:	ldrb.w	r0, [sp, #7]
	return -1;
}
    5a50:	add	sp, #12
    5a52:	ldr.w	pc, [sp], #4
// get the next character, or -1 if nothing received
int usb_serial_getchar(void)
{
	uint8_t c;
	if (usb_serial_read(&c, 1)) return c;
	return -1;
    5a56:	mov.w	r0, #4294967295
    5a5a:	b.n	5a50 <usb_serial_getchar+0x14>

00005a5c <usb_serial_putchar>:
int usb_serial_write(const void *buffer, uint32_t size)
{
	uint32_t sent=0;
	const uint8_t *data = (const uint8_t *)buffer;

	if (!usb_configuration) return 0;
    5a5c:	ldr	r3, [pc, #36]	; (5a84 <usb_serial_putchar+0x28>)
static uint8_t transmit_previous_timeout=0;


// transmit a character.  0 returned on success, -1 on error
int usb_serial_putchar(uint8_t c)
{
    5a5e:	push	{lr}
    5a60:	sub	sp, #12
int usb_serial_write(const void *buffer, uint32_t size)
{
	uint32_t sent=0;
	const uint8_t *data = (const uint8_t *)buffer;

	if (!usb_configuration) return 0;
    5a62:	ldrb	r3, [r3, #0]
static uint8_t transmit_previous_timeout=0;


// transmit a character.  0 returned on success, -1 on error
int usb_serial_putchar(uint8_t c)
{
    5a64:	strb.w	r0, [sp, #7]
int usb_serial_write(const void *buffer, uint32_t size)
{
	uint32_t sent=0;
	const uint8_t *data = (const uint8_t *)buffer;

	if (!usb_configuration) return 0;
    5a68:	cbnz	r3, 5a74 <usb_serial_putchar+0x18>
    5a6a:	and.w	r0, r3, #255	; 0xff

// transmit a character.  0 returned on success, -1 on error
int usb_serial_putchar(uint8_t c)
{
	return usb_serial_write(&c, 1);
}
    5a6e:	add	sp, #12
    5a70:	ldr.w	pc, [sp], #4
    5a74:	movs	r1, #1
    5a76:	add.w	r0, sp, #7
    5a7a:	bl	5604 <usb_serial_write.part.1>
    5a7e:	add	sp, #12
    5a80:	ldr.w	pc, [sp], #4
    5a84:	.word	0x20000b78

00005a88 <usb_serial_write>:
int usb_serial_write(const void *buffer, uint32_t size)
{
	uint32_t sent=0;
	const uint8_t *data = (const uint8_t *)buffer;

	if (!usb_configuration) return 0;
    5a88:	ldr	r3, [pc, #16]	; (5a9c <usb_serial_write+0x14>)
    5a8a:	ldrb	r3, [r3, #0]
    5a8c:	and.w	r2, r3, #255	; 0xff
    5a90:	cbz	r3, 5a96 <usb_serial_write+0xe>
    5a92:	b.w	5604 <usb_serial_write.part.1>
			size = 0;
			timer_start_oneshot();
		}
	}
	return sent;
}
    5a96:	mov	r0, r2
    5a98:	bx	lr
    5a9a:	nop
    5a9c:	.word	0x20000b78

00005aa0 <usb_serial_write_buffer_free>:

int usb_serial_write_buffer_free(void)
{
    5aa0:	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
	uint32_t sum = 0;
	tx_noautoflush = 1;
	for (uint32_t i=0; i < TX_NUM; i++) {
    5aa4:	movs	r4, #0
}

int usb_serial_write_buffer_free(void)
{
	uint32_t sum = 0;
	tx_noautoflush = 1;
    5aa6:	ldr.w	r8, [pc, #64]	; 5ae8 <usb_serial_write_buffer_free+0x48>
    5aaa:	movs	r3, #1
    5aac:	ldr	r5, [pc, #48]	; (5ae0 <usb_serial_write_buffer_free+0x40>)
	return sent;
}

int usb_serial_write_buffer_free(void)
{
	uint32_t sum = 0;
    5aae:	mov	r7, r4
    5ab0:	ldr	r6, [pc, #48]	; (5ae4 <usb_serial_write_buffer_free+0x44>)
	tx_noautoflush = 1;
    5ab2:	strb.w	r3, [r8]
	for (uint32_t i=0; i < TX_NUM; i++) {
		if (i == tx_head) continue;
    5ab6:	ldrb	r3, [r6, #0]
		if (!(usb_transfer_status(tx_transfer + i) & 0x80)) sum += TX_SIZE;
    5ab8:	mov	r0, r5
    5aba:	adds	r5, #32
int usb_serial_write_buffer_free(void)
{
	uint32_t sum = 0;
	tx_noautoflush = 1;
	for (uint32_t i=0; i < TX_NUM; i++) {
		if (i == tx_head) continue;
    5abc:	cmp	r3, r4

int usb_serial_write_buffer_free(void)
{
	uint32_t sum = 0;
	tx_noautoflush = 1;
	for (uint32_t i=0; i < TX_NUM; i++) {
    5abe:	add.w	r4, r4, #1
		if (i == tx_head) continue;
    5ac2:	beq.n	5ad0 <usb_serial_write_buffer_free+0x30>
		if (!(usb_transfer_status(tx_transfer + i) & 0x80)) sum += TX_SIZE;
    5ac4:	bl	64a4 <usb_transfer_status>
    5ac8:	lsls	r3, r0, #24
    5aca:	it	pl
    5acc:	addpl.w	r7, r7, #2048	; 0x800

int usb_serial_write_buffer_free(void)
{
	uint32_t sum = 0;
	tx_noautoflush = 1;
	for (uint32_t i=0; i < TX_NUM; i++) {
    5ad0:	cmp	r4, #4
    5ad2:	bne.n	5ab6 <usb_serial_write_buffer_free+0x16>
		if (i == tx_head) continue;
		if (!(usb_transfer_status(tx_transfer + i) & 0x80)) sum += TX_SIZE;
	}
	tx_noautoflush = 0;
    5ad4:	movs	r3, #0
	return sum;
}
    5ad6:	mov	r0, r7
	tx_noautoflush = 1;
	for (uint32_t i=0; i < TX_NUM; i++) {
		if (i == tx_head) continue;
		if (!(usb_transfer_status(tx_transfer + i) & 0x80)) sum += TX_SIZE;
	}
	tx_noautoflush = 0;
    5ad8:	strb.w	r3, [r8]
	return sum;
}
    5adc:	ldmia.w	sp!, {r4, r5, r6, r7, r8, pc}
    5ae0:	.word	0x20000ac0
    5ae4:	.word	0x2000097f
    5ae8:	.word	0x2000097e

00005aec <usb_serial_flush_output>:

void usb_serial_flush_output(void)
{
    5aec:	stmdb	sp!, {r3, r4, r5, r6, r7, r8, r9, lr}

	if (!usb_configuration) return;
    5af0:	ldr	r3, [pc, #124]	; (5b70 <usb_serial_flush_output+0x84>)
    5af2:	ldrb	r3, [r3, #0]
    5af4:	cbz	r3, 5afc <usb_serial_flush_output+0x10>
	if (tx_available == 0) return;
    5af6:	ldr	r5, [pc, #124]	; (5b74 <usb_serial_flush_output+0x88>)
    5af8:	ldrh	r2, [r5, #0]
    5afa:	cbnz	r2, 5b00 <usb_serial_flush_output+0x14>
    5afc:	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
	tx_noautoflush = 1;
	transfer_t *xfer = tx_transfer + tx_head;
    5b00:	ldr.w	r8, [pc, #132]	; 5b88 <usb_serial_flush_output+0x9c>
	uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
	uint32_t txnum = TX_SIZE - tx_available;
    5b04:	rsb	r9, r2, #2048	; 0x800
{

	if (!usb_configuration) return;
	if (tx_available == 0) return;
	tx_noautoflush = 1;
	transfer_t *xfer = tx_transfer + tx_head;
    5b08:	ldr	r6, [pc, #108]	; (5b78 <usb_serial_flush_output+0x8c>)
void usb_serial_flush_output(void)
{

	if (!usb_configuration) return;
	if (tx_available == 0) return;
	tx_noautoflush = 1;
    5b0a:	mov.w	lr, #1
	transfer_t *xfer = tx_transfer + tx_head;
    5b0e:	ldrb.w	r1, [r8]
	uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
	uint32_t txnum = TX_SIZE - tx_available;
	usb_prepare_transfer(xfer, txbuf, txnum, 0);
    5b12:	mov	r2, r9

	if (!usb_configuration) return;
	if (tx_available == 0) return;
	tx_noautoflush = 1;
	transfer_t *xfer = tx_transfer + tx_head;
	uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
    5b14:	ldr	r4, [pc, #100]	; (5b7c <usb_serial_flush_output+0x90>)
	uint32_t txnum = TX_SIZE - tx_available;
	usb_prepare_transfer(xfer, txbuf, txnum, 0);
    5b16:	movs	r3, #0
{

	if (!usb_configuration) return;
	if (tx_available == 0) return;
	tx_noautoflush = 1;
	transfer_t *xfer = tx_transfer + tx_head;
    5b18:	add.w	r6, r6, r1, lsl #5
void usb_serial_flush_output(void)
{

	if (!usb_configuration) return;
	if (tx_available == 0) return;
	tx_noautoflush = 1;
    5b1c:	ldr	r7, [pc, #96]	; (5b80 <usb_serial_flush_output+0x94>)
	transfer_t *xfer = tx_transfer + tx_head;
	uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
    5b1e:	add.w	r4, r4, r1, lsl #11
	uint32_t txnum = TX_SIZE - tx_available;
	usb_prepare_transfer(xfer, txbuf, txnum, 0);
    5b22:	mov	r0, r6
void usb_serial_flush_output(void)
{

	if (!usb_configuration) return;
	if (tx_available == 0) return;
	tx_noautoflush = 1;
    5b24:	strb.w	lr, [r7]
	transfer_t *xfer = tx_transfer + tx_head;
	uint8_t *txbuf = txbuffer + (tx_head * TX_SIZE);
	uint32_t txnum = TX_SIZE - tx_available;
	usb_prepare_transfer(xfer, txbuf, txnum, 0);
    5b28:	mov	r1, r4
    5b2a:	bl	6428 <usb_prepare_transfer>
// because you no longer need to access the data after transmission.
__attribute__((always_inline, unused))
static inline void arm_dcache_flush_delete(void *addr, uint32_t size)
{
	uint32_t location = (uint32_t)addr & 0xFFFFFFE0;
	uint32_t end_addr = (uint32_t)addr + size;
    5b2e:	add.w	r2, r9, r4
// any cached data written to memory, and then removed from the cache,
// because you no longer need to access the data after transmission.
__attribute__((always_inline, unused))
static inline void arm_dcache_flush_delete(void *addr, uint32_t size)
{
	uint32_t location = (uint32_t)addr & 0xFFFFFFE0;
    5b32:	bic.w	r1, r4, #31
	uint32_t end_addr = (uint32_t)addr + size;
	asm("dsb");
    5b36:	dsb	sy
	do {
		SCB_CACHE_DCCIMVAC = location;
    5b3a:	ldr	r3, [pc, #72]	; (5b84 <usb_serial_flush_output+0x98>)
    5b3c:	str	r1, [r3, #0]
		location += 32;
    5b3e:	adds	r1, #32
	} while (location < end_addr);
    5b40:	cmp	r2, r1
    5b42:	bhi.n	5b3c <usb_serial_flush_output+0x50>
	asm("dsb");
    5b44:	dsb	sy
	asm("isb");
    5b48:	isb	sy
	arm_dcache_flush_delete(txbuf, txnum);
	usb_transmit(CDC_TX_ENDPOINT, xfer);
    5b4c:	movs	r0, #4
    5b4e:	mov	r1, r6
    5b50:	bl	6458 <usb_transmit>
	if (++tx_head >= TX_NUM) tx_head = 0;
    5b54:	ldrb.w	r3, [r8]
    5b58:	ldr	r2, [pc, #44]	; (5b88 <usb_serial_flush_output+0x9c>)
    5b5a:	adds	r3, #1
    5b5c:	uxtb	r3, r3
    5b5e:	cmp	r3, #3
    5b60:	it	hi
    5b62:	movhi	r3, #0
    5b64:	strb	r3, [r2, #0]
	tx_available = 0;
    5b66:	movs	r3, #0
    5b68:	strh	r3, [r5, #0]
	tx_noautoflush = 0;
    5b6a:	strb	r3, [r7, #0]
    5b6c:	ldmia.w	sp!, {r3, r4, r5, r6, r7, r8, r9, pc}
    5b70:	.word	0x20000b78
    5b74:	.word	0x20000aa6
    5b78:	.word	0x20000ac0
    5b7c:	.word	0x20201000
    5b80:	.word	0x2000097e
    5b84:	.word	0xe000ef70
    5b88:	.word	0x2000097f

00005b8c <schedule_transfer>:
{
	// when we stop at 6, why is the last transfer missing from the USB output?
	//if (transfer_log_count >= 6) return;

	//uint32_t ret = (*(const uint8_t *)transfer->pointer0) << 8;
	if (endpoint->callback_function) {
    5b8c:	ldr	r3, [r0, #56]	; 0x38
	}
}
#endif

static void schedule_transfer(endpoint_t *endpoint, uint32_t epmask, transfer_t *transfer)
{
    5b8e:	push	{r4, r5}
	// when we stop at 6, why is the last transfer missing from the USB output?
	//if (transfer_log_count >= 6) return;

	//uint32_t ret = (*(const uint8_t *)transfer->pointer0) << 8;
	if (endpoint->callback_function) {
    5b90:	cbz	r3, 5b9a <schedule_transfer+0xe>
		transfer->status |= (1<<15);
    5b92:	ldr	r3, [r2, #4]
    5b94:	orr.w	r3, r3, #32768	; 0x8000
    5b98:	str	r3, [r2, #4]
	}
	__disable_irq();
    5b9a:	cpsid	i
	//digitalWriteFast(1, HIGH);
	// Executing A Transfer Descriptor, page 2468 (RT1060 manual, Rev 1, 12/2018)
	transfer_t *last = endpoint->last_transfer;
    5b9c:	ldr	r4, [r0, #52]	; 0x34
	if (last) {
    5b9e:	cbz	r4, 5bc8 <schedule_transfer+0x3c>
		last->next = (uint32_t)transfer;
		if (USB1_ENDPTPRIME & epmask) goto end;
    5ba0:	ldr	r3, [pc, #64]	; (5be4 <schedule_transfer+0x58>)
	__disable_irq();
	//digitalWriteFast(1, HIGH);
	// Executing A Transfer Descriptor, page 2468 (RT1060 manual, Rev 1, 12/2018)
	transfer_t *last = endpoint->last_transfer;
	if (last) {
		last->next = (uint32_t)transfer;
    5ba2:	str	r2, [r4, #0]
		if (USB1_ENDPTPRIME & epmask) goto end;
    5ba4:	ldr.w	r4, [r3, #432]	; 0x1b0
    5ba8:	tst	r4, r1
    5baa:	bne.n	5bdc <schedule_transfer+0x50>
		//digitalWriteFast(2, HIGH);
		//ret |= 0x01;
		uint32_t status;
		do {
			USB1_USBCMD |= USB_USBCMD_ATDTW;
    5bac:	ldr.w	r4, [r3, #320]	; 0x140
    5bb0:	orr.w	r4, r4, #16384	; 0x4000
    5bb4:	str.w	r4, [r3, #320]	; 0x140
			status = USB1_ENDPTSTATUS;
    5bb8:	ldr.w	r5, [r3, #440]	; 0x1b8
		} while (!(USB1_USBCMD & USB_USBCMD_ATDTW));
    5bbc:	ldr.w	r4, [r3, #320]	; 0x140
    5bc0:	lsls	r4, r4, #17
    5bc2:	bpl.n	5bac <schedule_transfer+0x20>
		//USB1_USBCMD &= ~USB_USBCMD_ATDTW;
		if (status & epmask) goto end;
    5bc4:	tst	r1, r5
    5bc6:	bne.n	5bdc <schedule_transfer+0x50>
		//ret |= 0x02;
	}
	//digitalWriteFast(4, HIGH);
	endpoint->next = (uint32_t)transfer;
	endpoint->status = 0;
    5bc8:	movs	r3, #0
	USB1_ENDPTPRIME |= epmask;
    5bca:	ldr	r4, [pc, #24]	; (5be4 <schedule_transfer+0x58>)
		//USB1_USBCMD &= ~USB_USBCMD_ATDTW;
		if (status & epmask) goto end;
		//ret |= 0x02;
	}
	//digitalWriteFast(4, HIGH);
	endpoint->next = (uint32_t)transfer;
    5bcc:	str	r2, [r0, #8]
	endpoint->status = 0;
    5bce:	str	r3, [r0, #12]
	USB1_ENDPTPRIME |= epmask;
    5bd0:	ldr.w	r3, [r4, #432]	; 0x1b0
    5bd4:	orrs	r1, r3
    5bd6:	str.w	r1, [r4, #432]	; 0x1b0
	endpoint->first_transfer = transfer;
    5bda:	str	r2, [r0, #48]	; 0x30
end:
	endpoint->last_transfer = transfer;
    5bdc:	str	r2, [r0, #52]	; 0x34
	__enable_irq();
    5bde:	cpsie	i
	//digitalWriteFast(2, LOW);
	//digitalWriteFast(1, LOW);
	//if (transfer_log_head > LOG_SIZE) transfer_log_head = 0;
	//transfer_log[transfer_log_head++] = ret;
	//transfer_log_count++;
}
    5be0:	pop	{r4, r5}
    5be2:	bx	lr
    5be4:	.word	0x402e0000

00005be8 <run_callbacks>:
	void (*callback_function)(transfer_t *completed_transfer);
	uint32_t unused1;
};*/

static void run_callbacks(endpoint_t *ep)
{
    5be8:	push	{r4, r5, r6, lr}
    5bea:	mov	r6, r0
	//printf("run_callbacks\n");
	transfer_t *first = ep->first_transfer;
    5bec:	ldr	r0, [r0, #48]	; 0x30
	if (first == NULL) return;
    5bee:	cbz	r0, 5c16 <run_callbacks+0x2e>
    5bf0:	mov	r2, r0
    5bf2:	movs	r4, #0
    5bf4:	b.n	5bfe <run_callbacks+0x16>
			//printf(" still active\n");
			ep->first_transfer = t;
			break;
		}
		count++;
		t = (transfer_t *)t->next;
    5bf6:	ldr	r2, [r2, #0]
			// found a still-active transfer, new list begins here
			//printf(" still active\n");
			ep->first_transfer = t;
			break;
		}
		count++;
    5bf8:	adds	r4, #1
		t = (transfer_t *)t->next;
		if ((uint32_t)t == 1) {
    5bfa:	cmp	r2, #1
    5bfc:	beq.n	5c18 <run_callbacks+0x30>

	// count how many transfers are completed, then remove them from the endpoint's list
	uint32_t count = 0;
	transfer_t *t = first;
	while (1) {
		if (t->status & (1<<7)) {
    5bfe:	ldr	r3, [r2, #4]
    5c00:	ands.w	r3, r3, #128	; 0x80
    5c04:	beq.n	5bf6 <run_callbacks+0xe>
			// found a still-active transfer, new list begins here
			//printf(" still active\n");
			ep->first_transfer = t;
    5c06:	str	r2, [r6, #48]	; 0x30
			ep->last_transfer = NULL;
			break;
		}
	}
	// do all the callbacks
	while (count) {
    5c08:	cbz	r4, 5c16 <run_callbacks+0x2e>
		transfer_t *next = (transfer_t *)first->next;
		ep->callback_function(first);
    5c0a:	ldr	r3, [r6, #56]	; 0x38
			break;
		}
	}
	// do all the callbacks
	while (count) {
		transfer_t *next = (transfer_t *)first->next;
    5c0c:	ldr	r5, [r0, #0]
		ep->callback_function(first);
    5c0e:	blx	r3
			ep->last_transfer = NULL;
			break;
		}
	}
	// do all the callbacks
	while (count) {
    5c10:	subs	r4, #1
		transfer_t *next = (transfer_t *)first->next;
		ep->callback_function(first);
		first = next;
    5c12:	mov	r0, r5
			ep->last_transfer = NULL;
			break;
		}
	}
	// do all the callbacks
	while (count) {
    5c14:	bne.n	5c0a <run_callbacks+0x22>
    5c16:	pop	{r4, r5, r6, pc}
		count++;
		t = (transfer_t *)t->next;
		if ((uint32_t)t == 1) {
			// reached end of list, all need callbacks, new list is empty
			//printf(" end of list\n");
			ep->first_transfer = NULL;
    5c18:	str	r3, [r6, #48]	; 0x30
			ep->last_transfer = NULL;
    5c1a:	str	r3, [r6, #52]	; 0x34
			break;
    5c1c:	b.n	5c08 <run_callbacks+0x20>
    5c1e:	nop

00005c20 <endpoint0_transmit.constprop.1>:
#endif
	}
	USB1_ENDPTCTRL0 = 0x000010001; // stall
}

static void endpoint0_transmit(const void *data, uint32_t len, int notify)
    5c20:	push	{r4, r5, r6, r7, lr}
{
	//printf("tx %lu\n", len);
	if (len > 0) {
    5c22:	cbnz	r1, 5c62 <endpoint0_transmit.constprop.1+0x42>
    5c24:	ldr	r4, [pc, #136]	; (5cb0 <endpoint0_transmit.constprop.1+0x90>)
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
		USB1_ENDPTPRIME |= (1<<16);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5c26:	ldr	r1, [pc, #140]	; (5cb4 <endpoint0_transmit.constprop.1+0x94>)
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    5c28:	movs	r0, #0
	endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[0].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5c2a:	ldr	r3, [pc, #140]	; (5cb8 <endpoint0_transmit.constprop.1+0x98>)
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
		USB1_ENDPTPRIME |= (1<<16);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5c2c:	movs	r2, #1
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    5c2e:	movs	r5, #128	; 0x80
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_ack;
    5c30:	str	r1, [r4, #8]
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
		USB1_ENDPTPRIME |= (1<<16);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5c32:	str	r2, [r1, #0]
	endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[0].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
	USB1_ENDPTPRIME |= (1<<0);
	endpoint0_notify_mask = (notify ? (1 << 0) : 0);
	while (USB1_ENDPTPRIME) ;
    5c34:	mov	r2, r3
		endpoint_queue_head[1].status = 0;
		USB1_ENDPTPRIME |= (1<<16);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    5c36:	str	r5, [r1, #4]
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[0].status = 0;
    5c38:	str	r0, [r4, #12]
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5c3a:	ldr.w	r4, [r3, #444]	; 0x1bc
		USB1_ENDPTPRIME |= (1<<16);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    5c3e:	str	r0, [r1, #8]
	endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[0].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5c40:	orr.w	r4, r4, #65537	; 0x10001
	USB1_ENDPTPRIME |= (1<<0);
	endpoint0_notify_mask = (notify ? (1 << 0) : 0);
    5c44:	ldr	r5, [pc, #116]	; (5cbc <endpoint0_transmit.constprop.1+0x9c>)
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[0].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5c46:	str.w	r4, [r3, #444]	; 0x1bc
	USB1_ENDPTPRIME |= (1<<0);
    5c4a:	ldr.w	r1, [r3, #432]	; 0x1b0
    5c4e:	orr.w	r1, r1, #1
    5c52:	str.w	r1, [r3, #432]	; 0x1b0
	endpoint0_notify_mask = (notify ? (1 << 0) : 0);
    5c56:	str	r0, [r5, #0]
	while (USB1_ENDPTPRIME) ;
    5c58:	ldr.w	r3, [r2, #432]	; 0x1b0
    5c5c:	cmp	r3, #0
    5c5e:	bne.n	5c58 <endpoint0_transmit.constprop.1+0x38>
}
    5c60:	pop	{r4, r5, r6, r7, pc}
{
	//printf("tx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
    5c62:	lsls	r1, r1, #16
static void endpoint0_transmit(const void *data, uint32_t len, int notify)
{
	//printf("tx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
    5c64:	ldr	r3, [pc, #88]	; (5cc0 <endpoint0_transmit.constprop.1+0xa0>)
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
		USB1_ENDPTPRIME |= (1<<16);
    5c66:	ldr	r5, [pc, #80]	; (5cb8 <endpoint0_transmit.constprop.1+0x98>)
static void endpoint0_transmit(const void *data, uint32_t len, int notify)
{
	//printf("tx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
    5c68:	movs	r6, #1
		endpoint0_transfer_data.pointer1 = addr + 4096;
		endpoint0_transfer_data.pointer2 = addr + 8192;
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
    5c6a:	ldr	r4, [pc, #68]	; (5cb0 <endpoint0_transmit.constprop.1+0x90>)
{
	//printf("tx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
    5c6c:	orr.w	r1, r1, #128	; 0x80
		endpoint0_transfer_data.pointer2 = addr + 8192;
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
    5c70:	movs	r2, #0
static void endpoint0_transmit(const void *data, uint32_t len, int notify)
{
	//printf("tx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
    5c72:	str	r6, [r3, #0]
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
    5c74:	str	r1, [r3, #4]
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
		endpoint0_transfer_data.pointer1 = addr + 4096;
    5c76:	add.w	ip, r0, #4096	; 0x1000
		endpoint0_transfer_data.pointer2 = addr + 8192;
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
    5c7a:	str	r2, [r4, #76]	; 0x4c
		endpoint0_transfer_data.next = 1;
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
		endpoint0_transfer_data.pointer1 = addr + 4096;
		endpoint0_transfer_data.pointer2 = addr + 8192;
    5c7c:	add.w	lr, r0, #8192	; 0x2000
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
    5c80:	str	r3, [r4, #72]	; 0x48
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
		endpoint0_transfer_data.pointer1 = addr + 4096;
		endpoint0_transfer_data.pointer2 = addr + 8192;
		endpoint0_transfer_data.pointer3 = addr + 12288;
    5c82:	add.w	r7, r0, #12288	; 0x3000
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
		USB1_ENDPTPRIME |= (1<<16);
    5c86:	ldr.w	r1, [r5, #432]	; 0x1b0
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
		endpoint0_transfer_data.pointer1 = addr + 4096;
		endpoint0_transfer_data.pointer2 = addr + 8192;
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
    5c8a:	add.w	r6, r0, #16384	; 0x4000
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
		USB1_ENDPTPRIME |= (1<<16);
		while (USB1_ENDPTPRIME) ;
    5c8e:	mov	r2, r5
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
    5c90:	str	r0, [r3, #8]
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
		USB1_ENDPTPRIME |= (1<<16);
    5c92:	orr.w	r1, r1, #65536	; 0x10000
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
		endpoint0_transfer_data.pointer1 = addr + 4096;
    5c96:	str.w	ip, [r3, #12]
		endpoint0_transfer_data.pointer2 = addr + 8192;
    5c9a:	str.w	lr, [r3, #16]
		endpoint0_transfer_data.pointer3 = addr + 12288;
    5c9e:	str	r7, [r3, #20]
		endpoint0_transfer_data.pointer4 = addr + 16384;
    5ca0:	str	r6, [r3, #24]
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[1].status = 0;
		USB1_ENDPTPRIME |= (1<<16);
    5ca2:	str.w	r1, [r5, #432]	; 0x1b0
		while (USB1_ENDPTPRIME) ;
    5ca6:	ldr.w	r3, [r2, #432]	; 0x1b0
    5caa:	cmp	r3, #0
    5cac:	bne.n	5ca6 <endpoint0_transmit.constprop.1+0x86>
    5cae:	b.n	5c26 <endpoint0_transmit.constprop.1+0x6>
    5cb0:	.word	0x20002000
    5cb4:	.word	0x20001020
    5cb8:	.word	0x402e0000
    5cbc:	.word	0x20000b54
    5cc0:	.word	0x20001000

00005cc4 <isr>:
	//transfer_log_count = 0;
}


static void isr(void)
{
    5cc4:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
	//printf("*");

	//  Port control in device mode is only used for
	//  status port reset, suspend, and current connect status.
	uint32_t status = USB1_USBSTS;
    5cc8:	ldr	r4, [pc, #752]	; (5fbc <isr+0x2f8>)
	//transfer_log_count = 0;
}


static void isr(void)
{
    5cca:	sub	sp, #12
	//printf("*");

	//  Port control in device mode is only used for
	//  status port reset, suspend, and current connect status.
	uint32_t status = USB1_USBSTS;
    5ccc:	ldr.w	r8, [r4, #324]	; 0x144

	// USB_USBSTS_SLI - set to 1 when enters a suspend state from an active state
	// USB_USBSTS_SRI - set at start of frame
	// USB_USBSTS_SRI - set when USB reset detected

	if (status & USB_USBSTS_UI) {
    5cd0:	tst.w	r8, #1
	//printf("*");

	//  Port control in device mode is only used for
	//  status port reset, suspend, and current connect status.
	uint32_t status = USB1_USBSTS;
	USB1_USBSTS = status;
    5cd4:	str.w	r8, [r4, #324]	; 0x144

	// USB_USBSTS_SLI - set to 1 when enters a suspend state from an active state
	// USB_USBSTS_SRI - set at start of frame
	// USB_USBSTS_SRI - set when USB reset detected

	if (status & USB_USBSTS_UI) {
    5cd8:	beq.n	5d98 <isr+0xd4>
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
    5cda:	ldr.w	r3, [r4, #428]	; 0x1ac
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    5cde:	cmp	r3, #0
    5ce0:	beq.n	5d8e <isr+0xca>
				s.word1 = endpoint_queue_head[0].setup0;
				s.word2 = endpoint_queue_head[0].setup1;
			} while (!(USB1_USBCMD & USB_USBCMD_SUTW));
			USB1_USBCMD &= ~USB_USBCMD_SUTW;
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
    5ce2:	mov.w	fp, #65537	; 0x10001
    5ce6:	ldr.w	r9, [pc, #764]	; 5fe4 <isr+0x320>
    5cea:	ldr	r6, [pc, #724]	; (5fc0 <isr+0x2fc>)
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
			USB1_ENDPTSETUPSTAT = setupstatus;
			setup_t s;
			do {
				USB1_USBCMD |= USB_USBCMD_SUTW;
    5cec:	mov	r5, r4
				s.word1 = endpoint_queue_head[0].setup0;
				s.word2 = endpoint_queue_head[0].setup1;
			} while (!(USB1_USBCMD & USB_USBCMD_SUTW));
			USB1_USBCMD &= ~USB_USBCMD_SUTW;
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
    5cee:	mov	sl, fp
    5cf0:	ldr	r0, [r6, #40]	; 0x28
    5cf2:	ldr	r2, [r6, #44]	; 0x2c
	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
			USB1_ENDPTSETUPSTAT = setupstatus;
    5cf4:	str.w	r3, [r4, #428]	; 0x1ac
			setup_t s;
			do {
				USB1_USBCMD |= USB_USBCMD_SUTW;
    5cf8:	ldr.w	r3, [r4, #320]	; 0x140
    5cfc:	orr.w	r3, r3, #8192	; 0x2000
    5d00:	str.w	r3, [r4, #320]	; 0x140
				s.word1 = endpoint_queue_head[0].setup0;
				s.word2 = endpoint_queue_head[0].setup1;
			} while (!(USB1_USBCMD & USB_USBCMD_SUTW));
    5d04:	ldr.w	r3, [r4, #320]	; 0x140
    5d08:	lsls	r7, r3, #18
    5d0a:	bpl.n	5cf8 <isr+0x34>
			USB1_USBCMD &= ~USB_USBCMD_SUTW;
    5d0c:	ldr.w	r3, [r5, #320]	; 0x140
    5d10:	bic.w	r3, r3, #8192	; 0x2000
    5d14:	str.w	r3, [r5, #320]	; 0x140
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
    5d18:	str.w	sl, [r5, #436]	; 0x1b4
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
    5d1c:	ldr.w	r3, [r4, #436]	; 0x1b4
    5d20:	ands.w	r3, r3, #65537	; 0x10001
    5d24:	bne.n	5d1c <isr+0x58>
	setup_t setup;
	uint32_t endpoint, dir, ctrl;
	const usb_descriptor_list_t *list;

	setup.bothwords = setupdata;
	switch (setup.wRequestAndType) {
    5d26:	uxth	r1, r0
    5d28:	movw	r7, #1665	; 0x681
			} while (!(USB1_USBCMD & USB_USBCMD_SUTW));
			USB1_USBCMD &= ~USB_USBCMD_SUTW;
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
    5d2c:	str.w	r3, [r9]
	setup_t setup;
	uint32_t endpoint, dir, ctrl;
	const usb_descriptor_list_t *list;

	setup.bothwords = setupdata;
	switch (setup.wRequestAndType) {
    5d30:	cmp	r1, r7
    5d32:	bhi.w	5e80 <isr+0x1bc>
    5d36:	cmp.w	r1, #1664	; 0x680
    5d3a:	bcs.w	6114 <isr+0x450>
    5d3e:	cmp.w	r1, #258	; 0x102
    5d42:	beq.w	601a <isr+0x356>
    5d46:	bhi.w	5f12 <isr+0x24e>
    5d4a:	cmp	r1, #128	; 0x80
    5d4c:	beq.w	6000 <isr+0x33c>
    5d50:	cmp	r1, #130	; 0x82
    5d52:	bne.w	5f02 <isr+0x23e>
		reply_buffer[0] = 0;
		reply_buffer[1] = 0;
		endpoint0_transmit(reply_buffer, 2, 0);
		return;
	  case 0x0082: // GET_STATUS (endpoint)
		endpoint = setup.wIndex & 0x7F;
    5d56:	uxth	r2, r2
    5d58:	and.w	r1, r2, #127	; 0x7f
		if (endpoint > 7) break;
    5d5c:	cmp	r1, #7
    5d5e:	bhi.w	5f02 <isr+0x23e>
		dir = setup.wIndex & 0x80;
		ctrl = *((uint32_t *)&USB1_ENDPTCTRL0 + endpoint);
    5d62:	lsls	r1, r1, #2
    5d64:	ldr	r0, [pc, #604]	; (5fc4 <isr+0x300>)
		reply_buffer[0] = 0;
    5d66:	ldr	r7, [pc, #608]	; (5fc8 <isr+0x304>)
		return;
	  case 0x0082: // GET_STATUS (endpoint)
		endpoint = setup.wIndex & 0x7F;
		if (endpoint > 7) break;
		dir = setup.wIndex & 0x80;
		ctrl = *((uint32_t *)&USB1_ENDPTCTRL0 + endpoint);
    5d68:	add	r0, r1
    5d6a:	ldr	r1, [r0, #0]
		reply_buffer[0] = 0;
		reply_buffer[1] = 0;
		if ((dir && (ctrl & USB_ENDPTCTRL_TXS)) || (!dir && (ctrl & USB_ENDPTCTRL_RXS))) {
    5d6c:	lsls	r0, r2, #24
	  case 0x0082: // GET_STATUS (endpoint)
		endpoint = setup.wIndex & 0x7F;
		if (endpoint > 7) break;
		dir = setup.wIndex & 0x80;
		ctrl = *((uint32_t *)&USB1_ENDPTCTRL0 + endpoint);
		reply_buffer[0] = 0;
    5d6e:	strb	r3, [r7, #0]
		reply_buffer[1] = 0;
    5d70:	strb	r3, [r7, #1]
		if ((dir && (ctrl & USB_ENDPTCTRL_TXS)) || (!dir && (ctrl & USB_ENDPTCTRL_RXS))) {
    5d72:	bpl.w	6192 <isr+0x4ce>
    5d76:	lsls	r2, r1, #15
    5d78:	bpl.n	5d7e <isr+0xba>
			reply_buffer[0] = 1;
    5d7a:	movs	r3, #1
    5d7c:	strb	r3, [r7, #0]
		}
		endpoint0_transmit(reply_buffer, 2, 0);
    5d7e:	movs	r1, #2
    5d80:	ldr	r0, [pc, #580]	; (5fc8 <isr+0x304>)
    5d82:	bl	5c20 <endpoint0_transmit.constprop.1>
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
    5d86:	ldr.w	r3, [r4, #428]	; 0x1ac

	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    5d8a:	cmp	r3, #0
    5d8c:	bne.n	5cf0 <isr+0x2c>
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
		}
		uint32_t completestatus = USB1_ENDPTCOMPLETE;
    5d8e:	ldr	r2, [pc, #556]	; (5fbc <isr+0x2f8>)
    5d90:	ldr.w	r3, [r2, #444]	; 0x1bc
		if (completestatus) {
    5d94:	cmp	r3, #0
    5d96:	bne.n	5e3a <isr+0x176>
					}
				}
			}
		}
	}
	if (status & USB_USBSTS_URI) { // page 3164
    5d98:	tst.w	r8, #64	; 0x40
    5d9c:	beq.n	5dd0 <isr+0x10c>
		USB1_ENDPTSETUPSTAT = USB1_ENDPTSETUPSTAT; // Clear all setup token semaphores
    5d9e:	ldr	r3, [pc, #540]	; (5fbc <isr+0x2f8>)
    5da0:	ldr.w	r1, [r3, #428]	; 0x1ac
		USB1_ENDPTCOMPLETE = USB1_ENDPTCOMPLETE; // Clear all the endpoint complete status
		while (USB1_ENDPTPRIME != 0) ; // Wait for any endpoint priming
    5da4:	mov	r2, r3
				}
			}
		}
	}
	if (status & USB_USBSTS_URI) { // page 3164
		USB1_ENDPTSETUPSTAT = USB1_ENDPTSETUPSTAT; // Clear all setup token semaphores
    5da6:	str.w	r1, [r3, #428]	; 0x1ac
		USB1_ENDPTCOMPLETE = USB1_ENDPTCOMPLETE; // Clear all the endpoint complete status
    5daa:	ldr.w	r1, [r3, #444]	; 0x1bc
    5dae:	str.w	r1, [r3, #444]	; 0x1bc
		while (USB1_ENDPTPRIME != 0) ; // Wait for any endpoint priming
    5db2:	ldr.w	r4, [r2, #432]	; 0x1b0
    5db6:	ldr	r3, [pc, #516]	; (5fbc <isr+0x2f8>)
    5db8:	cmp	r4, #0
    5dba:	bne.n	5db2 <isr+0xee>
		USB1_ENDPTFLUSH = 0xFFFFFFFF;  // Cancel all endpoint primed status
    5dbc:	mov.w	r2, #4294967295
    5dc0:	str.w	r2, [r3, #436]	; 0x1b4
		if ((USB1_PORTSC1 & USB_PORTSC1_PR)) {
    5dc4:	ldr.w	r3, [r3, #388]	; 0x184
			// we took too long to respond :(
			// TODO; is this ever really a problem?
			//printf("reset too slow\n");
		}
		#if defined(CDC_STATUS_INTERFACE) && defined(CDC_DATA_INTERFACE)
		usb_serial_reset();
    5dc8:	bl	5780 <usb_serial_reset>
		#endif
		endpointN_notify_mask = 0;
    5dcc:	ldr	r3, [pc, #508]	; (5fcc <isr+0x308>)
    5dce:	str	r4, [r3, #0]
			// shut off USB - easier to see results in protocol analyzer
			//USB1_USBCMD &= ~USB_USBCMD_RS;
			//printf("shut off USB\n");
		//}
	}
	if (status & USB_USBSTS_TI0) {
    5dd0:	tst.w	r8, #16777216	; 0x1000000
    5dd4:	beq.n	5dde <isr+0x11a>
		if (usb_timer0_callback != NULL) usb_timer0_callback();
    5dd6:	ldr	r3, [pc, #504]	; (5fd0 <isr+0x30c>)
    5dd8:	ldr	r3, [r3, #0]
    5dda:	cbz	r3, 5dde <isr+0x11a>
    5ddc:	blx	r3
	}
	if (status & USB_USBSTS_TI1) {
    5dde:	tst.w	r8, #33554432	; 0x2000000
    5de2:	beq.n	5dec <isr+0x128>
		if (usb_timer1_callback != NULL) usb_timer1_callback();
    5de4:	ldr	r3, [pc, #492]	; (5fd4 <isr+0x310>)
    5de6:	ldr	r3, [r3, #0]
    5de8:	cbz	r3, 5dec <isr+0x128>
    5dea:	blx	r3
	}
	if (status & USB_USBSTS_PCI) {
    5dec:	tst.w	r8, #4
    5df0:	beq.n	5e04 <isr+0x140>
		if (USB1_PORTSC1 & USB_PORTSC1_HSP) {
    5df2:	ldr	r3, [pc, #456]	; (5fbc <isr+0x2f8>)
    5df4:	ldr.w	r3, [r3, #388]	; 0x184
    5df8:	ands.w	r3, r3, #512	; 0x200
    5dfc:	beq.n	5e7a <isr+0x1b6>
			//printf("port at 480 Mbit\n");
			usb_high_speed = 1;
    5dfe:	ldr	r3, [pc, #472]	; (5fd8 <isr+0x314>)
    5e00:	movs	r2, #1
    5e02:	strb	r2, [r3, #0]
		//printf("suspend\n");
	}
	if (status & USB_USBSTS_UEI) {
		//printf("error\n");
	}
	if ((USB1_USBINTR & USB_USBINTR_SRE) && (status & USB_USBSTS_SRI)) {
    5e04:	ldr	r3, [pc, #436]	; (5fbc <isr+0x2f8>)
    5e06:	ldr.w	r2, [r3, #328]	; 0x148
    5e0a:	lsls	r2, r2, #24
    5e0c:	bpl.n	5e34 <isr+0x170>
    5e0e:	tst.w	r8, #128	; 0x80
    5e12:	beq.n	5e34 <isr+0x170>
		//printf("sof %d\n", usb_reboot_timer);
		if (usb_reboot_timer) {
    5e14:	ldr	r1, [pc, #452]	; (5fdc <isr+0x318>)
    5e16:	ldrb	r2, [r1, #0]
    5e18:	cbz	r2, 5e34 <isr+0x170>
			if (--usb_reboot_timer == 0) {
    5e1a:	subs	r2, #1
    5e1c:	uxtb	r2, r2
    5e1e:	strb	r2, [r1, #0]
    5e20:	cbnz	r2, 5e34 <isr+0x170>
	__enable_irq();
}

void usb_stop_sof_interrupts(int interface)
{
	sof_usage &= ~(1 << interface);
    5e22:	ldr	r1, [pc, #444]	; (5fe0 <isr+0x31c>)
    5e24:	ldrb	r2, [r1, #0]
    5e26:	and.w	r2, r2, #251	; 0xfb
    5e2a:	strb	r2, [r1, #0]
	if (sof_usage == 0) {
    5e2c:	cmp	r2, #0
    5e2e:	beq.w	6296 <isr+0x5d2>
	if ((USB1_USBINTR & USB_USBINTR_SRE) && (status & USB_USBSTS_SRI)) {
		//printf("sof %d\n", usb_reboot_timer);
		if (usb_reboot_timer) {
			if (--usb_reboot_timer == 0) {
				usb_stop_sof_interrupts(NUM_INTERFACE);
				asm("bkpt #251"); // run bootloader
    5e32:	bkpt	0x00fb
		#endif
		#ifdef FLIGHTSIM_INTERFACE
		usb_flightsim_flush_output();
		#endif
	}
}
    5e34:	add	sp, #12
    5e36:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
		}
		uint32_t completestatus = USB1_ENDPTCOMPLETE;
		if (completestatus) {
			USB1_ENDPTCOMPLETE = completestatus;
			//printf("USB1_ENDPTCOMPLETE=%lX\n", completestatus);
			if (completestatus & endpoint0_notify_mask) {
    5e3a:	ldr	r1, [pc, #424]	; (5fe4 <isr+0x320>)
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
		}
		uint32_t completestatus = USB1_ENDPTCOMPLETE;
		if (completestatus) {
			USB1_ENDPTCOMPLETE = completestatus;
    5e3c:	str.w	r3, [r2, #444]	; 0x1bc
			//printf("USB1_ENDPTCOMPLETE=%lX\n", completestatus);
			if (completestatus & endpoint0_notify_mask) {
    5e40:	ldr	r0, [r1, #0]
    5e42:	tst	r3, r0
    5e44:	bne.w	621e <isr+0x55a>
				endpoint0_notify_mask = 0;
				endpoint0_complete();
			}
			completestatus &= endpointN_notify_mask;
    5e48:	ldr	r2, [pc, #384]	; (5fcc <isr+0x308>)
    5e4a:	ldr	r4, [r2, #0]
			if (completestatus) {
    5e4c:	ands	r4, r3
    5e4e:	beq.n	5d98 <isr+0xd4>
				int i;   // TODO: optimize with __builtin_ctz()
				for (i=2; i <= NUM_ENDPOINTS; i++) {
					if (completestatus & (1 << i)) { // receive
    5e50:	lsls	r3, r4, #29
    5e52:	bmi.w	62b4 <isr+0x5f0>
						run_callbacks(endpoint_queue_head + i * 2);
					}
					if (completestatus & (1 << (i + 16))) { // transmit
    5e56:	lsls	r7, r4, #13
    5e58:	bmi.w	62ac <isr+0x5e8>
			}
			completestatus &= endpointN_notify_mask;
			if (completestatus) {
				int i;   // TODO: optimize with __builtin_ctz()
				for (i=2; i <= NUM_ENDPOINTS; i++) {
					if (completestatus & (1 << i)) { // receive
    5e5c:	lsls	r6, r4, #28
    5e5e:	bmi.w	62c4 <isr+0x600>
						run_callbacks(endpoint_queue_head + i * 2);
					}
					if (completestatus & (1 << (i + 16))) { // transmit
    5e62:	lsls	r5, r4, #12
    5e64:	bmi.w	62bc <isr+0x5f8>
			}
			completestatus &= endpointN_notify_mask;
			if (completestatus) {
				int i;   // TODO: optimize with __builtin_ctz()
				for (i=2; i <= NUM_ENDPOINTS; i++) {
					if (completestatus & (1 << i)) { // receive
    5e68:	lsls	r0, r4, #27
    5e6a:	bmi.w	62a4 <isr+0x5e0>
						run_callbacks(endpoint_queue_head + i * 2);
					}
					if (completestatus & (1 << (i + 16))) { // transmit
    5e6e:	lsls	r1, r4, #11
    5e70:	bpl.n	5d98 <isr+0xd4>
						run_callbacks(endpoint_queue_head + i * 2 + 1);
    5e72:	ldr	r0, [pc, #372]	; (5fe8 <isr+0x324>)
    5e74:	bl	5be8 <run_callbacks>
    5e78:	b.n	5d98 <isr+0xd4>
		if (USB1_PORTSC1 & USB_PORTSC1_HSP) {
			//printf("port at 480 Mbit\n");
			usb_high_speed = 1;
		} else {
			//printf("port at 12 Mbit\n");
			usb_high_speed = 0;
    5e7a:	ldr	r2, [pc, #348]	; (5fd8 <isr+0x314>)
    5e7c:	strb	r3, [r2, #0]
    5e7e:	b.n	5e04 <isr+0x140>
	setup_t setup;
	uint32_t endpoint, dir, ctrl;
	const usb_descriptor_list_t *list;

	setup.bothwords = setupdata;
	switch (setup.wRequestAndType) {
    5e80:	movw	r7, #8225	; 0x2021
    5e84:	cmp	r1, r7
    5e86:	beq.n	5efa <isr+0x236>
    5e88:	bhi.n	5f6a <isr+0x2a6>
    5e8a:	cmp.w	r1, #2176	; 0x880
    5e8e:	beq.w	60f8 <isr+0x434>
    5e92:	cmp.w	r1, #2304	; 0x900
    5e96:	bne.n	5f02 <isr+0x23e>
	  case 0x0500: // SET_ADDRESS
		endpoint0_receive(NULL, 0, 0);
		USB1_DEVICEADDR = USB_DEVICEADDR_USBADR(setup.wValue) | USB_DEVICEADDR_USBADRA;
		return;
	  case 0x0900: // SET_CONFIGURATION
		usb_configuration = setup.wValue;
    5e98:	ubfx	r0, r0, #16, #8
    5e9c:	ldr	r2, [pc, #332]	; (5fec <isr+0x328>)
		// configure all other endpoints
		#if defined(ENDPOINT2_CONFIG)
		USB1_ENDPTCTRL2 = ENDPOINT2_CONFIG;
		#endif
		#if defined(ENDPOINT3_CONFIG)
		USB1_ENDPTCTRL3 = ENDPOINT3_CONFIG;
    5e9e:	ldr	r1, [pc, #336]	; (5ff0 <isr+0x32c>)
	  case 0x0500: // SET_ADDRESS
		endpoint0_receive(NULL, 0, 0);
		USB1_DEVICEADDR = USB_DEVICEADDR_USBADR(setup.wValue) | USB_DEVICEADDR_USBADRA;
		return;
	  case 0x0900: // SET_CONFIGURATION
		usb_configuration = setup.wValue;
    5ea0:	strb	r0, [r2, #0]
		// configure all other endpoints
		#if defined(ENDPOINT2_CONFIG)
		USB1_ENDPTCTRL2 = ENDPOINT2_CONFIG;
    5ea2:	ldr	r7, [pc, #336]	; (5ff4 <isr+0x330>)
		#endif
		#if defined(ENDPOINT3_CONFIG)
		USB1_ENDPTCTRL3 = ENDPOINT3_CONFIG;
		#endif
		#if defined(ENDPOINT4_CONFIG)
		USB1_ENDPTCTRL4 = ENDPOINT4_CONFIG;
    5ea4:	ldr	r2, [pc, #336]	; (5ff8 <isr+0x334>)
    5ea6:	str	r3, [sp, #4]
		return;
	  case 0x0900: // SET_CONFIGURATION
		usb_configuration = setup.wValue;
		// configure all other endpoints
		#if defined(ENDPOINT2_CONFIG)
		USB1_ENDPTCTRL2 = ENDPOINT2_CONFIG;
    5ea8:	str.w	r7, [r5, #456]	; 0x1c8
		#endif
		#if defined(ENDPOINT3_CONFIG)
		USB1_ENDPTCTRL3 = ENDPOINT3_CONFIG;
    5eac:	str.w	r1, [r5, #460]	; 0x1cc
		#endif
		#if defined(ENDPOINT4_CONFIG)
		USB1_ENDPTCTRL4 = ENDPOINT4_CONFIG;
    5eb0:	str.w	r2, [r5, #464]	; 0x1d0
		#endif
		#if defined(ENDPOINT7_CONFIG)
		USB1_ENDPTCTRL7 = ENDPOINT7_CONFIG;
		#endif
		#if defined(CDC_STATUS_INTERFACE) && defined(CDC_DATA_INTERFACE)
		usb_serial_configure();
    5eb4:	bl	5784 <usb_serial_configure>
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5eb8:	ldr	r2, [pc, #320]	; (5ffc <isr+0x338>)
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
    5eba:	ldr	r3, [sp, #4]
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    5ebc:	movs	r1, #128	; 0x80
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5ebe:	movs	r0, #1
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
    5ec0:	str	r3, [r6, #76]	; 0x4c
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5ec2:	str	r0, [r2, #0]
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    5ec4:	str	r1, [r2, #4]
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5ec6:	ldr.w	r1, [r5, #444]	; 0x1bc
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    5eca:	str	r3, [r2, #8]
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5ecc:	orr.w	r1, r1, #65537	; 0x10001
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
    5ed0:	str	r2, [r6, #72]	; 0x48
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5ed2:	str.w	r1, [r5, #444]	; 0x1bc
	USB1_ENDPTPRIME |= (1<<16);
    5ed6:	ldr.w	r2, [r5, #432]	; 0x1b0
    5eda:	orr.w	r2, r2, #65536	; 0x10000
    5ede:	str.w	r2, [r5, #432]	; 0x1b0
	endpoint0_notify_mask = (notify ? (1 << 16) : 0);
    5ee2:	ldr	r2, [pc, #256]	; (5fe4 <isr+0x320>)
    5ee4:	str	r3, [r2, #0]
	while (USB1_ENDPTPRIME) ;
    5ee6:	ldr.w	r3, [r4, #432]	; 0x1b0
    5eea:	cmp	r3, #0
    5eec:	bne.n	5ee6 <isr+0x222>
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
    5eee:	ldr.w	r3, [r4, #428]	; 0x1ac

	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    5ef2:	cmp	r3, #0
    5ef4:	bne.w	5cf0 <isr+0x2c>
    5ef8:	b.n	5d8e <isr+0xca>
		usb_cdc_line_rtsdtr = setup.wValue;
	  case 0x2321: // CDC_SEND_BREAK
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x2021: // CDC_SET_LINE_CODING
		if (setup.wLength != 7) break;
    5efa:	lsrs	r1, r2, #16
    5efc:	cmp	r1, #7
    5efe:	beq.w	619a <isr+0x4d6>
			return;
		}
		break;
#endif
	}
	USB1_ENDPTCTRL0 = 0x000010001; // stall
    5f02:	str.w	fp, [r4, #448]	; 0x1c0
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
    5f06:	ldr.w	r3, [r4, #428]	; 0x1ac

	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    5f0a:	cmp	r3, #0
    5f0c:	bne.w	5cf0 <isr+0x2c>
    5f10:	b.n	5d8e <isr+0xca>
	setup_t setup;
	uint32_t endpoint, dir, ctrl;
	const usb_descriptor_list_t *list;

	setup.bothwords = setupdata;
	switch (setup.wRequestAndType) {
    5f12:	movw	r7, #770	; 0x302
    5f16:	cmp	r1, r7
    5f18:	beq.w	6092 <isr+0x3ce>
    5f1c:	cmp.w	r1, #1280	; 0x500
    5f20:	bne.n	5f02 <isr+0x23e>
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5f22:	ldr	r2, [pc, #216]	; (5ffc <isr+0x338>)
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    5f24:	movs	r1, #128	; 0x80
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5f26:	movs	r7, #1
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
    5f28:	str	r3, [r6, #76]	; 0x4c
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    5f2a:	str	r1, [r2, #4]
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5f2c:	str	r7, [r2, #0]
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5f2e:	ldr.w	r1, [r5, #444]	; 0x1bc
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    5f32:	str	r3, [r2, #8]
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5f34:	orr.w	r3, r1, #65537	; 0x10001
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
    5f38:	str	r2, [r6, #72]	; 0x48
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5f3a:	str.w	r3, [r5, #444]	; 0x1bc
	USB1_ENDPTPRIME |= (1<<16);
    5f3e:	ldr.w	r3, [r5, #432]	; 0x1b0
    5f42:	orr.w	r3, r3, #65536	; 0x10000
    5f46:	str.w	r3, [r5, #432]	; 0x1b0
	endpoint0_notify_mask = (notify ? (1 << 16) : 0);
	while (USB1_ENDPTPRIME) ;
    5f4a:	ldr.w	r3, [r4, #432]	; 0x1b0
    5f4e:	cmp	r3, #0
    5f50:	bne.n	5f4a <isr+0x286>

	setup.bothwords = setupdata;
	switch (setup.wRequestAndType) {
	  case 0x0500: // SET_ADDRESS
		endpoint0_receive(NULL, 0, 0);
		USB1_DEVICEADDR = USB_DEVICEADDR_USBADR(setup.wValue) | USB_DEVICEADDR_USBADRA;
    5f52:	lsrs	r3, r0, #16
    5f54:	lsls	r3, r3, #25
    5f56:	orr.w	r3, r3, #16777216	; 0x1000000
    5f5a:	str.w	r3, [r5, #340]	; 0x154
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
    5f5e:	ldr.w	r3, [r4, #428]	; 0x1ac

	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    5f62:	cmp	r3, #0
    5f64:	bne.w	5cf0 <isr+0x2c>
    5f68:	b.n	5d8e <isr+0xca>
	setup_t setup;
	uint32_t endpoint, dir, ctrl;
	const usb_descriptor_list_t *list;

	setup.bothwords = setupdata;
	switch (setup.wRequestAndType) {
    5f6a:	movw	r3, #8737	; 0x2221
    5f6e:	cmp	r1, r3
    5f70:	beq.w	6080 <isr+0x3bc>
    5f74:	movw	r3, #8993	; 0x2321
    5f78:	cmp	r1, r3
    5f7a:	bne.n	5f02 <isr+0x23e>
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5f7c:	ldr	r3, [pc, #124]	; (5ffc <isr+0x338>)
    5f7e:	movs	r1, #1
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    5f80:	movs	r2, #128	; 0x80
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    5f82:	str	r1, [r3, #0]
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    5f84:	movs	r1, #0
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    5f86:	str	r2, [r3, #4]
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5f88:	ldr.w	r2, [r4, #444]	; 0x1bc
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
    5f8c:	str	r3, [r6, #72]	; 0x48
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5f8e:	orr.w	r2, r2, #65537	; 0x10001
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    5f92:	str	r1, [r3, #8]
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
    5f94:	str	r1, [r6, #76]	; 0x4c
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    5f96:	str.w	r2, [r4, #444]	; 0x1bc
	USB1_ENDPTPRIME |= (1<<16);
    5f9a:	ldr.w	r3, [r4, #432]	; 0x1b0
    5f9e:	orr.w	r3, r3, #65536	; 0x10000
    5fa2:	str.w	r3, [r4, #432]	; 0x1b0
	endpoint0_notify_mask = (notify ? (1 << 16) : 0);
	while (USB1_ENDPTPRIME) ;
    5fa6:	ldr.w	r3, [r4, #432]	; 0x1b0
    5faa:	cmp	r3, #0
    5fac:	bne.n	5fa6 <isr+0x2e2>
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
    5fae:	ldr.w	r3, [r4, #428]	; 0x1ac

	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    5fb2:	cmp	r3, #0
    5fb4:	bne.w	5cf0 <isr+0x2c>
    5fb8:	b.n	5d8e <isr+0xca>
    5fba:	nop
    5fbc:	.word	0x402e0000
    5fc0:	.word	0x20002000
    5fc4:	.word	0x402e01c0
    5fc8:	.word	0x20000b68
    5fcc:	.word	0x20000b44
    5fd0:	.word	0x20000b40
    5fd4:	.word	0x20000b4c
    5fd8:	.word	0x20000b50
    5fdc:	.word	0x20000b58
    5fe0:	.word	0x20000b48
    5fe4:	.word	0x20000b54
    5fe8:	.word	0x20002240
    5fec:	.word	0x20000b78
    5ff0:	.word	0x000200c8
    5ff4:	.word	0x00cc0002
    5ff8:	.word	0x00c80002
    5ffc:	.word	0x20001020
	  case 0x0880: // GET_CONFIGURATION
		reply_buffer[0] = usb_configuration;
		endpoint0_transmit(reply_buffer, 1, 0);
		return;
	  case 0x0080: // GET_STATUS (device)
		reply_buffer[0] = 0;
    6000:	ldr	r2, [pc, #744]	; (62ec <isr+0x628>)
		reply_buffer[1] = 0;
		endpoint0_transmit(reply_buffer, 2, 0);
    6002:	movs	r1, #2
    6004:	mov	r0, r2
	  case 0x0880: // GET_CONFIGURATION
		reply_buffer[0] = usb_configuration;
		endpoint0_transmit(reply_buffer, 1, 0);
		return;
	  case 0x0080: // GET_STATUS (device)
		reply_buffer[0] = 0;
    6006:	strb	r3, [r2, #0]
		reply_buffer[1] = 0;
    6008:	strb	r3, [r2, #1]
		endpoint0_transmit(reply_buffer, 2, 0);
    600a:	bl	5c20 <endpoint0_transmit.constprop.1>
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
    600e:	ldr.w	r3, [r4, #428]	; 0x1ac

	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    6012:	cmp	r3, #0
    6014:	bne.w	5cf0 <isr+0x2c>
    6018:	b.n	5d8e <isr+0xca>
			*((volatile uint32_t *)&USB1_ENDPTCTRL0 + endpoint) |= USB_ENDPTCTRL_RXS;
		}
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x0102: // CLEAR_FEATURE (endpoint)
		endpoint = setup.wIndex & 0x7F;
    601a:	uxth	r2, r2
    601c:	and.w	r3, r2, #127	; 0x7f
		if (endpoint > 7) break;
    6020:	cmp	r3, #7
    6022:	bhi.w	5f02 <isr+0x23e>
		dir = setup.wIndex & 0x80;
		if (dir) {
    6026:	tst.w	r2, #128	; 0x80
			*((volatile uint32_t *)&USB1_ENDPTCTRL0 + endpoint) &= ~USB_ENDPTCTRL_TXS;
    602a:	mov.w	r3, r3, lsl #2
    602e:	ldr	r2, [pc, #704]	; (62f0 <isr+0x62c>)
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    6030:	mov.w	r1, #1
	  case 0x0102: // CLEAR_FEATURE (endpoint)
		endpoint = setup.wIndex & 0x7F;
		if (endpoint > 7) break;
		dir = setup.wIndex & 0x80;
		if (dir) {
			*((volatile uint32_t *)&USB1_ENDPTCTRL0 + endpoint) &= ~USB_ENDPTCTRL_TXS;
    6034:	add	r2, r3
    6036:	ldr	r3, [r2, #0]
    6038:	ite	ne
    603a:	bicne.w	r3, r3, #65536	; 0x10000
		} else {
			*((volatile uint32_t *)&USB1_ENDPTCTRL0 + endpoint) &= ~USB_ENDPTCTRL_RXS;
    603e:	biceq.w	r3, r3, #1
    6042:	str	r3, [r2, #0]
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    6044:	movs	r2, #128	; 0x80
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    6046:	ldr	r3, [pc, #684]	; (62f4 <isr+0x630>)
    6048:	str	r1, [r3, #0]
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    604a:	movs	r1, #0
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    604c:	str	r2, [r3, #4]
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    604e:	ldr.w	r2, [r4, #444]	; 0x1bc
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
    6052:	str	r3, [r6, #72]	; 0x48
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    6054:	orr.w	r2, r2, #65537	; 0x10001
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    6058:	str	r1, [r3, #8]
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
    605a:	str	r1, [r6, #76]	; 0x4c
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    605c:	str.w	r2, [r4, #444]	; 0x1bc
	USB1_ENDPTPRIME |= (1<<16);
    6060:	ldr.w	r3, [r4, #432]	; 0x1b0
    6064:	orr.w	r3, r3, #65536	; 0x10000
    6068:	str.w	r3, [r4, #432]	; 0x1b0
	endpoint0_notify_mask = (notify ? (1 << 16) : 0);
	while (USB1_ENDPTPRIME) ;
    606c:	ldr.w	r3, [r4, #432]	; 0x1b0
    6070:	cmp	r3, #0
    6072:	bne.n	606c <isr+0x3a8>
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
    6074:	ldr.w	r3, [r4, #428]	; 0x1ac

	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    6078:	cmp	r3, #0
    607a:	bne.w	5cf0 <isr+0x2c>
    607e:	b.n	5d8e <isr+0xca>
			}
		}
		break;
#if defined(CDC_STATUS_INTERFACE)
	  case 0x2221: // CDC_SET_CONTROL_LINE_STATE
		usb_cdc_line_rtsdtr_millis = systick_millis_count;
    6080:	ldr	r3, [pc, #628]	; (62f8 <isr+0x634>)
		usb_cdc_line_rtsdtr = setup.wValue;
    6082:	ubfx	r0, r0, #16, #8
			}
		}
		break;
#if defined(CDC_STATUS_INTERFACE)
	  case 0x2221: // CDC_SET_CONTROL_LINE_STATE
		usb_cdc_line_rtsdtr_millis = systick_millis_count;
    6086:	ldr	r2, [pc, #628]	; (62fc <isr+0x638>)
    6088:	ldr	r1, [r3, #0]
		usb_cdc_line_rtsdtr = setup.wValue;
    608a:	ldr	r3, [pc, #628]	; (6300 <isr+0x63c>)
			}
		}
		break;
#if defined(CDC_STATUS_INTERFACE)
	  case 0x2221: // CDC_SET_CONTROL_LINE_STATE
		usb_cdc_line_rtsdtr_millis = systick_millis_count;
    608c:	str	r1, [r2, #0]
		usb_cdc_line_rtsdtr = setup.wValue;
    608e:	strb	r0, [r3, #0]
    6090:	b.n	5f7c <isr+0x2b8>
			reply_buffer[0] = 1;
		}
		endpoint0_transmit(reply_buffer, 2, 0);
		return;
	  case 0x0302: // SET_FEATURE (endpoint)
		endpoint = setup.wIndex & 0x7F;
    6092:	uxth	r2, r2
    6094:	and.w	r3, r2, #127	; 0x7f
		if (endpoint > 7) break;
    6098:	cmp	r3, #7
    609a:	bhi.w	5f02 <isr+0x23e>
		dir = setup.wIndex & 0x80;
		if (dir) {
    609e:	tst.w	r2, #128	; 0x80
			*((volatile uint32_t *)&USB1_ENDPTCTRL0 + endpoint) |= USB_ENDPTCTRL_TXS;
    60a2:	mov.w	r3, r3, lsl #2
    60a6:	ldr	r2, [pc, #584]	; (62f0 <isr+0x62c>)
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    60a8:	mov.w	r1, #1
	  case 0x0302: // SET_FEATURE (endpoint)
		endpoint = setup.wIndex & 0x7F;
		if (endpoint > 7) break;
		dir = setup.wIndex & 0x80;
		if (dir) {
			*((volatile uint32_t *)&USB1_ENDPTCTRL0 + endpoint) |= USB_ENDPTCTRL_TXS;
    60ac:	add	r2, r3
    60ae:	ldr	r3, [r2, #0]
    60b0:	ite	ne
    60b2:	orrne.w	r3, r3, #65536	; 0x10000
		} else {
			*((volatile uint32_t *)&USB1_ENDPTCTRL0 + endpoint) |= USB_ENDPTCTRL_RXS;
    60b6:	orreq.w	r3, r3, #1
    60ba:	str	r3, [r2, #0]
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    60bc:	movs	r2, #128	; 0x80
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    60be:	ldr	r3, [pc, #564]	; (62f4 <isr+0x630>)
    60c0:	str	r1, [r3, #0]
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    60c2:	movs	r1, #0
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    60c4:	str	r2, [r3, #4]
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    60c6:	ldr.w	r2, [r4, #444]	; 0x1bc
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
    60ca:	str	r3, [r6, #72]	; 0x48
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    60cc:	orr.w	r2, r2, #65537	; 0x10001
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    60d0:	str	r1, [r3, #8]
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
    60d2:	str	r1, [r6, #76]	; 0x4c
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    60d4:	str.w	r2, [r4, #444]	; 0x1bc
	USB1_ENDPTPRIME |= (1<<16);
    60d8:	ldr.w	r3, [r4, #432]	; 0x1b0
    60dc:	orr.w	r3, r3, #65536	; 0x10000
    60e0:	str.w	r3, [r4, #432]	; 0x1b0
	endpoint0_notify_mask = (notify ? (1 << 16) : 0);
	while (USB1_ENDPTPRIME) ;
    60e4:	ldr.w	r3, [r4, #432]	; 0x1b0
    60e8:	cmp	r3, #0
    60ea:	bne.n	60e4 <isr+0x420>
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
    60ec:	ldr.w	r3, [r4, #428]	; 0x1ac

	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    60f0:	cmp	r3, #0
    60f2:	bne.w	5cf0 <isr+0x2c>
    60f6:	b.n	5d8e <isr+0xca>
		usb_midi_configure();
		#endif
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x0880: // GET_CONFIGURATION
		reply_buffer[0] = usb_configuration;
    60f8:	ldr	r2, [pc, #520]	; (6304 <isr+0x640>)
		endpoint0_transmit(reply_buffer, 1, 0);
    60fa:	movs	r1, #1
		usb_midi_configure();
		#endif
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x0880: // GET_CONFIGURATION
		reply_buffer[0] = usb_configuration;
    60fc:	ldr	r3, [pc, #492]	; (62ec <isr+0x628>)
    60fe:	ldrb	r2, [r2, #0]
		endpoint0_transmit(reply_buffer, 1, 0);
    6100:	mov	r0, r3
		usb_midi_configure();
		#endif
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x0880: // GET_CONFIGURATION
		reply_buffer[0] = usb_configuration;
    6102:	strb	r2, [r3, #0]
		endpoint0_transmit(reply_buffer, 1, 0);
    6104:	bl	5c20 <endpoint0_transmit.constprop.1>
			//printf("setup %08lX %08lX\n", s.word1, s.word2);
			USB1_ENDPTFLUSH = (1<<16) | (1<<0); // page 3174
			while (USB1_ENDPTFLUSH & ((1<<16) | (1<<0))) ;
			endpoint0_notify_mask = 0;
			endpoint0_setup(s.bothwords);
			setupstatus = USB1_ENDPTSETUPSTAT; // page 3175
    6108:	ldr.w	r3, [r4, #428]	; 0x1ac

	if (status & USB_USBSTS_UI) {
		//printf("data\n");
		uint32_t setupstatus = USB1_ENDPTSETUPSTAT;
		//printf("USB1_ENDPTSETUPSTAT=%X\n", setupstatus);
		while (setupstatus) {
    610c:	cmp	r3, #0
    610e:	bne.w	5cf0 <isr+0x2c>
    6112:	b.n	5d8e <isr+0xca>
		}
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x0680: // GET_DESCRIPTOR
	  case 0x0681:
		for (list = usb_descriptor_list; list->addr != NULL; list++) {
    6114:	ldr	r3, [pc, #496]	; (6308 <isr+0x644>)
    6116:	ldr	r1, [r3, #4]
    6118:	cmp	r1, #0
    611a:	beq.w	5f02 <isr+0x23e>
    611e:	lsrs	r0, r0, #16
			if (setup.wValue == list->wValue && setup.wIndex == list->wIndex) {
    6120:	uxth.w	lr, r2
    6124:	b.n	6130 <isr+0x46c>
		}
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x0680: // GET_DESCRIPTOR
	  case 0x0681:
		for (list = usb_descriptor_list; list->addr != NULL; list++) {
    6126:	adds	r3, #12
    6128:	ldr	r1, [r3, #4]
    612a:	cmp	r1, #0
    612c:	beq.w	5f02 <isr+0x23e>
			if (setup.wValue == list->wValue && setup.wIndex == list->wIndex) {
    6130:	ldrh	r7, [r3, #0]
    6132:	cmp	r7, r0
    6134:	bne.n	6126 <isr+0x462>
    6136:	ldrh	r7, [r3, #2]
    6138:	cmp	r7, lr
    613a:	bne.n	6126 <isr+0x462>
				uint32_t datalen;
				if ((setup.wValue >> 8) == 3) {
    613c:	lsrs	r7, r0, #8
    613e:	cmp	r7, #3
    6140:	beq.w	6350 <isr+0x68c>
					// for string descriptors, use the descriptor's
					// length field, allowing runtime configured length.
					datalen = *(list->addr);
				} else {
					datalen = list->length;
    6144:	ldrh	r3, [r3, #8]
				}
				if (datalen > setup.wLength) datalen = setup.wLength;
    6146:	lsrs	r2, r2, #16
    6148:	cmp	r3, r2
    614a:	it	cs
    614c:	movcs	r3, r2

				// copy the descriptor, from PROGMEM to DMAMEM
				if (setup.wValue == 0x200) {
    614e:	cmp.w	r0, #512	; 0x200
    6152:	beq.w	62cc <isr+0x608>
					// config descriptor needs to adapt to speed
					const uint8_t *src = usb_config_descriptor_12;
					if (usb_high_speed) src = usb_config_descriptor_480;
					memcpy(usb_descriptor_buffer, src, datalen);
				} else if (setup.wValue == 0x700) {
    6156:	cmp.w	r0, #1792	; 0x700
    615a:	beq.w	6270 <isr+0x5ac>
    615e:	ldr	r7, [pc, #428]	; (630c <isr+0x648>)
					const uint8_t *src = usb_config_descriptor_480;
					if (usb_high_speed) src = usb_config_descriptor_12;
					memcpy(usb_descriptor_buffer, src, datalen);
					usb_descriptor_buffer[1] = 7;
				} else {
					memcpy(usb_descriptor_buffer, list->addr, datalen);
    6160:	mov	r2, r3
    6162:	str	r3, [sp, #4]
    6164:	mov	r0, r7
    6166:	bl	5318 <memcpy>
    616a:	ldr	r3, [sp, #4]
// any cached data written to memory, and then removed from the cache,
// because you no longer need to access the data after transmission.
__attribute__((always_inline, unused))
static inline void arm_dcache_flush_delete(void *addr, uint32_t size)
{
	uint32_t location = (uint32_t)addr & 0xFFFFFFE0;
    616c:	bic.w	r2, r7, #31
	uint32_t end_addr = (uint32_t)addr + size;
    6170:	add	r7, r3
	asm("dsb");
    6172:	dsb	sy
	do {
		SCB_CACHE_DCCIMVAC = location;
    6176:	ldr	r1, [pc, #408]	; (6310 <isr+0x64c>)
    6178:	str	r2, [r1, #0]
		location += 32;
    617a:	adds	r2, #32
	} while (location < end_addr);
    617c:	cmp	r7, r2
    617e:	bhi.n	6176 <isr+0x4b2>
	asm("dsb");
    6180:	dsb	sy
	asm("isb");
    6184:	isb	sy
				}
				// prep transmit
				arm_dcache_flush_delete(usb_descriptor_buffer, datalen);
				endpoint0_transmit(usb_descriptor_buffer, datalen, 0);
    6188:	ldr	r0, [pc, #384]	; (630c <isr+0x648>)
    618a:	mov	r1, r3
    618c:	bl	5c20 <endpoint0_transmit.constprop.1>
    6190:	b.n	5d86 <isr+0xc2>
		if (endpoint > 7) break;
		dir = setup.wIndex & 0x80;
		ctrl = *((uint32_t *)&USB1_ENDPTCTRL0 + endpoint);
		reply_buffer[0] = 0;
		reply_buffer[1] = 0;
		if ((dir && (ctrl & USB_ENDPTCTRL_TXS)) || (!dir && (ctrl & USB_ENDPTCTRL_RXS))) {
    6192:	lsls	r3, r1, #31
    6194:	bpl.w	5d7e <isr+0xba>
    6198:	b.n	5d7a <isr+0xb6>
	  case 0x2321: // CDC_SEND_BREAK
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x2021: // CDC_SET_LINE_CODING
		if (setup.wLength != 7) break;
		endpoint0_setupdata.bothwords = setupdata;
    619a:	ldr	r7, [pc, #376]	; (6314 <isr+0x650>)
static void endpoint0_receive(void *data, uint32_t len, int notify)
{
	//printf("rx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
    619c:	mov.w	lr, #1
		endpoint0_transfer_data.pointer2 = addr + 8192;
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
    61a0:	str	r3, [r6, #12]
{
	//printf("rx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
    61a2:	ldr	r1, [pc, #372]	; (6318 <isr+0x654>)
static void endpoint0_receive(void *data, uint32_t len, int notify)
{
	//printf("rx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
    61a4:	ldr	r3, [pc, #372]	; (631c <isr+0x658>)
	  case 0x2321: // CDC_SEND_BREAK
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x2021: // CDC_SET_LINE_CODING
		if (setup.wLength != 7) break;
		endpoint0_setupdata.bothwords = setupdata;
    61a6:	str	r0, [r7, #0]
static void endpoint0_receive(void *data, uint32_t len, int notify)
{
	//printf("rx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
    61a8:	str.w	lr, [r3]
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
    61ac:	str	r1, [r3, #4]
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
    61ae:	ldr.w	r0, [r5, #432]	; 0x1b0
	//printf("rx %lu\n", len);
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
		uint32_t addr = (uint32_t)data;
    61b2:	ldr	r1, [pc, #364]	; (6320 <isr+0x65c>)
	  case 0x2321: // CDC_SEND_BREAK
		endpoint0_receive(NULL, 0, 0);
		return;
	  case 0x2021: // CDC_SET_LINE_CODING
		if (setup.wLength != 7) break;
		endpoint0_setupdata.bothwords = setupdata;
    61b4:	str	r2, [r7, #4]
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
    61b6:	orr.w	r2, r0, lr
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
		endpoint0_transfer_data.pointer1 = addr + 4096;
    61ba:	add.w	r7, r1, #4096	; 0x1000
		endpoint0_transfer_data.pointer2 = addr + 8192;
    61be:	add.w	lr, r1, #8192	; 0x2000
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
    61c2:	str	r3, [r6, #8]
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
		endpoint0_transfer_data.pointer1 = addr + 4096;
		endpoint0_transfer_data.pointer2 = addr + 8192;
		endpoint0_transfer_data.pointer3 = addr + 12288;
    61c4:	add.w	r0, r1, #12288	; 0x3000
		endpoint0_transfer_data.pointer4 = addr + 16384;
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
    61c8:	str.w	r2, [r5, #432]	; 0x1b0
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
		endpoint0_transfer_data.pointer1 = addr + 4096;
		endpoint0_transfer_data.pointer2 = addr + 8192;
		endpoint0_transfer_data.pointer3 = addr + 12288;
		endpoint0_transfer_data.pointer4 = addr + 16384;
    61cc:	add.w	r2, r1, #16384	; 0x4000
	if (len > 0) {
		// Executing A Transfer Descriptor, page 3182
		endpoint0_transfer_data.next = 1;
		endpoint0_transfer_data.status = (len << 16) | (1<<7);
		uint32_t addr = (uint32_t)data;
		endpoint0_transfer_data.pointer0 = addr; // format: table 55-60, pg 3159
    61d0:	str	r1, [r3, #8]
		endpoint0_transfer_data.pointer1 = addr + 4096;
    61d2:	str	r7, [r3, #12]
		endpoint0_transfer_data.pointer2 = addr + 8192;
    61d4:	str.w	lr, [r3, #16]
		endpoint0_transfer_data.pointer3 = addr + 12288;
    61d8:	str	r0, [r3, #20]
		endpoint0_transfer_data.pointer4 = addr + 16384;
    61da:	str	r2, [r3, #24]
		//  Case 1: Link list is empty, page 3182
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
    61dc:	ldr.w	r3, [r4, #432]	; 0x1b0
    61e0:	cmp	r3, #0
    61e2:	bne.n	61dc <isr+0x518>
	}
	endpoint0_transfer_ack.next = 1;
    61e4:	ldr	r2, [pc, #268]	; (62f4 <isr+0x630>)
    61e6:	movs	r0, #1
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    61e8:	movw	r1, #32896	; 0x8080
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
    61ec:	str	r3, [r6, #76]	; 0x4c
		endpoint_queue_head[0].next = (uint32_t)&endpoint0_transfer_data;
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
    61ee:	str	r0, [r2, #0]
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
	USB1_ENDPTPRIME |= (1<<16);
	endpoint0_notify_mask = (notify ? (1 << 16) : 0);
    61f0:	mov.w	r0, #65536	; 0x10000
		endpoint_queue_head[0].status = 0;
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
    61f4:	str	r1, [r2, #4]
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    61f6:	ldr.w	r1, [r5, #444]	; 0x1bc
		USB1_ENDPTPRIME |= (1<<0);
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
    61fa:	str	r3, [r2, #8]
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    61fc:	orr.w	r3, r1, #65537	; 0x10001
		while (USB1_ENDPTPRIME) ;
	}
	endpoint0_transfer_ack.next = 1;
	endpoint0_transfer_ack.status = (1<<7) | (notify ? (1 << 15) : 0);
	endpoint0_transfer_ack.pointer0 = 0;
	endpoint_queue_head[1].next = (uint32_t)&endpoint0_transfer_ack;
    6200:	str	r2, [r6, #72]	; 0x48
	endpoint_queue_head[1].status = 0;
	USB1_ENDPTCOMPLETE |= (1<<0) | (1<<16);
    6202:	str.w	r3, [r5, #444]	; 0x1bc
	USB1_ENDPTPRIME |= (1<<16);
    6206:	ldr.w	r3, [r5, #432]	; 0x1b0
    620a:	orrs	r3, r0
    620c:	str.w	r3, [r5, #432]	; 0x1b0
	endpoint0_notify_mask = (notify ? (1 << 16) : 0);
    6210:	str.w	r0, [r9]
	while (USB1_ENDPTPRIME) ;
    6214:	ldr.w	r3, [r4, #432]	; 0x1b0
    6218:	cmp	r3, #0
    621a:	bne.n	6214 <isr+0x550>
    621c:	b.n	5d86 <isr+0xc2>

static void endpoint0_complete(void)
{
	setup_t setup;

	setup.bothwords = endpoint0_setupdata.bothwords;
    621e:	ldr	r4, [pc, #244]	; (6314 <isr+0x650>)
	//printf("complete %x %x %x\n", setup.word1, setup.word2, endpoint0_buffer[0]);
#ifdef CDC_STATUS_INTERFACE
	if (setup.wRequestAndType == 0x2021 /*CDC_SET_LINE_CODING*/) {
    6220:	movw	r0, #8225	; 0x2021
		uint32_t completestatus = USB1_ENDPTCOMPLETE;
		if (completestatus) {
			USB1_ENDPTCOMPLETE = completestatus;
			//printf("USB1_ENDPTCOMPLETE=%lX\n", completestatus);
			if (completestatus & endpoint0_notify_mask) {
				endpoint0_notify_mask = 0;
    6224:	movs	r5, #0
	setup_t setup;

	setup.bothwords = endpoint0_setupdata.bothwords;
	//printf("complete %x %x %x\n", setup.word1, setup.word2, endpoint0_buffer[0]);
#ifdef CDC_STATUS_INTERFACE
	if (setup.wRequestAndType == 0x2021 /*CDC_SET_LINE_CODING*/) {
    6226:	ldrh	r4, [r4, #0]
		uint32_t completestatus = USB1_ENDPTCOMPLETE;
		if (completestatus) {
			USB1_ENDPTCOMPLETE = completestatus;
			//printf("USB1_ENDPTCOMPLETE=%lX\n", completestatus);
			if (completestatus & endpoint0_notify_mask) {
				endpoint0_notify_mask = 0;
    6228:	str	r5, [r1, #0]
	setup_t setup;

	setup.bothwords = endpoint0_setupdata.bothwords;
	//printf("complete %x %x %x\n", setup.word1, setup.word2, endpoint0_buffer[0]);
#ifdef CDC_STATUS_INTERFACE
	if (setup.wRequestAndType == 0x2021 /*CDC_SET_LINE_CODING*/) {
    622a:	cmp	r4, r0
    622c:	bne.w	5e48 <isr+0x184>
		memcpy(usb_cdc_line_coding, endpoint0_buffer, 7);
    6230:	ldr	r1, [pc, #236]	; (6320 <isr+0x65c>)
    6232:	ldr	r4, [pc, #240]	; (6324 <isr+0x660>)
    6234:	ldmia	r1, {r0, r1}
    6236:	lsrs	r5, r1, #16
		printf("usb_cdc_line_coding, baud=%u\n", usb_cdc_line_coding[0]);
		if (usb_cdc_line_coding[0] == 134) {
    6238:	cmp	r0, #134	; 0x86

	setup.bothwords = endpoint0_setupdata.bothwords;
	//printf("complete %x %x %x\n", setup.word1, setup.word2, endpoint0_buffer[0]);
#ifdef CDC_STATUS_INTERFACE
	if (setup.wRequestAndType == 0x2021 /*CDC_SET_LINE_CODING*/) {
		memcpy(usb_cdc_line_coding, endpoint0_buffer, 7);
    623a:	str	r0, [r4, #0]
    623c:	strh	r1, [r4, #4]
    623e:	strb	r5, [r4, #6]
		printf("usb_cdc_line_coding, baud=%u\n", usb_cdc_line_coding[0]);
		if (usb_cdc_line_coding[0] == 134) {
    6240:	bne.w	5e48 <isr+0x184>
}


void usb_start_sof_interrupts(int interface)
{
	__disable_irq();
    6244:	cpsid	i
	sof_usage |= (1 << interface);
    6246:	ldr	r0, [pc, #224]	; (6328 <isr+0x664>)
    6248:	ldrb	r1, [r0, #0]
    624a:	orr.w	r1, r1, #4
    624e:	strb	r1, [r0, #0]
	uint32_t intr = USB1_USBINTR;
    6250:	ldr.w	r1, [r2, #328]	; 0x148
	if (!(intr & USB_USBINTR_SRE)) {
    6254:	lsls	r0, r1, #24
    6256:	bmi.n	6266 <isr+0x5a2>
		USB1_USBSTS = USB_USBSTS_SRI; // clear prior SOF before SOF IRQ enable
		USB1_USBINTR = intr | USB_USBINTR_SRE;
    6258:	orr.w	r1, r1, #128	; 0x80
{
	__disable_irq();
	sof_usage |= (1 << interface);
	uint32_t intr = USB1_USBINTR;
	if (!(intr & USB_USBINTR_SRE)) {
		USB1_USBSTS = USB_USBSTS_SRI; // clear prior SOF before SOF IRQ enable
    625c:	movs	r0, #128	; 0x80
    625e:	str.w	r0, [r2, #324]	; 0x144
		USB1_USBINTR = intr | USB_USBINTR_SRE;
    6262:	str.w	r1, [r2, #328]	; 0x148
	}
	__enable_irq();
    6266:	cpsie	i
	if (setup.wRequestAndType == 0x2021 /*CDC_SET_LINE_CODING*/) {
		memcpy(usb_cdc_line_coding, endpoint0_buffer, 7);
		printf("usb_cdc_line_coding, baud=%u\n", usb_cdc_line_coding[0]);
		if (usb_cdc_line_coding[0] == 134) {
			usb_start_sof_interrupts(NUM_INTERFACE);
			usb_reboot_timer = 80; // TODO: 10 if only 12 Mbit/sec
    6268:	ldr	r2, [pc, #192]	; (632c <isr+0x668>)
    626a:	movs	r1, #80	; 0x50
    626c:	strb	r1, [r2, #0]
    626e:	b.n	5e48 <isr+0x184>
					if (usb_high_speed) src = usb_config_descriptor_480;
					memcpy(usb_descriptor_buffer, src, datalen);
				} else if (setup.wValue == 0x700) {
					// other speed config also needs to adapt
					const uint8_t *src = usb_config_descriptor_480;
					if (usb_high_speed) src = usb_config_descriptor_12;
    6270:	ldr	r0, [pc, #188]	; (6330 <isr+0x66c>)
					memcpy(usb_descriptor_buffer, src, datalen);
    6272:	mov	r2, r3
    6274:	ldr	r7, [pc, #148]	; (630c <isr+0x648>)
					if (usb_high_speed) src = usb_config_descriptor_480;
					memcpy(usb_descriptor_buffer, src, datalen);
				} else if (setup.wValue == 0x700) {
					// other speed config also needs to adapt
					const uint8_t *src = usb_config_descriptor_480;
					if (usb_high_speed) src = usb_config_descriptor_12;
    6276:	ldrb.w	lr, [r0]
					const uint8_t *src = usb_config_descriptor_12;
					if (usb_high_speed) src = usb_config_descriptor_480;
					memcpy(usb_descriptor_buffer, src, datalen);
				} else if (setup.wValue == 0x700) {
					// other speed config also needs to adapt
					const uint8_t *src = usb_config_descriptor_480;
    627a:	ldr	r1, [pc, #184]	; (6334 <isr+0x670>)
    627c:	ldr	r0, [pc, #184]	; (6338 <isr+0x674>)
					if (usb_high_speed) src = usb_config_descriptor_12;
					memcpy(usb_descriptor_buffer, src, datalen);
    627e:	str	r3, [sp, #4]
    6280:	cmp.w	lr, #0
    6284:	it	eq
    6286:	moveq	r1, r0
    6288:	mov	r0, r7
    628a:	bl	5318 <memcpy>
					usb_descriptor_buffer[1] = 7;
    628e:	movs	r2, #7
    6290:	ldr	r3, [sp, #4]
    6292:	strb	r2, [r7, #1]
    6294:	b.n	616c <isr+0x4a8>

void usb_stop_sof_interrupts(int interface)
{
	sof_usage &= ~(1 << interface);
	if (sof_usage == 0) {
		USB1_USBINTR &= ~USB_USBINTR_SRE;
    6296:	ldr.w	r2, [r3, #328]	; 0x148
    629a:	bic.w	r2, r2, #128	; 0x80
    629e:	str.w	r2, [r3, #328]	; 0x148
    62a2:	b.n	5e32 <isr+0x16e>
			completestatus &= endpointN_notify_mask;
			if (completestatus) {
				int i;   // TODO: optimize with __builtin_ctz()
				for (i=2; i <= NUM_ENDPOINTS; i++) {
					if (completestatus & (1 << i)) { // receive
						run_callbacks(endpoint_queue_head + i * 2);
    62a4:	ldr	r0, [pc, #148]	; (633c <isr+0x678>)
    62a6:	bl	5be8 <run_callbacks>
    62aa:	b.n	5e6e <isr+0x1aa>
					}
					if (completestatus & (1 << (i + 16))) { // transmit
						run_callbacks(endpoint_queue_head + i * 2 + 1);
    62ac:	ldr	r0, [pc, #144]	; (6340 <isr+0x67c>)
    62ae:	bl	5be8 <run_callbacks>
    62b2:	b.n	5e5c <isr+0x198>
			completestatus &= endpointN_notify_mask;
			if (completestatus) {
				int i;   // TODO: optimize with __builtin_ctz()
				for (i=2; i <= NUM_ENDPOINTS; i++) {
					if (completestatus & (1 << i)) { // receive
						run_callbacks(endpoint_queue_head + i * 2);
    62b4:	ldr	r0, [pc, #140]	; (6344 <isr+0x680>)
    62b6:	bl	5be8 <run_callbacks>
    62ba:	b.n	5e56 <isr+0x192>
					}
					if (completestatus & (1 << (i + 16))) { // transmit
						run_callbacks(endpoint_queue_head + i * 2 + 1);
    62bc:	ldr	r0, [pc, #136]	; (6348 <isr+0x684>)
    62be:	bl	5be8 <run_callbacks>
    62c2:	b.n	5e68 <isr+0x1a4>
			completestatus &= endpointN_notify_mask;
			if (completestatus) {
				int i;   // TODO: optimize with __builtin_ctz()
				for (i=2; i <= NUM_ENDPOINTS; i++) {
					if (completestatus & (1 << i)) { // receive
						run_callbacks(endpoint_queue_head + i * 2);
    62c4:	ldr	r0, [pc, #132]	; (634c <isr+0x688>)
    62c6:	bl	5be8 <run_callbacks>
    62ca:	b.n	5e62 <isr+0x19e>

				// copy the descriptor, from PROGMEM to DMAMEM
				if (setup.wValue == 0x200) {
					// config descriptor needs to adapt to speed
					const uint8_t *src = usb_config_descriptor_12;
					if (usb_high_speed) src = usb_config_descriptor_480;
    62cc:	ldr	r0, [pc, #96]	; (6330 <isr+0x66c>)
					memcpy(usb_descriptor_buffer, src, datalen);
    62ce:	mov	r2, r3
				if (datalen > setup.wLength) datalen = setup.wLength;

				// copy the descriptor, from PROGMEM to DMAMEM
				if (setup.wValue == 0x200) {
					// config descriptor needs to adapt to speed
					const uint8_t *src = usb_config_descriptor_12;
    62d0:	ldr	r1, [pc, #100]	; (6338 <isr+0x674>)
					if (usb_high_speed) src = usb_config_descriptor_480;
    62d2:	ldrb	r7, [r0, #0]
				if (datalen > setup.wLength) datalen = setup.wLength;

				// copy the descriptor, from PROGMEM to DMAMEM
				if (setup.wValue == 0x200) {
					// config descriptor needs to adapt to speed
					const uint8_t *src = usb_config_descriptor_12;
    62d4:	ldr	r0, [pc, #92]	; (6334 <isr+0x670>)
					if (usb_high_speed) src = usb_config_descriptor_480;
					memcpy(usb_descriptor_buffer, src, datalen);
    62d6:	str	r3, [sp, #4]
    62d8:	cmp	r7, #0
    62da:	it	eq
    62dc:	moveq	r1, r0
    62de:	ldr	r0, [pc, #44]	; (630c <isr+0x648>)
    62e0:	bl	5318 <memcpy>
    62e4:	ldr	r7, [pc, #36]	; (630c <isr+0x648>)
    62e6:	ldr	r3, [sp, #4]
    62e8:	b.n	616c <isr+0x4a8>
    62ea:	nop
    62ec:	.word	0x20000b68
    62f0:	.word	0x402e01c0
    62f4:	.word	0x20001020
    62f8:	.word	0x20000b84
    62fc:	.word	0x20000c18
    6300:	.word	0x20000aa8
    6304:	.word	0x20000b78
    6308:	.word	0x20000014
    630c:	.word	0x20203000
    6310:	.word	0xe000ef70
    6314:	.word	0x20000b60
    6318:	.word	0x00070080
    631c:	.word	0x20001000
    6320:	.word	0x20000b70
    6324:	.word	0x20000c10
    6328:	.word	0x20000b48
    632c:	.word	0x20000b58
    6330:	.word	0x20000b50
    6334:	.word	0x60001654
    6338:	.word	0x60001698
    633c:	.word	0x20002200
    6340:	.word	0x20002140
    6344:	.word	0x20002100
    6348:	.word	0x200021c0
    634c:	.word	0x20002180
					// length field, allowing runtime configured length.
					datalen = *(list->addr);
				} else {
					datalen = list->length;
				}
				if (datalen > setup.wLength) datalen = setup.wLength;
    6350:	lsrs	r2, r2, #16
			if (setup.wValue == list->wValue && setup.wIndex == list->wIndex) {
				uint32_t datalen;
				if ((setup.wValue >> 8) == 3) {
					// for string descriptors, use the descriptor's
					// length field, allowing runtime configured length.
					datalen = *(list->addr);
    6352:	ldrb	r3, [r1, #0]
    6354:	cmp	r3, r2
    6356:	it	cs
    6358:	movcs	r3, r2
    635a:	b.n	6156 <isr+0x492>

0000635c <usb_config_rx>:
	qh->callback_function = callback;
}

void usb_config_rx(uint32_t ep, uint32_t packet_size, int do_zlp, void (*cb)(transfer_t *))
{
	uint32_t config = (packet_size << 16) | (do_zlp ? 0 : (1 << 29));
    635c:	cmp	r2, #0
	if (ep < 2 || ep > NUM_ENDPOINTS) return;
    635e:	sub.w	r2, r0, #2
	qh->next = 1; // Terminate bit = 1
	qh->callback_function = callback;
}

void usb_config_rx(uint32_t ep, uint32_t packet_size, int do_zlp, void (*cb)(transfer_t *))
{
    6362:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	uint32_t config = (packet_size << 16) | (do_zlp ? 0 : (1 << 29));
    6366:	ite	ne
    6368:	movne	r7, #0
    636a:	moveq.w	r7, #536870912	; 0x20000000
	if (ep < 2 || ep > NUM_ENDPOINTS) return;
    636e:	cmp	r2, #2
    6370:	bls.n	6376 <usb_config_rx+0x1a>
    6372:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
	usb_endpoint_config(endpoint_queue_head + ep * 2, config, cb);
    6376:	mov.w	sl, r0, lsl #7
    637a:	ldr.w	r9, [pc, #64]	; 63bc <usb_config_rx+0x60>
    637e:	mov	r5, r1
    6380:	mov	r4, r0
    6382:	add.w	r6, sl, r9
#endif
}

static void usb_endpoint_config(endpoint_t *qh, uint32_t config, void (*callback)(transfer_t *))
{
	memset(qh, 0, sizeof(endpoint_t));
    6386:	movs	r1, #0
    6388:	movs	r2, #64	; 0x40
    638a:	mov	r8, r3
    638c:	mov	r0, r6
    638e:	bl	77c8 <memset>
	qh->config = config;
	qh->next = 1; // Terminate bit = 1
    6392:	movs	r0, #1
}

static void usb_endpoint_config(endpoint_t *qh, uint32_t config, void (*callback)(transfer_t *))
{
	memset(qh, 0, sizeof(endpoint_t));
	qh->config = config;
    6394:	orr.w	r1, r7, r5, lsl #16
    6398:	str.w	r1, [sl, r9]
	qh->next = 1; // Terminate bit = 1
	qh->callback_function = callback;
    639c:	str.w	r8, [r6, #56]	; 0x38

static void usb_endpoint_config(endpoint_t *qh, uint32_t config, void (*callback)(transfer_t *))
{
	memset(qh, 0, sizeof(endpoint_t));
	qh->config = config;
	qh->next = 1; // Terminate bit = 1
    63a0:	str	r0, [r6, #8]
void usb_config_rx(uint32_t ep, uint32_t packet_size, int do_zlp, void (*cb)(transfer_t *))
{
	uint32_t config = (packet_size << 16) | (do_zlp ? 0 : (1 << 29));
	if (ep < 2 || ep > NUM_ENDPOINTS) return;
	usb_endpoint_config(endpoint_queue_head + ep * 2, config, cb);
	if (cb) endpointN_notify_mask |= (1 << ep);
    63a2:	cmp.w	r8, #0
    63a6:	beq.n	6372 <usb_config_rx+0x16>
    63a8:	ldr	r3, [pc, #12]	; (63b8 <usb_config_rx+0x5c>)
    63aa:	lsls	r0, r4
    63ac:	ldr	r4, [r3, #0]
    63ae:	orrs	r0, r4
    63b0:	str	r0, [r3, #0]
    63b2:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    63b6:	nop
    63b8:	.word	0x20000b44
    63bc:	.word	0x20002000

000063c0 <usb_config_tx>:
}

void usb_config_tx(uint32_t ep, uint32_t packet_size, int do_zlp, void (*cb)(transfer_t *))
{
	uint32_t config = (packet_size << 16) | (do_zlp ? 0 : (1 << 29));
    63c0:	cmp	r2, #0
	if (ep < 2 || ep > NUM_ENDPOINTS) return;
    63c2:	sub.w	r2, r0, #2
	usb_endpoint_config(endpoint_queue_head + ep * 2, config, cb);
	if (cb) endpointN_notify_mask |= (1 << ep);
}

void usb_config_tx(uint32_t ep, uint32_t packet_size, int do_zlp, void (*cb)(transfer_t *))
{
    63c6:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, lr}
	uint32_t config = (packet_size << 16) | (do_zlp ? 0 : (1 << 29));
    63ca:	ite	ne
    63cc:	movne	r7, #0
    63ce:	moveq.w	r7, #536870912	; 0x20000000
	if (ep < 2 || ep > NUM_ENDPOINTS) return;
    63d2:	cmp	r2, #2
    63d4:	bls.n	63da <usb_config_tx+0x1a>
    63d6:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
#endif
}

static void usb_endpoint_config(endpoint_t *qh, uint32_t config, void (*callback)(transfer_t *))
{
	memset(qh, 0, sizeof(endpoint_t));
    63da:	movs	r2, #64	; 0x40

void usb_config_tx(uint32_t ep, uint32_t packet_size, int do_zlp, void (*cb)(transfer_t *))
{
	uint32_t config = (packet_size << 16) | (do_zlp ? 0 : (1 << 29));
	if (ep < 2 || ep > NUM_ENDPOINTS) return;
	usb_endpoint_config(endpoint_queue_head + ep * 2 + 1, config, cb);
    63dc:	lsls	r5, r0, #7
    63de:	ldr.w	r9, [pc, #68]	; 6424 <usb_config_tx+0x64>
    63e2:	mov	r8, r1
    63e4:	add	r5, r2
#endif
}

static void usb_endpoint_config(endpoint_t *qh, uint32_t config, void (*callback)(transfer_t *))
{
	memset(qh, 0, sizeof(endpoint_t));
    63e6:	movs	r1, #0
    63e8:	mov	r4, r0
    63ea:	mov	r6, r3

void usb_config_tx(uint32_t ep, uint32_t packet_size, int do_zlp, void (*cb)(transfer_t *))
{
	uint32_t config = (packet_size << 16) | (do_zlp ? 0 : (1 << 29));
	if (ep < 2 || ep > NUM_ENDPOINTS) return;
	usb_endpoint_config(endpoint_queue_head + ep * 2 + 1, config, cb);
    63ec:	add.w	sl, r5, r9
#endif
}

static void usb_endpoint_config(endpoint_t *qh, uint32_t config, void (*callback)(transfer_t *))
{
	memset(qh, 0, sizeof(endpoint_t));
    63f0:	mov	r0, sl
    63f2:	bl	77c8 <memset>
	qh->config = config;
	qh->next = 1; // Terminate bit = 1
    63f6:	movs	r2, #1
}

static void usb_endpoint_config(endpoint_t *qh, uint32_t config, void (*callback)(transfer_t *))
{
	memset(qh, 0, sizeof(endpoint_t));
	qh->config = config;
    63f8:	orr.w	r1, r7, r8, lsl #16
    63fc:	str.w	r1, [r5, r9]
	qh->next = 1; // Terminate bit = 1
	qh->callback_function = callback;
    6400:	str.w	r6, [sl, #56]	; 0x38

static void usb_endpoint_config(endpoint_t *qh, uint32_t config, void (*callback)(transfer_t *))
{
	memset(qh, 0, sizeof(endpoint_t));
	qh->config = config;
	qh->next = 1; // Terminate bit = 1
    6404:	str.w	r2, [sl, #8]
void usb_config_tx(uint32_t ep, uint32_t packet_size, int do_zlp, void (*cb)(transfer_t *))
{
	uint32_t config = (packet_size << 16) | (do_zlp ? 0 : (1 << 29));
	if (ep < 2 || ep > NUM_ENDPOINTS) return;
	usb_endpoint_config(endpoint_queue_head + ep * 2 + 1, config, cb);
	if (cb) endpointN_notify_mask |= (1 << (ep + 16));
    6408:	cmp	r6, #0
    640a:	beq.n	63d6 <usb_config_tx+0x16>
    640c:	add.w	r0, r4, #16
    6410:	ldr	r3, [pc, #12]	; (6420 <usb_config_tx+0x60>)
    6412:	lsls	r2, r0
    6414:	ldr	r0, [r3, #0]
    6416:	orrs	r2, r0
    6418:	str	r2, [r3, #0]
    641a:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, pc}
    641e:	nop
    6420:	.word	0x20000b44
    6424:	.word	0x20002000

00006428 <usb_prepare_transfer>:


void usb_prepare_transfer(transfer_t *transfer, const void *data, uint32_t len, uint32_t param)
{
	transfer->next = 1;
	transfer->status = (len << 16) | (1<<7);
    6428:	lsls	r2, r2, #16
	uint32_t addr = (uint32_t)data;
	transfer->pointer0 = addr;
    642a:	str	r1, [r0, #8]
	transfer->pointer1 = addr + 4096;
	transfer->pointer2 = addr + 8192;
	transfer->pointer3 = addr + 12288;
	transfer->pointer4 = addr + 16384;
	transfer->callback_param = param;
    642c:	str	r3, [r0, #28]


void usb_prepare_transfer(transfer_t *transfer, const void *data, uint32_t len, uint32_t param)
{
	transfer->next = 1;
	transfer->status = (len << 16) | (1<<7);
    642e:	orr.w	r2, r2, #128	; 0x80
}



void usb_prepare_transfer(transfer_t *transfer, const void *data, uint32_t len, uint32_t param)
{
    6432:	push	{r4, r5, r6, r7}
	transfer->next = 1;
	transfer->status = (len << 16) | (1<<7);
    6434:	str	r2, [r0, #4]



void usb_prepare_transfer(transfer_t *transfer, const void *data, uint32_t len, uint32_t param)
{
	transfer->next = 1;
    6436:	movs	r7, #1
	transfer->status = (len << 16) | (1<<7);
	uint32_t addr = (uint32_t)data;
	transfer->pointer0 = addr;
	transfer->pointer1 = addr + 4096;
    6438:	add.w	r6, r1, #4096	; 0x1000
	transfer->pointer2 = addr + 8192;
    643c:	add.w	r5, r1, #8192	; 0x2000
	transfer->pointer3 = addr + 12288;
    6440:	add.w	r4, r1, #12288	; 0x3000
	transfer->pointer4 = addr + 16384;
    6444:	add.w	r2, r1, #16384	; 0x4000



void usb_prepare_transfer(transfer_t *transfer, const void *data, uint32_t len, uint32_t param)
{
	transfer->next = 1;
    6448:	str	r7, [r0, #0]
	transfer->status = (len << 16) | (1<<7);
	uint32_t addr = (uint32_t)data;
	transfer->pointer0 = addr;
	transfer->pointer1 = addr + 4096;
    644a:	str	r6, [r0, #12]
	transfer->pointer2 = addr + 8192;
    644c:	str	r5, [r0, #16]
	transfer->pointer3 = addr + 12288;
    644e:	str	r4, [r0, #20]
	transfer->pointer4 = addr + 16384;
    6450:	str	r2, [r0, #24]
	transfer->callback_param = param;
}
    6452:	pop	{r4, r5, r6, r7}
    6454:	bx	lr
    6456:	nop

00006458 <usb_transmit>:
	}
}

void usb_transmit(int endpoint_number, transfer_t *transfer)
{
	if (endpoint_number < 2 || endpoint_number > NUM_ENDPOINTS) return;
    6458:	subs	r3, r0, #2
    645a:	cmp	r3, #2
    645c:	bls.n	6460 <usb_transmit+0x8>
    645e:	bx	lr
		count--;
	}
}

void usb_transmit(int endpoint_number, transfer_t *transfer)
{
    6460:	push	{r4, r5}
	if (endpoint_number < 2 || endpoint_number > NUM_ENDPOINTS) return;
	endpoint_t *endpoint = endpoint_queue_head + endpoint_number * 2 + 1;
	uint32_t mask = 1 << (endpoint_number + 16);
	schedule_transfer(endpoint, mask, transfer);
    6462:	ldr	r3, [pc, #24]	; (647c <usb_transmit+0x24>)
    6464:	add.w	r4, r0, #16
    6468:	movs	r5, #1
    646a:	mov	r2, r1
    646c:	add.w	r0, r3, r0, lsl #7
    6470:	lsl.w	r1, r5, r4
}
    6474:	pop	{r4, r5}
void usb_transmit(int endpoint_number, transfer_t *transfer)
{
	if (endpoint_number < 2 || endpoint_number > NUM_ENDPOINTS) return;
	endpoint_t *endpoint = endpoint_queue_head + endpoint_number * 2 + 1;
	uint32_t mask = 1 << (endpoint_number + 16);
	schedule_transfer(endpoint, mask, transfer);
    6476:	b.w	5b8c <schedule_transfer>
    647a:	nop
    647c:	.word	0x20002040

00006480 <usb_receive>:
}

void usb_receive(int endpoint_number, transfer_t *transfer)
{
	if (endpoint_number < 2 || endpoint_number > NUM_ENDPOINTS) return;
    6480:	subs	r3, r0, #2
    6482:	cmp	r3, #2
    6484:	bls.n	6488 <usb_receive+0x8>
    6486:	bx	lr
	uint32_t mask = 1 << (endpoint_number + 16);
	schedule_transfer(endpoint, mask, transfer);
}

void usb_receive(int endpoint_number, transfer_t *transfer)
{
    6488:	push	{r4}
	if (endpoint_number < 2 || endpoint_number > NUM_ENDPOINTS) return;
	endpoint_t *endpoint = endpoint_queue_head + endpoint_number * 2;
	uint32_t mask = 1 << endpoint_number;
	schedule_transfer(endpoint, mask, transfer);
    648a:	ldr	r3, [pc, #20]	; (64a0 <usb_receive+0x20>)
    648c:	movs	r4, #1
    648e:	mov	r2, r1
    6490:	lsl.w	r1, r4, r0
    6494:	add.w	r0, r3, r0, lsl #7
}
    6498:	ldr.w	r4, [sp], #4
void usb_receive(int endpoint_number, transfer_t *transfer)
{
	if (endpoint_number < 2 || endpoint_number > NUM_ENDPOINTS) return;
	endpoint_t *endpoint = endpoint_queue_head + endpoint_number * 2;
	uint32_t mask = 1 << endpoint_number;
	schedule_transfer(endpoint, mask, transfer);
    649c:	b.w	5b8c <schedule_transfer>
    64a0:	.word	0x20002000

000064a4 <usb_transfer_status>:
		//if (!(cmd & USB_USBCMD_ATDTW)) continue;
		//if (status & 0x80) break; // for still active, only 1 reading needed
		//if (++count > 1) break; // for completed, check 10 times
	}
#else
	return transfer->status;
    64a4:	ldr	r0, [r0, #4]
#endif
}
    64a6:	bx	lr

000064a8 <delay>:

void delay(uint32_t msec)
{
	uint32_t start;

	if (msec == 0) return;
    64a8:	cmp	r0, #0
    64aa:	beq.n	655c <delay+0xb4>
 */
__attribute__( ( always_inline ) ) __STATIC_INLINE uint32_t __STREXW(uint32_t value, volatile uint32_t *addr)
{
   uint32_t result;

   __ASM volatile ("strex %0, %2, [%1]" : "=&r" (result) : "r" (addr), "r" (value) );
    64ac:	movs	r2, #1
{

}*/

void delay(uint32_t msec)
{
    64ae:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    64b2:	sub	sp, #20
    64b4:	mov	fp, r0
    64b6:	ldr	r4, [pc, #168]	; (6560 <delay+0xb8>)
    64b8:	ldr	r5, [pc, #168]	; (6564 <delay+0xbc>)
    64ba:	ldr	r6, [pc, #172]	; (6568 <delay+0xc0>)
    64bc:	ldrd	r8, r9, [sp, #8]
 */
__attribute__( ( always_inline ) ) __STATIC_INLINE uint32_t __LDREXW(volatile uint32_t *addr)
{
    uint32_t result;

   __ASM volatile ("ldrex %0, [%1]" : "=r" (result) : "r" (addr) );
    64c0:	ldrex	r3, [r4]
uint32_t micros(void)
{
	uint32_t smc, scc;
	do {
		__LDREXW(&systick_safe_read);
		smc = systick_millis_count;
    64c4:	ldr	r0, [r5, #0]
		scc = systick_cycle_count;
    64c6:	ldr	r3, [r6, #0]
 */
__attribute__( ( always_inline ) ) __STATIC_INLINE uint32_t __STREXW(uint32_t value, volatile uint32_t *addr)
{
   uint32_t result;

   __ASM volatile ("strex %0, %2, [%1]" : "=&r" (result) : "r" (addr), "r" (value) );
    64c8:	strex	r1, r2, [r4]
	} while ( __STREXW(1, &systick_safe_read));
    64cc:	cmp	r1, #0
    64ce:	bne.n	64c0 <delay+0x18>
	uint32_t cyccnt = ARM_DWT_CYCCNT;
    64d0:	ldr	r7, [pc, #152]	; (656c <delay+0xc4>)
    64d2:	strd	r8, r9, [sp, #8]
    64d6:	ldr	r2, [r7, #0]
	asm volatile("" : : : "memory");
	uint32_t ccdelta = cyccnt - scc;
    64d8:	subs	r3, r2, r3
	uint32_t frac = ((uint64_t)ccdelta * scale_cpu_cycles_to_microseconds) >> 32;
    64da:	ldr	r2, [pc, #148]	; (6570 <delay+0xc8>)
	if (frac > 1000) frac = 1000;
	uint32_t usec = 1000*smc + frac;
    64dc:	mov.w	lr, #1000	; 0x3e8
	do {
		__LDREXW(&systick_safe_read);
		smc = systick_millis_count;
		scc = systick_cycle_count;
	} while ( __STREXW(1, &systick_safe_read));
	uint32_t cyccnt = ARM_DWT_CYCCNT;
    64e0:	str	r7, [sp, #4]
	asm volatile("" : : : "memory");
	uint32_t ccdelta = cyccnt - scc;
	uint32_t frac = ((uint64_t)ccdelta * scale_cpu_cycles_to_microseconds) >> 32;
    64e2:	ldr	r2, [r2, #0]
    64e4:	movs	r7, #1
    64e6:	umull	r2, r3, r3, r2
	if (frac > 1000) frac = 1000;
    64ea:	mov.w	r2, #1000	; 0x3e8
		scc = systick_cycle_count;
	} while ( __STREXW(1, &systick_safe_read));
	uint32_t cyccnt = ARM_DWT_CYCCNT;
	asm volatile("" : : : "memory");
	uint32_t ccdelta = cyccnt - scc;
	uint32_t frac = ((uint64_t)ccdelta * scale_cpu_cycles_to_microseconds) >> 32;
    64ee:	mov	r8, r3
	if (frac > 1000) frac = 1000;
    64f0:	movs	r3, #0
		scc = systick_cycle_count;
	} while ( __STREXW(1, &systick_safe_read));
	uint32_t cyccnt = ARM_DWT_CYCCNT;
	asm volatile("" : : : "memory");
	uint32_t ccdelta = cyccnt - scc;
	uint32_t frac = ((uint64_t)ccdelta * scale_cpu_cycles_to_microseconds) >> 32;
    64f2:	cmp	r3, r1
    64f4:	it	eq
    64f6:	cmpeq	r2, r8
    64f8:	ite	cs
    64fa:	movcs	sl, r8
    64fc:	movcc	sl, lr
	if (frac > 1000) frac = 1000;
	uint32_t usec = 1000*smc + frac;
    64fe:	mla	sl, lr, r0, sl
 */
__attribute__( ( always_inline ) ) __STATIC_INLINE uint32_t __LDREXW(volatile uint32_t *addr)
{
    uint32_t result;

   __ASM volatile ("ldrex %0, [%1]" : "=r" (result) : "r" (addr) );
    6502:	ldrex	r3, [r4]
uint32_t micros(void)
{
	uint32_t smc, scc;
	do {
		__LDREXW(&systick_safe_read);
		smc = systick_millis_count;
    6506:	ldr	r2, [r5, #0]
		scc = systick_cycle_count;
    6508:	ldr	r1, [r6, #0]
 */
__attribute__( ( always_inline ) ) __STATIC_INLINE uint32_t __STREXW(uint32_t value, volatile uint32_t *addr)
{
   uint32_t result;

   __ASM volatile ("strex %0, %2, [%1]" : "=&r" (result) : "r" (addr), "r" (value) );
    650a:	strex	r3, r7, [r4]
	} while ( __STREXW(1, &systick_safe_read));
    650e:	cmp	r3, #0
    6510:	bne.n	6502 <delay+0x5a>
	uint32_t cyccnt = ARM_DWT_CYCCNT;
    6512:	ldr	r0, [sp, #4]
    6514:	ldr	r0, [r0, #0]
	asm volatile("" : : : "memory");
	uint32_t ccdelta = cyccnt - scc;
    6516:	subs	r1, r0, r1
	uint32_t frac = ((uint64_t)ccdelta * scale_cpu_cycles_to_microseconds) >> 32;
    6518:	ldr	r0, [pc, #84]	; (6570 <delay+0xc8>)
	uint32_t start;

	if (msec == 0) return;
	start = micros();
	while (1) {
		while ((micros() - start) >= 1000) {
    651a:	mov.w	lr, #1000	; 0x3e8
		scc = systick_cycle_count;
	} while ( __STREXW(1, &systick_safe_read));
	uint32_t cyccnt = ARM_DWT_CYCCNT;
	asm volatile("" : : : "memory");
	uint32_t ccdelta = cyccnt - scc;
	uint32_t frac = ((uint64_t)ccdelta * scale_cpu_cycles_to_microseconds) >> 32;
    651e:	ldr	r0, [r0, #0]
	uint32_t start;

	if (msec == 0) return;
	start = micros();
	while (1) {
		while ((micros() - start) >= 1000) {
    6520:	mul.w	r2, lr, r2
		scc = systick_cycle_count;
	} while ( __STREXW(1, &systick_safe_read));
	uint32_t cyccnt = ARM_DWT_CYCCNT;
	asm volatile("" : : : "memory");
	uint32_t ccdelta = cyccnt - scc;
	uint32_t frac = ((uint64_t)ccdelta * scale_cpu_cycles_to_microseconds) >> 32;
    6524:	umull	r0, r1, r1, r0
	if (frac > 1000) frac = 1000;
    6528:	mov.w	r0, #1000	; 0x3e8
	uint32_t start;

	if (msec == 0) return;
	start = micros();
	while (1) {
		while ((micros() - start) >= 1000) {
    652c:	rsb	r2, sl, r2
		scc = systick_cycle_count;
	} while ( __STREXW(1, &systick_safe_read));
	uint32_t cyccnt = ARM_DWT_CYCCNT;
	asm volatile("" : : : "memory");
	uint32_t ccdelta = cyccnt - scc;
	uint32_t frac = ((uint64_t)ccdelta * scale_cpu_cycles_to_microseconds) >> 32;
    6530:	mov	r8, r1
	if (frac > 1000) frac = 1000;
    6532:	movs	r1, #0
		scc = systick_cycle_count;
	} while ( __STREXW(1, &systick_safe_read));
	uint32_t cyccnt = ARM_DWT_CYCCNT;
	asm volatile("" : : : "memory");
	uint32_t ccdelta = cyccnt - scc;
	uint32_t frac = ((uint64_t)ccdelta * scale_cpu_cycles_to_microseconds) >> 32;
    6534:	cmp	r1, r3
    6536:	it	eq
    6538:	cmpeq	r0, r8
    653a:	ite	cs
    653c:	movcs	r3, r8
    653e:	movcc	r3, lr
	uint32_t start;

	if (msec == 0) return;
	start = micros();
	while (1) {
		while ((micros() - start) >= 1000) {
    6540:	add	r2, r3
    6542:	cmp	r2, lr
    6544:	bcc.n	6556 <delay+0xae>
			if (--msec == 0) return;
    6546:	subs.w	fp, fp, #1
			start += 1000;
    654a:	add.w	sl, sl, #1000	; 0x3e8

	if (msec == 0) return;
	start = micros();
	while (1) {
		while ((micros() - start) >= 1000) {
			if (--msec == 0) return;
    654e:	bne.n	6502 <delay+0x5a>
			start += 1000;
		}
		yield();
	}
	// TODO...
}
    6550:	add	sp, #20
    6552:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
	while (1) {
		while ((micros() - start) >= 1000) {
			if (--msec == 0) return;
			start += 1000;
		}
		yield();
    6556:	bl	6894 <yield>
	}
    655a:	b.n	6502 <delay+0x5a>
    655c:	bx	lr
    655e:	nop
    6560:	.word	0x20002280
    6564:	.word	0x20000b84
    6568:	.word	0x20000b7c
    656c:	.word	0xe0001004
    6570:	.word	0x20000b80

00006574 <pwm_init>:
}

void pwm_init(void)
{
	//printf("pwm init\n");
	CCM_CCGR4 |= CCM_CCGR4_PWM1(CCM_CCGR_ON) | CCM_CCGR4_PWM2(CCM_CCGR_ON) |
    6574:	ldr	r0, [pc, #656]	; (6808 <pwm_init+0x294>)
void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
    6576:	mov.w	ip, #15

void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
    657a:	ldr	r3, [pc, #656]	; (680c <pwm_init+0x298>)
}

void pwm_init(void)
{
	//printf("pwm init\n");
	CCM_CCGR4 |= CCM_CCGR4_PWM1(CCM_CCGR_ON) | CCM_CCGR4_PWM2(CCM_CCGR_ON) |
    657c:	ldr	r2, [r0, #120]	; 0x78
    657e:	orr.w	r2, r2, #16711680	; 0xff0000
			TMR_CTRL_LENGTH | TMR_CTRL_OUTMODE(6);
	}
}

void pwm_init(void)
{
    6582:	push	{r4, r5, r6, r7, lr}
	//printf("pwm init\n");
	CCM_CCGR4 |= CCM_CCGR4_PWM1(CCM_CCGR_ON) | CCM_CCGR4_PWM2(CCM_CCGR_ON) |
    6584:	str	r2, [r0, #120]	; 0x78
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
    6586:	movs	r5, #0
void pwm_init(void)
{
	//printf("pwm init\n");
	CCM_CCGR4 |= CCM_CCGR4_PWM1(CCM_CCGR_ON) | CCM_CCGR4_PWM2(CCM_CCGR_ON) |
		CCM_CCGR4_PWM3(CCM_CCGR_ON) | CCM_CCGR4_PWM4(CCM_CCGR_ON);
	CCM_CCGR6 |= CCM_CCGR6_QTIMER1(CCM_CCGR_ON) | CCM_CCGR6_QTIMER2(CCM_CCGR_ON) |
    6588:	ldr.w	r2, [r0, #128]	; 0x80

void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
    658c:	mov.w	r6, #61440	; 0xf000
void pwm_init(void)
{
	//printf("pwm init\n");
	CCM_CCGR4 |= CCM_CCGR4_PWM1(CCM_CCGR_ON) | CCM_CCGR4_PWM2(CCM_CCGR_ON) |
		CCM_CCGR4_PWM3(CCM_CCGR_ON) | CCM_CCGR4_PWM4(CCM_CCGR_ON);
	CCM_CCGR6 |= CCM_CCGR6_QTIMER1(CCM_CCGR_ON) | CCM_CCGR6_QTIMER2(CCM_CCGR_ON) |
    6590:	ldr	r4, [pc, #636]	; (6810 <pwm_init+0x29c>)
	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
    6592:	mov.w	lr, #57344	; 0xe000

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    6596:	mov	r1, r5
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
    6598:	mov.w	r7, #1024	; 0x400
void pwm_init(void)
{
	//printf("pwm init\n");
	CCM_CCGR4 |= CCM_CCGR4_PWM1(CCM_CCGR_ON) | CCM_CCGR4_PWM2(CCM_CCGR_ON) |
		CCM_CCGR4_PWM3(CCM_CCGR_ON) | CCM_CCGR4_PWM4(CCM_CCGR_ON);
	CCM_CCGR6 |= CCM_CCGR6_QTIMER1(CCM_CCGR_ON) | CCM_CCGR6_QTIMER2(CCM_CCGR_ON) |
    659c:	orrs	r4, r2
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
    659e:	mov	r2, r5
void pwm_init(void)
{
	//printf("pwm init\n");
	CCM_CCGR4 |= CCM_CCGR4_PWM1(CCM_CCGR_ON) | CCM_CCGR4_PWM2(CCM_CCGR_ON) |
		CCM_CCGR4_PWM3(CCM_CCGR_ON) | CCM_CCGR4_PWM4(CCM_CCGR_ON);
	CCM_CCGR6 |= CCM_CCGR6_QTIMER1(CCM_CCGR_ON) | CCM_CCGR6_QTIMER2(CCM_CCGR_ON) |
    65a0:	str.w	r4, [r0, #128]	; 0x80

void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
    65a4:	strh.w	r6, [r3, #396]	; 0x18c
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
		p->SM[i].DTCNT0 = 0;
		p->SM[i].INIT = 0;
		p->SM[i].VAL0 = 0;
		p->SM[i].VAL1 = 33464;
    65a8:	movw	r6, #33464	; 0x82b8
void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
    65ac:	strh.w	ip, [r3, #398]	; 0x18e
	p->FFILT0 = 0;
    65b0:	strh.w	r5, [r3, #400]	; 0x190
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
    65b4:	ldrh.w	r0, [r3, #392]	; 0x188
    65b8:	uxth	r0, r0
    65ba:	orr.w	r0, r0, #240	; 0xf0
    65be:	strh.w	r0, [r3, #392]	; 0x188
    65c2:	add.w	r0, r1, r1, lsl #1
    65c6:	ldr	r3, [pc, #580]	; (680c <pwm_init+0x298>)
	for (i=0; i < 4; i++) {
    65c8:	adds	r1, #1
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
    65ca:	movs	r5, #0
    65cc:	lsls	r0, r0, #5
    65ce:	mov	r4, r3

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    65d0:	cmp	r1, #4
    65d2:	add	r3, r0
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
    65d4:	strh.w	lr, [r3, #4]
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
    65d8:	strh	r7, [r3, #6]
		p->SM[i].OCTRL = 0;
    65da:	strh	r2, [r3, #34]	; 0x22
		p->SM[i].DTCNT0 = 0;
    65dc:	strh	r2, [r3, #48]	; 0x30
		p->SM[i].INIT = 0;
    65de:	strh	r2, [r3, #2]
		p->SM[i].VAL0 = 0;
    65e0:	strh	r2, [r3, #10]
		p->SM[i].VAL1 = 33464;
    65e2:	strh	r6, [r3, #14]
		p->SM[i].VAL2 = 0;
    65e4:	strh	r2, [r3, #18]
		p->SM[i].VAL3 = 0;
    65e6:	strh	r2, [r3, #22]
		p->SM[i].VAL4 = 0;
    65e8:	strh	r2, [r3, #26]
		p->SM[i].VAL5 = 0;
    65ea:	strh	r2, [r3, #30]

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    65ec:	bne.n	65c2 <pwm_init+0x4e>
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    65ee:	ldrh.w	r0, [r4, #392]	; 0x188
void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
    65f2:	mov.w	ip, #15

void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
    65f6:	ldr	r3, [pc, #540]	; (6814 <pwm_init+0x2a0>)
    65f8:	mov.w	r6, #61440	; 0xf000
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    65fc:	uxth	r0, r0

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    65fe:	mov	r1, r5
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
    6600:	mov.w	r7, #57344	; 0xe000
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
    6604:	mov	r2, r5
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    6606:	orr.w	r0, r0, ip
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
    660a:	mov.w	lr, #1024	; 0x400
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    660e:	strh.w	r0, [r4, #392]	; 0x188
	p->MCTRL |= FLEXPWM_MCTRL_RUN(15);
    6612:	ldrh.w	r0, [r4, #392]	; 0x188
    6616:	uxth	r0, r0
    6618:	orr.w	r0, r0, #3840	; 0xf00
    661c:	strh.w	r0, [r4, #392]	; 0x188

void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
    6620:	strh.w	r6, [r3, #396]	; 0x18c
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
		p->SM[i].DTCNT0 = 0;
		p->SM[i].INIT = 0;
		p->SM[i].VAL0 = 0;
		p->SM[i].VAL1 = 33464;
    6624:	movw	r6, #33464	; 0x82b8
void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
    6628:	strh.w	ip, [r3, #398]	; 0x18e
	p->FFILT0 = 0;
    662c:	strh.w	r5, [r3, #400]	; 0x190
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
    6630:	ldrh.w	r0, [r3, #392]	; 0x188
    6634:	uxth	r0, r0
    6636:	orr.w	r0, r0, #240	; 0xf0
    663a:	strh.w	r0, [r3, #392]	; 0x188
    663e:	add.w	r0, r1, r1, lsl #1
    6642:	ldr	r3, [pc, #464]	; (6814 <pwm_init+0x2a0>)
	for (i=0; i < 4; i++) {
    6644:	adds	r1, #1
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
    6646:	movs	r5, #0
    6648:	lsls	r0, r0, #5
    664a:	mov	r4, r3

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    664c:	cmp	r1, #4
    664e:	add	r3, r0
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
    6650:	strh	r7, [r3, #4]
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
    6652:	strh.w	lr, [r3, #6]
		p->SM[i].OCTRL = 0;
    6656:	strh	r2, [r3, #34]	; 0x22
		p->SM[i].DTCNT0 = 0;
    6658:	strh	r2, [r3, #48]	; 0x30
		p->SM[i].INIT = 0;
    665a:	strh	r2, [r3, #2]
		p->SM[i].VAL0 = 0;
    665c:	strh	r2, [r3, #10]
		p->SM[i].VAL1 = 33464;
    665e:	strh	r6, [r3, #14]
		p->SM[i].VAL2 = 0;
    6660:	strh	r2, [r3, #18]
		p->SM[i].VAL3 = 0;
    6662:	strh	r2, [r3, #22]
		p->SM[i].VAL4 = 0;
    6664:	strh	r2, [r3, #26]
		p->SM[i].VAL5 = 0;
    6666:	strh	r2, [r3, #30]

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    6668:	bne.n	663e <pwm_init+0xca>
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    666a:	ldrh.w	r0, [r4, #392]	; 0x188
void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
    666e:	mov.w	ip, #15

void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
    6672:	ldr	r3, [pc, #420]	; (6818 <pwm_init+0x2a4>)
    6674:	mov.w	r6, #61440	; 0xf000
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    6678:	uxth	r0, r0

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    667a:	mov	r1, r5
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
    667c:	mov.w	r7, #57344	; 0xe000
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
    6680:	mov	r2, r5
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    6682:	orr.w	r0, r0, ip
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
    6686:	mov.w	lr, #1024	; 0x400
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    668a:	strh.w	r0, [r4, #392]	; 0x188
	p->MCTRL |= FLEXPWM_MCTRL_RUN(15);
    668e:	ldrh.w	r0, [r4, #392]	; 0x188
    6692:	uxth	r0, r0
    6694:	orr.w	r0, r0, #3840	; 0xf00
    6698:	strh.w	r0, [r4, #392]	; 0x188

void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
    669c:	strh.w	r6, [r3, #396]	; 0x18c
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
		p->SM[i].DTCNT0 = 0;
		p->SM[i].INIT = 0;
		p->SM[i].VAL0 = 0;
		p->SM[i].VAL1 = 33464;
    66a0:	movw	r6, #33464	; 0x82b8
void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
    66a4:	strh.w	ip, [r3, #398]	; 0x18e
	p->FFILT0 = 0;
    66a8:	strh.w	r5, [r3, #400]	; 0x190
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
    66ac:	ldrh.w	r0, [r3, #392]	; 0x188
    66b0:	uxth	r0, r0
    66b2:	orr.w	r0, r0, #240	; 0xf0
    66b6:	strh.w	r0, [r3, #392]	; 0x188
    66ba:	add.w	r0, r1, r1, lsl #1
    66be:	ldr	r3, [pc, #344]	; (6818 <pwm_init+0x2a4>)
	for (i=0; i < 4; i++) {
    66c0:	adds	r1, #1
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
    66c2:	movs	r5, #0
    66c4:	lsls	r0, r0, #5
    66c6:	mov	r4, r3

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    66c8:	cmp	r1, #4
    66ca:	add	r3, r0
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
    66cc:	strh	r7, [r3, #4]
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
    66ce:	strh.w	lr, [r3, #6]
		p->SM[i].OCTRL = 0;
    66d2:	strh	r2, [r3, #34]	; 0x22
		p->SM[i].DTCNT0 = 0;
    66d4:	strh	r2, [r3, #48]	; 0x30
		p->SM[i].INIT = 0;
    66d6:	strh	r2, [r3, #2]
		p->SM[i].VAL0 = 0;
    66d8:	strh	r2, [r3, #10]
		p->SM[i].VAL1 = 33464;
    66da:	strh	r6, [r3, #14]
		p->SM[i].VAL2 = 0;
    66dc:	strh	r2, [r3, #18]
		p->SM[i].VAL3 = 0;
    66de:	strh	r2, [r3, #22]
		p->SM[i].VAL4 = 0;
    66e0:	strh	r2, [r3, #26]
		p->SM[i].VAL5 = 0;
    66e2:	strh	r2, [r3, #30]

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    66e4:	bne.n	66ba <pwm_init+0x146>
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    66e6:	ldrh.w	r0, [r4, #392]	; 0x188
void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
    66ea:	mov.w	ip, #15

void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
    66ee:	ldr	r3, [pc, #300]	; (681c <pwm_init+0x2a8>)
    66f0:	mov.w	r7, #61440	; 0xf000
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    66f4:	uxth	r0, r0

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    66f6:	mov	r1, r5
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
    66f8:	mov.w	r6, #57344	; 0xe000
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
    66fc:	mov	r2, r5
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    66fe:	orr.w	r0, r0, ip
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
    6702:	mov.w	lr, #1024	; 0x400
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    6706:	strh.w	r0, [r4, #392]	; 0x188
	p->MCTRL |= FLEXPWM_MCTRL_RUN(15);
    670a:	ldrh.w	r0, [r4, #392]	; 0x188
    670e:	uxth	r0, r0
    6710:	orr.w	r0, r0, #3840	; 0xf00
    6714:	strh.w	r0, [r4, #392]	; 0x188

void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
    6718:	strh.w	r7, [r3, #396]	; 0x18c
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
		p->SM[i].OCTRL = 0;
		p->SM[i].DTCNT0 = 0;
		p->SM[i].INIT = 0;
		p->SM[i].VAL0 = 0;
		p->SM[i].VAL1 = 33464;
    671c:	movw	r7, #33464	; 0x82b8
void flexpwm_init(IMXRT_FLEXPWM_t *p)
{
	int i;

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
    6720:	strh.w	ip, [r3, #398]	; 0x18e
	p->FFILT0 = 0;
    6724:	strh.w	r5, [r3, #400]	; 0x190
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
    6728:	ldrh.w	r0, [r3, #392]	; 0x188
    672c:	uxth	r0, r0
    672e:	orr.w	r0, r0, #240	; 0xf0
    6732:	strh.w	r0, [r3, #392]	; 0x188
    6736:	add.w	r0, r1, r1, lsl #1
    673a:	ldr	r3, [pc, #224]	; (681c <pwm_init+0x2a8>)
	for (i=0; i < 4; i++) {
    673c:	adds	r1, #1
    673e:	lsls	r0, r0, #5
    6740:	mov	r4, r3
    6742:	cmp	r1, #4
    6744:	add	r3, r0
		p->SM[i].CTRL2 = FLEXPWM_SMCTRL2_INDEP | FLEXPWM_SMCTRL2_WAITEN
    6746:	strh	r6, [r3, #4]
			| FLEXPWM_SMCTRL2_DBGEN;
		p->SM[i].CTRL = FLEXPWM_SMCTRL_FULL;
    6748:	strh.w	lr, [r3, #6]
		p->SM[i].OCTRL = 0;
    674c:	strh	r2, [r3, #34]	; 0x22
		p->SM[i].DTCNT0 = 0;
    674e:	strh	r2, [r3, #48]	; 0x30
		p->SM[i].INIT = 0;
    6750:	strh	r2, [r3, #2]
		p->SM[i].VAL0 = 0;
    6752:	strh	r2, [r3, #10]
		p->SM[i].VAL1 = 33464;
    6754:	strh	r7, [r3, #14]
		p->SM[i].VAL2 = 0;
    6756:	strh	r2, [r3, #18]
		p->SM[i].VAL3 = 0;
    6758:	strh	r2, [r3, #22]
		p->SM[i].VAL4 = 0;
    675a:	strh	r2, [r3, #26]
		p->SM[i].VAL5 = 0;
    675c:	strh	r2, [r3, #30]

	p->FCTRL0 = FLEXPWM_FCTRL0_FLVL(15); // logic high = fault
	p->FSTS0 = 0x000F; // clear fault status
	p->FFILT0 = 0;
	p->MCTRL |= FLEXPWM_MCTRL_CLDOK(15);
	for (i=0; i < 4; i++) {
    675e:	bne.n	6736 <pwm_init+0x1c2>
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    6760:	ldrh.w	r3, [r4, #392]	; 0x188
	int i;

	for (i=0; i < 4; i++) {
		p->CH[i].CTRL = 0; // stop timer
		p->CH[i].CNTR = 0;
		p->CH[i].SCTRL = TMR_SCTRL_OEN | TMR_SCTRL_OPS | TMR_SCTRL_VAL | TMR_SCTRL_FORCE;
    6764:	movs	r7, #15

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    6766:	movs	r2, #0
		p->CH[i].CTRL = 0; // stop timer
		p->CH[i].CNTR = 0;
		p->CH[i].SCTRL = TMR_SCTRL_OEN | TMR_SCTRL_OPS | TMR_SCTRL_VAL | TMR_SCTRL_FORCE;
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
    6768:	movw	r6, #4097	; 0x1001
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    676c:	uxth	r3, r3
		p->CH[i].CTRL = 0; // stop timer
		p->CH[i].CNTR = 0;
		p->CH[i].SCTRL = TMR_SCTRL_OEN | TMR_SCTRL_OPS | TMR_SCTRL_VAL | TMR_SCTRL_FORCE;
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
		// COMP must be less than LOAD - otherwise output is always low
		p->CH[i].LOAD = 24000;   // low time  (65537 - x) - 
    676e:	movw	lr, #24000	; 0x5dc0
void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
		p->CH[i].CTRL = 0; // stop timer
    6772:	mov	r1, r2
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
		// COMP must be less than LOAD - otherwise output is always low
		p->CH[i].LOAD = 24000;   // low time  (65537 - x) - 
		p->CH[i].COMP1 = 0;  // high time (0 = always low, max = LOAD-1)
		p->CH[i].CMPLD1 = 0;
		p->CH[i].CTRL = TMR_CTRL_CM(1) | TMR_CTRL_PCS(8) |
    6774:	movw	r5, #12326	; 0x3026
		p->SM[i].VAL2 = 0;
		p->SM[i].VAL3 = 0;
		p->SM[i].VAL4 = 0;
		p->SM[i].VAL5 = 0;
	}
	p->MCTRL |= FLEXPWM_MCTRL_LDOK(15);
    6778:	orrs	r3, r7
    677a:	strh.w	r3, [r4, #392]	; 0x188
	p->MCTRL |= FLEXPWM_MCTRL_RUN(15);
    677e:	ldrh.w	r3, [r4, #392]	; 0x188
    6782:	uxth	r3, r3
    6784:	orr.w	r3, r3, #3840	; 0xf00
    6788:	strh.w	r3, [r4, #392]	; 0x188
void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
		p->CH[i].CTRL = 0; // stop timer
    678c:	lsls	r0, r2, #5
    678e:	ldr	r3, [pc, #144]	; (6820 <pwm_init+0x2ac>)

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    6790:	adds	r2, #1
		p->CH[i].CTRL = 0; // stop timer
    6792:	add	r3, r0

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    6794:	cmp	r2, #4
		p->CH[i].CTRL = 0; // stop timer
    6796:	strh	r1, [r3, #12]
		p->CH[i].CNTR = 0;
    6798:	strh	r1, [r3, #10]
		p->CH[i].SCTRL = TMR_SCTRL_OEN | TMR_SCTRL_OPS | TMR_SCTRL_VAL | TMR_SCTRL_FORCE;
    679a:	strh	r7, [r3, #14]
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
    679c:	strh	r6, [r3, #20]
		// COMP must be less than LOAD - otherwise output is always low
		p->CH[i].LOAD = 24000;   // low time  (65537 - x) - 
    679e:	strh.w	lr, [r3, #6]
		p->CH[i].COMP1 = 0;  // high time (0 = always low, max = LOAD-1)
    67a2:	strh	r1, [r3, #0]
		p->CH[i].CMPLD1 = 0;
    67a4:	strh	r1, [r3, #16]
		p->CH[i].CTRL = TMR_CTRL_CM(1) | TMR_CTRL_PCS(8) |
    67a6:	strh	r5, [r3, #12]

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    67a8:	bne.n	678c <pwm_init+0x218>
    67aa:	movs	r2, #0
		p->CH[i].CTRL = 0; // stop timer
		p->CH[i].CNTR = 0;
		p->CH[i].SCTRL = TMR_SCTRL_OEN | TMR_SCTRL_OPS | TMR_SCTRL_VAL | TMR_SCTRL_FORCE;
    67ac:	movs	r7, #15
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
    67ae:	movw	r6, #4097	; 0x1001
		// COMP must be less than LOAD - otherwise output is always low
		p->CH[i].LOAD = 24000;   // low time  (65537 - x) - 
    67b2:	movw	r5, #24000	; 0x5dc0
void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
		p->CH[i].CTRL = 0; // stop timer
    67b6:	mov	r1, r2
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
		// COMP must be less than LOAD - otherwise output is always low
		p->CH[i].LOAD = 24000;   // low time  (65537 - x) - 
		p->CH[i].COMP1 = 0;  // high time (0 = always low, max = LOAD-1)
		p->CH[i].CMPLD1 = 0;
		p->CH[i].CTRL = TMR_CTRL_CM(1) | TMR_CTRL_PCS(8) |
    67b8:	movw	r4, #12326	; 0x3026
void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
		p->CH[i].CTRL = 0; // stop timer
    67bc:	lsls	r0, r2, #5
    67be:	ldr	r3, [pc, #100]	; (6824 <pwm_init+0x2b0>)

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    67c0:	adds	r2, #1
		p->CH[i].CTRL = 0; // stop timer
    67c2:	add	r3, r0

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    67c4:	cmp	r2, #4
		p->CH[i].CTRL = 0; // stop timer
    67c6:	strh	r1, [r3, #12]
		p->CH[i].CNTR = 0;
    67c8:	strh	r1, [r3, #10]
		p->CH[i].SCTRL = TMR_SCTRL_OEN | TMR_SCTRL_OPS | TMR_SCTRL_VAL | TMR_SCTRL_FORCE;
    67ca:	strh	r7, [r3, #14]
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
    67cc:	strh	r6, [r3, #20]
		// COMP must be less than LOAD - otherwise output is always low
		p->CH[i].LOAD = 24000;   // low time  (65537 - x) - 
    67ce:	strh	r5, [r3, #6]
		p->CH[i].COMP1 = 0;  // high time (0 = always low, max = LOAD-1)
    67d0:	strh	r1, [r3, #0]
		p->CH[i].CMPLD1 = 0;
    67d2:	strh	r1, [r3, #16]
		p->CH[i].CTRL = TMR_CTRL_CM(1) | TMR_CTRL_PCS(8) |
    67d4:	strh	r4, [r3, #12]

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    67d6:	bne.n	67bc <pwm_init+0x248>
    67d8:	movs	r2, #0
		p->CH[i].CTRL = 0; // stop timer
		p->CH[i].CNTR = 0;
		p->CH[i].SCTRL = TMR_SCTRL_OEN | TMR_SCTRL_OPS | TMR_SCTRL_VAL | TMR_SCTRL_FORCE;
    67da:	movs	r7, #15
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
    67dc:	movw	r6, #4097	; 0x1001
		// COMP must be less than LOAD - otherwise output is always low
		p->CH[i].LOAD = 24000;   // low time  (65537 - x) - 
    67e0:	movw	r5, #24000	; 0x5dc0
void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
		p->CH[i].CTRL = 0; // stop timer
    67e4:	mov	r1, r2
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
		// COMP must be less than LOAD - otherwise output is always low
		p->CH[i].LOAD = 24000;   // low time  (65537 - x) - 
		p->CH[i].COMP1 = 0;  // high time (0 = always low, max = LOAD-1)
		p->CH[i].CMPLD1 = 0;
		p->CH[i].CTRL = TMR_CTRL_CM(1) | TMR_CTRL_PCS(8) |
    67e6:	movw	r4, #12326	; 0x3026
void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
		p->CH[i].CTRL = 0; // stop timer
    67ea:	lsls	r0, r2, #5
    67ec:	ldr	r3, [pc, #56]	; (6828 <pwm_init+0x2b4>)

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    67ee:	adds	r2, #1
		p->CH[i].CTRL = 0; // stop timer
    67f0:	add	r3, r0

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    67f2:	cmp	r2, #4
		p->CH[i].CTRL = 0; // stop timer
    67f4:	strh	r1, [r3, #12]
		p->CH[i].CNTR = 0;
    67f6:	strh	r1, [r3, #10]
		p->CH[i].SCTRL = TMR_SCTRL_OEN | TMR_SCTRL_OPS | TMR_SCTRL_VAL | TMR_SCTRL_FORCE;
    67f8:	strh	r7, [r3, #14]
		p->CH[i].CSCTRL = TMR_CSCTRL_CL1(1) | TMR_CSCTRL_ALT_LOAD;
    67fa:	strh	r6, [r3, #20]
		// COMP must be less than LOAD - otherwise output is always low
		p->CH[i].LOAD = 24000;   // low time  (65537 - x) - 
    67fc:	strh	r5, [r3, #6]
		p->CH[i].COMP1 = 0;  // high time (0 = always low, max = LOAD-1)
    67fe:	strh	r1, [r3, #0]
		p->CH[i].CMPLD1 = 0;
    6800:	strh	r1, [r3, #16]
		p->CH[i].CTRL = TMR_CTRL_CM(1) | TMR_CTRL_PCS(8) |
    6802:	strh	r4, [r3, #12]

void quadtimer_init(IMXRT_TMR_t *p)
{
	int i;

	for (i=0; i < 4; i++) {
    6804:	bne.n	67ea <pwm_init+0x276>
	flexpwm_init(&IMXRT_FLEXPWM3);
	flexpwm_init(&IMXRT_FLEXPWM4);
	quadtimer_init(&IMXRT_TMR1);
	quadtimer_init(&IMXRT_TMR2);
	quadtimer_init(&IMXRT_TMR3);
}
    6806:	pop	{r4, r5, r6, r7, pc}
    6808:	.word	0x400fc000
    680c:	.word	0x403dc000
    6810:	.word	0xfc030000
    6814:	.word	0x403e0000
    6818:	.word	0x403e4000
    681c:	.word	0x403e8000
    6820:	.word	0x401dc000
    6824:	.word	0x401e0000
    6828:	.word	0x401e4000

0000682c <usb_init_serialnumber>:
void usb_init_serialnumber(void)
{
	char buf[11];
	uint32_t i, num;

	num = HW_OCOTP_MAC0 & 0xFFFFFF;
    682c:	ldr	r2, [pc, #72]	; (6878 <usb_init_serialnumber+0x4c>)
	// add extra zero to work around OS-X CDC-ACM driver bug
	if (num < 10000000) num = num * 10;
    682e:	ldr	r3, [pc, #76]	; (687c <usb_init_serialnumber+0x50>)
void usb_init_serialnumber(void)
{
	char buf[11];
	uint32_t i, num;

	num = HW_OCOTP_MAC0 & 0xFFFFFF;
    6830:	ldr.w	r0, [r2, #544]	; 0x220
    6834:	bic.w	r0, r0, #4278190080	; 0xff000000
	// add extra zero to work around OS-X CDC-ACM driver bug
	if (num < 10000000) num = num * 10;
    6838:	cmp	r0, r3
	{'M','T','P'}
};
#endif

void usb_init_serialnumber(void)
{
    683a:	push	{r4, lr}
    683c:	sub	sp, #16
	char buf[11];
	uint32_t i, num;

	num = HW_OCOTP_MAC0 & 0xFFFFFF;
	// add extra zero to work around OS-X CDC-ACM driver bug
	if (num < 10000000) num = num * 10;
    683e:	bhi.n	6846 <usb_init_serialnumber+0x1a>
    6840:	add.w	r0, r0, r0, lsl #2
    6844:	lsls	r0, r0, #1
    6846:	ldr	r4, [pc, #56]	; (6880 <usb_init_serialnumber+0x54>)
	ultoa(num, buf, 10);
    6848:	add	r1, sp, #4
    684a:	movs	r2, #10
    684c:	bl	7140 <ultoa>
    6850:	add	r1, sp, #4
	for (i=0; i<10; i++) {
    6852:	movs	r3, #0
    6854:	mov	r0, r4
		char c = buf[i];
    6856:	ldrb.w	r2, [r1], #1
    685a:	adds	r3, #1
		if (!c) break;
    685c:	cbz	r2, 686e <usb_init_serialnumber+0x42>

	num = HW_OCOTP_MAC0 & 0xFFFFFF;
	// add extra zero to work around OS-X CDC-ACM driver bug
	if (num < 10000000) num = num * 10;
	ultoa(num, buf, 10);
	for (i=0; i<10; i++) {
    685e:	cmp	r3, #10
		char c = buf[i];
		if (!c) break;
		usb_string_serial_number_default.wString[i] = c;
    6860:	strh.w	r2, [r0, #2]!

	num = HW_OCOTP_MAC0 & 0xFFFFFF;
	// add extra zero to work around OS-X CDC-ACM driver bug
	if (num < 10000000) num = num * 10;
	ultoa(num, buf, 10);
	for (i=0; i<10; i++) {
    6864:	bne.n	6856 <usb_init_serialnumber+0x2a>
    6866:	movs	r3, #22
		char c = buf[i];
		if (!c) break;
		usb_string_serial_number_default.wString[i] = c;
	}
	usb_string_serial_number_default.bLength = i * 2 + 2;
    6868:	strb	r3, [r4, #0]
}
    686a:	add	sp, #16
    686c:	pop	{r4, pc}
    686e:	lsls	r3, r3, #1
    6870:	uxtb	r3, r3
	for (i=0; i<10; i++) {
		char c = buf[i];
		if (!c) break;
		usb_string_serial_number_default.wString[i] = c;
	}
	usb_string_serial_number_default.bLength = i * 2 + 2;
    6872:	strb	r3, [r4, #0]
}
    6874:	add	sp, #16
    6876:	pop	{r4, pc}
    6878:	.word	0x401f4400
    687c:	.word	0x0098967f
    6880:	.word	0x200000cc

00006884 <main>:
 */

#include <Arduino.h>

extern "C" int main(void)
{
    6884:	push	{r3, lr}
	}


#else
	// Arduino's main() function just calls setup() and loop()....
	setup();
    6886:	bl	7c <setup>
	while (1) {
		loop();
    688a:	bl	34ec <loop>
		yield();
    688e:	bl	6894 <yield>
    6892:	b.n	688a <main+0x6>

00006894 <yield>:

extern uint8_t usb_enable_serial_event_processing; // from usb_inst.cpp

void yield(void) __attribute__ ((weak));
void yield(void)
{
    6894:	push	{r4, r5, r6, lr}
	static uint8_t running=0;

	if (running) return; // TODO: does this need to be atomic?
    6896:	ldr	r4, [pc, #132]	; (691c <yield+0x88>)
    6898:	ldrb	r3, [r4, #0]
    689a:	cbnz	r3, 68be <yield+0x2a>
	running = 1;


	// USB Serail - Add hack to minimize impact...
	if (usb_enable_serial_event_processing && Serial.available()) serialEvent();
    689c:	ldr	r3, [pc, #128]	; (6920 <yield+0x8c>)
void yield(void)
{
	static uint8_t running=0;

	if (running) return; // TODO: does this need to be atomic?
	running = 1;
    689e:	movs	r2, #1


	// USB Serail - Add hack to minimize impact...
	if (usb_enable_serial_event_processing && Serial.available()) serialEvent();
    68a0:	ldrb	r3, [r3, #0]
void yield(void)
{
	static uint8_t running=0;

	if (running) return; // TODO: does this need to be atomic?
	running = 1;
    68a2:	strb	r2, [r4, #0]


	// USB Serail - Add hack to minimize impact...
	if (usb_enable_serial_event_processing && Serial.available()) serialEvent();
    68a4:	cbnz	r3, 68ee <yield+0x5a>

	// Current workaround until integrate with EventResponder.
	if (HardwareSerial::serial_event_handlers_active) HardwareSerial::processSerialEvents();
    68a6:	ldr	r3, [pc, #124]	; (6924 <yield+0x90>)
    68a8:	ldrb	r3, [r3, #0]
    68aa:	cmp	r3, #0
    68ac:	bne.n	6902 <yield+0x6e>
	// used with a scheduler or RTOS.
	bool waitForEvent(EventResponderRef event, int timeout);
	EventResponder * waitForEvent(EventResponder *list, int listsize, int timeout);

	static void runFromYield() {
		if (!firstYield) return;
    68ae:	ldr	r3, [pc, #120]	; (6928 <yield+0x94>)

	running = 0;
    68b0:	movs	r1, #0
    68b2:	ldr	r2, [r3, #0]
    68b4:	strb	r1, [r4, #0]
    68b6:	cbz	r2, 68be <yield+0x2a>
		// First, check if yield was called from an interrupt
		// never call normal handler functions from any interrupt context
		uint32_t ipsr;
		__asm__ volatile("mrs %0, ipsr\n" : "=r" (ipsr)::);
    68b8:	mrs	r2, IPSR
		if (ipsr != 0) return;
    68bc:	cbz	r2, 68c0 <yield+0x2c>
    68be:	pop	{r4, r5, r6, pc}
	static EventResponder *lastInterrupt;
	static bool runningFromYield;
private:
	static bool disableInterrupts() {
		uint32_t primask;
		__asm__ volatile("mrs %0, primask\n" : "=r" (primask)::);
    68c0:	mrs	r0, PRIMASK
		__disable_irq();
    68c4:	cpsid	i
		uint32_t ipsr;
		__asm__ volatile("mrs %0, ipsr\n" : "=r" (ipsr)::);
		if (ipsr != 0) return;
		// Next, check if any events have been triggered
		bool irq = disableInterrupts();
		EventResponder *first = firstYield;
    68c6:	ldr	r2, [r3, #0]
		if (first == nullptr) {
    68c8:	cbz	r2, 6908 <yield+0x74>
			return;
		}
		// Finally, make sure we're not being recursively called,
		// which can happen if the user's function does anything
		// that calls yield.
		if (runningFromYield) {
    68ca:	ldr	r4, [pc, #96]	; (692c <yield+0x98>)
    68cc:	ldrb	r1, [r4, #0]
    68ce:	cbnz	r1, 6908 <yield+0x74>
			enableInterrupts(irq);
			return;
		}
		// Ok, update the runningFromYield flag and process event
		runningFromYield = true;
    68d0:	movs	r6, #1
		firstYield = first->_next;
    68d2:	ldr	r5, [r2, #20]
		if (runningFromYield) {
			enableInterrupts(irq);
			return;
		}
		// Ok, update the runningFromYield flag and process event
		runningFromYield = true;
    68d4:	strb	r6, [r4, #0]
		firstYield = first->_next;
    68d6:	str	r5, [r3, #0]
		if (firstYield) {
    68d8:	cbz	r5, 6910 <yield+0x7c>
			firstYield->_prev = nullptr;
    68da:	str	r1, [r5, #24]
		__asm__ volatile("mrs %0, primask\n" : "=r" (primask)::);
		__disable_irq();
		return (primask == 0) ? true : false;
	}
	static void enableInterrupts(bool doit) {
		if (doit) __enable_irq();
    68dc:	cbnz	r0, 68e0 <yield+0x4c>
    68de:	cpsie	i
			firstYield->_prev = nullptr;
		} else {
			lastYield = nullptr;
		}
		enableInterrupts(irq);
		first->_triggered = false;
    68e0:	movs	r5, #0
		(*(first->_function))(*first);
    68e2:	ldr	r3, [r2, #8]
    68e4:	mov	r0, r2
			firstYield->_prev = nullptr;
		} else {
			lastYield = nullptr;
		}
		enableInterrupts(irq);
		first->_triggered = false;
    68e6:	strb	r5, [r2, #29]
		(*(first->_function))(*first);
    68e8:	blx	r3
		runningFromYield = false;
    68ea:	strb	r5, [r4, #0]
    68ec:	pop	{r4, r5, r6, pc}
			// sketch still gets to run normally after this wait time.
			//if ((uint32_t)(systick_millis_count - millis_begin) > 2500) break;
		//}
	}
        void end() { /* TODO: flush output and shut down USB port */ };
        virtual int available() { return usb_serial_available(); }
    68ee:	bl	59bc <usb_serial_available>
	if (running) return; // TODO: does this need to be atomic?
	running = 1;


	// USB Serail - Add hack to minimize impact...
	if (usb_enable_serial_event_processing && Serial.available()) serialEvent();
    68f2:	cmp	r0, #0
    68f4:	beq.n	68a6 <yield+0x12>
    68f6:	bl	6b60 <serialEvent()>

	// Current workaround until integrate with EventResponder.
	if (HardwareSerial::serial_event_handlers_active) HardwareSerial::processSerialEvents();
    68fa:	ldr	r3, [pc, #40]	; (6924 <yield+0x90>)
    68fc:	ldrb	r3, [r3, #0]
    68fe:	cmp	r3, #0
    6900:	beq.n	68ae <yield+0x1a>
    6902:	bl	71b4 <HardwareSerial::processSerialEvents()>
    6906:	b.n	68ae <yield+0x1a>
		__asm__ volatile("mrs %0, primask\n" : "=r" (primask)::);
		__disable_irq();
		return (primask == 0) ? true : false;
	}
	static void enableInterrupts(bool doit) {
		if (doit) __enable_irq();
    6908:	cmp	r0, #0
    690a:	bne.n	68be <yield+0x2a>
    690c:	cpsie	i
    690e:	pop	{r4, r5, r6, pc}
		runningFromYield = true;
		firstYield = first->_next;
		if (firstYield) {
			firstYield->_prev = nullptr;
		} else {
			lastYield = nullptr;
    6910:	ldr	r3, [pc, #28]	; (6930 <yield+0x9c>)
    6912:	str	r5, [r3, #0]
		__asm__ volatile("mrs %0, primask\n" : "=r" (primask)::);
		__disable_irq();
		return (primask == 0) ? true : false;
	}
	static void enableInterrupts(bool doit) {
		if (doit) __enable_irq();
    6914:	cmp	r0, #0
    6916:	bne.n	68e0 <yield+0x4c>
    6918:	b.n	68de <yield+0x4a>
    691a:	nop
    691c:	.word	0x20000b88
    6920:	.word	0x200000e2
    6924:	.word	0x20000bd8
    6928:	.word	0x20000b9c
    692c:	.word	0x20000ba0
    6930:	.word	0x20000b98

00006934 <EventResponder::triggerEventNotImmediate()>:
bool EventResponder::runningFromYield = false;

// TODO: interrupt disable/enable needed in many places!!!

void EventResponder::triggerEventNotImmediate()
{
    6934:	push	{r4}
	static EventResponder *lastInterrupt;
	static bool runningFromYield;
private:
	static bool disableInterrupts() {
		uint32_t primask;
		__asm__ volatile("mrs %0, primask\n" : "=r" (primask)::);
    6936:	mrs	r2, PRIMASK
		__disable_irq();
    693a:	cpsid	i
	bool irq = disableInterrupts();
	if (_triggered == false) {
    693c:	ldrb	r3, [r0, #29]
    693e:	cbnz	r3, 694e <EventResponder::triggerEventNotImmediate()+0x1a>
		// not already triggered
		if (_type == EventTypeYield) {
    6940:	ldrb	r1, [r0, #28]
    6942:	cmp	r1, #1
    6944:	beq.n	6958 <EventResponder::triggerEventNotImmediate()+0x24>
				_next = nullptr;
				_prev = lastYield;
				_prev->_next = this;
				lastYield = this;
			}
		} else if (_type == EventTypeInterrupt) {
    6946:	cmp	r1, #3
    6948:	beq.n	696c <EventResponder::triggerEventNotImmediate()+0x38>
			}
			SCB_ICSR = SCB_ICSR_PENDSVSET; // set PendSV interrupt
		} else {
			// detached, easy :-)
		}
		_triggered = true;
    694a:	movs	r3, #1
    694c:	strb	r3, [r0, #29]
		return (primask == 0) ? true : false;
	}
	static void enableInterrupts(bool doit) {
		if (doit) __enable_irq();
    694e:	cbnz	r2, 6952 <EventResponder::triggerEventNotImmediate()+0x1e>
    6950:	cpsie	i
	}
	enableInterrupts(irq);
}
    6952:	ldr.w	r4, [sp], #4
    6956:	bx	lr
	bool irq = disableInterrupts();
	if (_triggered == false) {
		// not already triggered
		if (_type == EventTypeYield) {
			// normal type, called from yield()
			if (firstYield == nullptr) {
    6958:	ldr	r4, [pc, #68]	; (69a0 <EventResponder::triggerEventNotImmediate()+0x6c>)
    695a:	ldr	r1, [r4, #0]
    695c:	cbz	r1, 6988 <EventResponder::triggerEventNotImmediate()+0x54>
				_prev = nullptr;
				firstYield = this;
				lastYield = this;
			} else {
				_next = nullptr;
				_prev = lastYield;
    695e:	ldr	r1, [pc, #68]	; (69a4 <EventResponder::triggerEventNotImmediate()+0x70>)
				_next = nullptr;
				_prev = nullptr;
				firstYield = this;
				lastYield = this;
			} else {
				_next = nullptr;
    6960:	str	r3, [r0, #20]
				_prev = lastYield;
    6962:	ldr	r3, [r1, #0]
				_prev->_next = this;
				lastYield = this;
    6964:	str	r0, [r1, #0]
				_prev = nullptr;
				firstYield = this;
				lastYield = this;
			} else {
				_next = nullptr;
				_prev = lastYield;
    6966:	str	r3, [r0, #24]
				_prev->_next = this;
    6968:	str	r0, [r3, #20]
    696a:	b.n	694a <EventResponder::triggerEventNotImmediate()+0x16>
				lastYield = this;
			}
		} else if (_type == EventTypeInterrupt) {
			// interrupt, called from software interrupt
			if (firstInterrupt == nullptr) {
    696c:	ldr	r4, [pc, #56]	; (69a8 <EventResponder::triggerEventNotImmediate()+0x74>)
    696e:	ldr	r1, [r4, #0]
    6970:	cbz	r1, 6994 <EventResponder::triggerEventNotImmediate()+0x60>
				_prev = nullptr;
				firstInterrupt = this;
				lastInterrupt = this;
			} else {
				_next = nullptr;
				_prev = lastInterrupt;
    6972:	ldr	r1, [pc, #56]	; (69ac <EventResponder::triggerEventNotImmediate()+0x78>)
				_next = nullptr;
				_prev = nullptr;
				firstInterrupt = this;
				lastInterrupt = this;
			} else {
				_next = nullptr;
    6974:	str	r3, [r0, #20]
				_prev = lastInterrupt;
    6976:	ldr	r3, [r1, #0]
				_prev->_next = this;
				lastInterrupt = this;
    6978:	str	r0, [r1, #0]
				_prev = nullptr;
				firstInterrupt = this;
				lastInterrupt = this;
			} else {
				_next = nullptr;
				_prev = lastInterrupt;
    697a:	str	r3, [r0, #24]
				_prev->_next = this;
    697c:	str	r0, [r3, #20]
				lastInterrupt = this;
			}
			SCB_ICSR = SCB_ICSR_PENDSVSET; // set PendSV interrupt
    697e:	ldr	r3, [pc, #48]	; (69b0 <EventResponder::triggerEventNotImmediate()+0x7c>)
    6980:	mov.w	r1, #268435456	; 0x10000000
    6984:	str	r1, [r3, #0]
    6986:	b.n	694a <EventResponder::triggerEventNotImmediate()+0x16>
			// normal type, called from yield()
			if (firstYield == nullptr) {
				_next = nullptr;
				_prev = nullptr;
				firstYield = this;
				lastYield = this;
    6988:	ldr	r3, [pc, #24]	; (69a4 <EventResponder::triggerEventNotImmediate()+0x70>)
	if (_triggered == false) {
		// not already triggered
		if (_type == EventTypeYield) {
			// normal type, called from yield()
			if (firstYield == nullptr) {
				_next = nullptr;
    698a:	str	r1, [r0, #20]
				_prev = nullptr;
    698c:	str	r1, [r0, #24]
				firstYield = this;
    698e:	str	r0, [r4, #0]
				lastYield = this;
    6990:	str	r0, [r3, #0]
    6992:	b.n	694a <EventResponder::triggerEventNotImmediate()+0x16>
			// interrupt, called from software interrupt
			if (firstInterrupt == nullptr) {
				_next = nullptr;
				_prev = nullptr;
				firstInterrupt = this;
				lastInterrupt = this;
    6994:	ldr	r3, [pc, #20]	; (69ac <EventResponder::triggerEventNotImmediate()+0x78>)
				lastYield = this;
			}
		} else if (_type == EventTypeInterrupt) {
			// interrupt, called from software interrupt
			if (firstInterrupt == nullptr) {
				_next = nullptr;
    6996:	str	r1, [r0, #20]
				_prev = nullptr;
    6998:	str	r1, [r0, #24]
				firstInterrupt = this;
    699a:	str	r0, [r4, #0]
				lastInterrupt = this;
    699c:	str	r0, [r3, #0]
    699e:	b.n	697e <EventResponder::triggerEventNotImmediate()+0x4a>
    69a0:	.word	0x20000b9c
    69a4:	.word	0x20000b98
    69a8:	.word	0x20000b8c
    69ac:	.word	0x20000b90
    69b0:	.word	0xe000ed04

000069b4 <EventResponder::triggerEvent(int, void*)>:
	}

	// Trigger the event.  An optional status code and data may be provided.
	// The code triggering the event does NOT control which of the above
	// response methods will be used.
	virtual void triggerEvent(int status=0, void *data=nullptr) {
    69b4:	push	{r4}
		_status = status;
		_data = data;
		if (_type == EventTypeImmediate) {
    69b6:	ldrb	r4, [r0, #28]

	// Trigger the event.  An optional status code and data may be provided.
	// The code triggering the event does NOT control which of the above
	// response methods will be used.
	virtual void triggerEvent(int status=0, void *data=nullptr) {
		_status = status;
    69b8:	str	r1, [r0, #4]
		_data = data;
		if (_type == EventTypeImmediate) {
    69ba:	cmp	r4, #2
	// Trigger the event.  An optional status code and data may be provided.
	// The code triggering the event does NOT control which of the above
	// response methods will be used.
	virtual void triggerEvent(int status=0, void *data=nullptr) {
		_status = status;
		_data = data;
    69bc:	str	r2, [r0, #12]
		if (_type == EventTypeImmediate) {
    69be:	beq.n	69c8 <EventResponder::triggerEvent(int, void*)+0x14>
			(*_function)(*this);
		} else {
			triggerEventNotImmediate();
		}
	}
    69c0:	ldr.w	r4, [sp], #4
		_status = status;
		_data = data;
		if (_type == EventTypeImmediate) {
			(*_function)(*this);
		} else {
			triggerEventNotImmediate();
    69c4:	b.w	6934 <EventResponder::triggerEventNotImmediate()>
	// response methods will be used.
	virtual void triggerEvent(int status=0, void *data=nullptr) {
		_status = status;
		_data = data;
		if (_type == EventTypeImmediate) {
			(*_function)(*this);
    69c8:	ldr	r3, [r0, #8]
		} else {
			triggerEventNotImmediate();
		}
	}
    69ca:	ldr.w	r4, [sp], #4
	// response methods will be used.
	virtual void triggerEvent(int status=0, void *data=nullptr) {
		_status = status;
		_data = data;
		if (_type == EventTypeImmediate) {
			(*_function)(*this);
    69ce:	bx	r3

000069d0 <EventResponder::runFromInterrupt()>:
{
	EventResponder::runFromInterrupt();
}

void EventResponder::runFromInterrupt()
{
    69d0:	push	{r4, r5, r6, lr}
	static EventResponder *lastInterrupt;
	static bool runningFromYield;
private:
	static bool disableInterrupts() {
		uint32_t primask;
		__asm__ volatile("mrs %0, primask\n" : "=r" (primask)::);
    69d2:	mrs	r1, PRIMASK
		__disable_irq();
    69d6:	cpsid	i
	while (1) {
		bool irq = disableInterrupts();
		EventResponder *first = firstInterrupt;
    69d8:	ldr	r4, [pc, #48]	; (6a0c <EventResponder::runFromInterrupt()+0x3c>)
    69da:	ldr	r3, [r4, #0]
		if (first) {
    69dc:	cbz	r3, 6a02 <EventResponder::runFromInterrupt()+0x32>
			firstInterrupt = first->_next;
			if (firstInterrupt) {
				firstInterrupt->_prev = nullptr;
			} else {
				lastInterrupt = nullptr;
    69de:	ldr	r6, [pc, #48]	; (6a10 <EventResponder::runFromInterrupt()+0x40>)
		bool irq = disableInterrupts();
		EventResponder *first = firstInterrupt;
		if (first) {
			firstInterrupt = first->_next;
			if (firstInterrupt) {
				firstInterrupt->_prev = nullptr;
    69e0:	movs	r5, #0
{
	while (1) {
		bool irq = disableInterrupts();
		EventResponder *first = firstInterrupt;
		if (first) {
			firstInterrupt = first->_next;
    69e2:	ldr	r2, [r3, #20]
    69e4:	str	r2, [r4, #0]
			if (firstInterrupt) {
    69e6:	cbz	r2, 6a08 <EventResponder::runFromInterrupt()+0x38>
				firstInterrupt->_prev = nullptr;
    69e8:	str	r5, [r2, #24]
		return (primask == 0) ? true : false;
	}
	static void enableInterrupts(bool doit) {
		if (doit) __enable_irq();
    69ea:	cbnz	r1, 69ee <EventResponder::runFromInterrupt()+0x1e>
    69ec:	cpsie	i
			} else {
				lastInterrupt = nullptr;
			}
			enableInterrupts(irq);
			first->_triggered = false;
    69ee:	strb	r5, [r3, #29]
			(*(first->_function))(*first);
    69f0:	mov	r0, r3
    69f2:	ldr	r3, [r3, #8]
    69f4:	blx	r3
	static EventResponder *lastInterrupt;
	static bool runningFromYield;
private:
	static bool disableInterrupts() {
		uint32_t primask;
		__asm__ volatile("mrs %0, primask\n" : "=r" (primask)::);
    69f6:	mrs	r1, PRIMASK
		__disable_irq();
    69fa:	cpsid	i

void EventResponder::runFromInterrupt()
{
	while (1) {
		bool irq = disableInterrupts();
		EventResponder *first = firstInterrupt;
    69fc:	ldr	r3, [r4, #0]
		if (first) {
    69fe:	cmp	r3, #0
    6a00:	bne.n	69e2 <EventResponder::runFromInterrupt()+0x12>
		return (primask == 0) ? true : false;
	}
	static void enableInterrupts(bool doit) {
		if (doit) __enable_irq();
    6a02:	cbnz	r1, 6a06 <EventResponder::runFromInterrupt()+0x36>
    6a04:	cpsie	i
    6a06:	pop	{r4, r5, r6, pc}
			firstInterrupt = first->_next;
			if (firstInterrupt) {
				firstInterrupt->_prev = nullptr;
			} else {
				lastInterrupt = nullptr;
    6a08:	str	r2, [r6, #0]
    6a0a:	b.n	69ea <EventResponder::runFromInterrupt()+0x1a>
    6a0c:	.word	0x20000b8c
    6a10:	.word	0x20000b90

00006a14 <pendablesrvreq_isr>:
	enableInterrupts(irq);
}

extern "C" void pendablesrvreq_isr(void)
{
	EventResponder::runFromInterrupt();
    6a14:	b.w	69d0 <EventResponder::runFromInterrupt()>

00006a18 <MillisTimer::addToActiveList()>:
	enableTimerInterrupt(irq);
}

void MillisTimer::addToActiveList() // only called by runFromTimer()
{
	if (listActive == nullptr) {
    6a18:	ldr	r2, [pc, #96]	; (6a7c <MillisTimer::addToActiveList()+0x64>)
	_state = TimerWaiting;
	enableTimerInterrupt(irq);
}

void MillisTimer::addToActiveList() // only called by runFromTimer()
{
    6a1a:	push	{r4, r5}
	if (listActive == nullptr) {
    6a1c:	ldr	r4, [r2, #0]
    6a1e:	cmp	r4, #0
    6a20:	beq.n	6a74 <MillisTimer::addToActiveList()+0x5c>
		// list is empty, easy case
		_next = nullptr;
		_prev = nullptr;
		listActive = this;
	} else if (_ms < listActive->_ms) {
    6a22:	ldr	r3, [r0, #0]
    6a24:	ldr	r1, [r4, #0]
    6a26:	cmp	r3, r1
    6a28:	bcs.n	6a4a <MillisTimer::addToActiveList()+0x32>
		// this timer triggers before any on the list
		_next = listActive;
		_prev = nullptr;
		listActive->_prev = this;
		// Decrement the next items wait time be our wait time as to properly handle waits for all other items...
		listActive->_ms -= _ms;	
    6a2a:	subs	r3, r1, r3
		_prev = nullptr;
		listActive = this;
	} else if (_ms < listActive->_ms) {
		// this timer triggers before any on the list
		_next = listActive;
		_prev = nullptr;
    6a2c:	movs	r1, #0
		_next = nullptr;
		_prev = nullptr;
		listActive = this;
	} else if (_ms < listActive->_ms) {
		// this timer triggers before any on the list
		_next = listActive;
    6a2e:	str	r4, [r0, #8]
		_prev = nullptr;
    6a30:	str	r1, [r0, #12]
		listActive->_prev = this;
		// Decrement the next items wait time be our wait time as to properly handle waits for all other items...
		listActive->_ms -= _ms;	
    6a32:	str	r3, [r4, #0]
		listActive = this;
	} else if (_ms < listActive->_ms) {
		// this timer triggers before any on the list
		_next = listActive;
		_prev = nullptr;
		listActive->_prev = this;
    6a34:	str	r0, [r4, #12]
		// Decrement the next items wait time be our wait time as to properly handle waits for all other items...
		listActive->_ms -= _ms;	
		listActive = this;
    6a36:	str	r0, [r2, #0]
		_ms -= timer->_ms;
		_next = nullptr;
		_prev = timer;
		timer->_next = this;
	}
	_state = TimerActive;
    6a38:	movs	r3, #2
}
    6a3a:	pop	{r4, r5}
		_ms -= timer->_ms;
		_next = nullptr;
		_prev = timer;
		timer->_next = this;
	}
	_state = TimerActive;
    6a3c:	strb	r3, [r0, #20]
}
    6a3e:	bx	lr
		listActive = this;
	} else {
		// add this timer somewhere after the first already on the list
		MillisTimer *timer = listActive;
		while (timer->_next) {
			_ms -= timer->_ms;
    6a40:	str	r3, [r0, #0]
    6a42:	mov	r4, r2
			timer = timer->_next;
			if (_ms < timer->_ms) {
    6a44:	ldr	r1, [r2, #0]
    6a46:	cmp	r3, r1
    6a48:	bcc.n	6a5c <MillisTimer::addToActiveList()+0x44>
		listActive->_ms -= _ms;	
		listActive = this;
	} else {
		// add this timer somewhere after the first already on the list
		MillisTimer *timer = listActive;
		while (timer->_next) {
    6a4a:	ldr	r2, [r4, #8]
				_state = TimerActive;
				return;
			}
		}
		// add this time at the end of the list
		_ms -= timer->_ms;
    6a4c:	subs	r3, r3, r1
		listActive->_ms -= _ms;	
		listActive = this;
	} else {
		// add this timer somewhere after the first already on the list
		MillisTimer *timer = listActive;
		while (timer->_next) {
    6a4e:	cmp	r2, #0
    6a50:	bne.n	6a40 <MillisTimer::addToActiveList()+0x28>
				return;
			}
		}
		// add this time at the end of the list
		_ms -= timer->_ms;
		_next = nullptr;
    6a52:	str	r2, [r0, #8]
		_prev = timer;
    6a54:	str	r4, [r0, #12]
				_state = TimerActive;
				return;
			}
		}
		// add this time at the end of the list
		_ms -= timer->_ms;
    6a56:	str	r3, [r0, #0]
		_next = nullptr;
		_prev = timer;
		timer->_next = this;
    6a58:	str	r0, [r4, #8]
    6a5a:	b.n	6a38 <MillisTimer::addToActiveList()+0x20>
			_ms -= timer->_ms;
			timer = timer->_next;
			if (_ms < timer->_ms) {
				// found the right place in the middle of list
				_next = timer;
				_prev = timer->_prev;
    6a5c:	ldr	r5, [r2, #12]
				timer->_prev = this;
				_prev->_next = this;
				timer->_ms -= _ms;
    6a5e:	subs	r3, r1, r3
		while (timer->_next) {
			_ms -= timer->_ms;
			timer = timer->_next;
			if (_ms < timer->_ms) {
				// found the right place in the middle of list
				_next = timer;
    6a60:	str	r2, [r0, #8]
				_prev = timer->_prev;
				timer->_prev = this;
				_prev->_next = this;
				timer->_ms -= _ms;
				_state = TimerActive;
    6a62:	movs	r2, #2
			_ms -= timer->_ms;
			timer = timer->_next;
			if (_ms < timer->_ms) {
				// found the right place in the middle of list
				_next = timer;
				_prev = timer->_prev;
    6a64:	str	r5, [r0, #12]
				timer->_prev = this;
    6a66:	str	r0, [r4, #12]
				_prev->_next = this;
    6a68:	ldr	r1, [r0, #12]
    6a6a:	str	r0, [r1, #8]
				timer->_ms -= _ms;
    6a6c:	str	r3, [r4, #0]
				_state = TimerActive;
    6a6e:	strb	r2, [r0, #20]
		_next = nullptr;
		_prev = timer;
		timer->_next = this;
	}
	_state = TimerActive;
}
    6a70:	pop	{r4, r5}
    6a72:	bx	lr

void MillisTimer::addToActiveList() // only called by runFromTimer()
{
	if (listActive == nullptr) {
		// list is empty, easy case
		_next = nullptr;
    6a74:	str	r4, [r0, #8]
		_prev = nullptr;
    6a76:	str	r4, [r0, #12]
		listActive = this;
    6a78:	str	r0, [r2, #0]
    6a7a:	b.n	6a38 <MillisTimer::addToActiveList()+0x20>
    6a7c:	.word	0x20000b94

00006a80 <MillisTimer::runFromTimer()>:
	}
	enableTimerInterrupt(irq);
}

void MillisTimer::runFromTimer()
{
    6a80:	push	{r3, r4, r5, r6, r7, lr}
	MillisTimer *timer = listActive;
    6a82:	ldr	r6, [pc, #136]	; (6b0c <MillisTimer::runFromTimer()+0x8c>)
    6a84:	ldr	r4, [r6, #0]
	while (timer) {
    6a86:	cbz	r4, 6ad4 <MillisTimer::runFromTimer()+0x54>
		if (timer->_ms > 0) {
    6a88:	ldr	r3, [r4, #0]
    6a8a:	cmp	r3, #0
    6a8c:	bne.n	6b04 <MillisTimer::runFromTimer()+0x84>
			timer->_ms--;
			break;
		} else {
			MillisTimer *next = timer->_next;
			if (next) next->_prev = nullptr;
    6a8e:	mov	r5, r3
    6a90:	ldr	r7, [pc, #124]	; (6b10 <MillisTimer::runFromTimer()+0x90>)
    6a92:	b.n	6a9e <MillisTimer::runFromTimer()+0x1e>
			event.triggerEvent(0, timer);
			if (timer->_reload) {
				timer->_ms = timer->_reload;
				timer->addToActiveList();
			}
			timer = listActive;
    6a94:	ldr	r4, [r6, #0]
}

void MillisTimer::runFromTimer()
{
	MillisTimer *timer = listActive;
	while (timer) {
    6a96:	cbz	r4, 6ad4 <MillisTimer::runFromTimer()+0x54>
		if (timer->_ms > 0) {
    6a98:	ldr	r3, [r4, #0]
    6a9a:	cmp	r3, #0
    6a9c:	bne.n	6b04 <MillisTimer::runFromTimer()+0x84>
			timer->_ms--;
			break;
		} else {
			MillisTimer *next = timer->_next;
    6a9e:	ldr	r3, [r4, #8]
			if (next) next->_prev = nullptr;
    6aa0:	cbz	r3, 6aa4 <MillisTimer::runFromTimer()+0x24>
    6aa2:	str	r5, [r3, #12]
			listActive = next;
			timer->_state = TimerOff;
			EventResponderRef event = *(timer->_event);
    6aa4:	ldr	r0, [r4, #16]
			timer->_ms--;
			break;
		} else {
			MillisTimer *next = timer->_next;
			if (next) next->_prev = nullptr;
			listActive = next;
    6aa6:	str	r3, [r6, #0]
			timer->_state = TimerOff;
			EventResponderRef event = *(timer->_event);
			event.triggerEvent(0, timer);
    6aa8:	ldr	r3, [r0, #0]
			break;
		} else {
			MillisTimer *next = timer->_next;
			if (next) next->_prev = nullptr;
			listActive = next;
			timer->_state = TimerOff;
    6aaa:	strb	r5, [r4, #20]
			EventResponderRef event = *(timer->_event);
			event.triggerEvent(0, timer);
    6aac:	ldr	r3, [r3, #0]
    6aae:	cmp	r3, r7
    6ab0:	bne.n	6af6 <MillisTimer::runFromTimer()+0x76>
	// The code triggering the event does NOT control which of the above
	// response methods will be used.
	virtual void triggerEvent(int status=0, void *data=nullptr) {
		_status = status;
		_data = data;
		if (_type == EventTypeImmediate) {
    6ab2:	ldrb	r3, [r0, #28]

	// Trigger the event.  An optional status code and data may be provided.
	// The code triggering the event does NOT control which of the above
	// response methods will be used.
	virtual void triggerEvent(int status=0, void *data=nullptr) {
		_status = status;
    6ab4:	str	r5, [r0, #4]
		_data = data;
		if (_type == EventTypeImmediate) {
    6ab6:	cmp	r3, #2
	// Trigger the event.  An optional status code and data may be provided.
	// The code triggering the event does NOT control which of the above
	// response methods will be used.
	virtual void triggerEvent(int status=0, void *data=nullptr) {
		_status = status;
		_data = data;
    6ab8:	str	r4, [r0, #12]
		if (_type == EventTypeImmediate) {
    6aba:	beq.n	6afe <MillisTimer::runFromTimer()+0x7e>
			(*_function)(*this);
		} else {
			triggerEventNotImmediate();
    6abc:	bl	6934 <EventResponder::triggerEventNotImmediate()>
			if (timer->_reload) {
    6ac0:	ldr	r3, [r4, #4]
    6ac2:	cmp	r3, #0
    6ac4:	beq.n	6a94 <MillisTimer::runFromTimer()+0x14>
				timer->_ms = timer->_reload;
    6ac6:	str	r3, [r4, #0]
				timer->addToActiveList();
    6ac8:	mov	r0, r4
    6aca:	bl	6a18 <MillisTimer::addToActiveList()>
			}
			timer = listActive;
    6ace:	ldr	r4, [r6, #0]
}

void MillisTimer::runFromTimer()
{
	MillisTimer *timer = listActive;
	while (timer) {
    6ad0:	cmp	r4, #0
    6ad2:	bne.n	6a98 <MillisTimer::runFromTimer()+0x18>
	volatile TimerStateType _state = TimerOff;
	static MillisTimer *listWaiting; // single linked list of waiting to start timers
	static MillisTimer *listActive;  // double linked list of running timers
	static bool disableTimerInterrupt() {
		uint32_t primask;
		__asm__ volatile("mrs %0, primask\n" : "=r" (primask)::);
    6ad4:	mrs	r3, PRIMASK
		__disable_irq();
    6ad8:	cpsid	i
			}
			timer = listActive;
		}
	}
	bool irq = disableTimerInterrupt();
	MillisTimer *waiting = listWaiting;
    6ada:	ldr	r2, [pc, #56]	; (6b14 <MillisTimer::runFromTimer()+0x94>)
	listWaiting = nullptr; // TODO: use STREX to avoid interrupt disable
    6adc:	movs	r1, #0
			}
			timer = listActive;
		}
	}
	bool irq = disableTimerInterrupt();
	MillisTimer *waiting = listWaiting;
    6ade:	ldr	r0, [r2, #0]
	listWaiting = nullptr; // TODO: use STREX to avoid interrupt disable
    6ae0:	str	r1, [r2, #0]
		return (primask == 0) ? true : false;
	}
	static void enableTimerInterrupt(bool doit) {
		if (doit) __enable_irq();
    6ae2:	cbnz	r3, 6ae6 <MillisTimer::runFromTimer()+0x66>
    6ae4:	cpsie	i
	enableTimerInterrupt(irq);
	while (waiting) {
    6ae6:	cbz	r0, 6af4 <MillisTimer::runFromTimer()+0x74>
		MillisTimer *next = waiting->_next;
    6ae8:	ldr	r4, [r0, #8]
		waiting->addToActiveList();
    6aea:	bl	6a18 <MillisTimer::addToActiveList()>
	}
	bool irq = disableTimerInterrupt();
	MillisTimer *waiting = listWaiting;
	listWaiting = nullptr; // TODO: use STREX to avoid interrupt disable
	enableTimerInterrupt(irq);
	while (waiting) {
    6aee:	mov	r0, r4
    6af0:	cmp	r0, #0
    6af2:	bne.n	6ae8 <MillisTimer::runFromTimer()+0x68>
    6af4:	pop	{r3, r4, r5, r6, r7, pc}
			MillisTimer *next = timer->_next;
			if (next) next->_prev = nullptr;
			listActive = next;
			timer->_state = TimerOff;
			EventResponderRef event = *(timer->_event);
			event.triggerEvent(0, timer);
    6af6:	mov	r2, r4
    6af8:	movs	r1, #0
    6afa:	blx	r3
    6afc:	b.n	6ac0 <MillisTimer::runFromTimer()+0x40>
	// response methods will be used.
	virtual void triggerEvent(int status=0, void *data=nullptr) {
		_status = status;
		_data = data;
		if (_type == EventTypeImmediate) {
			(*_function)(*this);
    6afe:	ldr	r3, [r0, #8]
    6b00:	blx	r3
    6b02:	b.n	6ac0 <MillisTimer::runFromTimer()+0x40>
void MillisTimer::runFromTimer()
{
	MillisTimer *timer = listActive;
	while (timer) {
		if (timer->_ms > 0) {
			timer->_ms--;
    6b04:	subs	r3, #1
    6b06:	str	r3, [r4, #0]
			break;
    6b08:	b.n	6ad4 <MillisTimer::runFromTimer()+0x54>
    6b0a:	nop
    6b0c:	.word	0x20000b94
    6b10:	.word	0x000069b5
    6b14:	.word	0x20000ba4

00006b18 <systick_isr>:
extern "C" volatile uint32_t systick_millis_count;
extern "C" volatile uint32_t systick_cycle_count;
extern "C" uint32_t systick_safe_read; // micros() synchronization
extern "C" void systick_isr(void)
{
	systick_cycle_count = ARM_DWT_CYCCNT;
    6b18:	ldr	r2, [pc, #16]	; (6b2c <systick_isr+0x14>)
    6b1a:	ldr	r3, [pc, #20]	; (6b30 <systick_isr+0x18>)
    6b1c:	ldr	r1, [r2, #0]
	systick_millis_count++;
    6b1e:	ldr	r2, [pc, #20]	; (6b34 <systick_isr+0x1c>)
extern "C" volatile uint32_t systick_millis_count;
extern "C" volatile uint32_t systick_cycle_count;
extern "C" uint32_t systick_safe_read; // micros() synchronization
extern "C" void systick_isr(void)
{
	systick_cycle_count = ARM_DWT_CYCCNT;
    6b20:	str	r1, [r3, #0]
	systick_millis_count++;
    6b22:	ldr	r3, [r2, #0]
    6b24:	adds	r3, #1
    6b26:	str	r3, [r2, #0]
	MillisTimer::runFromTimer();
    6b28:	b.w	6a80 <MillisTimer::runFromTimer()>
    6b2c:	.word	0xe0001004
    6b30:	.word	0x20000b7c
    6b34:	.word	0x20000b84

00006b38 <usb_serial_class::clear()>:
        virtual int read() { return usb_serial_getchar(); }
        virtual int peek() { return usb_serial_peekchar(); }
        virtual void flush() { usb_serial_flush_output(); }  // TODO: actually wait for data to leave USB...
        virtual void clear(void) { usb_serial_flush_input(); }
    6b38:	b.w	59c8 <usb_serial_flush_input>

00006b3c <usb_serial_class::peek()>:
		//}
	}
        void end() { /* TODO: flush output and shut down USB port */ };
        virtual int available() { return usb_serial_available(); }
        virtual int read() { return usb_serial_getchar(); }
        virtual int peek() { return usb_serial_peekchar(); }
    6b3c:	b.w	5978 <usb_serial_peekchar>

00006b40 <usb_serial_class::read()>:
			//if ((uint32_t)(systick_millis_count - millis_begin) > 2500) break;
		//}
	}
        void end() { /* TODO: flush output and shut down USB port */ };
        virtual int available() { return usb_serial_available(); }
        virtual int read() { return usb_serial_getchar(); }
    6b40:	b.w	5a3c <usb_serial_getchar>

00006b44 <usb_serial_class::available()>:
			// sketch still gets to run normally after this wait time.
			//if ((uint32_t)(systick_millis_count - millis_begin) > 2500) break;
		//}
	}
        void end() { /* TODO: flush output and shut down USB port */ };
        virtual int available() { return usb_serial_available(); }
    6b44:	b.w	59bc <usb_serial_available>

00006b48 <usb_serial_class::flush()>:
        virtual int read() { return usb_serial_getchar(); }
        virtual int peek() { return usb_serial_peekchar(); }
        virtual void flush() { usb_serial_flush_output(); }  // TODO: actually wait for data to leave USB...
    6b48:	b.w	5aec <usb_serial_flush_output>

00006b4c <usb_serial_class::availableForWrite()>:
        virtual size_t write(const uint8_t *buffer, size_t size) { return usb_serial_write(buffer, size); }
	size_t write(unsigned long n) { return write((uint8_t)n); }
	size_t write(long n) { return write((uint8_t)n); }
	size_t write(unsigned int n) { return write((uint8_t)n); }
	size_t write(int n) { return write((uint8_t)n); }
	virtual int availableForWrite() { return usb_serial_write_buffer_free(); }
    6b4c:	b.w	5aa0 <usb_serial_write_buffer_free>

00006b50 <usb_serial_class::write(unsigned char const*, unsigned int)>:
        virtual int read() { return usb_serial_getchar(); }
        virtual int peek() { return usb_serial_peekchar(); }
        virtual void flush() { usb_serial_flush_output(); }  // TODO: actually wait for data to leave USB...
        virtual void clear(void) { usb_serial_flush_input(); }
        virtual size_t write(uint8_t c) { return usb_serial_putchar(c); }
        virtual size_t write(const uint8_t *buffer, size_t size) { return usb_serial_write(buffer, size); }
    6b50:	mov	r0, r1
    6b52:	mov	r1, r2
    6b54:	b.w	5a88 <usb_serial_write>

00006b58 <usb_serial_class::write(unsigned char)>:
        virtual int available() { return usb_serial_available(); }
        virtual int read() { return usb_serial_getchar(); }
        virtual int peek() { return usb_serial_peekchar(); }
        virtual void flush() { usb_serial_flush_output(); }  // TODO: actually wait for data to leave USB...
        virtual void clear(void) { usb_serial_flush_input(); }
        virtual size_t write(uint8_t c) { return usb_serial_putchar(c); }
    6b58:	mov	r0, r1
    6b5a:	b.w	5a5c <usb_serial_putchar>
    6b5e:	nop

00006b60 <serialEvent()>:
#endif

#endif // F_CPU
uint8_t usb_enable_serial_event_processing = 1;
void serialEvent() __attribute__((weak));
void serialEvent() {usb_enable_serial_event_processing = 0;}
    6b60:	ldr	r3, [pc, #4]	; (6b68 <serialEvent()+0x8>)
    6b62:	movs	r2, #0
    6b64:	strb	r2, [r3, #0]
    6b66:	bx	lr
    6b68:	.word	0x200000e2

00006b6c <Print::println()>:
	return printNumber(n, 10, sign);
}


size_t Print::println(void)
{
    6b6c:	push	{r4, lr}
	uint8_t buf[2]={'\r', '\n'};
    6b6e:	ldr	r4, [pc, #24]	; (6b88 <Print::println()+0x1c>)
	return printNumber(n, 10, sign);
}


size_t Print::println(void)
{
    6b70:	sub	sp, #8
	uint8_t buf[2]={'\r', '\n'};
	return write(buf, 2);
    6b72:	ldr	r3, [r0, #0]
    6b74:	movs	r2, #2
}


size_t Print::println(void)
{
	uint8_t buf[2]={'\r', '\n'};
    6b76:	ldrh	r4, [r4, #0]
	return write(buf, 2);
    6b78:	add	r1, sp, #4
    6b7a:	ldr	r3, [r3, #4]
}


size_t Print::println(void)
{
	uint8_t buf[2]={'\r', '\n'};
    6b7c:	strh.w	r4, [sp, #4]
	return write(buf, 2);
    6b80:	blx	r3
}
    6b82:	add	sp, #8
    6b84:	pop	{r4, pc}
    6b86:	nop
    6b88:	.word	0x200000a8

00006b8c <Print::printNumber(unsigned long, unsigned char, unsigned char)>:
	return vdprintf((int)this, (const char *)format, ap);
#endif
}

size_t Print::printNumber(unsigned long n, uint8_t base, uint8_t sign)
{
    6b8c:	push	{r4, r5, r6, r7, lr}
    6b8e:	mov	r6, r0
    6b90:	sub	sp, #44	; 0x2c
	uint8_t digit, i;

	// TODO: make these checks as inline, since base is
	// almost always a constant.  base = 0 (BYTE) should
	// inline as a call directly to write()
	if (base == 0) {
    6b92:	cmp	r2, #0
    6b94:	beq.n	6bfe <Print::printNumber(unsigned long, unsigned char, unsigned char)+0x72>
		return write((uint8_t)n);
	} else if (base == 1) {
		base = 10;
    6b96:	cmp	r2, #1
    6b98:	it	eq
    6b9a:	moveq	r2, #10
	}


	if (n == 0) {
    6b9c:	cbz	r1, 6bf4 <Print::printNumber(unsigned long, unsigned char, unsigned char)+0x68>
    6b9e:	movs	r5, #33	; 0x21
    6ba0:	b.n	6ba4 <Print::printNumber(unsigned long, unsigned char, unsigned char)+0x18>
		while (1) {
			digit = n % base;
			buf[i] = ((digit < 10) ? '0' + digit : 'A' + digit - 10);
			n /= base;
			if (n == 0) break;
			i--;
    6ba2:	uxtb	r5, r7
    6ba4:	subs	r7, r5, #1
		buf[sizeof(buf) - 1] = '0';
		i = sizeof(buf) - 1;
	} else {
		i = sizeof(buf) - 1;
		while (1) {
			digit = n % base;
    6ba6:	udiv	r4, r1, r2
    6baa:	mls	r1, r2, r4, r1
    6bae:	uxtb	r0, r1
			buf[i] = ((digit < 10) ? '0' + digit : 'A' + digit - 10);
    6bb0:	cmp	r1, #9
    6bb2:	add.w	r1, r0, #55	; 0x37
    6bb6:	add.w	r0, r0, #48	; 0x30
    6bba:	it	hi
    6bbc:	uxtbhi	r0, r1
			n /= base;
			if (n == 0) break;
    6bbe:	mov	r1, r4
		i = sizeof(buf) - 1;
	} else {
		i = sizeof(buf) - 1;
		while (1) {
			digit = n % base;
			buf[i] = ((digit < 10) ? '0' + digit : 'A' + digit - 10);
    6bc0:	add	r4, sp, #40	; 0x28
    6bc2:	it	ls
    6bc4:	uxtbls	r0, r0
    6bc6:	add	r4, r5
    6bc8:	strb.w	r0, [r4, #-36]
			n /= base;
			if (n == 0) break;
    6bcc:	cmp	r1, #0
    6bce:	bne.n	6ba2 <Print::printNumber(unsigned long, unsigned char, unsigned char)+0x16>
			i--;
		}
	}
	if (sign) {
    6bd0:	cbz	r3, 6be0 <Print::printNumber(unsigned long, unsigned char, unsigned char)+0x54>
		i--;
    6bd2:	subs	r5, #1
		buf[i] = '-';
    6bd4:	add	r3, sp, #40	; 0x28
    6bd6:	movs	r2, #45	; 0x2d
			if (n == 0) break;
			i--;
		}
	}
	if (sign) {
		i--;
    6bd8:	uxtb	r5, r5
		buf[i] = '-';
    6bda:	add	r3, r5
    6bdc:	strb.w	r2, [r3, #-36]
	}
	return write(buf + i, sizeof(buf) - i);
    6be0:	ldr	r3, [r6, #0]
    6be2:	add	r1, sp, #4
    6be4:	rsb	r2, r5, #34	; 0x22
    6be8:	mov	r0, r6
    6bea:	add	r1, r5
    6bec:	ldr	r3, [r3, #4]
    6bee:	blx	r3
}
    6bf0:	add	sp, #44	; 0x2c
    6bf2:	pop	{r4, r5, r6, r7, pc}
		base = 10;
	}


	if (n == 0) {
		buf[sizeof(buf) - 1] = '0';
    6bf4:	movs	r2, #48	; 0x30
		i = sizeof(buf) - 1;
    6bf6:	movs	r5, #33	; 0x21
		base = 10;
	}


	if (n == 0) {
		buf[sizeof(buf) - 1] = '0';
    6bf8:	strb.w	r2, [sp, #37]	; 0x25
    6bfc:	b.n	6bd0 <Print::printNumber(unsigned long, unsigned char, unsigned char)+0x44>

	// TODO: make these checks as inline, since base is
	// almost always a constant.  base = 0 (BYTE) should
	// inline as a call directly to write()
	if (base == 0) {
		return write((uint8_t)n);
    6bfe:	ldr	r3, [r0, #0]
    6c00:	uxtb	r1, r1
    6c02:	ldr	r3, [r3, #0]
    6c04:	blx	r3
	if (sign) {
		i--;
		buf[i] = '-';
	}
	return write(buf + i, sizeof(buf) - i);
}
    6c06:	add	sp, #44	; 0x2c
    6c08:	pop	{r4, r5, r6, r7, pc}
    6c0a:	nop

00006c0c <Print::print(long)>:

size_t Print::print(long n)
{
	uint8_t sign=0;

	if (n < 0) {
    6c0c:	cmp	r1, #0
    6c0e:	blt.n	6c18 <Print::print(long)+0xc>
}


size_t Print::print(long n)
{
	uint8_t sign=0;
    6c10:	movs	r3, #0

	if (n < 0) {
		sign = '-';
		n = -n;
	}
	return printNumber(n, 10, sign);
    6c12:	movs	r2, #10
    6c14:	b.w	6b8c <Print::printNumber(unsigned long, unsigned char, unsigned char)>
{
	uint8_t sign=0;

	if (n < 0) {
		sign = '-';
		n = -n;
    6c18:	negs	r1, r1
size_t Print::print(long n)
{
	uint8_t sign=0;

	if (n < 0) {
		sign = '-';
    6c1a:	movs	r3, #45	; 0x2d
		n = -n;
	}
	return printNumber(n, 10, sign);
    6c1c:	movs	r2, #10
    6c1e:	b.w	6b8c <Print::printNumber(unsigned long, unsigned char, unsigned char)>
    6c22:	nop
    6c24:	movs	r0, r0
	...

00006c28 <Print::printFloat(double, unsigned char)>:
size_t Print::printFloat(double number, uint8_t digits) 
{
	uint8_t sign=0;
	size_t count=0;

	if (isnan(number)) return print("nan");
    6c28:	vcmp.f64	d0, d0
	}
	return write(buf + i, sizeof(buf) - i);
}

size_t Print::printFloat(double number, uint8_t digits) 
{
    6c2c:	push	{r4, r5, r6, lr}
	uint8_t sign=0;
	size_t count=0;

	if (isnan(number)) return print("nan");
    6c2e:	vmrs	APSR_nzcv, fpscr
	}
	return write(buf + i, sizeof(buf) - i);
}

size_t Print::printFloat(double number, uint8_t digits) 
{
    6c32:	mov	r5, r0
    6c34:	vpush	{d8}
    6c38:	sub	sp, #24
	uint8_t sign=0;
	size_t count=0;

	if (isnan(number)) return print("nan");
    6c3a:	bvs.w	6d60 <Print::printFloat(double, unsigned char)+0x138>
    	if (isinf(number)) return print("inf");
    6c3e:	vabs.f64	d7, d0
    6c42:	vldr	d6, [pc, #300]	; 6d70 <Print::printFloat(double, unsigned char)+0x148>
    6c46:	vcmp.f64	d7, d6
    6c4a:	vmrs	APSR_nzcv, fpscr
    6c4e:	ble.n	6c66 <Print::printFloat(double, unsigned char)+0x3e>
class Print
{
  public:
	constexpr Print() : write_error(0) {}
	virtual size_t write(uint8_t b) = 0;
	size_t write(const char *str)			{ return write((const uint8_t *)str, strlen(str)); }
    6c50:	ldr	r3, [r0, #0]
    6c52:	movs	r2, #3
    6c54:	ldr	r1, [pc, #312]	; (6d90 <Print::printFloat(double, unsigned char)+0x168>)
    6c56:	ldr	r3, [r3, #4]
    6c58:	blx	r3
    6c5a:	mov	r6, r0
			remainder -= n; 
		}
		count += write(buf, count);
	}
	return count;
}
    6c5c:	mov	r0, r6
    6c5e:	add	sp, #24
    6c60:	vpop	{d8}
    6c64:	pop	{r4, r5, r6, pc}
	uint8_t sign=0;
	size_t count=0;

	if (isnan(number)) return print("nan");
    	if (isinf(number)) return print("inf");
    	if (number > 4294967040.0f) return print("ovf");  // constant determined empirically
    6c66:	vldr	d7, [pc, #272]	; 6d78 <Print::printFloat(double, unsigned char)+0x150>
    6c6a:	vcmpe.f64	d0, d7
    6c6e:	vmrs	APSR_nzcv, fpscr
    6c72:	bgt.n	6d26 <Print::printFloat(double, unsigned char)+0xfe>
    	if (number <-4294967040.0f) return print("ovf");  // constant determined empirically
    6c74:	vldr	d7, [pc, #264]	; 6d80 <Print::printFloat(double, unsigned char)+0x158>
    6c78:	vcmpe.f64	d0, d7
    6c7c:	vmrs	APSR_nzcv, fpscr
    6c80:	bmi.n	6d26 <Print::printFloat(double, unsigned char)+0xfe>
	
	// Handle negative numbers
	if (number < 0.0) {
    6c82:	vcmpe.f64	d0, #0.0
    6c86:	mov	r4, r1
    6c88:	vmrs	APSR_nzcv, fpscr
    6c8c:	bmi.n	6d3c <Print::printFloat(double, unsigned char)+0x114>
	return write(buf + i, sizeof(buf) - i);
}

size_t Print::printFloat(double number, uint8_t digits) 
{
	uint8_t sign=0;
    6c8e:	movs	r3, #0
		number = -number;
	}

	// Round correctly so that print(1.999, 2) prints as "2.00"
	double rounding = 0.5;
	for (uint8_t i=0; i<digits; ++i) {
    6c90:	cmp	r4, #0
    6c92:	beq.n	6d44 <Print::printFloat(double, unsigned char)+0x11c>
    6c94:	vmov.f64	d8, #96	; 0x3f000000  0.5
    6c98:	movs	r2, #0
		rounding *= 0.1;
    6c9a:	vldr	d7, [pc, #236]	; 6d88 <Print::printFloat(double, unsigned char)+0x160>
    6c9e:	adds	r2, #1
    6ca0:	vmul.f64	d8, d8, d7
		number = -number;
	}

	// Round correctly so that print(1.999, 2) prints as "2.00"
	double rounding = 0.5;
	for (uint8_t i=0; i<digits; ++i) {
    6ca4:	uxtb	r1, r2
    6ca6:	cmp	r4, r1
    6ca8:	bhi.n	6c9e <Print::printFloat(double, unsigned char)+0x76>
		rounding *= 0.1;
	}
	number += rounding;
    6caa:	vadd.f64	d0, d0, d8

	// Extract the integer part of the number and print it
	unsigned long int_part = (unsigned long)number;
	double remainder = number - (double)int_part;
	count += printNumber(int_part, 10, sign);
    6cae:	movs	r2, #10
    6cb0:	mov	r0, r5
		rounding *= 0.1;
	}
	number += rounding;

	// Extract the integer part of the number and print it
	unsigned long int_part = (unsigned long)number;
    6cb2:	vcvt.u32.f64	s15, d0
	double remainder = number - (double)int_part;
    6cb6:	vcvt.f64.u32	d8, s15
	count += printNumber(int_part, 10, sign);
    6cba:	vmov	r1, s15
	}
	number += rounding;

	// Extract the integer part of the number and print it
	unsigned long int_part = (unsigned long)number;
	double remainder = number - (double)int_part;
    6cbe:	vsub.f64	d8, d0, d8
	count += printNumber(int_part, 10, sign);
    6cc2:	bl	6b8c <Print::printNumber(unsigned long, unsigned char, unsigned char)>
    6cc6:	cmp	r4, #15

	// Print the decimal point, but only if there are digits beyond
	if (digits > 0) {
		uint8_t n, buf[16], count=1;
		buf[0] = '.';
    6cc8:	mov.w	r2, #1

		// Extract digits from the remainder one at a time
		if (digits > sizeof(buf) - 1) digits = sizeof(buf) - 1;

		while (digits-- > 0) {
			remainder *= 10.0;
    6ccc:	vmov.f64	d7, #36	; 0x41200000  10.0
	count += printNumber(int_part, 10, sign);

	// Print the decimal point, but only if there are digits beyond
	if (digits > 0) {
		uint8_t n, buf[16], count=1;
		buf[0] = '.';
    6cd0:	mov.w	r3, #46	; 0x2e
    6cd4:	it	cs
    6cd6:	movcs	r4, #15
	number += rounding;

	// Extract the integer part of the number and print it
	unsigned long int_part = (unsigned long)number;
	double remainder = number - (double)int_part;
	count += printNumber(int_part, 10, sign);
    6cd8:	mov	r6, r0

	// Print the decimal point, but only if there are digits beyond
	if (digits > 0) {
		uint8_t n, buf[16], count=1;
		buf[0] = '.';
    6cda:	strb.w	r3, [sp, #8]
    6cde:	add	r4, r2
    6ce0:	uxtb	r4, r4

		// Extract digits from the remainder one at a time
		if (digits > sizeof(buf) - 1) digits = sizeof(buf) - 1;

		while (digits-- > 0) {
			remainder *= 10.0;
    6ce2:	vmul.f64	d0, d8, d7
			n = (uint8_t)(remainder);
			buf[count++] = '0' + n;
    6ce6:	adds	r3, r2, #1
    6ce8:	add	r1, sp, #24
    6cea:	add	r1, r2
    6cec:	uxtb	r2, r3
		buf[0] = '.';

		// Extract digits from the remainder one at a time
		if (digits > sizeof(buf) - 1) digits = sizeof(buf) - 1;

		while (digits-- > 0) {
    6cee:	cmp	r2, r4
			remainder *= 10.0;
			n = (uint8_t)(remainder);
    6cf0:	vcvt.u32.f64	s13, d0
    6cf4:	vstr	s13, [sp, #4]
    6cf8:	ldrb.w	r3, [sp, #4]
			buf[count++] = '0' + n;
			remainder -= n; 
    6cfc:	vmov	s13, r3
		if (digits > sizeof(buf) - 1) digits = sizeof(buf) - 1;

		while (digits-- > 0) {
			remainder *= 10.0;
			n = (uint8_t)(remainder);
			buf[count++] = '0' + n;
    6d00:	add.w	r3, r3, #48	; 0x30
			remainder -= n; 
    6d04:	vcvt.f64.s32	d8, s13
		if (digits > sizeof(buf) - 1) digits = sizeof(buf) - 1;

		while (digits-- > 0) {
			remainder *= 10.0;
			n = (uint8_t)(remainder);
			buf[count++] = '0' + n;
    6d08:	strb.w	r3, [r1, #-16]
			remainder -= n; 
    6d0c:	vsub.f64	d8, d0, d8
		buf[0] = '.';

		// Extract digits from the remainder one at a time
		if (digits > sizeof(buf) - 1) digits = sizeof(buf) - 1;

		while (digits-- > 0) {
    6d10:	bne.n	6ce2 <Print::printFloat(double, unsigned char)+0xba>
			remainder *= 10.0;
			n = (uint8_t)(remainder);
			buf[count++] = '0' + n;
			remainder -= n; 
		}
		count += write(buf, count);
    6d12:	ldr	r3, [r5, #0]
    6d14:	mov	r0, r5
    6d16:	add	r1, sp, #8
    6d18:	ldr	r3, [r3, #4]
    6d1a:	blx	r3
	}
	return count;
}
    6d1c:	mov	r0, r6
    6d1e:	add	sp, #24
    6d20:	vpop	{d8}
    6d24:	pop	{r4, r5, r6, pc}
    6d26:	ldr	r3, [r5, #0]
    6d28:	movs	r2, #3
    6d2a:	ldr	r1, [pc, #104]	; (6d94 <Print::printFloat(double, unsigned char)+0x16c>)
    6d2c:	ldr	r3, [r3, #4]
    6d2e:	blx	r3
    6d30:	mov	r6, r0
    6d32:	mov	r0, r6
    6d34:	add	sp, #24
    6d36:	vpop	{d8}
    6d3a:	pop	{r4, r5, r6, pc}
    	if (number <-4294967040.0f) return print("ovf");  // constant determined empirically
	
	// Handle negative numbers
	if (number < 0.0) {
		sign = 1;
		number = -number;
    6d3c:	vneg.f64	d0, d0
    	if (number > 4294967040.0f) return print("ovf");  // constant determined empirically
    	if (number <-4294967040.0f) return print("ovf");  // constant determined empirically
	
	// Handle negative numbers
	if (number < 0.0) {
		sign = 1;
    6d40:	movs	r3, #1
    6d42:	b.n	6c90 <Print::printFloat(double, unsigned char)+0x68>
	number += rounding;

	// Extract the integer part of the number and print it
	unsigned long int_part = (unsigned long)number;
	double remainder = number - (double)int_part;
	count += printNumber(int_part, 10, sign);
    6d44:	vmov.f64	d7, #96	; 0x3f000000  0.5
    6d48:	mov	r0, r5
    6d4a:	movs	r2, #10
    6d4c:	vadd.f64	d0, d0, d7
    6d50:	vcvt.u32.f64	s15, d0
    6d54:	vmov	r1, s15
    6d58:	bl	6b8c <Print::printNumber(unsigned long, unsigned char, unsigned char)>
    6d5c:	mov	r6, r0
    6d5e:	b.n	6c5c <Print::printFloat(double, unsigned char)+0x34>
    6d60:	ldr	r3, [r0, #0]
    6d62:	movs	r2, #3
    6d64:	ldr	r1, [pc, #48]	; (6d98 <Print::printFloat(double, unsigned char)+0x170>)
    6d66:	ldr	r3, [r3, #4]
    6d68:	blx	r3
    6d6a:	mov	r6, r0
size_t Print::printFloat(double number, uint8_t digits) 
{
	uint8_t sign=0;
	size_t count=0;

	if (isnan(number)) return print("nan");
    6d6c:	b.n	6c5c <Print::printFloat(double, unsigned char)+0x34>
    6d6e:	nop
    6d70:	.word	0xffffffff
    6d74:	.word	0x7fefffff
    6d78:	.word	0xe0000000
    6d7c:	.word	0x41efffff
    6d80:	.word	0xe0000000
    6d84:	.word	0xc1efffff
    6d88:	.word	0x9999999a
    6d8c:	.word	0x3fb99999
    6d90:	.word	0x200000b4
    6d94:	.word	0x200000b0
    6d98:	.word	0x200000ac

00006d9c <operator new(unsigned int)>:
    6d9c:	b.w	7238 <malloc>

00006da0 <unused_interrupt_vector>:
//  R0
// Code from :: https://community.nxp.com/thread/389002
__attribute__((naked))
void unused_interrupt_vector(void)
{
  __asm( ".syntax unified\n"
    6da0:	movs	r0, #4
    6da2:	mov	r1, lr
    6da4:	tst	r0, r1
    6da6:	beq.n	6db0 <_MSP>
    6da8:	mrs	r0, PSP
    6dac:	b.w	6dc0 <HardFault_HandlerC>

00006db0 <_MSP>:
    6db0:	mrs	r0, MSP
    6db4:	b.w	6dc0 <HardFault_HandlerC>

00006db8 <startup_default_early_hook>:
         "B HardFault_HandlerC \n"
         "_MSP: \n"
         "MRS R0, MSP \n"
         "B HardFault_HandlerC \n"
         ".syntax divided\n") ;
}
    6db8:	bx	lr
    6dba:	nop

00006dbc <startup_default_late_hook>:


extern int main (void);
void startup_default_early_hook(void) {}
void startup_early_hook(void)		__attribute__ ((weak, alias("startup_default_early_hook")));
void startup_default_late_hook(void) {}
    6dbc:	bx	lr
    6dbe:	nop

00006dc0 <HardFault_HandlerC>:
  printf(" _MMAR ::  %x\n", _MMAR);
#endif

  IOMUXC_SW_MUX_CTL_PAD_GPIO_B0_03 = 5; // pin 13
  IOMUXC_SW_PAD_CTL_PAD_GPIO_B0_03 = IOMUXC_PAD_DSE(7);
  GPIO2_GDIR |= (1 << 3);
    6dc0:	ldr	r3, [pc, #108]	; (6e30 <HardFault_HandlerC+0x70>)
  printf(" _AFSR ::  %x\n", _AFSR);
  printf(" _BFAR ::  %x\n", _BFAR);
  printf(" _MMAR ::  %x\n", _MMAR);
#endif

  IOMUXC_SW_MUX_CTL_PAD_GPIO_B0_03 = 5; // pin 13
    6dc2:	movs	r1, #5
    6dc4:	ldr	r2, [pc, #108]	; (6e34 <HardFault_HandlerC+0x74>)
  IOMUXC_SW_PAD_CTL_PAD_GPIO_B0_03 = IOMUXC_PAD_DSE(7);
    6dc6:	movs	r0, #56	; 0x38
         ".syntax divided\n") ;
}

__attribute__((weak))
void HardFault_HandlerC(unsigned int *hardfault_args)
{
    6dc8:	push	{r4, r5, lr}
  printf(" _AFSR ::  %x\n", _AFSR);
  printf(" _BFAR ::  %x\n", _BFAR);
  printf(" _MMAR ::  %x\n", _MMAR);
#endif

  IOMUXC_SW_MUX_CTL_PAD_GPIO_B0_03 = 5; // pin 13
    6dca:	str.w	r1, [r2, #328]	; 0x148
  IOMUXC_SW_PAD_CTL_PAD_GPIO_B0_03 = IOMUXC_PAD_DSE(7);
  GPIO2_GDIR |= (1 << 3);
  GPIO2_DR_SET = (1 << 3);
    6dce:	movs	r1, #8
  printf(" _BFAR ::  %x\n", _BFAR);
  printf(" _MMAR ::  %x\n", _MMAR);
#endif

  IOMUXC_SW_MUX_CTL_PAD_GPIO_B0_03 = 5; // pin 13
  IOMUXC_SW_PAD_CTL_PAD_GPIO_B0_03 = IOMUXC_PAD_DSE(7);
    6dd0:	str.w	r0, [r2, #824]	; 0x338
         ".syntax divided\n") ;
}

__attribute__((weak))
void HardFault_HandlerC(unsigned int *hardfault_args)
{
    6dd4:	sub	sp, #12
  printf(" _MMAR ::  %x\n", _MMAR);
#endif

  IOMUXC_SW_MUX_CTL_PAD_GPIO_B0_03 = 5; // pin 13
  IOMUXC_SW_PAD_CTL_PAD_GPIO_B0_03 = IOMUXC_PAD_DSE(7);
  GPIO2_GDIR |= (1 << 3);
    6dd6:	ldr	r2, [r3, #4]
  GPIO2_DR_SET = (1 << 3);
  GPIO2_DR_CLEAR = (1 << 3); //digitalWrite(13, LOW);

  if ( F_CPU_ACTUAL >= 600000000 )
    6dd8:	ldr	r4, [pc, #92]	; (6e38 <HardFault_HandlerC+0x78>)
  printf(" _MMAR ::  %x\n", _MMAR);
#endif

  IOMUXC_SW_MUX_CTL_PAD_GPIO_B0_03 = 5; // pin 13
  IOMUXC_SW_PAD_CTL_PAD_GPIO_B0_03 = IOMUXC_PAD_DSE(7);
  GPIO2_GDIR |= (1 << 3);
    6dda:	orrs	r2, r1
  GPIO2_DR_SET = (1 << 3);
  GPIO2_DR_CLEAR = (1 << 3); //digitalWrite(13, LOW);

  if ( F_CPU_ACTUAL >= 600000000 )
    6ddc:	ldr	r0, [pc, #92]	; (6e3c <HardFault_HandlerC+0x7c>)
  printf(" _MMAR ::  %x\n", _MMAR);
#endif

  IOMUXC_SW_MUX_CTL_PAD_GPIO_B0_03 = 5; // pin 13
  IOMUXC_SW_PAD_CTL_PAD_GPIO_B0_03 = IOMUXC_PAD_DSE(7);
  GPIO2_GDIR |= (1 << 3);
    6dde:	str	r2, [r3, #4]
  GPIO2_DR_SET = (1 << 3);
    6de0:	str.w	r1, [r3, #132]	; 0x84
  GPIO2_DR_CLEAR = (1 << 3); //digitalWrite(13, LOW);
    6de4:	str.w	r1, [r3, #136]	; 0x88

  if ( F_CPU_ACTUAL >= 600000000 )
    6de8:	ldr	r3, [r4, #0]
    6dea:	cmp	r3, r0
    6dec:	bls.n	6df4 <HardFault_HandlerC+0x34>
    set_arm_clock(300000000);
    6dee:	ldr	r0, [pc, #80]	; (6e40 <HardFault_HandlerC+0x80>)
    6df0:	bl	6e7c <set_arm_clock>

  while (1)
  {
    GPIO2_DR_SET = (1 << 3); //digitalWrite(13, HIGH);
    6df4:	ldr	r5, [pc, #56]	; (6e30 <HardFault_HandlerC+0x70>)
    6df6:	movs	r4, #8
    // digitalWrite(13, HIGH);
    for (nn = 0; nn < 2000000/2; nn++) ;
    6df8:	movs	r0, #0
    6dfa:	ldr	r2, [pc, #72]	; (6e44 <HardFault_HandlerC+0x84>)
    GPIO2_DR_CLEAR = (1 << 3); //digitalWrite(13, LOW);
    // digitalWrite(13, LOW);
    for (nn = 0; nn < 18000000/2; nn++) ;
    6dfc:	ldr	r1, [pc, #72]	; (6e48 <HardFault_HandlerC+0x88>)
  if ( F_CPU_ACTUAL >= 600000000 )
    set_arm_clock(300000000);

  while (1)
  {
    GPIO2_DR_SET = (1 << 3); //digitalWrite(13, HIGH);
    6dfe:	str.w	r4, [r5, #132]	; 0x84
    // digitalWrite(13, HIGH);
    for (nn = 0; nn < 2000000/2; nn++) ;
    6e02:	str	r0, [sp, #4]
    6e04:	ldr	r3, [sp, #4]
    6e06:	cmp	r3, r2
    6e08:	bhi.n	6e16 <HardFault_HandlerC+0x56>
    6e0a:	ldr	r3, [sp, #4]
    6e0c:	adds	r3, #1
    6e0e:	str	r3, [sp, #4]
    6e10:	ldr	r3, [sp, #4]
    6e12:	cmp	r3, r2
    6e14:	bls.n	6e0a <HardFault_HandlerC+0x4a>
    GPIO2_DR_CLEAR = (1 << 3); //digitalWrite(13, LOW);
    6e16:	str.w	r4, [r5, #136]	; 0x88
    // digitalWrite(13, LOW);
    for (nn = 0; nn < 18000000/2; nn++) ;
    6e1a:	str	r0, [sp, #4]
    6e1c:	ldr	r3, [sp, #4]
    6e1e:	cmp	r3, r1
    6e20:	bhi.n	6dfe <HardFault_HandlerC+0x3e>
    6e22:	ldr	r3, [sp, #4]
    6e24:	adds	r3, #1
    6e26:	str	r3, [sp, #4]
    6e28:	ldr	r3, [sp, #4]
    6e2a:	cmp	r3, r1
    6e2c:	bls.n	6e22 <HardFault_HandlerC+0x62>
    6e2e:	b.n	6dfe <HardFault_HandlerC+0x3e>
    6e30:	.word	0x401bc000
    6e34:	.word	0x401f8000
    6e38:	.word	0x200000fc
    6e3c:	.word	0x23c345ff
    6e40:	.word	0x11e1a300
    6e44:	.word	0x000f423f
    6e48:	.word	0x0089543f

00006e4c <_sbrk>:

char *__brkval = (char *)&_heap_start;

void * _sbrk(int incr)
{
        char *prev = __brkval;
    6e4c:	ldr	r2, [pc, #36]	; (6e74 <_sbrk+0x28>)
extern unsigned long _heap_end;

char *__brkval = (char *)&_heap_start;

void * _sbrk(int incr)
{
    6e4e:	push	{r3, lr}
        char *prev = __brkval;
    6e50:	ldr	r3, [r2, #0]
        if (incr != 0) {
    6e52:	cbz	r0, 6e5e <_sbrk+0x12>
                if (prev + incr > (char *)&_heap_end) {
    6e54:	add	r0, r3
    6e56:	ldr	r1, [pc, #32]	; (6e78 <_sbrk+0x2c>)
    6e58:	cmp	r0, r1
    6e5a:	bhi.n	6e62 <_sbrk+0x16>
                        errno = ENOMEM;
                        return (void *)-1;
                }
                __brkval = prev + incr;
    6e5c:	str	r0, [r2, #0]
        }
        return prev;
}
    6e5e:	mov	r0, r3
    6e60:	pop	{r3, pc}
void * _sbrk(int incr)
{
        char *prev = __brkval;
        if (incr != 0) {
                if (prev + incr > (char *)&_heap_end) {
                        errno = ENOMEM;
    6e62:	bl	71dc <__errno>
    6e66:	movs	r2, #12
                        return (void *)-1;
    6e68:	mov.w	r3, #4294967295
void * _sbrk(int incr)
{
        char *prev = __brkval;
        if (incr != 0) {
                if (prev + incr > (char *)&_heap_end) {
                        errno = ENOMEM;
    6e6c:	str	r2, [r0, #0]
                        return (void *)-1;
                }
                __brkval = prev + incr;
        }
        return prev;
}
    6e6e:	mov	r0, r3
    6e70:	pop	{r3, pc}
    6e72:	nop
    6e74:	.word	0x200000f4
    6e78:	.word	0x20280000

00006e7c <set_arm_clock>:
	uint32_t cbcmr = CCM_CBCMR; // pg 1023
	uint32_t dcdc = DCDC_REG3;

	// compute required voltage
	uint32_t voltage = 1150; // default = 1.15V
	if (frequency > 528000000) {
    6e7c:	ldr	r2, [pc, #600]	; (70d8 <set_arm_clock+0x25c>)
//  CCM_CBCDR  AHB_PODF
//  CCM_CBCDR  SEMC_PODF

uint32_t set_arm_clock(uint32_t frequency)
{
	uint32_t cbcdr = CCM_CBCDR; // pg 1021
    6e7e:	ldr	r3, [pc, #604]	; (70dc <set_arm_clock+0x260>)
	uint32_t cbcmr = CCM_CBCMR; // pg 1023
	uint32_t dcdc = DCDC_REG3;

	// compute required voltage
	uint32_t voltage = 1150; // default = 1.15V
	if (frequency > 528000000) {
    6e80:	cmp	r0, r2
//  CCM_CBCMR  PERIPH2_CLK_SEL
//  CCM_CBCDR  AHB_PODF
//  CCM_CBCDR  SEMC_PODF

uint32_t set_arm_clock(uint32_t frequency)
{
    6e82:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, lr}
	uint32_t cbcdr = CCM_CBCDR; // pg 1021
	uint32_t cbcmr = CCM_CBCMR; // pg 1023
	uint32_t dcdc = DCDC_REG3;
    6e86:	ldr	r4, [pc, #600]	; (70e0 <set_arm_clock+0x264>)
//  CCM_CBCDR  AHB_PODF
//  CCM_CBCDR  SEMC_PODF

uint32_t set_arm_clock(uint32_t frequency)
{
	uint32_t cbcdr = CCM_CBCDR; // pg 1021
    6e88:	ldr.w	lr, [r3, #20]
	uint32_t cbcmr = CCM_CBCMR; // pg 1023
    6e8c:	ldr	r1, [r3, #24]
	uint32_t dcdc = DCDC_REG3;
    6e8e:	ldr	r6, [r4, #12]

	// compute required voltage
	uint32_t voltage = 1150; // default = 1.15V
	if (frequency > 528000000) {
    6e90:	bls.n	6ecc <set_arm_clock+0x50>
		voltage = 1250; // 1.25V
#if defined(OVERCLOCK_STEPSIZE) && defined(OVERCLOCK_MAX_VOLT)
		if (frequency > 600000000) {
    6e92:	ldr	r3, [pc, #592]	; (70e4 <set_arm_clock+0x268>)
    6e94:	cmp	r0, r3
    6e96:	bls.w	70c4 <set_arm_clock+0x248>
			voltage += ((frequency - 600000000) / OVERCLOCK_STEPSIZE) * 25;
    6e9a:	ldr	r3, [pc, #588]	; (70e8 <set_arm_clock+0x26c>)
    6e9c:	movw	r5, #1575	; 0x627
    6ea0:	ldr	r7, [pc, #584]	; (70ec <set_arm_clock+0x270>)
    6ea2:	add	r3, r0
    6ea4:	ldr	r4, [pc, #584]	; (70f0 <set_arm_clock+0x274>)
    6ea6:	lsrs	r2, r3, #8
    6ea8:	umull	r3, r2, r7, r2
    6eac:	lsrs	r3, r2, #7
    6eae:	add.w	r3, r3, r3, lsl #2
    6eb2:	add.w	r2, r3, r3, lsl #2
    6eb6:	addw	r3, r2, #1250	; 0x4e2
    6eba:	cmp	r3, r5
    6ebc:	it	cs
    6ebe:	movcs	r3, r5
    6ec0:	sub.w	r3, r3, #800	; 0x320
    6ec4:	umull	r3, r5, r4, r3
    6ec8:	lsrs	r5, r5, #3
    6eca:	b.n	6ed6 <set_arm_clock+0x5a>
			if (voltage > OVERCLOCK_MAX_VOLT) voltage = OVERCLOCK_MAX_VOLT;
		}
#endif
	} else if (frequency <= 24000000) {
    6ecc:	ldr	r5, [pc, #548]	; (70f4 <set_arm_clock+0x278>)
    6ece:	cmp	r0, r5
    6ed0:	ite	ls
    6ed2:	movls	r5, #6
    6ed4:	movhi	r5, #14
		voltage = 950; // 0.95
	}

	// if voltage needs to increase, do it before switch clock speed
	CCM_CCGR6 |= CCM_CCGR6_DCDC(CCM_CCGR_ON);
    6ed6:	ldr	r2, [pc, #516]	; (70dc <set_arm_clock+0x260>)
	if ((dcdc & DCDC_REG3_TRG_MASK) < DCDC_REG3_TRG((voltage - 800) / 25)) {
    6ed8:	and.w	r7, r6, #31
	} else if (frequency <= 24000000) {
		voltage = 950; // 0.95
	}

	// if voltage needs to increase, do it before switch clock speed
	CCM_CCGR6 |= CCM_CCGR6_DCDC(CCM_CCGR_ON);
    6edc:	ldr.w	r3, [r2, #128]	; 0x80
	if ((dcdc & DCDC_REG3_TRG_MASK) < DCDC_REG3_TRG((voltage - 800) / 25)) {
    6ee0:	cmp	r7, r5
	} else if (frequency <= 24000000) {
		voltage = 950; // 0.95
	}

	// if voltage needs to increase, do it before switch clock speed
	CCM_CCGR6 |= CCM_CCGR6_DCDC(CCM_CCGR_ON);
    6ee2:	orr.w	r3, r3, #192	; 0xc0
    6ee6:	str.w	r3, [r2, #128]	; 0x80
	if ((dcdc & DCDC_REG3_TRG_MASK) < DCDC_REG3_TRG((voltage - 800) / 25)) {
    6eea:	bcs.n	6f02 <set_arm_clock+0x86>
		printf("Increasing voltage to %u mV\n", voltage);
		dcdc &= ~DCDC_REG3_TRG_MASK;
		dcdc |= DCDC_REG3_TRG((voltage - 800) / 25);
		DCDC_REG3 = dcdc;
    6eec:	ldr	r3, [pc, #496]	; (70e0 <set_arm_clock+0x264>)

	// if voltage needs to increase, do it before switch clock speed
	CCM_CCGR6 |= CCM_CCGR6_DCDC(CCM_CCGR_ON);
	if ((dcdc & DCDC_REG3_TRG_MASK) < DCDC_REG3_TRG((voltage - 800) / 25)) {
		printf("Increasing voltage to %u mV\n", voltage);
		dcdc &= ~DCDC_REG3_TRG_MASK;
    6eee:	bic.w	r6, r6, #31
		dcdc |= DCDC_REG3_TRG((voltage - 800) / 25);
		DCDC_REG3 = dcdc;
		while (!(DCDC_REG0 & DCDC_REG0_STS_DC_OK)) ; // wait voltage settling
    6ef2:	mov	r2, r3
	// if voltage needs to increase, do it before switch clock speed
	CCM_CCGR6 |= CCM_CCGR6_DCDC(CCM_CCGR_ON);
	if ((dcdc & DCDC_REG3_TRG_MASK) < DCDC_REG3_TRG((voltage - 800) / 25)) {
		printf("Increasing voltage to %u mV\n", voltage);
		dcdc &= ~DCDC_REG3_TRG_MASK;
		dcdc |= DCDC_REG3_TRG((voltage - 800) / 25);
    6ef4:	orrs	r6, r5
		DCDC_REG3 = dcdc;
    6ef6:	str	r6, [r3, #12]
		while (!(DCDC_REG0 & DCDC_REG0_STS_DC_OK)) ; // wait voltage settling
    6ef8:	ldr	r3, [r2, #0]
    6efa:	cmp	r3, #0
    6efc:	bge.n	6ef8 <set_arm_clock+0x7c>
    6efe:	and.w	r7, r6, #31
	}

	if (!(cbcdr & CCM_CBCDR_PERIPH_CLK_SEL)) {
    6f02:	ands.w	r3, lr, #33554432	; 0x2000000
    6f06:	bne.n	6f6c <set_arm_clock+0xf0>
		printf("need to switch to alternate clock during reconfigure of ARM PLL\n");
		const uint32_t need1s = CCM_ANALOG_PLL_USB1_ENABLE | CCM_ANALOG_PLL_USB1_POWER |
			CCM_ANALOG_PLL_USB1_LOCK | CCM_ANALOG_PLL_USB1_EN_USB_CLKS;
		uint32_t sel, div;
		if ((CCM_ANALOG_PLL_USB1 & need1s) == need1s) {
    6f08:	ldr	r4, [pc, #492]	; (70f8 <set_arm_clock+0x27c>)
    6f0a:	ldr	r2, [pc, #496]	; (70fc <set_arm_clock+0x280>)
    6f0c:	ldr.w	ip, [r4, #16]
    6f10:	mov	r4, r2
    6f12:	and.w	r2, ip, r2
    6f16:	cmp	r2, r4
    6f18:	itet	eq
    6f1a:	moveq.w	r3, #402653184	; 0x18000000
    6f1e:	movne.w	r2, #4096	; 0x1000
    6f22:	moveq	r2, #0
		} else {
			printf("USB PLL is off, use 24 MHz crystal\n");
			sel = 1;
			div = 0;
		}
		if ((cbcdr & CCM_CBCDR_PERIPH_CLK2_PODF_MASK) != CCM_CBCDR_PERIPH_CLK2_PODF(div)) {
    6f24:	eor.w	r4, lr, r3
    6f28:	tst.w	r4, #939524096	; 0x38000000
    6f2c:	beq.n	6f40 <set_arm_clock+0xc4>
			// PERIPH_CLK2 divider needs to be changed
			cbcdr &= ~CCM_CBCDR_PERIPH_CLK2_PODF_MASK;
    6f2e:	bic.w	lr, lr, #939524096	; 0x38000000
			cbcdr |= CCM_CBCDR_PERIPH_CLK2_PODF(div);
    6f32:	and.w	r3, r3, #939524096	; 0x38000000
			CCM_CBCDR = cbcdr;
    6f36:	ldr	r4, [pc, #420]	; (70dc <set_arm_clock+0x260>)
			div = 0;
		}
		if ((cbcdr & CCM_CBCDR_PERIPH_CLK2_PODF_MASK) != CCM_CBCDR_PERIPH_CLK2_PODF(div)) {
			// PERIPH_CLK2 divider needs to be changed
			cbcdr &= ~CCM_CBCDR_PERIPH_CLK2_PODF_MASK;
			cbcdr |= CCM_CBCDR_PERIPH_CLK2_PODF(div);
    6f38:	orr.w	lr, r3, lr
			CCM_CBCDR = cbcdr;
    6f3c:	str.w	lr, [r4, #20]
		}
		if ((cbcmr & CCM_CBCMR_PERIPH_CLK2_SEL_MASK) != CCM_CBCMR_PERIPH_CLK2_SEL(sel)) {
    6f40:	eor.w	r3, r1, r2
    6f44:	tst.w	r3, #12288	; 0x3000
    6f48:	beq.n	6f5c <set_arm_clock+0xe0>
			// PERIPH_CLK2 source select needs to be changed
			cbcmr &= ~CCM_CBCMR_PERIPH_CLK2_SEL_MASK;
			cbcmr |= CCM_CBCMR_PERIPH_CLK2_SEL(sel);
			CCM_CBCMR = cbcmr;
    6f4a:	ldr	r3, [pc, #400]	; (70dc <set_arm_clock+0x260>)
			cbcdr |= CCM_CBCDR_PERIPH_CLK2_PODF(div);
			CCM_CBCDR = cbcdr;
		}
		if ((cbcmr & CCM_CBCMR_PERIPH_CLK2_SEL_MASK) != CCM_CBCMR_PERIPH_CLK2_SEL(sel)) {
			// PERIPH_CLK2 source select needs to be changed
			cbcmr &= ~CCM_CBCMR_PERIPH_CLK2_SEL_MASK;
    6f4c:	bic.w	r1, r1, #12288	; 0x3000
			cbcmr |= CCM_CBCMR_PERIPH_CLK2_SEL(sel);
    6f50:	orrs	r1, r2
			CCM_CBCMR = cbcmr;
			while (CCM_CDHIPR & CCM_CDHIPR_PERIPH2_CLK_SEL_BUSY) ; // wait
    6f52:	mov	r2, r3
		}
		if ((cbcmr & CCM_CBCMR_PERIPH_CLK2_SEL_MASK) != CCM_CBCMR_PERIPH_CLK2_SEL(sel)) {
			// PERIPH_CLK2 source select needs to be changed
			cbcmr &= ~CCM_CBCMR_PERIPH_CLK2_SEL_MASK;
			cbcmr |= CCM_CBCMR_PERIPH_CLK2_SEL(sel);
			CCM_CBCMR = cbcmr;
    6f54:	str	r1, [r3, #24]
			while (CCM_CDHIPR & CCM_CDHIPR_PERIPH2_CLK_SEL_BUSY) ; // wait
    6f56:	ldr	r3, [r2, #72]	; 0x48
    6f58:	lsls	r4, r3, #28
    6f5a:	bmi.n	6f56 <set_arm_clock+0xda>
		}
		// switch over to PERIPH_CLK2
		cbcdr |= CCM_CBCDR_PERIPH_CLK_SEL;
    6f5c:	orr.w	lr, lr, #33554432	; 0x2000000
		CCM_CBCDR = cbcdr;
    6f60:	ldr	r2, [pc, #376]	; (70dc <set_arm_clock+0x260>)
    6f62:	str.w	lr, [r2, #20]
		while (CCM_CDHIPR & CCM_CDHIPR_PERIPH_CLK_SEL_BUSY) ; // wait
    6f66:	ldr	r3, [r2, #72]	; 0x48
    6f68:	lsls	r1, r3, #26
    6f6a:	bmi.n	6f66 <set_arm_clock+0xea>

	// TODO: check if PLL2 running, can 352, 396 or 528 can work? (no need for ARM PLL)

	// DIV_SELECT: 54-108 = official range 648 to 1296 in 12 MHz steps
	uint32_t div_arm = 1;
	uint32_t div_ahb = 1;
    6f6c:	movs	r1, #1
	while (frequency * div_arm * div_ahb < 648000000) {
    6f6e:	ldr	r4, [pc, #400]	; (7100 <set_arm_clock+0x284>)
	}

	// TODO: check if PLL2 running, can 352, 396 or 528 can work? (no need for ARM PLL)

	// DIV_SELECT: 54-108 = official range 648 to 1296 in 12 MHz steps
	uint32_t div_arm = 1;
    6f70:	mov	r2, r1
	uint32_t div_ahb = 1;
	while (frequency * div_arm * div_ahb < 648000000) {
    6f72:	mul.w	r3, r1, r2
    6f76:	mul.w	r3, r0, r3
    6f7a:	cmp	r3, r4
    6f7c:	bhi.n	6f92 <set_arm_clock+0x116>
		if (div_arm < 8) {
    6f7e:	cmp	r2, #7
    6f80:	bhi.w	70ae <set_arm_clock+0x232>
			div_arm = div_arm + 1;
    6f84:	adds	r2, #1
	// TODO: check if PLL2 running, can 352, 396 or 528 can work? (no need for ARM PLL)

	// DIV_SELECT: 54-108 = official range 648 to 1296 in 12 MHz steps
	uint32_t div_arm = 1;
	uint32_t div_ahb = 1;
	while (frequency * div_arm * div_ahb < 648000000) {
    6f86:	mul.w	r3, r1, r2
    6f8a:	mul.w	r3, r0, r3
    6f8e:	cmp	r3, r4
    6f90:	bls.n	6f7e <set_arm_clock+0x102>
			} else {
				break;
			}
		}
	}
	uint32_t mult = (frequency * div_arm * div_ahb + 6000000) / 12000000;
    6f92:	ldr	r0, [pc, #368]	; (7104 <set_arm_clock+0x288>)
    6f94:	ldr	r4, [pc, #368]	; (7108 <set_arm_clock+0x28c>)
    6f96:	add	r0, r3
    6f98:	umull	r0, r3, r4, r0
    6f9c:	lsrs	r3, r3, #20
	if (mult > 108) mult = 108;
    6f9e:	cmp	r3, #108	; 0x6c
    6fa0:	bhi.w	70ba <set_arm_clock+0x23e>
	if (mult < 54) mult = 54;
    6fa4:	cmp	r3, #53	; 0x35
    6fa6:	bhi.w	70c8 <set_arm_clock+0x24c>
    6faa:	ldr.w	r8, [pc, #392]	; 7134 <set_arm_clock+0x2b8>
    6fae:	movs	r3, #54	; 0x36
    6fb0:	ldr	r0, [pc, #344]	; (710c <set_arm_clock+0x290>)

	printf("ARM PLL=%x\n", CCM_ANALOG_PLL_ARM);
	const uint32_t arm_pll_mask = CCM_ANALOG_PLL_ARM_LOCK | CCM_ANALOG_PLL_ARM_BYPASS |
		CCM_ANALOG_PLL_ARM_ENABLE | CCM_ANALOG_PLL_ARM_POWERDOWN |
		CCM_ANALOG_PLL_ARM_DIV_SELECT_MASK;
	if ((CCM_ANALOG_PLL_ARM & arm_pll_mask) != (CCM_ANALOG_PLL_ARM_LOCK
    6fb2:	ldr.w	ip, [pc, #324]	; 70f8 <set_arm_clock+0x27c>
    6fb6:	ldr	r4, [pc, #344]	; (7110 <set_arm_clock+0x294>)
    6fb8:	ldr.w	r9, [ip]
	}
	uint32_t mult = (frequency * div_arm * div_ahb + 6000000) / 12000000;
	if (mult > 108) mult = 108;
	if (mult < 54) mult = 54;
	printf("Freq: 12 MHz * %u / %u / %u\n", mult, div_arm, div_ahb);
	frequency = mult * 12000000 / div_arm / div_ahb;
    6fbc:	udiv	r0, r0, r2

	printf("ARM PLL=%x\n", CCM_ANALOG_PLL_ARM);
	const uint32_t arm_pll_mask = CCM_ANALOG_PLL_ARM_LOCK | CCM_ANALOG_PLL_ARM_BYPASS |
		CCM_ANALOG_PLL_ARM_ENABLE | CCM_ANALOG_PLL_ARM_POWERDOWN |
		CCM_ANALOG_PLL_ARM_DIV_SELECT_MASK;
	if ((CCM_ANALOG_PLL_ARM & arm_pll_mask) != (CCM_ANALOG_PLL_ARM_LOCK
    6fc0:	and.w	r4, r9, r4
    6fc4:	cmp	r4, r8
	}
	uint32_t mult = (frequency * div_arm * div_ahb + 6000000) / 12000000;
	if (mult > 108) mult = 108;
	if (mult < 54) mult = 54;
	printf("Freq: 12 MHz * %u / %u / %u\n", mult, div_arm, div_ahb);
	frequency = mult * 12000000 / div_arm / div_ahb;
    6fc6:	udiv	r0, r0, r1

	printf("ARM PLL=%x\n", CCM_ANALOG_PLL_ARM);
	const uint32_t arm_pll_mask = CCM_ANALOG_PLL_ARM_LOCK | CCM_ANALOG_PLL_ARM_BYPASS |
		CCM_ANALOG_PLL_ARM_ENABLE | CCM_ANALOG_PLL_ARM_POWERDOWN |
		CCM_ANALOG_PLL_ARM_DIV_SELECT_MASK;
	if ((CCM_ANALOG_PLL_ARM & arm_pll_mask) != (CCM_ANALOG_PLL_ARM_LOCK
    6fca:	beq.n	6fe4 <set_arm_clock+0x168>
	  | CCM_ANALOG_PLL_ARM_ENABLE | CCM_ANALOG_PLL_ARM_DIV_SELECT(mult))) {
		printf("ARM PLL needs reconfigure\n");
		CCM_ANALOG_PLL_ARM = CCM_ANALOG_PLL_ARM_POWERDOWN;
		// TODO: delay needed?
		CCM_ANALOG_PLL_ARM = CCM_ANALOG_PLL_ARM_ENABLE
			| CCM_ANALOG_PLL_ARM_DIV_SELECT(mult);
    6fcc:	orr.w	r3, r3, #8192	; 0x2000
		CCM_ANALOG_PLL_ARM_ENABLE | CCM_ANALOG_PLL_ARM_POWERDOWN |
		CCM_ANALOG_PLL_ARM_DIV_SELECT_MASK;
	if ((CCM_ANALOG_PLL_ARM & arm_pll_mask) != (CCM_ANALOG_PLL_ARM_LOCK
	  | CCM_ANALOG_PLL_ARM_ENABLE | CCM_ANALOG_PLL_ARM_DIV_SELECT(mult))) {
		printf("ARM PLL needs reconfigure\n");
		CCM_ANALOG_PLL_ARM = CCM_ANALOG_PLL_ARM_POWERDOWN;
    6fd0:	mov.w	r8, #4096	; 0x1000
		// TODO: delay needed?
		CCM_ANALOG_PLL_ARM = CCM_ANALOG_PLL_ARM_ENABLE
			| CCM_ANALOG_PLL_ARM_DIV_SELECT(mult);
		while (!(CCM_ANALOG_PLL_ARM & CCM_ANALOG_PLL_ARM_LOCK)) ; // wait for lock
    6fd4:	mov	r4, ip
		CCM_ANALOG_PLL_ARM_ENABLE | CCM_ANALOG_PLL_ARM_POWERDOWN |
		CCM_ANALOG_PLL_ARM_DIV_SELECT_MASK;
	if ((CCM_ANALOG_PLL_ARM & arm_pll_mask) != (CCM_ANALOG_PLL_ARM_LOCK
	  | CCM_ANALOG_PLL_ARM_ENABLE | CCM_ANALOG_PLL_ARM_DIV_SELECT(mult))) {
		printf("ARM PLL needs reconfigure\n");
		CCM_ANALOG_PLL_ARM = CCM_ANALOG_PLL_ARM_POWERDOWN;
    6fd6:	str.w	r8, [ip]
		// TODO: delay needed?
		CCM_ANALOG_PLL_ARM = CCM_ANALOG_PLL_ARM_ENABLE
    6fda:	str.w	r3, [ip]
			| CCM_ANALOG_PLL_ARM_DIV_SELECT(mult);
		while (!(CCM_ANALOG_PLL_ARM & CCM_ANALOG_PLL_ARM_LOCK)) ; // wait for lock
    6fde:	ldr	r3, [r4, #0]
    6fe0:	cmp	r3, #0
    6fe2:	bge.n	6fde <set_arm_clock+0x162>
		printf("ARM PLL=%x\n", CCM_ANALOG_PLL_ARM);
	} else {
		printf("ARM PLL already running at required frequency\n");
	}

	if ((CCM_CACRR & CCM_CACRR_ARM_PODF_MASK) != (div_arm - 1)) {
    6fe4:	ldr.w	ip, [pc, #244]	; 70dc <set_arm_clock+0x260>
    6fe8:	subs	r2, #1
    6fea:	ldr.w	r3, [ip, #16]
    6fee:	and.w	r3, r3, #7
    6ff2:	cmp	r3, r2
    6ff4:	beq.n	7006 <set_arm_clock+0x18a>
		CCM_CACRR = CCM_CACRR_ARM_PODF(div_arm - 1);
    6ff6:	and.w	r2, r2, #7
		while (CCM_CDHIPR & CCM_CDHIPR_ARM_PODF_BUSY) ; // wait
    6ffa:	mov	r4, ip
	} else {
		printf("ARM PLL already running at required frequency\n");
	}

	if ((CCM_CACRR & CCM_CACRR_ARM_PODF_MASK) != (div_arm - 1)) {
		CCM_CACRR = CCM_CACRR_ARM_PODF(div_arm - 1);
    6ffc:	str.w	r2, [ip, #16]
		while (CCM_CDHIPR & CCM_CDHIPR_ARM_PODF_BUSY) ; // wait
    7000:	ldr	r3, [r4, #72]	; 0x48
    7002:	lsls	r3, r3, #15
    7004:	bmi.n	7000 <set_arm_clock+0x184>
	}

	if ((cbcdr & CCM_CBCDR_AHB_PODF_MASK) != CCM_CBCDR_AHB_PODF(div_ahb - 1)) {
    7006:	subs	r1, #1
    7008:	lsls	r1, r1, #10
    700a:	eor.w	r3, lr, r1
    700e:	tst.w	r3, #7168	; 0x1c00
    7012:	beq.n	702e <set_arm_clock+0x1b2>
		cbcdr &= ~CCM_CBCDR_AHB_PODF_MASK;
		cbcdr |= CCM_CBCDR_AHB_PODF(div_ahb - 1);
		CCM_CBCDR = cbcdr;
    7014:	ldr	r3, [pc, #196]	; (70dc <set_arm_clock+0x260>)
		CCM_CACRR = CCM_CACRR_ARM_PODF(div_arm - 1);
		while (CCM_CDHIPR & CCM_CDHIPR_ARM_PODF_BUSY) ; // wait
	}

	if ((cbcdr & CCM_CBCDR_AHB_PODF_MASK) != CCM_CBCDR_AHB_PODF(div_ahb - 1)) {
		cbcdr &= ~CCM_CBCDR_AHB_PODF_MASK;
    7016:	bic.w	lr, lr, #7168	; 0x1c00
		cbcdr |= CCM_CBCDR_AHB_PODF(div_ahb - 1);
    701a:	and.w	r1, r1, #7168	; 0x1c00
		CCM_CBCDR = cbcdr;
		while (CCM_CDHIPR & CCM_CDHIPR_AHB_PODF_BUSY); // wait
    701e:	mov	r2, r3
		while (CCM_CDHIPR & CCM_CDHIPR_ARM_PODF_BUSY) ; // wait
	}

	if ((cbcdr & CCM_CBCDR_AHB_PODF_MASK) != CCM_CBCDR_AHB_PODF(div_ahb - 1)) {
		cbcdr &= ~CCM_CBCDR_AHB_PODF_MASK;
		cbcdr |= CCM_CBCDR_AHB_PODF(div_ahb - 1);
    7020:	orr.w	lr, r1, lr
		CCM_CBCDR = cbcdr;
    7024:	str.w	lr, [r3, #20]
		while (CCM_CDHIPR & CCM_CDHIPR_AHB_PODF_BUSY); // wait
    7028:	ldr	r3, [r2, #72]	; 0x48
    702a:	lsls	r1, r3, #30
    702c:	bmi.n	7028 <set_arm_clock+0x1ac>
	}

	uint32_t div_ipg = (frequency + 149999999) / 150000000;
    702e:	ldr	r3, [pc, #228]	; (7114 <set_arm_clock+0x298>)
    7030:	ldr	r1, [pc, #228]	; (7118 <set_arm_clock+0x29c>)
    7032:	add	r3, r0
    7034:	lsrs	r3, r3, #7
    7036:	umull	r3, r1, r1, r3
    703a:	lsrs	r1, r1, #12
    703c:	cmp	r1, #4
    703e:	it	cs
    7040:	movcs	r1, #4
	if (div_ipg > 4) div_ipg = 4;
	if ((cbcdr & CCM_CBCDR_IPG_PODF_MASK) != (CCM_CBCDR_IPG_PODF(div_ipg - 1))) {
    7042:	subs	r3, r1, #1
    7044:	lsls	r3, r3, #8
    7046:	eor.w	r2, lr, r3
    704a:	tst.w	r2, #768	; 0x300
    704e:	beq.n	7060 <set_arm_clock+0x1e4>
		cbcdr &= ~CCM_CBCDR_IPG_PODF_MASK;
    7050:	bic.w	lr, lr, #768	; 0x300
		cbcdr |= CCM_CBCDR_IPG_PODF(div_ipg - 1);
    7054:	and.w	r3, r3, #768	; 0x300
		// TODO: how to safely change IPG_PODF ??
		CCM_CBCDR = cbcdr;
    7058:	ldr	r2, [pc, #128]	; (70dc <set_arm_clock+0x260>)

	uint32_t div_ipg = (frequency + 149999999) / 150000000;
	if (div_ipg > 4) div_ipg = 4;
	if ((cbcdr & CCM_CBCDR_IPG_PODF_MASK) != (CCM_CBCDR_IPG_PODF(div_ipg - 1))) {
		cbcdr &= ~CCM_CBCDR_IPG_PODF_MASK;
		cbcdr |= CCM_CBCDR_IPG_PODF(div_ipg - 1);
    705a:	orr.w	r3, r3, lr
		// TODO: how to safely change IPG_PODF ??
		CCM_CBCDR = cbcdr;
    705e:	str	r3, [r2, #20]
	}

	//cbcdr &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	//CCM_CBCDR = cbcdr;  // why does this not work at 24 MHz?
	CCM_CBCDR &= ~CCM_CBCDR_PERIPH_CLK_SEL;
    7060:	ldr	r3, [pc, #120]	; (70dc <set_arm_clock+0x260>)
    7062:	ldr	r4, [r3, #20]
	while (CCM_CDHIPR & CCM_CDHIPR_PERIPH_CLK_SEL_BUSY) ; // wait
    7064:	mov	r2, r3
		CCM_CBCDR = cbcdr;
	}

	//cbcdr &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	//CCM_CBCDR = cbcdr;  // why does this not work at 24 MHz?
	CCM_CBCDR &= ~CCM_CBCDR_PERIPH_CLK_SEL;
    7066:	bic.w	r4, r4, #33554432	; 0x2000000
    706a:	str	r4, [r3, #20]
	while (CCM_CDHIPR & CCM_CDHIPR_PERIPH_CLK_SEL_BUSY) ; // wait
    706c:	ldr	r3, [r2, #72]	; 0x48
    706e:	lsls	r3, r3, #26
    7070:	bmi.n	706c <set_arm_clock+0x1f0>

	F_CPU_ACTUAL = frequency;
	F_BUS_ACTUAL = frequency / div_ipg;
	scale_cpu_cycles_to_microseconds = 0xFFFFFFFFu / (uint32_t)(frequency / 1000000u);
    7072:	ldr	r3, [pc, #168]	; (711c <set_arm_clock+0x2a0>)
    7074:	mov.w	r2, #4294967295
	//cbcdr &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	//CCM_CBCDR = cbcdr;  // why does this not work at 24 MHz?
	CCM_CBCDR &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	while (CCM_CDHIPR & CCM_CDHIPR_PERIPH_CLK_SEL_BUSY) ; // wait

	F_CPU_ACTUAL = frequency;
    7078:	ldr	r4, [pc, #164]	; (7120 <set_arm_clock+0x2a4>)
	scale_cpu_cycles_to_microseconds = 0xFFFFFFFFu / (uint32_t)(frequency / 1000000u);

	printf("New Frequency: ARM=%u, IPG=%u\n", frequency, frequency / div_ipg);

	// if voltage needs to decrease, do it after switch clock speed
	if ((dcdc & DCDC_REG3_TRG_MASK) > DCDC_REG3_TRG((voltage - 800) / 25)) {
    707a:	cmp	r5, r7
	CCM_CBCDR &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	while (CCM_CDHIPR & CCM_CDHIPR_PERIPH_CLK_SEL_BUSY) ; // wait

	F_CPU_ACTUAL = frequency;
	F_BUS_ACTUAL = frequency / div_ipg;
	scale_cpu_cycles_to_microseconds = 0xFFFFFFFFu / (uint32_t)(frequency / 1000000u);
    707c:	umull	lr, r3, r3, r0
	//cbcdr &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	//CCM_CBCDR = cbcdr;  // why does this not work at 24 MHz?
	CCM_CBCDR &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	while (CCM_CDHIPR & CCM_CDHIPR_PERIPH_CLK_SEL_BUSY) ; // wait

	F_CPU_ACTUAL = frequency;
    7080:	str	r0, [r4, #0]
	F_BUS_ACTUAL = frequency / div_ipg;
	scale_cpu_cycles_to_microseconds = 0xFFFFFFFFu / (uint32_t)(frequency / 1000000u);
    7082:	mov.w	r3, r3, lsr #18
	//CCM_CBCDR = cbcdr;  // why does this not work at 24 MHz?
	CCM_CBCDR &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	while (CCM_CDHIPR & CCM_CDHIPR_PERIPH_CLK_SEL_BUSY) ; // wait

	F_CPU_ACTUAL = frequency;
	F_BUS_ACTUAL = frequency / div_ipg;
    7086:	ldr	r4, [pc, #156]	; (7124 <set_arm_clock+0x2a8>)
	scale_cpu_cycles_to_microseconds = 0xFFFFFFFFu / (uint32_t)(frequency / 1000000u);
    7088:	udiv	r3, r2, r3
	//CCM_CBCDR = cbcdr;  // why does this not work at 24 MHz?
	CCM_CBCDR &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	while (CCM_CDHIPR & CCM_CDHIPR_PERIPH_CLK_SEL_BUSY) ; // wait

	F_CPU_ACTUAL = frequency;
	F_BUS_ACTUAL = frequency / div_ipg;
    708c:	udiv	r1, r0, r1
	scale_cpu_cycles_to_microseconds = 0xFFFFFFFFu / (uint32_t)(frequency / 1000000u);
    7090:	ldr	r2, [pc, #148]	; (7128 <set_arm_clock+0x2ac>)
	//CCM_CBCDR = cbcdr;  // why does this not work at 24 MHz?
	CCM_CBCDR &= ~CCM_CBCDR_PERIPH_CLK_SEL;
	while (CCM_CDHIPR & CCM_CDHIPR_PERIPH_CLK_SEL_BUSY) ; // wait

	F_CPU_ACTUAL = frequency;
	F_BUS_ACTUAL = frequency / div_ipg;
    7092:	str	r1, [r4, #0]
	scale_cpu_cycles_to_microseconds = 0xFFFFFFFFu / (uint32_t)(frequency / 1000000u);
    7094:	str	r3, [r2, #0]

	printf("New Frequency: ARM=%u, IPG=%u\n", frequency, frequency / div_ipg);

	// if voltage needs to decrease, do it after switch clock speed
	if ((dcdc & DCDC_REG3_TRG_MASK) > DCDC_REG3_TRG((voltage - 800) / 25)) {
    7096:	bcs.n	70aa <set_arm_clock+0x22e>
		printf("Decreasing voltage to %u mV\n", voltage);
		dcdc &= ~DCDC_REG3_TRG_MASK;
		dcdc |= DCDC_REG3_TRG((voltage - 800) / 25);
		DCDC_REG3 = dcdc;
    7098:	ldr	r3, [pc, #68]	; (70e0 <set_arm_clock+0x264>)
	printf("New Frequency: ARM=%u, IPG=%u\n", frequency, frequency / div_ipg);

	// if voltage needs to decrease, do it after switch clock speed
	if ((dcdc & DCDC_REG3_TRG_MASK) > DCDC_REG3_TRG((voltage - 800) / 25)) {
		printf("Decreasing voltage to %u mV\n", voltage);
		dcdc &= ~DCDC_REG3_TRG_MASK;
    709a:	bic.w	r6, r6, #31
		dcdc |= DCDC_REG3_TRG((voltage - 800) / 25);
		DCDC_REG3 = dcdc;
		while (!(DCDC_REG0 & DCDC_REG0_STS_DC_OK)) ; // wait voltage settling
    709e:	mov	r2, r3

	// if voltage needs to decrease, do it after switch clock speed
	if ((dcdc & DCDC_REG3_TRG_MASK) > DCDC_REG3_TRG((voltage - 800) / 25)) {
		printf("Decreasing voltage to %u mV\n", voltage);
		dcdc &= ~DCDC_REG3_TRG_MASK;
		dcdc |= DCDC_REG3_TRG((voltage - 800) / 25);
    70a0:	orrs	r6, r5
		DCDC_REG3 = dcdc;
    70a2:	str	r6, [r3, #12]
		while (!(DCDC_REG0 & DCDC_REG0_STS_DC_OK)) ; // wait voltage settling
    70a4:	ldr	r3, [r2, #0]
    70a6:	cmp	r3, #0
    70a8:	bge.n	70a4 <set_arm_clock+0x228>
	}

	return frequency;
}
    70aa:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, pc}
	uint32_t div_ahb = 1;
	while (frequency * div_arm * div_ahb < 648000000) {
		if (div_arm < 8) {
			div_arm = div_arm + 1;
		} else {
			if (div_ahb < 5) {
    70ae:	cmp	r1, #4
    70b0:	bhi.w	6f92 <set_arm_clock+0x116>
				div_ahb = div_ahb + 1;
    70b4:	adds	r1, #1
				div_arm = 1;
    70b6:	movs	r2, #1
    70b8:	b.n	6f72 <set_arm_clock+0xf6>
    70ba:	ldr.w	r8, [pc, #124]	; 7138 <set_arm_clock+0x2bc>
				break;
			}
		}
	}
	uint32_t mult = (frequency * div_arm * div_ahb + 6000000) / 12000000;
	if (mult > 108) mult = 108;
    70be:	movs	r3, #108	; 0x6c
    70c0:	ldr	r0, [pc, #104]	; (712c <set_arm_clock+0x2b0>)
    70c2:	b.n	6fb2 <set_arm_clock+0x136>
    70c4:	movs	r5, #18
    70c6:	b.n	6ed6 <set_arm_clock+0x5a>
    70c8:	ldr	r0, [pc, #100]	; (7130 <set_arm_clock+0x2b4>)
    70ca:	ldr.w	r8, [pc, #112]	; 713c <set_arm_clock+0x2c0>
    70ce:	mul.w	r0, r0, r3
    70d2:	orr.w	r8, r3, r8
    70d6:	b.n	6fb2 <set_arm_clock+0x136>
    70d8:	.word	0x1f78a400
    70dc:	.word	0x400fc000
    70e0:	.word	0x40080000
    70e4:	.word	0x23c34600
    70e8:	.word	0xdc3cba00
    70ec:	.word	0x004cb223
    70f0:	.word	0x51eb851f
    70f4:	.word	0x016e3600
    70f8:	.word	0x400d8000
    70fc:	.word	0x80003040
    7100:	.word	0x269fb1ff
    7104:	.word	0x005b8d80
    7108:	.word	0x165e9f81
    710c:	.word	0x269fb200
    7110:	.word	0x8001307f
    7114:	.word	0x08f0d17f
    7118:	.word	0x00e5109f
    711c:	.word	0x431bde83
    7120:	.word	0x200000fc
    7124:	.word	0x200000f8
    7128:	.word	0x20000b80
    712c:	.word	0x4d3f6400
    7130:	.word	0x00b71b00
    7134:	.word	0x80002036
    7138:	.word	0x8000206c
    713c:	.word	0x80002000

00007140 <ultoa>:
#include <stdlib.h>
#include <math.h>


char * ultoa(unsigned long val, char *buf, int radix)
{
    7140:	push	{r4, r5, r6, r7}
    7142:	subs	r6, r1, #1
	unsigned digit;
	int i=0, j;
    7144:	movs	r5, #0
#include <stdlib.h>
#include <math.h>


char * ultoa(unsigned long val, char *buf, int radix)
{
    7146:	mov	r7, r6
    7148:	b.n	714c <ultoa+0xc>
	while (1) {
		digit = val % radix;
		buf[i] = ((digit < 10) ? '0' + digit : 'A' + digit - 10);
		val /= radix;
		if (val == 0) break;
		i++;
    714a:	adds	r5, #1
	unsigned digit;
	int i=0, j;
	char t;

	while (1) {
		digit = val % radix;
    714c:	udiv	r3, r0, r2
    7150:	mls	r0, r2, r3, r0
		buf[i] = ((digit < 10) ? '0' + digit : 'A' + digit - 10);
    7154:	add.w	r4, r0, #55	; 0x37
    7158:	cmp	r0, #9
    715a:	add.w	r0, r0, #48	; 0x30
    715e:	uxtb	r4, r4
    7160:	it	ls
    7162:	uxtbls	r4, r0
		val /= radix;
		if (val == 0) break;
    7164:	mov	r0, r3
	int i=0, j;
	char t;

	while (1) {
		digit = val % radix;
		buf[i] = ((digit < 10) ? '0' + digit : 'A' + digit - 10);
    7166:	strb.w	r4, [r7, #1]!
		val /= radix;
		if (val == 0) break;
    716a:	cmp	r3, #0
    716c:	bne.n	714a <ultoa+0xa>
		i++;
	}
	buf[i + 1] = 0;
    716e:	adds	r2, r1, r5
    7170:	strb	r3, [r2, #1]
	for (j=0; j < i; j++, i--) {
    7172:	cbz	r5, 7188 <ultoa+0x48>
    7174:	adds	r3, #1
		t = buf[j];
    7176:	ldrb.w	r4, [r6, #1]!
		buf[j] = buf[i];
    717a:	ldrb	r7, [r2, #0]
		val /= radix;
		if (val == 0) break;
		i++;
	}
	buf[i + 1] = 0;
	for (j=0; j < i; j++, i--) {
    717c:	subs	r0, r5, r3
		t = buf[j];
		buf[j] = buf[i];
    717e:	strb	r7, [r6, #0]
		val /= radix;
		if (val == 0) break;
		i++;
	}
	buf[i + 1] = 0;
	for (j=0; j < i; j++, i--) {
    7180:	cmp	r3, r0
		t = buf[j];
		buf[j] = buf[i];
		buf[i] = t;
    7182:	strb.w	r4, [r2], #-1
		val /= radix;
		if (val == 0) break;
		i++;
	}
	buf[i + 1] = 0;
	for (j=0; j < i; j++, i--) {
    7186:	blt.n	7174 <ultoa+0x34>
		t = buf[j];
		buf[j] = buf[i];
		buf[i] = t;
	}
	return buf;
}
    7188:	mov	r0, r1
    718a:	pop	{r4, r5, r6, r7}
    718c:	bx	lr
    718e:	nop

00007190 <Panic_Temp_isr>:

static uint32_t s_hotTemp, s_hotCount, s_roomC_hotC;
static float s_hot_ROOM;

void Panic_Temp_isr(void) {
  __disable_irq();
    7190:	cpsid	i
  IOMUXC_GPR_GPR16 = 0x00000007;
  SNVS_LPCR |= SNVS_LPCR_TOP; //Switch off now
    7192:	ldr	r2, [pc, #24]	; (71ac <Panic_Temp_isr+0x1c>)
static uint32_t s_hotTemp, s_hotCount, s_roomC_hotC;
static float s_hot_ROOM;

void Panic_Temp_isr(void) {
  __disable_irq();
  IOMUXC_GPR_GPR16 = 0x00000007;
    7194:	movs	r1, #7
    7196:	ldr	r3, [pc, #24]	; (71b0 <Panic_Temp_isr+0x20>)
    7198:	str	r1, [r3, #64]	; 0x40
  SNVS_LPCR |= SNVS_LPCR_TOP; //Switch off now
    719a:	ldr	r3, [r2, #56]	; 0x38
    719c:	orr.w	r3, r3, #64	; 0x40
    71a0:	str	r3, [r2, #56]	; 0x38
  asm volatile ("dsb":::"memory");
    71a2:	dsb	sy
  while (1) asm ("wfi");
    71a6:	wfi
    71a8:	b.n	71a6 <Panic_Temp_isr+0x16>
    71aa:	nop
    71ac:	.word	0x400d4000
    71b0:	.word	0x400ac000

000071b4 <HardwareSerial::processSerialEvents()>:
	//digitalWrite(4, LOW);
}


void HardwareSerial::processSerialEvents()
{
    71b4:	push	{r3, r4, r5, lr}
	if (!serial_event_handlers_active) return;	// bail quick if no one processing SerialEvents.
    71b6:	ldr	r3, [pc, #28]	; (71d4 <HardwareSerial::processSerialEvents()+0x20>)
    71b8:	ldrb	r4, [r3, #0]
    71ba:	cbz	r4, 71d0 <HardwareSerial::processSerialEvents()+0x1c>
    71bc:	ldr	r5, [pc, #24]	; (71d8 <HardwareSerial::processSerialEvents()+0x24>)
	uint8_t handlers_still_to_process = serial_event_handlers_active;
	for (uint8_t i = 0; i < 8; i++) {
		if (serial_event_handler_checks[i]) {
    71be:	ldr.w	r3, [r5, #4]!
    71c2:	cmp	r3, #0
    71c4:	beq.n	71be <HardwareSerial::processSerialEvents()+0xa>
			(*serial_event_handler_checks[i])();
    71c6:	blx	r3
			if (--handlers_still_to_process == 0) return;
    71c8:	subs	r3, r4, #1
    71ca:	ands.w	r4, r3, #255	; 0xff
    71ce:	bne.n	71be <HardwareSerial::processSerialEvents()+0xa>
    71d0:	pop	{r3, r4, r5, pc}
    71d2:	nop
    71d4:	.word	0x20000bd8
    71d8:	.word	0x20000bb8

000071dc <__errno>:
    71dc:	ldr	r3, [pc, #4]	; (71e4 <__errno+0x8>)
    71de:	ldr	r0, [r3, #0]
    71e0:	bx	lr
    71e2:	nop
    71e4:	.word	0x20000528

000071e8 <__libc_init_array>:
    71e8:	push	{r4, r5, r6, lr}
    71ea:	ldr	r6, [pc, #60]	; (7228 <__libc_init_array+0x40>)
    71ec:	ldr	r5, [pc, #60]	; (722c <__libc_init_array+0x44>)
    71ee:	subs	r6, r6, r5
    71f0:	asrs	r6, r6, #2
    71f2:	it	ne
    71f4:	movne	r4, #0
    71f6:	beq.n	7204 <__libc_init_array+0x1c>
    71f8:	adds	r4, #1
    71fa:	ldr.w	r3, [r5], #4
    71fe:	blx	r3
    7200:	cmp	r6, r4
    7202:	bne.n	71f8 <__libc_init_array+0x10>
    7204:	ldr	r6, [pc, #40]	; (7230 <__libc_init_array+0x48>)
    7206:	ldr	r5, [pc, #44]	; (7234 <__libc_init_array+0x4c>)
    7208:	subs	r6, r6, r5
    720a:	bl	7b00 <___init_veneer>
    720e:	asrs	r6, r6, #2
    7210:	it	ne
    7212:	movne	r4, #0
    7214:	beq.n	7224 <__libc_init_array+0x3c>
    7216:	adds	r4, #1
    7218:	ldr.w	r3, [r5], #4
    721c:	blx	r3
    721e:	cmp	r6, r4
    7220:	bne.n	7216 <__libc_init_array+0x2e>
    7222:	pop	{r4, r5, r6, pc}
    7224:	pop	{r4, r5, r6, pc}
    7226:	nop
    7228:	.word	0x60001740
    722c:	.word	0x60001740
    7230:	.word	0x60001744
    7234:	.word	0x60001740

00007238 <malloc>:
    7238:	ldr	r3, [pc, #8]	; (7244 <malloc+0xc>)
    723a:	mov	r1, r0
    723c:	ldr	r0, [r3, #0]
    723e:	b.w	7258 <_malloc_r>
    7242:	nop
    7244:	.word	0x20000528

00007248 <free>:
    7248:	ldr	r3, [pc, #8]	; (7254 <free+0xc>)
    724a:	mov	r1, r0
    724c:	ldr	r0, [r3, #0]
    724e:	b.w	792c <_free_r>
    7252:	nop
    7254:	.word	0x20000528

00007258 <_malloc_r>:
    7258:	stmdb	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, lr}
    725c:	add.w	r5, r1, #11
    7260:	cmp	r5, #22
    7262:	sub	sp, #12
    7264:	mov	r6, r0
    7266:	bls.w	73a8 <_malloc_r+0x150>
    726a:	bics.w	r5, r5, #7
    726e:	bmi.w	73f0 <_malloc_r+0x198>
    7272:	cmp	r1, r5
    7274:	bhi.w	73f0 <_malloc_r+0x198>
    7278:	bl	7864 <__malloc_lock>
    727c:	cmp.w	r5, #504	; 0x1f8
    7280:	bcc.w	77bc <_malloc_r+0x564>
    7284:	lsrs	r3, r5, #9
    7286:	beq.w	73fe <_malloc_r+0x1a6>
    728a:	cmp	r3, #4
    728c:	bhi.w	7596 <_malloc_r+0x33e>
    7290:	lsrs	r0, r5, #6
    7292:	add.w	lr, r0, #57	; 0x39
    7296:	mov.w	r3, lr, lsl #1
    729a:	adds	r0, #56	; 0x38
    729c:	ldr	r7, [pc, #784]	; (75b0 <_malloc_r+0x358>)
    729e:	add.w	r3, r7, r3, lsl #2
    72a2:	sub.w	r1, r3, #8
    72a6:	ldr	r4, [r3, #4]
    72a8:	cmp	r1, r4
    72aa:	bne.n	72bc <_malloc_r+0x64>
    72ac:	b.n	7408 <_malloc_r+0x1b0>
    72ae:	cmp	r2, #0
    72b0:	bge.w	740c <_malloc_r+0x1b4>
    72b4:	ldr	r4, [r4, #12]
    72b6:	cmp	r1, r4
    72b8:	beq.w	7408 <_malloc_r+0x1b0>
    72bc:	ldr	r3, [r4, #4]
    72be:	bic.w	r3, r3, #3
    72c2:	subs	r2, r3, r5
    72c4:	cmp	r2, #15
    72c6:	ble.n	72ae <_malloc_r+0x56>
    72c8:	ldr	r1, [pc, #740]	; (75b0 <_malloc_r+0x358>)
    72ca:	ldr	r4, [r7, #16]
    72cc:	add.w	lr, r1, #8
    72d0:	cmp	r4, lr
    72d2:	beq.w	763c <_malloc_r+0x3e4>
    72d6:	ldr	r3, [r4, #4]
    72d8:	bic.w	r3, r3, #3
    72dc:	subs	r2, r3, r5
    72de:	cmp	r2, #15
    72e0:	bgt.w	7616 <_malloc_r+0x3be>
    72e4:	cmp	r2, #0
    72e6:	str.w	lr, [r1, #20]
    72ea:	str.w	lr, [r1, #16]
    72ee:	bge.w	742e <_malloc_r+0x1d6>
    72f2:	cmp.w	r3, #512	; 0x200
    72f6:	bcs.w	75c8 <_malloc_r+0x370>
    72fa:	lsrs	r3, r3, #3
    72fc:	add.w	ip, r3, #1
    7300:	movs	r2, #1
    7302:	asrs	r3, r3, #2
    7304:	lsl.w	r3, r2, r3
    7308:	ldr	r2, [r1, #4]
    730a:	ldr.w	r8, [r1, ip, lsl #3]
    730e:	str.w	r8, [r4, #8]
    7312:	add.w	r9, r1, ip, lsl #3
    7316:	orrs	r2, r3
    7318:	sub.w	r3, r9, #8
    731c:	str	r3, [r4, #12]
    731e:	str	r2, [r1, #4]
    7320:	str.w	r4, [r1, ip, lsl #3]
    7324:	str.w	r4, [r8, #12]
    7328:	asrs	r3, r0, #2
    732a:	movs	r4, #1
    732c:	lsls	r4, r3
    732e:	cmp	r4, r2
    7330:	bhi.w	7448 <_malloc_r+0x1f0>
    7334:	tst	r4, r2
    7336:	bne.n	7346 <_malloc_r+0xee>
    7338:	bic.w	r0, r0, #3
    733c:	lsls	r4, r4, #1
    733e:	tst	r4, r2
    7340:	add.w	r0, r0, #4
    7344:	beq.n	733c <_malloc_r+0xe4>
    7346:	add.w	r9, r7, r0, lsl #3
    734a:	mov	ip, r9
    734c:	mov	r8, r0
    734e:	ldr.w	r1, [ip, #12]
    7352:	cmp	ip, r1
    7354:	bne.n	7366 <_malloc_r+0x10e>
    7356:	b.n	7640 <_malloc_r+0x3e8>
    7358:	cmp	r2, #0
    735a:	bge.w	7660 <_malloc_r+0x408>
    735e:	ldr	r1, [r1, #12]
    7360:	cmp	ip, r1
    7362:	beq.w	7640 <_malloc_r+0x3e8>
    7366:	ldr	r3, [r1, #4]
    7368:	bic.w	r3, r3, #3
    736c:	subs	r2, r3, r5
    736e:	cmp	r2, #15
    7370:	ble.n	7358 <_malloc_r+0x100>
    7372:	mov	r4, r1
    7374:	ldr.w	ip, [r1, #12]
    7378:	ldr.w	r8, [r4, #8]!
    737c:	adds	r3, r1, r5
    737e:	orr.w	r5, r5, #1
    7382:	str	r5, [r1, #4]
    7384:	orr.w	r1, r2, #1
    7388:	str.w	ip, [r8, #12]
    738c:	mov	r0, r6
    738e:	str.w	r8, [ip, #8]
    7392:	str	r3, [r7, #20]
    7394:	str	r3, [r7, #16]
    7396:	str.w	lr, [r3, #12]
    739a:	str.w	lr, [r3, #8]
    739e:	str	r1, [r3, #4]
    73a0:	str	r2, [r3, r2]
    73a2:	bl	7868 <__malloc_unlock>
    73a6:	b.n	73e8 <_malloc_r+0x190>
    73a8:	cmp	r1, #16
    73aa:	bhi.n	73f0 <_malloc_r+0x198>
    73ac:	bl	7864 <__malloc_lock>
    73b0:	movs	r5, #16
    73b2:	movs	r3, #6
    73b4:	movs	r0, #2
    73b6:	ldr	r7, [pc, #504]	; (75b0 <_malloc_r+0x358>)
    73b8:	add.w	r3, r7, r3, lsl #2
    73bc:	sub.w	r2, r3, #8
    73c0:	ldr	r4, [r3, #4]
    73c2:	cmp	r4, r2
    73c4:	beq.w	7652 <_malloc_r+0x3fa>
    73c8:	ldr	r3, [r4, #4]
    73ca:	ldr	r1, [r4, #12]
    73cc:	ldr	r5, [r4, #8]
    73ce:	bic.w	r3, r3, #3
    73d2:	add	r3, r4
    73d4:	mov	r0, r6
    73d6:	ldr	r2, [r3, #4]
    73d8:	str	r1, [r5, #12]
    73da:	orr.w	r2, r2, #1
    73de:	str	r5, [r1, #8]
    73e0:	str	r2, [r3, #4]
    73e2:	bl	7868 <__malloc_unlock>
    73e6:	adds	r4, #8
    73e8:	mov	r0, r4
    73ea:	add	sp, #12
    73ec:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    73f0:	movs	r4, #0
    73f2:	movs	r3, #12
    73f4:	mov	r0, r4
    73f6:	str	r3, [r6, #0]
    73f8:	add	sp, #12
    73fa:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    73fe:	movs	r3, #128	; 0x80
    7400:	mov.w	lr, #64	; 0x40
    7404:	movs	r0, #63	; 0x3f
    7406:	b.n	729c <_malloc_r+0x44>
    7408:	mov	r0, lr
    740a:	b.n	72c8 <_malloc_r+0x70>
    740c:	add	r3, r4
    740e:	ldr	r1, [r4, #12]
    7410:	ldr	r2, [r3, #4]
    7412:	ldr	r5, [r4, #8]
    7414:	orr.w	r2, r2, #1
    7418:	str	r1, [r5, #12]
    741a:	mov	r0, r6
    741c:	str	r5, [r1, #8]
    741e:	str	r2, [r3, #4]
    7420:	bl	7868 <__malloc_unlock>
    7424:	adds	r4, #8
    7426:	mov	r0, r4
    7428:	add	sp, #12
    742a:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    742e:	add	r3, r4
    7430:	mov	r0, r6
    7432:	ldr	r2, [r3, #4]
    7434:	orr.w	r2, r2, #1
    7438:	str	r2, [r3, #4]
    743a:	bl	7868 <__malloc_unlock>
    743e:	adds	r4, #8
    7440:	mov	r0, r4
    7442:	add	sp, #12
    7444:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    7448:	ldr	r4, [r7, #8]
    744a:	ldr	r3, [r4, #4]
    744c:	bic.w	r8, r3, #3
    7450:	cmp	r8, r5
    7452:	bcc.n	745e <_malloc_r+0x206>
    7454:	rsb	r3, r5, r8
    7458:	cmp	r3, #15
    745a:	bgt.w	7576 <_malloc_r+0x31e>
    745e:	ldr	r3, [pc, #340]	; (75b4 <_malloc_r+0x35c>)
    7460:	ldr.w	r9, [pc, #352]	; 75c4 <_malloc_r+0x36c>
    7464:	ldr	r2, [r3, #0]
    7466:	ldr.w	r3, [r9]
    746a:	adds	r3, #1
    746c:	add	r2, r5
    746e:	add.w	sl, r4, r8
    7472:	beq.w	7736 <_malloc_r+0x4de>
    7476:	add.w	r2, r2, #4096	; 0x1000
    747a:	adds	r2, #15
    747c:	bic.w	r2, r2, #4080	; 0xff0
    7480:	bic.w	r2, r2, #15
    7484:	mov	r1, r2
    7486:	mov	r0, r6
    7488:	str	r2, [sp, #4]
    748a:	bl	786c <_sbrk_r>
    748e:	cmp.w	r0, #4294967295
    7492:	mov	fp, r0
    7494:	ldr	r2, [sp, #4]
    7496:	beq.w	774a <_malloc_r+0x4f2>
    749a:	cmp	sl, r0
    749c:	bhi.w	7698 <_malloc_r+0x440>
    74a0:	ldr	r3, [pc, #276]	; (75b8 <_malloc_r+0x360>)
    74a2:	ldr	r1, [r3, #0]
    74a4:	cmp	sl, fp
    74a6:	add	r1, r2
    74a8:	str	r1, [r3, #0]
    74aa:	beq.w	7754 <_malloc_r+0x4fc>
    74ae:	ldr.w	r0, [r9]
    74b2:	ldr.w	lr, [pc, #272]	; 75c4 <_malloc_r+0x36c>
    74b6:	adds	r0, #1
    74b8:	ittet	ne
    74ba:	rsbne	sl, sl, fp
    74be:	addne	r1, sl
    74c0:	streq.w	fp, [lr]
    74c4:	strne	r1, [r3, #0]
    74c6:	ands.w	r1, fp, #7
    74ca:	beq.w	76fc <_malloc_r+0x4a4>
    74ce:	rsb	r0, r1, #8
    74d2:	rsb	r1, r1, #4096	; 0x1000
    74d6:	add	fp, r0
    74d8:	adds	r1, #8
    74da:	add	r2, fp
    74dc:	ubfx	r2, r2, #0, #12
    74e0:	rsb	r9, r2, r1
    74e4:	mov	r1, r9
    74e6:	mov	r0, r6
    74e8:	str	r3, [sp, #4]
    74ea:	bl	786c <_sbrk_r>
    74ee:	adds	r3, r0, #1
    74f0:	ldr	r3, [sp, #4]
    74f2:	beq.w	7774 <_malloc_r+0x51c>
    74f6:	rsb	r2, fp, r0
    74fa:	add	r2, r9
    74fc:	orr.w	r2, r2, #1
    7500:	ldr	r1, [r3, #0]
    7502:	str.w	fp, [r7, #8]
    7506:	add	r1, r9
    7508:	cmp	r4, r7
    750a:	str.w	r2, [fp, #4]
    750e:	str	r1, [r3, #0]
    7510:	ldr.w	r9, [pc, #164]	; 75b8 <_malloc_r+0x360>
    7514:	beq.n	7544 <_malloc_r+0x2ec>
    7516:	cmp.w	r8, #15
    751a:	bls.w	7718 <_malloc_r+0x4c0>
    751e:	ldr	r2, [r4, #4]
    7520:	sub.w	r3, r8, #12
    7524:	bic.w	r3, r3, #7
    7528:	adds	r0, r4, r3
    752a:	and.w	r2, r2, #1
    752e:	mov.w	lr, #5
    7532:	orrs	r2, r3
    7534:	cmp	r3, #15
    7536:	str	r2, [r4, #4]
    7538:	str.w	lr, [r0, #4]
    753c:	str.w	lr, [r0, #8]
    7540:	bhi.w	777c <_malloc_r+0x524>
    7544:	ldr	r3, [pc, #116]	; (75bc <_malloc_r+0x364>)
    7546:	ldr	r4, [r7, #8]
    7548:	ldr	r2, [r3, #0]
    754a:	cmp	r1, r2
    754c:	it	hi
    754e:	strhi	r1, [r3, #0]
    7550:	ldr	r3, [pc, #108]	; (75c0 <_malloc_r+0x368>)
    7552:	ldr	r2, [r3, #0]
    7554:	cmp	r1, r2
    7556:	ldr	r2, [r4, #4]
    7558:	it	hi
    755a:	strhi	r1, [r3, #0]
    755c:	bic.w	r2, r2, #3
    7560:	cmp	r5, r2
    7562:	sub.w	r3, r2, r5
    7566:	bhi.n	756c <_malloc_r+0x314>
    7568:	cmp	r3, #15
    756a:	bgt.n	7576 <_malloc_r+0x31e>
    756c:	mov	r0, r6
    756e:	bl	7868 <__malloc_unlock>
    7572:	movs	r4, #0
    7574:	b.n	73e8 <_malloc_r+0x190>
    7576:	adds	r2, r4, r5
    7578:	orr.w	r3, r3, #1
    757c:	orr.w	r5, r5, #1
    7580:	str	r5, [r4, #4]
    7582:	mov	r0, r6
    7584:	str	r2, [r7, #8]
    7586:	str	r3, [r2, #4]
    7588:	bl	7868 <__malloc_unlock>
    758c:	adds	r4, #8
    758e:	mov	r0, r4
    7590:	add	sp, #12
    7592:	ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, sl, fp, pc}
    7596:	cmp	r3, #20
    7598:	bls.n	767e <_malloc_r+0x426>
    759a:	cmp	r3, #84	; 0x54
    759c:	bhi.w	76e8 <_malloc_r+0x490>
    75a0:	lsrs	r0, r5, #12
    75a2:	add.w	lr, r0, #111	; 0x6f
    75a6:	mov.w	r3, lr, lsl #1
    75aa:	adds	r0, #110	; 0x6e
    75ac:	b.n	729c <_malloc_r+0x44>
    75ae:	nop
    75b0:	.word	0x2000052c
    75b4:	.word	0x20000be4
    75b8:	.word	0x20000be8
    75bc:	.word	0x20000be0
    75c0:	.word	0x20000bdc
    75c4:	.word	0x20000938
    75c8:	lsrs	r2, r3, #9
    75ca:	cmp	r2, #4
    75cc:	bls.n	768c <_malloc_r+0x434>
    75ce:	cmp	r2, #20
    75d0:	bhi.w	773a <_malloc_r+0x4e2>
    75d4:	add.w	r1, r2, #92	; 0x5c
    75d8:	lsls	r1, r1, #1
    75da:	adds	r2, #91	; 0x5b
    75dc:	add.w	ip, r7, r1, lsl #2
    75e0:	ldr.w	r1, [r7, r1, lsl #2]
    75e4:	ldr.w	r8, [pc, #476]	; 77c4 <_malloc_r+0x56c>
    75e8:	sub.w	ip, ip, #8
    75ec:	cmp	ip, r1
    75ee:	beq.w	7702 <_malloc_r+0x4aa>
    75f2:	ldr	r2, [r1, #4]
    75f4:	bic.w	r2, r2, #3
    75f8:	cmp	r3, r2
    75fa:	bcs.n	7602 <_malloc_r+0x3aa>
    75fc:	ldr	r1, [r1, #8]
    75fe:	cmp	ip, r1
    7600:	bne.n	75f2 <_malloc_r+0x39a>
    7602:	ldr.w	ip, [r1, #12]
    7606:	ldr	r2, [r7, #4]
    7608:	str.w	ip, [r4, #12]
    760c:	str	r1, [r4, #8]
    760e:	str.w	r4, [ip, #8]
    7612:	str	r4, [r1, #12]
    7614:	b.n	7328 <_malloc_r+0xd0>
    7616:	adds	r3, r4, r5
    7618:	orr.w	r7, r2, #1
    761c:	orr.w	r5, r5, #1
    7620:	str	r5, [r4, #4]
    7622:	mov	r0, r6
    7624:	str	r3, [r1, #20]
    7626:	str	r3, [r1, #16]
    7628:	str.w	lr, [r3, #12]
    762c:	str.w	lr, [r3, #8]
    7630:	str	r7, [r3, #4]
    7632:	str	r2, [r3, r2]
    7634:	adds	r4, #8
    7636:	bl	7868 <__malloc_unlock>
    763a:	b.n	73e8 <_malloc_r+0x190>
    763c:	ldr	r2, [r1, #4]
    763e:	b.n	7328 <_malloc_r+0xd0>
    7640:	add.w	r8, r8, #1
    7644:	tst.w	r8, #3
    7648:	add.w	ip, ip, #8
    764c:	bne.w	734e <_malloc_r+0xf6>
    7650:	b.n	76b4 <_malloc_r+0x45c>
    7652:	ldr	r4, [r3, #12]
    7654:	cmp	r3, r4
    7656:	it	eq
    7658:	addeq	r0, #2
    765a:	beq.w	72c8 <_malloc_r+0x70>
    765e:	b.n	73c8 <_malloc_r+0x170>
    7660:	add	r3, r1
    7662:	mov	r4, r1
    7664:	ldr	r2, [r3, #4]
    7666:	ldr	r1, [r1, #12]
    7668:	ldr.w	r5, [r4, #8]!
    766c:	orr.w	r2, r2, #1
    7670:	str	r2, [r3, #4]
    7672:	mov	r0, r6
    7674:	str	r1, [r5, #12]
    7676:	str	r5, [r1, #8]
    7678:	bl	7868 <__malloc_unlock>
    767c:	b.n	73e8 <_malloc_r+0x190>
    767e:	add.w	lr, r3, #92	; 0x5c
    7682:	add.w	r0, r3, #91	; 0x5b
    7686:	mov.w	r3, lr, lsl #1
    768a:	b.n	729c <_malloc_r+0x44>
    768c:	lsrs	r2, r3, #6
    768e:	add.w	r1, r2, #57	; 0x39
    7692:	lsls	r1, r1, #1
    7694:	adds	r2, #56	; 0x38
    7696:	b.n	75dc <_malloc_r+0x384>
    7698:	cmp	r4, r7
    769a:	ldr	r3, [pc, #296]	; (77c4 <_malloc_r+0x56c>)
    769c:	beq.w	74a0 <_malloc_r+0x248>
    76a0:	ldr	r4, [r3, #8]
    76a2:	ldr	r2, [r4, #4]
    76a4:	bic.w	r2, r2, #3
    76a8:	b.n	7560 <_malloc_r+0x308>
    76aa:	ldr.w	r3, [r9], #-8
    76ae:	cmp	r9, r3
    76b0:	bne.w	77b8 <_malloc_r+0x560>
    76b4:	tst.w	r0, #3
    76b8:	add.w	r0, r0, #4294967295
    76bc:	bne.n	76aa <_malloc_r+0x452>
    76be:	ldr	r3, [r7, #4]
    76c0:	bic.w	r3, r3, r4
    76c4:	str	r3, [r7, #4]
    76c6:	lsls	r4, r4, #1
    76c8:	cmp	r4, r3
    76ca:	bhi.w	7448 <_malloc_r+0x1f0>
    76ce:	cmp	r4, #0
    76d0:	beq.w	7448 <_malloc_r+0x1f0>
    76d4:	tst	r4, r3
    76d6:	mov	r0, r8
    76d8:	bne.w	7346 <_malloc_r+0xee>
    76dc:	lsls	r4, r4, #1
    76de:	tst	r4, r3
    76e0:	add.w	r0, r0, #4
    76e4:	beq.n	76dc <_malloc_r+0x484>
    76e6:	b.n	7346 <_malloc_r+0xee>
    76e8:	cmp.w	r3, #340	; 0x154
    76ec:	bhi.n	7720 <_malloc_r+0x4c8>
    76ee:	lsrs	r0, r5, #15
    76f0:	add.w	lr, r0, #120	; 0x78
    76f4:	mov.w	r3, lr, lsl #1
    76f8:	adds	r0, #119	; 0x77
    76fa:	b.n	729c <_malloc_r+0x44>
    76fc:	mov.w	r1, #4096	; 0x1000
    7700:	b.n	74da <_malloc_r+0x282>
    7702:	movs	r1, #1
    7704:	ldr.w	r3, [r8, #4]
    7708:	asrs	r2, r2, #2
    770a:	lsl.w	r2, r1, r2
    770e:	orrs	r2, r3
    7710:	str.w	r2, [r8, #4]
    7714:	mov	r1, ip
    7716:	b.n	7608 <_malloc_r+0x3b0>
    7718:	movs	r3, #1
    771a:	str.w	r3, [fp, #4]
    771e:	b.n	756c <_malloc_r+0x314>
    7720:	movw	r2, #1364	; 0x554
    7724:	cmp	r3, r2
    7726:	bhi.n	776a <_malloc_r+0x512>
    7728:	lsrs	r0, r5, #18
    772a:	add.w	lr, r0, #125	; 0x7d
    772e:	mov.w	r3, lr, lsl #1
    7732:	adds	r0, #124	; 0x7c
    7734:	b.n	729c <_malloc_r+0x44>
    7736:	adds	r2, #16
    7738:	b.n	7484 <_malloc_r+0x22c>
    773a:	cmp	r2, #84	; 0x54
    773c:	bhi.n	778c <_malloc_r+0x534>
    773e:	lsrs	r2, r3, #12
    7740:	add.w	r1, r2, #111	; 0x6f
    7744:	lsls	r1, r1, #1
    7746:	adds	r2, #110	; 0x6e
    7748:	b.n	75dc <_malloc_r+0x384>
    774a:	ldr	r4, [r7, #8]
    774c:	ldr	r2, [r4, #4]
    774e:	bic.w	r2, r2, #3
    7752:	b.n	7560 <_malloc_r+0x308>
    7754:	ubfx	r0, sl, #0, #12
    7758:	cmp	r0, #0
    775a:	bne.w	74ae <_malloc_r+0x256>
    775e:	add	r2, r8
    7760:	ldr	r3, [r7, #8]
    7762:	orr.w	r2, r2, #1
    7766:	str	r2, [r3, #4]
    7768:	b.n	7544 <_malloc_r+0x2ec>
    776a:	movs	r3, #254	; 0xfe
    776c:	mov.w	lr, #127	; 0x7f
    7770:	movs	r0, #126	; 0x7e
    7772:	b.n	729c <_malloc_r+0x44>
    7774:	movs	r2, #1
    7776:	mov.w	r9, #0
    777a:	b.n	7500 <_malloc_r+0x2a8>
    777c:	add.w	r1, r4, #8
    7780:	mov	r0, r6
    7782:	bl	792c <_free_r>
    7786:	ldr.w	r1, [r9]
    778a:	b.n	7544 <_malloc_r+0x2ec>
    778c:	cmp.w	r2, #340	; 0x154
    7790:	bhi.n	779e <_malloc_r+0x546>
    7792:	lsrs	r2, r3, #15
    7794:	add.w	r1, r2, #120	; 0x78
    7798:	lsls	r1, r1, #1
    779a:	adds	r2, #119	; 0x77
    779c:	b.n	75dc <_malloc_r+0x384>
    779e:	movw	r1, #1364	; 0x554
    77a2:	cmp	r2, r1
    77a4:	bhi.n	77b2 <_malloc_r+0x55a>
    77a6:	lsrs	r2, r3, #18
    77a8:	add.w	r1, r2, #125	; 0x7d
    77ac:	lsls	r1, r1, #1
    77ae:	adds	r2, #124	; 0x7c
    77b0:	b.n	75dc <_malloc_r+0x384>
    77b2:	movs	r1, #254	; 0xfe
    77b4:	movs	r2, #126	; 0x7e
    77b6:	b.n	75dc <_malloc_r+0x384>
    77b8:	ldr	r3, [r7, #4]
    77ba:	b.n	76c6 <_malloc_r+0x46e>
    77bc:	lsrs	r0, r5, #3
    77be:	adds	r3, r0, #1
    77c0:	lsls	r3, r3, #1
    77c2:	b.n	73b6 <_malloc_r+0x15e>
    77c4:	.word	0x2000052c

000077c8 <memset>:
    77c8:	push	{r4, r5, r6}
    77ca:	lsls	r4, r0, #30
    77cc:	beq.n	785c <memset+0x94>
    77ce:	subs	r4, r2, #1
    77d0:	cmp	r2, #0
    77d2:	beq.n	7858 <memset+0x90>
    77d4:	uxtb	r5, r1
    77d6:	mov	r3, r0
    77d8:	b.n	77e0 <memset+0x18>
    77da:	subs	r2, r4, #1
    77dc:	cbz	r4, 7858 <memset+0x90>
    77de:	mov	r4, r2
    77e0:	strb.w	r5, [r3], #1
    77e4:	lsls	r2, r3, #30
    77e6:	bne.n	77da <memset+0x12>
    77e8:	cmp	r4, #3
    77ea:	bls.n	784a <memset+0x82>
    77ec:	uxtb	r5, r1
    77ee:	orr.w	r5, r5, r5, lsl #8
    77f2:	cmp	r4, #15
    77f4:	orr.w	r5, r5, r5, lsl #16
    77f8:	bls.n	782e <memset+0x66>
    77fa:	add.w	r2, r3, #16
    77fe:	mov	r6, r4
    7800:	subs	r6, #16
    7802:	cmp	r6, #15
    7804:	str.w	r5, [r2, #-16]
    7808:	str.w	r5, [r2, #-12]
    780c:	str.w	r5, [r2, #-8]
    7810:	str.w	r5, [r2, #-4]
    7814:	add.w	r2, r2, #16
    7818:	bhi.n	7800 <memset+0x38>
    781a:	sub.w	r2, r4, #16
    781e:	bic.w	r2, r2, #15
    7822:	and.w	r4, r4, #15
    7826:	adds	r2, #16
    7828:	cmp	r4, #3
    782a:	add	r3, r2
    782c:	bls.n	784a <memset+0x82>
    782e:	mov	r6, r3
    7830:	mov	r2, r4
    7832:	subs	r2, #4
    7834:	cmp	r2, #3
    7836:	str.w	r5, [r6], #4
    783a:	bhi.n	7832 <memset+0x6a>
    783c:	subs	r2, r4, #4
    783e:	bic.w	r2, r2, #3
    7842:	adds	r2, #4
    7844:	add	r3, r2
    7846:	and.w	r4, r4, #3
    784a:	cbz	r4, 7858 <memset+0x90>
    784c:	uxtb	r1, r1
    784e:	add	r4, r3
    7850:	strb.w	r1, [r3], #1
    7854:	cmp	r3, r4
    7856:	bne.n	7850 <memset+0x88>
    7858:	pop	{r4, r5, r6}
    785a:	bx	lr
    785c:	mov	r4, r2
    785e:	mov	r3, r0
    7860:	b.n	77e8 <memset+0x20>
    7862:	nop

00007864 <__malloc_lock>:
    7864:	bx	lr
    7866:	nop

00007868 <__malloc_unlock>:
    7868:	bx	lr
    786a:	nop

0000786c <_sbrk_r>:
    786c:	push	{r3, r4, r5, lr}
    786e:	ldr	r4, [pc, #28]	; (788c <_sbrk_r+0x20>)
    7870:	movs	r3, #0
    7872:	mov	r5, r0
    7874:	mov	r0, r1
    7876:	str	r3, [r4, #0]
    7878:	bl	6e4c <_sbrk>
    787c:	adds	r3, r0, #1
    787e:	beq.n	7882 <_sbrk_r+0x16>
    7880:	pop	{r3, r4, r5, pc}
    7882:	ldr	r3, [r4, #0]
    7884:	cmp	r3, #0
    7886:	beq.n	7880 <_sbrk_r+0x14>
    7888:	str	r3, [r5, #0]
    788a:	pop	{r3, r4, r5, pc}
    788c:	.word	0x200026c0

00007890 <_malloc_trim_r>:
    7890:	push	{r3, r4, r5, r6, r7, lr}
    7892:	ldr	r7, [pc, #140]	; (7920 <_malloc_trim_r+0x90>)
    7894:	mov	r4, r1
    7896:	mov	r6, r0
    7898:	bl	7864 <__malloc_lock>
    789c:	ldr	r3, [r7, #8]
    789e:	ldr	r5, [r3, #4]
    78a0:	bic.w	r5, r5, #3
    78a4:	subs	r1, r5, r4
    78a6:	addw	r1, r1, #4079	; 0xfef
    78aa:	bic.w	r1, r1, #4080	; 0xff0
    78ae:	bic.w	r1, r1, #15
    78b2:	sub.w	r4, r1, #4096	; 0x1000
    78b6:	cmp.w	r4, #4096	; 0x1000
    78ba:	blt.n	78cc <_malloc_trim_r+0x3c>
    78bc:	movs	r1, #0
    78be:	mov	r0, r6
    78c0:	bl	786c <_sbrk_r>
    78c4:	ldr	r3, [r7, #8]
    78c6:	add	r3, r5
    78c8:	cmp	r0, r3
    78ca:	beq.n	78d6 <_malloc_trim_r+0x46>
    78cc:	mov	r0, r6
    78ce:	bl	7868 <__malloc_unlock>
    78d2:	movs	r0, #0
    78d4:	pop	{r3, r4, r5, r6, r7, pc}
    78d6:	negs	r1, r4
    78d8:	mov	r0, r6
    78da:	bl	786c <_sbrk_r>
    78de:	adds	r0, #1
    78e0:	beq.n	78fe <_malloc_trim_r+0x6e>
    78e2:	ldr	r3, [pc, #64]	; (7924 <_malloc_trim_r+0x94>)
    78e4:	ldr	r2, [r7, #8]
    78e6:	ldr	r1, [r3, #0]
    78e8:	subs	r5, r5, r4
    78ea:	orr.w	r5, r5, #1
    78ee:	mov	r0, r6
    78f0:	subs	r1, r1, r4
    78f2:	str	r5, [r2, #4]
    78f4:	str	r1, [r3, #0]
    78f6:	bl	7868 <__malloc_unlock>
    78fa:	movs	r0, #1
    78fc:	pop	{r3, r4, r5, r6, r7, pc}
    78fe:	movs	r1, #0
    7900:	mov	r0, r6
    7902:	bl	786c <_sbrk_r>
    7906:	ldr	r2, [r7, #8]
    7908:	subs	r3, r0, r2
    790a:	cmp	r3, #15
    790c:	ble.n	78cc <_malloc_trim_r+0x3c>
    790e:	ldr	r4, [pc, #24]	; (7928 <_malloc_trim_r+0x98>)
    7910:	ldr	r1, [pc, #16]	; (7924 <_malloc_trim_r+0x94>)
    7912:	ldr	r4, [r4, #0]
    7914:	orr.w	r3, r3, #1
    7918:	subs	r0, r0, r4
    791a:	str	r3, [r2, #4]
    791c:	str	r0, [r1, #0]
    791e:	b.n	78cc <_malloc_trim_r+0x3c>
    7920:	.word	0x2000052c
    7924:	.word	0x20000be8
    7928:	.word	0x20000938

0000792c <_free_r>:
    792c:	cmp	r1, #0
    792e:	beq.n	79bc <_free_r+0x90>
    7930:	stmdb	sp!, {r4, r5, r6, r7, r8, lr}
    7934:	mov	r5, r1
    7936:	mov	r8, r0
    7938:	bl	7864 <__malloc_lock>
    793c:	ldr.w	r7, [r5, #-4]
    7940:	ldr	r1, [pc, #424]	; (7aec <_free_r+0x1c0>)
    7942:	bic.w	r3, r7, #1
    7946:	sub.w	r4, r5, #8
    794a:	adds	r2, r4, r3
    794c:	ldr	r6, [r1, #8]
    794e:	ldr	r0, [r2, #4]
    7950:	cmp	r2, r6
    7952:	bic.w	r0, r0, #3
    7956:	beq.n	7a1e <_free_r+0xf2>
    7958:	lsls	r6, r7, #31
    795a:	str	r0, [r2, #4]
    795c:	bmi.n	7976 <_free_r+0x4a>
    795e:	ldr.w	r7, [r5, #-8]
    7962:	subs	r4, r4, r7
    7964:	add.w	lr, r1, #8
    7968:	ldr	r5, [r4, #8]
    796a:	cmp	r5, lr
    796c:	add	r3, r7
    796e:	beq.n	7a50 <_free_r+0x124>
    7970:	ldr	r7, [r4, #12]
    7972:	str	r7, [r5, #12]
    7974:	str	r5, [r7, #8]
    7976:	adds	r5, r2, r0
    7978:	ldr	r5, [r5, #4]
    797a:	lsls	r5, r5, #31
    797c:	bpl.n	7a04 <_free_r+0xd8>
    797e:	orr.w	r2, r3, #1
    7982:	str	r2, [r4, #4]
    7984:	str	r3, [r4, r3]
    7986:	cmp.w	r3, #512	; 0x200
    798a:	bcs.n	79be <_free_r+0x92>
    798c:	lsrs	r3, r3, #3
    798e:	adds	r2, r3, #1
    7990:	ldr	r5, [r1, #4]
    7992:	ldr.w	r7, [r1, r2, lsl #3]
    7996:	str	r7, [r4, #8]
    7998:	movs	r0, #1
    799a:	asrs	r3, r3, #2
    799c:	lsl.w	r3, r0, r3
    79a0:	add.w	r0, r1, r2, lsl #3
    79a4:	orrs	r5, r3
    79a6:	subs	r0, #8
    79a8:	str	r0, [r4, #12]
    79aa:	str	r5, [r1, #4]
    79ac:	str.w	r4, [r1, r2, lsl #3]
    79b0:	str	r4, [r7, #12]
    79b2:	mov	r0, r8
    79b4:	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    79b8:	b.w	7868 <__malloc_unlock>
    79bc:	bx	lr
    79be:	lsrs	r2, r3, #9
    79c0:	cmp	r2, #4
    79c2:	bhi.n	7a6c <_free_r+0x140>
    79c4:	lsrs	r2, r3, #6
    79c6:	add.w	r7, r2, #57	; 0x39
    79ca:	lsls	r7, r7, #1
    79cc:	add.w	r5, r2, #56	; 0x38
    79d0:	add.w	r0, r1, r7, lsl #2
    79d4:	ldr.w	r2, [r1, r7, lsl #2]
    79d8:	ldr	r1, [pc, #272]	; (7aec <_free_r+0x1c0>)
    79da:	subs	r0, #8
    79dc:	cmp	r0, r2
    79de:	beq.n	7a7c <_free_r+0x150>
    79e0:	ldr	r1, [r2, #4]
    79e2:	bic.w	r1, r1, #3
    79e6:	cmp	r3, r1
    79e8:	bcs.n	79f0 <_free_r+0xc4>
    79ea:	ldr	r2, [r2, #8]
    79ec:	cmp	r0, r2
    79ee:	bne.n	79e0 <_free_r+0xb4>
    79f0:	ldr	r0, [r2, #12]
    79f2:	str	r0, [r4, #12]
    79f4:	str	r2, [r4, #8]
    79f6:	str	r4, [r0, #8]
    79f8:	str	r4, [r2, #12]
    79fa:	mov	r0, r8
    79fc:	ldmia.w	sp!, {r4, r5, r6, r7, r8, lr}
    7a00:	b.w	7868 <__malloc_unlock>
    7a04:	ldr	r5, [r2, #8]
    7a06:	ldr	r7, [pc, #232]	; (7af0 <_free_r+0x1c4>)
    7a08:	cmp	r5, r7
    7a0a:	add	r3, r0
    7a0c:	beq.n	7a8e <_free_r+0x162>
    7a0e:	ldr	r0, [r2, #12]
    7a10:	str	r0, [r5, #12]
    7a12:	orr.w	r2, r3, #1
    7a16:	str	r5, [r0, #8]
    7a18:	str	r2, [r4, #4]
    7a1a:	str	r3, [r4, r3]
    7a1c:	b.n	7986 <_free_r+0x5a>
    7a1e:	lsls	r7, r7, #31
    7a20:	add	r3, r0
    7a22:	bmi.n	7a34 <_free_r+0x108>
    7a24:	ldr.w	r2, [r5, #-8]
    7a28:	subs	r4, r4, r2
    7a2a:	add	r3, r2
    7a2c:	ldr	r0, [r4, #8]
    7a2e:	ldr	r2, [r4, #12]
    7a30:	str	r2, [r0, #12]
    7a32:	str	r0, [r2, #8]
    7a34:	ldr	r2, [pc, #188]	; (7af4 <_free_r+0x1c8>)
    7a36:	ldr	r2, [r2, #0]
    7a38:	orr.w	r0, r3, #1
    7a3c:	cmp	r3, r2
    7a3e:	str	r0, [r4, #4]
    7a40:	str	r4, [r1, #8]
    7a42:	bcc.n	79b2 <_free_r+0x86>
    7a44:	ldr	r3, [pc, #176]	; (7af8 <_free_r+0x1cc>)
    7a46:	mov	r0, r8
    7a48:	ldr	r1, [r3, #0]
    7a4a:	bl	7890 <_malloc_trim_r>
    7a4e:	b.n	79b2 <_free_r+0x86>
    7a50:	adds	r1, r2, r0
    7a52:	ldr	r1, [r1, #4]
    7a54:	lsls	r1, r1, #31
    7a56:	bmi.n	7ae2 <_free_r+0x1b6>
    7a58:	ldr	r1, [r2, #8]
    7a5a:	ldr	r2, [r2, #12]
    7a5c:	str	r2, [r1, #12]
    7a5e:	add	r3, r0
    7a60:	orr.w	r0, r3, #1
    7a64:	str	r1, [r2, #8]
    7a66:	str	r0, [r4, #4]
    7a68:	str	r3, [r4, r3]
    7a6a:	b.n	79b2 <_free_r+0x86>
    7a6c:	cmp	r2, #20
    7a6e:	bhi.n	7aa0 <_free_r+0x174>
    7a70:	add.w	r7, r2, #92	; 0x5c
    7a74:	lsls	r7, r7, #1
    7a76:	add.w	r5, r2, #91	; 0x5b
    7a7a:	b.n	79d0 <_free_r+0xa4>
    7a7c:	asrs	r2, r5, #2
    7a7e:	ldr	r3, [r1, #4]
    7a80:	movs	r5, #1
    7a82:	lsl.w	r2, r5, r2
    7a86:	orrs	r3, r2
    7a88:	str	r3, [r1, #4]
    7a8a:	mov	r2, r0
    7a8c:	b.n	79f2 <_free_r+0xc6>
    7a8e:	orr.w	r2, r3, #1
    7a92:	str	r4, [r1, #20]
    7a94:	str	r4, [r1, #16]
    7a96:	str	r5, [r4, #12]
    7a98:	str	r5, [r4, #8]
    7a9a:	str	r2, [r4, #4]
    7a9c:	str	r3, [r4, r3]
    7a9e:	b.n	79b2 <_free_r+0x86>
    7aa0:	cmp	r2, #84	; 0x54
    7aa2:	bhi.n	7ab2 <_free_r+0x186>
    7aa4:	lsrs	r2, r3, #12
    7aa6:	add.w	r7, r2, #111	; 0x6f
    7aaa:	lsls	r7, r7, #1
    7aac:	add.w	r5, r2, #110	; 0x6e
    7ab0:	b.n	79d0 <_free_r+0xa4>
    7ab2:	cmp.w	r2, #340	; 0x154
    7ab6:	bhi.n	7ac6 <_free_r+0x19a>
    7ab8:	lsrs	r2, r3, #15
    7aba:	add.w	r7, r2, #120	; 0x78
    7abe:	lsls	r7, r7, #1
    7ac0:	add.w	r5, r2, #119	; 0x77
    7ac4:	b.n	79d0 <_free_r+0xa4>
    7ac6:	movw	r0, #1364	; 0x554
    7aca:	cmp	r2, r0
    7acc:	bhi.n	7adc <_free_r+0x1b0>
    7ace:	lsrs	r2, r3, #18
    7ad0:	add.w	r7, r2, #125	; 0x7d
    7ad4:	lsls	r7, r7, #1
    7ad6:	add.w	r5, r2, #124	; 0x7c
    7ada:	b.n	79d0 <_free_r+0xa4>
    7adc:	movs	r7, #254	; 0xfe
    7ade:	movs	r5, #126	; 0x7e
    7ae0:	b.n	79d0 <_free_r+0xa4>
    7ae2:	orr.w	r2, r3, #1
    7ae6:	str	r2, [r4, #4]
    7ae8:	str	r3, [r4, r3]
    7aea:	b.n	79b2 <_free_r+0x86>
    7aec:	.word	0x2000052c
    7af0:	.word	0x20000534
    7af4:	.word	0x20000934
    7af8:	.word	0x20000be4
    7afc:	.word	0x00000000

00007b00 <___init_veneer>:
    7b00:	ldr.w	pc, [pc]	; 7b04 <___init_veneer+0x4>
    7b04:	.word	0x600016e9
	...

Disassembly of section .fini:

00007b10 <_fini>:
    7b10:	push	{r3, r4, r5, r6, r7, lr}
    7b12:	nop
